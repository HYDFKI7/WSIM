{fenge}
84929761003	Sensitivity analysis of non-linear performance with probability distortion	Human preference over random outcomes may not be as rational as shown in the expected utility theory. Such an "irrational" (as a matter of fact, closer to reality) behavior can be modeled by distorting the probability of the outcomes. Stochastic control of such a distorted performance is difficult because dynamic programming fails to work due to the time inconsistency. In this paper, we formulate the stochastic control problem with the distorted performance and show that the mono-linearity of the distorted performance, which claims that the derivative of the distorted performance equals the expected value of the sample derivative under a changed probability measure, makes the gradient-based sensitivity analysis suitable for optimization of the distorted performance. We derive the first order optimality conditions (or the differential counterpart of the HJK equation) for the optimal solution. We use the portfolio allocation problem in finance as an example of application.
{fenge}
84945547755	Semi-Markov decision problems and performance sensitivity analysis	We extend the results about performance potentials, perturbation realization matrices, policy iteration of Markov decision processes, etc., to semi-Markov processes (SMPs). Starting with the concept of perturbation realization, we define a realization matrix and prove that it satisfies the Lyapunov equation. From the realization matrix we define a performance potential and prove that it satisfies the Poisson equation. Sensitivity formulas and policy iteration algorithms of Semi-Markov decision process (SMDPs) can be derived. The performance sensitivities can be obtained and policy iteration of SMDPs can be implemeted on a single sample path of the SMPs.
{fenge}
84945973943	How does perturbation analysis work in finance and economics?	In this paper, we summarize and report the results that demonstrate how the perturbation analysis (PA), which was originally developed for discrete event dynamic systems, can be applied to obtain interesting results in financial engineering and economic problems where both time and states are continuous and dynamic programming fails. We study the "irrational" behavior of human preference over random outcomes, modeled by distorting the probability of the events. Efficient PA based algorithms can be developed for the optimization of potforlio with distorted performance, and analytical solution can be obtained for complete markets. In addition, the property obtained can be used to replace the independence axiom in the non-linear expected utility theory to characterize the representations.
{fenge}
14244262208	Partially observable Markov decision processes with reward information	In a partially observable Markov decision process (POMDP), if the reward can be observed at each step, then the observed reward history contains information for the unknown state. This information, in addition to the information contained in the observation history, can be used to update the state probability distribution. The policy thus obtained is called a reward-information policy (RI-policy); an optimal RI policy performs no worse than any normal optimal policy depending only on the observation history. The above observation leads to four different problem-formulations for partially observable Markov decision processes (POMDPs) depending on whether the reward function is known and whether the reward at each step is observable.
{fenge}
1542320155	A System Theoretic Perspective of Learning and Optimization	Learning and optimization of stochastic systems is a multi-disciplinary area that attracts wide attentions from researchers in control systems, operations research and computer science. Areas such as perturbation analysis (PA), Markov decision process (MDP), and reinforcement learning (RL) share the common goal. In this paper, we offer an overview of the area of learning and optimization from a system theoretic perspective. We show how these seemly different disciplines are closely related, how one topic leads to the others, and how this perspective may lead to new research topics and new results, and how the performance sensitivity formulas can serve as the basis for learning and optimization.
{fenge}
1542350287	Constructing Performance Sensitivities of Markov Systems with Potentials as Building Blocks	We study the structure of sample paths of Markov systems by using performance potentials as the fundamental units. With a sample path-based approach, we show that performance sensitivities of Markov systems can be constructed by using performance potentials (or equivalently, perturbation realization factors) as building blocks. We propose an intuitive approach to derive, by first principles, formulas for performance derivatives and performance differences for two Markov chains. These formulas are the basis for performance optimization of discrete event dynamic systems, including perturbation analysis, Markov decision processes, and reinforcement learning.
{fenge}
14644388113	Basic ideas for event-based optimization of markov systems	The goal of this paper is two-fold: First, we present a sensitivity point of view on the optimization of Markov systems. We show that Markov decision processes (MDPs) and the policy-gradient approach, or perturbation analysis (PA), can be derived easily from two fundamental sensitivity formulas, and such formulas can be flexibly constructed, by first principles, with performance potentials as building blocks. Second, with this sensitivity view we propose an event-based optimization approach, including the event-based sensitivity analysis and event-based policy iteration. This approach utilizes the special feature of a system characterized by events and illustrates how the potentials can be aggregated using the special feature and how the aggregated potential can be used in policy iteration. Compared with the traditional MDP approach, the event-based approach has its advantages: the number of aggregated potentials may scale to the system size despite that the number of states grows exponentially in the system size, this reduces the policy space and saves computation; the approach does not require actions at different states to be independent; and it utilizes the special feature of a system and does not need to know the exact transition probability matrix. The main ideas of the approach are illustrated by an admission control problem. Â© 2005 Springer Science + Business Media, Inc.
{fenge}
18744371849	Resource management with service guarantee and differentiation in broadband multimedia-enabled wireless networks	We have recently witnessed a phenomenal growth in the development and deployment of wireless services, evident from the proliferation of the cellular data services and the emerging wireless multimedia applications. This opens up a new avenue for research, and calls for the re-examination of some of the fundamental issues in wireless cellular networks. With the cell size being systematically reduced into micro-cell and pico-cell systems, in order to increase the overall network capacity, one of the key challenges is the design of effective call admission control (CAC) policies, which have to guarantee potentially different quality of service (QoS) requirements from diverse traffic types while at the same time maintaining high utilization of the scarce wireless bandwidth. The objectives of this article are to review the key issues involved in the design of call admission control policies based on some of the recent proposals, and to discuss the challenges associated to offer effective support for multi-services.
{fenge}
0009843739	The Maclaurin series for performance functions of Markov chains	We derive formulas for the first- and higher-order derivatives of the steady state performance measures for changes in transition matrices of irreducible and aperiodic Markov chains. Using these formulas, we obtain a Maclaurin series for the performance measures of such Markov chains. The convergence range of the Maclaurin series can be determined. We show that the derivatives and the coefficients of the Maclaurin series can be easily estimated by analysing a single sample path of the Markov chain. Algorithms for estimating these quantities are provided. Markov chains consisting of transient states and multiple chains are also studied. The results can be easily extended to Markov processes. The derivation of the results is closely related to some fundamental concepts, such as group inverse, potentials, and realization factors in perturbation analysis. Simulation results are provided to illustrate the accuracy of the single sample path based estimation. Possible applications to engineering problems are discussed.
{fenge}
0012200466	Forecasting power market clearing price and quantity using a neural network method	Deregulation of the electric power industry worldwide raises many challenging issues. Forecasting the hourly market clearing prices and quantities in daily power markets is the most essential task and basis for any decision making. One approach to predict the market behaviors is to use the historical prices, quantities and other information to forecast the future prices and quantities. The basic idea is to use history and other estimated factors in the future to "fit" and "extrapolate" the prices and quantities. Aiming at this challenging task, we developed a neural network method to forecast the MCPs and MCQs for the California day-ahead energy markets. The structure of the neural network is a three-layer back propagation (BP) network. The historical MCPs and MCQs of California day-ahead energy market, the ISO load forecasts and other public information that may influence the markets are used for training, validating and forecasting test. Preliminary results show that our method is promising.
{fenge}
0030107018	General approach to blind source separation	This paper identifies and studies two major issues in the blind source separation problem: separability and separation principles. We show that separability is an intrinsic property of the measured signals and can be described by the concept of m-row decomposability introduced in this paper; we also show that separation principles can be developed by using the structure characterization theory of random variables. In particular, we show that these principles can be derived concisely and intuitively by applying the Darmois-Skitovich theorem, which is well known in statistical inference theory and psychology. Some new insights are gained for designing blind source separation filters. Â© 1996 IEEE.
{fenge}
0029697474	Unified algorithm for blind separation of independent sources	This paper presents a unified algorithm of blind source separation based on the 'Independent Component Analysis' (ICA) principle. The algorithm can separate all sources provided there is at most one Gaussian distributed source. The key point is to find a matrix by which the estimates of the original signals are pairwise independent in the absence of noises. If the observed signals are corrupted by noises, minimum-variance unbiased estimates are obtained. In comparison with the algorithm proposed in [5], this algorithm has a parallel-pipeline structure, and will not need a preset threshold if both of the 3rd- and 4th-order cumulants of any non-Gaussian distributed source are not zero. This algorithm has several advantages over existing algorithms.
{fenge}
0030242526	Performance sensitivity formulae, algorithms and estimates for closed queueing networks with exponential servers	We study the sensitivities of the performance measures in a closed queueing network with exponential service requirements and load-dependent service rates. The performance measures have two general forms: customer average and time average. We derive formulae for the elasticities of the performance measures for both averages with respect to system parameters and develop efficient algorithms for the calculation of them. The obtained formulae lead naturally to new on-line consistent estimation schemes for the elasticities; these schemes are based purely on the sample average performances, thus recursive and requiring no knowledge of the system parameters.
{fenge}
0030638095	Efficient scheduling algorithm for input-queuing ATM switches	In this paper, we propose and evaluate a three-phase scheduling algorithm for input-queuing ATM switches, and we term it WRRLA algorithm. The WRRLA algorithm is an improvement over the conventional Weighted Round Robin (WRR) algorithm by simply combining it together with the Look Ahead (LA) technique. In a WRRLA scheduling operation, the WRR algorithm is first applied to schedule the time-sensitive traffics in order to guarantee their quality of service, and then the LA technique is applied to schedule the data traffics in order to increase the throughput of the ATM switches. Simulation results show that the WRRLA algorithm achieves good performances in simple architecture, less scheduling computation, higher efficiency (throughput) and lower delay bounds. Moreover, WRRLA compares favorably with other famous scheduling algorithms, such as PIM and WRR.
{fenge}
0030377995	Potential based sensitivity analysis of Markov chains	We propose a new approach to the single-sample-path-based sensitivity analysis of Markov chains. The approach is based on a fundamental concept: performance potentials. Like the potential energy in physics, only the differences between potentials are important. We show that the differences of potentials can be determined by using the group inverse of I - P, where I is the identity matrix and P the transition matrix of the Markov chain. Potentials reflect the system performance in transient periods and can be used to determine the performance sensitivity with respect to a change of the transition matrix. The results provide a general and efficient approach to the single-sample-path-based sensitivity analysis for many engineering systems, for which the standard perturbation analysis does not work well.
{fenge}
0030383366	Conditions on source signals for blind separation	In blind source separation problem it is usually assumed that the source signals are mutually independent. It has been realized that this assumption is not necessary. In this paper, we provide some general conditions under which the source signals can be recovered from their linear mixtures. We first define two concepts, the mutually M-th order independence and the pairwise M-th order independence, on a set of random variables. Then we prove that if the source signals are mutually M-th order independent, then those source signals, each of which has at least one nonzero m-th order cumulant for 3 â¤ m â¤ M, can be separated. This conclusion is in spirit similar to but more general than that proposed by Tong et al[10]. The constructive proof suggests an algorithm for the blind separation of sources which are mutually M-th order independent. Simulation examples are presented to illustrate the results.
{fenge}
0030417401	Controllability is not necessary for adaptive pole placement control	The key issue for adaptive pole placement control of linear time-invariant systems is the possible singularity of the Sylvester Matrix corresponding to the coefficient estimate. The methods developed for modifying the estimates are either nonrecursive and with a high computation load or recursive but with random search involved. All the previous works are done under the assumption that the system is controllable. This paper gives necessary and sufficient condition, which is weaker than controllability, for the system to be adaptively stabilizable. While proving the sufficient part, a nonrecursive algorithm is proposed to modify the estimates. It is proved that the algorithm terminates in a finite many steps. Further, under the same condition with the help of stochastic approximation a recursive algorithm is proposed for obtaining the modification parameters; it is proved that these modification parameters are convergent, and this leads to the convergence of the modified coefficient estimates. For both algorithms the Sylvester matrices corresponding to the modified coefficient estimates are asymptotically uniformly nonsingular; thus with these Sylvester matrices, the adaptive pole placement control problem can be solved, i.e., the system can be adaptively stabilized.
{fenge}
0031680873	Blind intersymbol interference cancellation method for multi-user systems with channel diversity	We propose a direct blind zeroforcing approach to cancel inter-symbol interference (ISI) in multiple user FIR channels. By selectively anchoring columns of the channel convolution matrix, we present two column-anchoring zeroforcing equalizers (CAZE). Unlike many known blind identification algorithms, these equalizers do not need an accurate estimate of the channel orders. Exploiting second order statistics of the received signals, they can retain a pre-selected block column in the channel convolution matrix (the number of columns in a block column equals that of users) and force the remaining columns to zero. Simulation results show that the CAZE is effective for blind equalization of linear QAM wireless communication systems.
{fenge}
0031334299	Fast cell loss rate estimation of ATM switches using importance sampling	The performance evaluation of ATM switches is of paramount importance in designing an ATM network. In this paper, we focus on the evaluation of the cell loss rate (CLR) in nonblocking ATM switches using computer simulations. In particular, we investigate the potential of using importance sampling techniques as an 'superfast' alternative to conventional Monte Carlo simulation in finding the CLR in nonblocking ATM switches. We propose a 'split switch' method to decouple the input and output queue behaviors, along with the notion of regenerative cycles to achieve fast and accurate results. Numerical results will demonstrate that considerable computation cost can be saves using these proposed importance sampling techniques while maintaining a high degree of accuracy.
{fenge}
0031356460	Efficient estimation of cell loss and cell delay of nonblocking ATM switches	The performance evaluation of ATM switches is of paramount importance in the design and analysis of ATM networks. In this paper, we focus on the evaluation of the cell loss rate (CLR) and cell delay probability (CDP) in nonblocking ATM switches using computer simulations. In particular, we investigate the potential of using importance sampling techniques as an `superfast' alternative to conventional Monte Carlo simulation in finding the CLR and CDP in nonblocking ATM switches. We propose a `split switch' method to decouple the input and output queue behaviors, along with the notion of regenerative cycles. Numerical results' will demonstrate that considerable computation cost can be saved using the proposed importance sampling techniques while maintaining a high degree of accuracy.
{fenge}
0031385547	Single sample path based optimization of Markov systems: Examples and algorithms	Motivated by the needs of on-line optimization of real world engineering systems, we study the single sample path based algorithms for Markov decision problems (MDP). We give a simple example to explain the advantages of the sample path based approach over the traditional computation based approach: matrix inversion is not required; some transition probabilities do not have to be known; it may save storage space; and it gives the flexibility of iterating the actions for a subset of the state space in each iteration. The effect of the estimation errors and the convergence property of the sample path based approach are studied. Finally, we propose a `fast' algorithm which updates the policy whenever the system reaches a particular set of states; the algorithm converges to the true optimal policy with probability one under some conditions.
{fenge}
0031234950	Controllability is not necessary for adaptive pole placement control	The key issue for adaptive pole-placement control of linear time-invariant systems is the possible singularity of the Sylvester matrix corresponding to the coefficient estimate. However, to over come the difficulty, the estimate is modified by several methods which are either nonrecursive and with high computational load or recursive but with random search involved. All of the previous works are done under the assumption that the system is controllable. This paper gives the necessary and sufficient condition, which is weaker than controllability, for the system to be adaptively stabilizable. First, a nonrecursive algorithm is proposed to modify the estimates, and the algorithm is proved to terminate in finitely many steps. Then, with the help of stochastic approximation, a recursive algorithm is proposed for obtaining the modification parameters; it is proved that these modification parameters turn out to be a constant vector in a finite number of steps. This leads to the convergence of the modified coefficient estimates. For both algorithms the Sylvester matrices corresponding to the modified coefficient estimates are asymptotically uniformly nonsingular; thus, the adaptive pole-placement control problem can be solved, i.e., the system can be adaptively stabilized.
{fenge}
0031645007	Experimental results on the impact of cell delay variation on speech quality in ATM networks	I Recently, the concept of Voice and Telephony Over ATM (VTOA) has been widely studied. Although ATM benefits voice communications in many aspects, its packet-switched nature impairs the speech quality. In this paper, we evaluate the speech quality with a focus on the impact of Cell Delay Variation (CDV). We build an experimental system to do the evaluations. We also define a new parameter, named Cell Delay Variation Accumulation Length (CDVAL), to measure the impact of CDV on speech quality. We observe that the speech quality mainly depends on the value of CDVAL, but does not strongly depend on the other items, including the distribution of cell end-to-end delay, the position and even the number of the intermittence caused by CDV. We find that there exists an acceptable threshold of CDVAL. According to our experiments, to keep the speech in `good' quality (MOSâ3.5), the CDVAL value must be less than 3 ms without any speech cell loss; such a threshold drops to 2 ms if 5% speech cells are lost. The results indicate that buffer is necessary for doing CDV compensation at the far end devices in VTOA. The results are also very helpful for the proper design of the network architecture and control algorithms, especially be important for the designing of the CDV compensation schemes, when ATM networks are used to provide voice and telephony services.
{fenge}
0031258478	Perturbation realization, potentials, and sensitivity analysis of markov processes	Two fundamental concepts and quantities, realization factors and performance potentials, are introduced for Markov processes. The relations among these two quantities and the group inverse of the infinitesimal generator are studied. It is shown that the sensitivity of the steady-state performance with respect to the change of the infinitesimal generator can be easily calculated by using ether of these three quantities and that these quantities can be estimated by analyzing a single sample path of a Markov process. Based on these results, algorithms for estimating performance sensitivities on a single sample path of a Markov process can be proposed. The potentials in this paper are defined through realization factors and are shown to be the same as those defined by Poisson equations. The results provide a uniform framework of perturbation realization for infinitesimal perturbation analysis (IPA) and non-IPA approaches to the sensitivity analysis of steady-state performance; they also provide a theoretical background for the PA algorithms developed in recent years.
{fenge}
0032291257	Performance analysis of a nonblocking ATM switch with a bufferless internal speedup fabric	In this paper, we study a non-blocking ATM switch with internal speedup. Modifying the model developed in [X.R. Cao, The maximum throughput of a nonblocking space-division packet switch with correlated destinations. IEEE Transactions on Communications, 43 (5) (1995) 1898-1901], we can obtain the maximum throughput of such a switch; approximating the output process by a discrete-time Markov modulated arrival, we can calculate the cell loss probability at the output buffers. Our approach can be applied to switches with arrival traffic having correlated destinations and asymmetric routing probabilities. Simulation results illustrate that the approach is very accurate under various traffic conditions. Â© 1998 Elsevier Science B.V. All rights reserved.
{fenge}
0032122986	Algorithms for sensitivity analysis of Markov systems through potentials and perturbation realization	We provide algorithms to compute the performance derivatives of Markov chains with respect to changes in their transition matrices and of Markov processes with respect to changes in their infinitesimal generators. Our algorithms are readily applicable to the control and optimization of these Markov systems, since they are based on analyzing a single sample path and do not need explicit specification of transition matrices, nor infinitesimal generators. Compared to infinitesimal perturbation analysis (IPA), the algorithms have a wider scope of application and require nearly the same computational effort. Numerical examples are provided to illustrate the applications of the algorithms. In particular, we apply one of our algorithms to a closed queueing network and the results are promising. Â© 1998 IEEE.
{fenge}
0032310480	Optimization in distributed controlled Markov chains	The performance potential theory has proved to be a promising tool in optimizing the infinite-horizon Markov decision problem (MDP). So far, the research in this area is implicitly focused on a simple system with a single controller. In this paper, we consider the distributed controlled Markov chain, where the system consists of several individual control units and it evolves under the combined control of these nodes. Motivated by practical background, we investigate a structure of MDP with event-dependent decisions. We explore a notion of expanded Markov chain to map this problem to a traditional MDP model. In particular, we address ourselves to the complexity-reduction techniques to deal with the enlarge state space. For the distributed system where a particular node can only access partial system information, we develop some algorithms for decentralized potential estimation and policy iteration.
{fenge}
0032285294	Event-dependent and distributed Markov decision processes in communications	Many communication systems are distributed in nature where each geographically separated node has to make its own decisions. In addition, the actions in such systems depend on events, such as packet arrivals. In this paper, we study the optimization problem for such systems. Our method is based on the notion of potential. We show that by including the events into the states, the event-dependent systems can be modeled by the standard Markov decision process, and by introducing `aggregated potentials' the dimension of the problem can be reduced. We also propose a distributed approach to the problem, in which each node can estimate the `local potential', and it only requires to transfer the estimated values of these local potentials among nodes, no state information has to be transferred.
{fenge}
2442614974	Potential-based online policy iteration algorithms for Markov decision processes	Performance potentials play a crucial role in performance sensitivity analysis and policy iteration of Markov decision processes. The potentials can be estimated on a single sample path of a Markov process. In this paper, we propose two potential-based online policy iteration algorithms for performance optimization of Markov systems. The algorithms are based on online estimation of potentials and stochastic approximation. We prove that with these two algorithms the optimal policy can be attained after a finite number of iterations. A simulation example is given to illustrate the main ideas and the convergence rates of the algorithms.
{fenge}
2442665677	Statistical bounds on the drop probability of assured forwarding services in DiffServ interior nodes under the processor sharing scheduling discipline	This paper addresses the problem of modelling and analysing an interior node in IETF's DiffServ services model. Specifically it is concerned with the performance of the DiffServ assured forwarding service category in presence of a premium service class. In this model, the network node shares its outgoing link capacity between a Premium service representing the Expedited Forwarding (EF) per-hop behavior, and two classes of Assured service, that represent two classes of the Assured forwarding (AF) per-hop behavior. It this paper, the traffic is modelled as Markov modulated fluid sources, and we focus on a system where out of profile traffic is dropped at the edge of the network thus both AF queues support only one drop precedence. Using a decomposition approach, approximations, and spectral analysis, we are able to derive upper and lower bounds on the tail of the distribution of the buffer content for both AF classes given a generalized processor sharing scheduling is used to differentiate the two classes. Such approximate analysis of the interaction between traffic classes can help to achieve a better understanding of this type of networks; enables the provision of throughput differentiation as defined by the AF PHB through the GPS scheduler while quantifying delay; and finally helps simplify greatly the design of bandwidth brokers that do not rely on long term bandwidth (over) provisioning.
{fenge}
2542503493	Call admission control for voice/data integrated cellular networks: Performance analysis and comparative study	In this paper, we propose a new call admission control scheme called dual threshold bandwidth reservation, or DTBR scheme. The main novelty is that it builds upon a complete sharing approach, in which the channels in each cell are shared among the different traffic types and multiple thresholds are used to meet the specific quality-of-service (QoS) requirements. We present a detailed comparative study based on mathematical and simulation models, and quantitatively demonstrate that the DTBR is capable of providing the QoS guarantee for each type of traffic, while at the same time leading to much better channel efficiency. We further show that the DTBR scheme with elastic data service can offer both service guarantee and service differentiation for voice and data services, and enhance the bandwidth utilization.
{fenge}
31144441396	The control of a two-level Markov decision process by time aggregation	The solution of Markov Decision Processes (MDPs) often relies on special properties of the processes. For two-level MDPs, the difference in the rates of state changes of the upper and lower levels has led to limiting or approximate solutions of such problems. In this paper, we solve a two-level MDP without making any assumption on the rates of state changes of the two levels. We first show that such a two-level MDP is a non-standard one where the optimal actions of different states can be related to each other. Then we give assumptions (conditions) under which such a specially constrained MDP can be solved by policy iteration. We further show that the computational effort can be reduced by decomposing the MDP. A two-level MDP with M upper-level states can be decomposed into one MDP for the upper level and M to M(M-1) MDPs for the lower level, depending on the structure of the two-level MDP. The upper-level MDP is solved by time aggregation, a technique introduced in a recent paper [Cao, X.-R., Ren, Z. Y., Bhatnagar, S., Fu, M., & Marcus, S. (2002). A time aggregation approach to Markov decision processes. Automatica, 38(6), 929-943.], and the lower-level MDPs are solved by embedded Markov chains. Â© 2005 Elsevier Ltd. All rights reserved.
{fenge}
33645818765	Generalized LQR control and Kalman filtering with relations to computations of inner-outer and spectral factorizations	We investigate the generalized linear quadratic regulator (LQR) control where the dimension of the control input is strictly greater than the dimension of the controlled output, and the weighting matrix on the control signal is singular. The dual problem is the generalized Kalman filtering where the dimension of the input noise process is strictly smaller than the dimension of the output measurement, and the covariance of the observation noise is singular. These two problems are intimately related to inner-outer factorizations for nonsquare stable transfer matrices with square inners of the smaller size. Such inner-outer factorizations are in turn related to spectral factorizations for power spectral density (PSD) matrices whose normal ranks are not full. We propose iterative algorithms and establish their convergence for inner-outer and spectral factorizations, which in turn solve the generalized LQR control and Kalman filtering. Â© 2006 IEEE.
{fenge}
33745090293	A matrix-analytic solution for the DBMAP/PH/1 priority queue	Priority queueing models have been commonly used in telecommunication systems. The development of analytically tractable models to determine their performance is vitally important. The discrete time batch Markovian arrival process (DBMAP) has been widely used to model the source behavior of data traffic, while phase-type (PH) distribution has been extensively applied to model the service time. This paper focuses on the computation of the DBMAP/PH/1 queueing system with priorities, in which the arrival process is considered to be a DBMAP with two priority levels and the service time obeys a discrete PH distribution. Such a queueing model has potential in performance evaluation of computer networks such as video transmission over wireless networks and priority scheduling in ATM or TDMA networks. Based on matrix-analytic methods, we develop computation algorithms for obtaining the stationary distribution of the system numbers and further deriving the key performance indices of the DBMAP/PH/1 priority queue. Â© Springer Science + Business Media, LLC 2006.
{fenge}
33750102921	Relationship between perturbation realization factors with queueing models and Markov models	Perturbation realization factor is an important concept in perturbation analysis of both queueing systems and Markov systems. A perturbation realization factor measures the effect of a perturbation on the system performance. This concept is important for the performance sensitivity and performance optimization of these systems. Since the perturbations in queueing systems are continuous in nature and those in Markov systems are discrete, it is not straightforward to establish the relationship between these two types of fundamental concepts. This note solves this long-standing problem. We find a formula that links these two types of perturbation realization factors in Gordon-Newell and open Jackson networks together. The results enhance our understanding of perturbation analysis and lead to new research directions. Â© 2006 IEEE.
{fenge}
34247229563	Partially observable markov decision processes with reward information: Basic ideas and models	In a partially observable Markov decision process (POMDP), if the reward can be observed at each step, then the observed reward history contains information on the unknown state. This information, in addition to the information contained in the observation history, can be used to update the state probability distribution. The policy thus obtained is called a reward-information policy (RI-policy); an optimal RI-policy performs no worse than any normal optimal policy depending only on the observation history. The above observation leads to four different problem-formulations for POMDPs depending on whether the reward function is known and whether the reward at each step is observable. This exploratory work may attract attention to these interesting problems. Â© 2007 IEEE.
{fenge}
0032685806	Algebraic principle for blind separation of white non-Gaussian sources	An algebraic principle for blind source separation is presented in this paper. This separation principle identifies a (smaller) set of equations whose solutions can blindly extract non-Gaussian signals. The concept of `Mth-order uncorrelatedness' is introduced and it is proven that for Mth-order uncorrelated source signals, signals with nonzero kth-order cumulant (2<kâ¤M) can always be extracted by setting a small set of kth-order cross-cumulants of output signals to zero. The set of kth-order cross-cumulants specified here is a sub-set of those used by other existing methods. The relationship between the algebraic principle and several existing algorithms is presented. The contributions of this principle are the reduction of the number of cross-cumulants used and the flexibility it affords in designing algorithms for blind source separation.
{fenge}
0033098488	Column-anchored zeroforcing blind equalization for multiuser wireless FIR channels	We propose a direct blind zeroforcing approach to cancel intersymbol interference (ISI) in multiple user finite impulse response (FIR) channels. By selectively anchoring columns of the channel convolution matrix, we present two column-anchored zeroforciug equalizers (CAZE), one without output delay and one with a chosen delay. Unlike many known blind identification algorithms, these equalizers do not need an accurate estimate of the channel orders. Exploiting second-order statistics (SOS) of the received signals, they can retain preselected d columns in the channel convolution matrix (d is the number of users) and force the remaining columns to zero. CAZE can effectively equalize single-input-multiple-output (SIMO) systems and can reduce dynamic multiple-input-multiple-output (MIMO) systems into a memoryless signal mixing system for source separation. Simulation results show that the CAZE is not only effective for blind equalization of linear quadrature amplitude modulation (QAM) systems, but it is also applicable to the nonlinear GMSK modulation in the popular wireless GSM systems when computational cost severely limits the use of nonlinear methods such as the Viterbi algorithm.
{fenge}
0033413046	On performance potentials and conditional Monte Carlo for gradient estimation for Markov chains	We consider the problem of sample path-based gradient estimation for long-run (steady-state) performance measures defined on discrete-time Markov chains. We show how two estimators - one derived using the likelihood ratio method with conditional Monte Carlo and splitting, and the other derived using performance potentials and perturbation analysis -are related. In particular, one can be expressed as the conditional expectation of a suitably weighted average of the other. This demonstrates yet another connection between the two gradient estimation techniques of perturbation analysis and the likelihood ratio method.
{fenge}
0033247533	Single sample path-based optimization of Markov chains	Motivated by the needs of on-line optimization of real-world engineering systems, we studied single sample path-based algorithms for Markov decision problems (MDP). The sample path used in the algorithms can be obtained by observing the operation of a real system. We give a simple example to explain the advantages of the sample path-based approach over the traditional computation-based approach: matrix inversion is not required; some transition probabilities do not have to be known; it may save storage space; and it gives the flexibility of iterating the actions for a subset of the state space in each iteration. The effect of the estimation errors and the convergence property of the sample path-based approach are studied. Finally, we propose a fast algorithm, which updates the policy whenever the system reaches a particular set of states and prove that the algorithm converges to the true optimal policy with probability one under some conditions. The sample path-based approach may have important applications to the design and management of engineering systems, such as high speed communication networks.
{fenge}
0034172586	QoS-enabled voice support in the next-generation Internet: issues, existing approaches and challenges	The Internet is under rapid growth and continuous evolution in order to accommodate an increasingly large number of applications with diverse service requirements. In particular, Internet telephony, or voice over IP is one of the most promising services currently being deployed. Besides the potentially significant cost reduction, Internet telephony can offer many new features and easier integration with widely adopted Web-based services. Despite these advantages, there still exist a number of barriers to the widespread deployment of Internet telephony such as the lack of control architectures and associated protocols for managing calls, a security mechanism for user authentication, and proper charging schemes. The most prominent one, however, is how to ensure the QoS needed for voice conversation. The purpose of this article is to survey the state-of-the-art technologies in enabling the QoS support for voice communications in the next-generation Internet. In this article, we first review the existing technologies in supporting voice over IP networks, including the basic mechanisms in the IETF Internet telephony architecture and ITU-T H.323-related Recommendations. We then discuss the IETF QoS framework, specifically the Intserv and Diffserv framework. Finally, we present two leading companies' (Cisco and Lucent) solutions to offering IP telephony services as examples to illustrate how real systems are implemented.
{fenge}
39649083774	Aggregation of perturbation realization factors and service rate-based policy iteration for queueing systems	In the previous works, we have shown that policy iteration algorithms in performance optimization follow directly from performance difference formulas. In this paper, we show that based on this idea, we can develop policy iteration type of optimization algorithms for "policies" that depend on system parameters. We illustrate this idea with a load-dependent closed Jackson network, where the policy is different from that of standard Markov decision processes. First we establish the performance difference formula. Then we show that a service rate-based policy iteration algorithm can be developed using the aggregation of perturbation realization factors. The algorithm can be used to optimize the customer-average performance, which is another important performance metric compared with the traditional time-average performance. Sample path-based learning algorithm is also developed and it does not require the explicit knowledge of system parameters, such as the routing probability of queueing network. Finally, a numerical example is given to illustrate the efficiency of our algorithms. This approach can save computation because the space of parameterbased policies is smaller than that of state-based policies in standard Markov decision processes. Â© 2006 IEEE.
{fenge}
39649119386	Constructing performance sensitivities with sample paths in continuous-time Markov systems	Sensitivity analysis plays an important role in performance optimization of stochastic systems. It provides a unified view to different areas such as perturbation analysis, Markov decision processes, and reinforcement learning. Furthermore, with the sample path based construction of sensitivity this approach leads to some new research directions such as the event-based optimization approach [5]. The previous results are on discrete-time Markov chains [4] and in this paper, we extend the sample path based construction approach to continuous-time Markov processes. The complexity involved is that in continuous-time Markov processes the transition rate also changes in addition to the changes in the transition probability matrix. Â© 2006 IEEE.
{fenge}
3843150404	A unified approach to Markov decision problems and performance sensitivity analysis with discounted and average criteria: Multichain cases	We propose a unified framework to Markov decision problems and performance sensitivity analysis for multichain Markov processes with both discounted and average-cost performance criteria. With the fundamental concept of performance potentials, we derive both performance-gradient and performance-difference formulas, which play the central role in performance optimization. The standard policy iteration algorithms for both discounted- and average-reward MDPs can be established using the performance-difference formulas in a simple and intuitive way; and the performance-gradient formulas together with stochastic approximation may lead to new optimization schemes. This sensitivity-based point of view of performance optimization provides some insights that link perturbation analysis, Markov decision processes, and reinforcement learning together. The research is an extension of the previous work on ergodic Markov chains (Cao, Automatica 36 (2000) 771). Â© 2004 Elsevier Ltd. All rights reserved.
{fenge}
39749190567	Discrete Event Dynamic Systems Theory and Applications: Editorial	Some of the steps taken by the editorial board to develop the journal in the field of discrete event dynamic systems are discussed. The editorial board recently engaged in an extensive discussion to decide a number of actions. A new category called 'short papers' will be created. Short papers are limited to 12 journal pages. They will go through a different and accelerated review process compared with regular papers. The authors are required to indicate the type of paper a submission is. Papers that are 12 pages or less in length may be submitted as regular papers and the papers will go through the normal review process for regular papers. A new option of 'reject but submission of a new paper on the topic encouraged' will be added to the choices of final decisions for those papers that contain potentially publishable results but require substantive revisions.
{fenge}
33244489385	Optimal control of ergodic continuous-time Markov chains with average sample-path rewards	In this paper we study continuous-time Markov decision processes with the average sample-path reward (ASPR) criterion and possibly unbounded transition and reward rates. We propose conditions on the system's primitive data for the existence of e-ASPR-optimal (deterministic) stationary policies in a class of randomized Markov policies satisfying some additional continuity assumptions. The proof of this fact is based on the time discretization technique, the martingale stability theory, and the concept of potential. We also provide both policy and value iteration algorithms for computing, or at least approximating, the e-ASPR-optimal stationary policies. We illustrate with examples our main results as well as the difference between the ASPR and the average expected reward criteria. Â© 2005 Society for Industrial and Applied Mathematics.
{fenge}
41049116683	Policy iteration based feedback control	It is well known that stochastic control systems can be viewed as Markov decision processes (MDPs) with continuous state spaces. In this paper, we propose to apply the policy iteration approach in MDPs to the optimal control problem of stochastic systems. We first provide an optimality equation based on performance potentials and develop a policy iteration procedure. Then we apply policy iteration to the jump linear quadratic problem and obtain the coupled Riccati equations for their optimal solutions. The approach is applicable to linear as well as nonlinear systems and can be implemented on-line on real world systems without identifying all the system structure and parameters. Â© 2007 Elsevier Ltd. All rights reserved.
{fenge}
0034591624	Forecasting power market clearing price using neural networks	Deregulation of the electric power industry worldwide raises many challenging issues. Forecasting the hourly market clearing prices in the daily power markets is the most essential task and basis for any decision making. One approach to predict the market behaviors is to use the historical prices, quantities and other information to forecast the future prices. The basic idea is to use history and other estimated factors in the future to "fit" and "extrapolate" the prices. Aiming at this challenging task, we developed a neural network method to forecast the MCPs for the California day-ahead energy markets. The structure of the neural network we used is a three-layer back propagation (BP) network. The historical MCPs and quantities of California day-ahead energy market, the ISO load forecasts and other public information that may influence the markets are used for training, validating and forecasting test. Preliminary results show that our method is promising.
{fenge}
79951555826	Stochastic control via direct comparison	The standard approach to stochastic control is dynamic programming. In this paper, we introduce an alternative approach based on direct comparison of the performance of any two policies. This is achieved by modeling the state process as a continuous-time and continuous-state Markov process and applying the same ideas as for the discrete-time and discrete-state case. This approach is simple and intuitively clear; it applies to different problems with, finite and infinite horizons, discounted and long-run-average performance, continuous and jump diffusions, in the same way. Discounting is not needed when dealing with long-run average performance. The approach provides a unified framework for stochastic control and other optimization theory and methodologies, including Markov decision processes, perturbation analysis, and reinforcement learning. Â© 2010 Springer Science+Business Media, LLC.
{fenge}
80052288535	Stochastic learning and optimization - Ideas vs mathematics?	What are the roles that ideas and mathematics play in research of engineering subjects? This article tries to answer this question with the author's own research experience. In the past 30 years, the author's research started from perturbation analysis (PA) of queueing networks, to PA of Markov systems, to Markov decision processes (MDP), and to stochastic control; and based on these research, the author has successfully developed a sensitivity-based optimization approach to the area of learning and optimization of stochastic systems, leading to a simple and unified framework for the area, new research directions, and new results in the area. This paper reviews the above research topics and the history of their development with an emphasis on what the roles that ideas and mathematics play in each of the advances along the path. Â© 2011 Higher Education Press and Springer-Verlag Berlin Heidelberg.
{fenge}
42549107844	Fine-grained scalable video broadcasting over cellular networks	In layered video broadcasting, if adaptation is performed only by receivers, significant mismatches between a receiver's expected bandwidth and the actually delivered bandwidth could occur as the adaptation unit is a coarse-grained layer. The paper shows that fine-grained sender adaptation, as a complement to receiver adaptation, can significantly decrease these mismatches. A formal study on optimal session and layer bandwidth allocations for sender adaptation in a broadband cellular network is carried out. The most fundamental issues associated with layered video broadcasting, including system utility and the overhead of layering, are considered. A polynomial-time algorithm is derived for optimal allocation. Experimental results show that it can significantly improve the system utility compared to static allocation algorithms.
{fenge}
44849084717	The nth-order bias optimality for multichain Markov decision processes	In this paper, we propose a new approach to the theory of finite multichain Markov decision processes (MDPs) with different performance optimization criteria. We first propose the concept of nth-order bias; then, using the average reward and bias difference formulas derived in this paper, we develop an optimization theory for finite MDPs that covers a complete spectrum from average optimality, bias optimality, to all high-order bias optimality, in a unified way. The approach is simple, direct, natural, and intuitive; it depends neither on Laurent series expansion nor on discounted MDPs. We also propose one-phase policy iteration algorithms for bias and high-order bias optimal policies, which are more efficient than the two-phase algorithms in the literature. Furthermore, we derive high-order bias optimality equations. This research is a part of our effort in developing sensitivity-based learning and optimization theory. Â© 2008 IEEE.
{fenge}
44849134414	Event-based optimization of Markov systems	Recent research indicates that Markov decision processes (MDPs) and perturbation analysis (PA) based optimization can be derived easily from two fundamental performance sensitivity formulas. With this sensitivity point of view, an event-based optimization approach, including event-based sensitivity analysis and event-based policy iteration, was proposed via an example by X. R. Cao (Discrete Event Dyn. Syst.: Theory Appl., vol. 15, pp. 169-197, 2005). This approach utilizes the special feature of a system and illustrates how the potentials can be aggregated using the special feature. The approach applies to many practical problems that do not fit well the standard MDP formulation. This note provides a mathematical formulation and proves the main results for this approach. Â© 2008 IEEE.
{fenge}
52349114487	Limitation of Markov models and event-based learning and optimization	We first illustrate the possible limitations of the widely-used Markov model and then introduce the concepts of events, event-based policies and event-based optimization. Compared with the state-based policies, event-based policies may utilize the "future" information and therefore may perform better. In addition, the number of events may scale to the system size while the number of states grows exponentially. The event-based approach is particularly efficient for systems with special structural properties. The solutions to the event-based optimization can be developed with a sensitivity-based view, which is developed recently for the area of stochastic learning and optimization. Â©2008 IEEE.
{fenge}
62949129183	Event-based optimization for dispatching policies in material handling systems of general assembly lines	A material handling (MH) system of a general assembly line dispatching parts from inventory to working buffers could be complicated and costly to operate. Generally it is extremely difficult to find the optimal dispatching policy due to the complicated system dynamics and the large problem size. In this paper, we formulate the dispatching problem as a Markov decision process (MDP), and use event-based optimization framework to overcome the difficulty caused by problem dimensionality and size. By exploiting the problem structures, we focus on responding to certain events instead of all state transitions, so that the number of aggregated potential function (i.e., value function) is scaled to the square of the system size despite of the exponential growth of the state space. This effectively reduces the computational requirements to a level that is acceptable in practice. We then develop a sample path based algorithm to estimate the potentials, and implement a gradient-based policy optimization procedure. Numerical results demonstrate that the policies obtained by the event-based optimization approach significantly outperform the current dispatching method in production. Â© 2008 IEEE.
{fenge}
67349212859	Stochastic learning and optimization-A sensitivity-based approach	We introduce a sensitivity-based view to the area of learning and optimization of stochastic dynamic systems. We show that this sensitivity-based view provides a unified framework for many different disciplines in this area, including perturbation analysis, Markov decision processes, reinforcement learning, identification and adaptive control, and singular stochastic control; and that this unified framework applies to both the discrete event dynamic systems and continuous-time continuous-state systems. Many results in these disciplines can be simply derived and intuitively explained by using two performance sensitivity formulas. In addition, we show that this sensitivity-based view leads to new results and opens up new directions for future research. For example, the n th bias optimality of Markov processes has been established and the event-based optimization may be developed; this approach has computational and other advantages over the state-based approaches. Â© 2009 Elsevier Ltd. All rights reserved.
{fenge}
67349214932	Policy iteration for customer-average performance optimization of closed queueing systems	We consider the optimization of queueing systems with service rates depending on system states. The optimization criterion is the long-run customer-average performance, which is an important performance metric, different from the traditional time-average performance. We first establish, with perturbation analysis, a difference equation of the customer-average performance in closed networks with exponentially distributed service times and state-dependent service rates. Then we propose a policy iteration optimization algorithm based on this difference equation. This algorithm can be implemented on-line with a single sample path and does not require knowing the routing probabilities of queueing systems. Finally, we give numerical experiments which demonstrate the efficiency of our algorithm. This paper gives a new direction to efficiently optimize the "customer-centric" performance in queueing systems. Â© 2009 Elsevier Ltd. All rights reserved.
{fenge}
0034439193	Internet pricing: Comparison and examples	The central issue of Internet economics is pricing. In [1], we studied the Internet pricing based on the leader-follower game, the cooperative game, and the two-person game theory. In this paper, we continue our study by comparing different pricing schemes with the above approaches. These schemes include Paris Metro Pricing (PMP) and pricing with priority. We show that PMP does not provide better social welfare thus does not provide better cooperative solutions. Numerical examples indicate that the leader-follower game leads to an optimal solution with the same price for both "classes" of users in PMP. This contradicts to the intention of the original design of the scheme.
{fenge}
0035263966	Recursive approaches for single sample path based Markov reward processes	Two single sample path-based recursive approaches for Markov decision problems are proposed. One is based on the simultaneous perturbation approach and can be applied to the general state problem, but its convergence rate is low. In this algorithm, the small perturbation on current parameters is necessary to get another sample path for comparison, but it may worsen the system. Hence, another approach is introduced, which directly estimates the gradient of the performance for optimization by 'potential' theory. This algorithm, however, is limited to finite state space systems, but its convergence speed is higher than the first one. The estimate for gradient can be obtained by using the sample path with current parameters without any perturbation. This approach is more acceptable for practical applications.
{fenge}
77950854495	A new model of continuous-time markov processes and impulse stochastic control	We propose a composite model for Markov processes. The state space of a composite Markov process consists of two parts, J and JÌ. When the process is in JÌ, it evolves like a continuous-time Levy process; and once the process enters J, it makes a jump instantly according to a transition function like a direct-time Markov chain. The composite Markov process provides a new model for impulse stochastic control problem, with the instant jumps in J modeling the impulse control feature (e.g., selling or buying stocks in the portfolio management problem). With this model, a new approach may be developed to the impulse stochastic control problem. The approach is based on a direct comparison of the performance of any two policies, and hence the results are intuitive clear. The new approach also provides some new insights leading to new research topics in the area, such as sample-path-based policy iteration and gradient based optimization. Â©2009 IEEE.
{fenge}
77950410744	Direct-comparison approach to continuous time linear quadratic Gaussian control problem	Recently, a direct-comparison approach has been developed to control and optimize the performance of a stochastic Markov system, see [1] for discrete time case, and [2] for continuous time case. Compared with dynamic programming, the standard approach for stochastic control problem, this alternative approach is simple and intuitive. It is based on the direct comparison of the system performance under two policies, and discounting is not needed when dealing with long-run average criterion. By directly applying this approach, we studied the continuous time Linear Quadratic Gaussian (LQG) control problem, obtained the optimal policy for the long run average criterion without introducing discounting. The well known algebraic Riccati equation for the optimal policy can be easily obtained by this direct-comparison approach. This paper servers as an example to show the effectiveness of direct-comparison approach for the continuous time case. Â©2009 IEEE.
{fenge}
0035681186	Analysis of packet reservation multiple access for data transmission	Packet Reservation Multiple Access (PRMA) is a media access control (MAC) protocol for wireless system which can also be used as a packet control layer on top of TDMA. This paper analyzes the performance of PRMA for data traffic in a wireless communication system. A modification has also been proposed to improve the data transmission fairness under congested traffic condition. Markov model and computer simulations have been used to study the channel utilization, packet access time, etc. of the data system. Analysis shows that the performance of PRMA protocol for data traffic is satisfactory. The derived mathematical model provides an accurate tool for evaluating the system performance.
{fenge}
0036554070	Internet pricing with a game theoretical approach: Concepts and examples	The basic concepts of three branches of game theory, leader-follower, cooperative, and two-person nonzero sum games, are reviewed and applied to the study of the Internet pricing issue. In particular, we emphasize that the cooperative game (also called the bargaining problem) provides an overall picture for the issue. With a simple model for Internet quality of service (QoS), we demonstrate that the leader-follower game may lead to a solution that is not Pareto optimal and in some cases may be "unfair," and that the cooperative game may provide a better solution for both the Internet service provider (ISP) and the user. The practical implication of the results is that government regulation or arbitration may be helpful. The QoS model is also applied to study the competition between two ISPs, and we find a Nash equilibrium point from which the two ISPs would not move out without cooperation. The proposed approaches can be applied to other Internet pricing problems such as the Paris Metro pricing scheme.
{fenge}
0036604532	A time aggregation approach to Markov decision processes	We propose a time aggregation approach for the solution of infinite horizon average cost Markov decision processes via policy iteration. In this approach, policy update is only carried out when the process visits a subset of the state space. As in state aggregation, this approach leads to a reduced state space, which may lead to a substantial reduction in computational and storage requirements, especially for problems with certain structural properties. However, in contrast to state aggregation, which generally results in an approximate model due to the loss of Markov property, time aggregation suffers no loss of accuracy, because the Markov property is preserved. Single sample path-based estimation algorithms are developed that allow the time aggregation approach to be implemented on-line for practical systems. Some numerical and simulation examples are presented to illustrate the ideas and potential computational savings. Â© 2002 Elsevier Science Ltd. All rights reserved.
{fenge}
0036646845	A note on the relation between weak derivatives and perturbation realization	This note studies the relationship between two important approaches in perturbation analysis (PA) - perturbation realization (PR) and weak derivatives (WDs). Specifically, we study the relation between PR and WDs for estimating the gradient of stationary performance measures of a finite state-space Markov chain. Will show that the WDs expression for the gradient of a stationary performance measure can be interpreted as the expected PR factor where the expectation is carried out with respect to a distribution that is given through the weak derivative of the transition kernel of the Markov chain. Moreover, we present unbiased gradient estimators.
{fenge}
79960711152	Bias optimality for multichain Markov decision processes	in recent research we find that the policy iteration algorithm for Markov decision processes (MDPs) is a natural consequence of the performance difference formula that compares the difference of the performance of two different policies. in this paper, we extend this idea to the bias-optimal policy of MDPs. We first derive a formula that compares the biases of any two policies which have the same gains, and then we show that a policy iteration algorithm leading to a bias-optimal policy follows naturally from this bias difference formula. Our results extend those in (Lewis & Puterman, 2001) to the multichain case and provide a simple and intuitive explanation for the mathematics in (Veinott, 1966; Veinott, 1969). The results also confirm the idea that the solutions to performance (including bias) optimal problems can be obtained from performance sensitivity formulas. Copyright Â© 2005 IFAC.
{fenge}
80051992017	Event-based optimization for the continuous-time Markov systems	Performance optimization plays an important role in both applied and theoretical research. Recent research provides a unified view, with which the main results in many different areas can be derived or explained using two foundational sensitivities equations. With this approach, event-based optimization has been proposed to overcome the difficulties that the traditional approaches could not solve. However, most of the previous results are on discrete-time Markov systems. In the real world, many practical problems require the model of the continuous-time Markov systems. This paper focuses on extending the event-based optimization approach to the continuous-time Markov systems. As any Markov process can be viewed as a GSMP, we first give a standard description on the GSMP model and then slightly modify it to fit our problem setting. Compared with the event-based optimization with the discrete-time model, in the continuous-time case, in addition to control the probabilities of the controllable events, we need also control the rates of the triggerable events. The final result keeps as intuitive as that for the discrete-time Markov systems, and provides a natural framework for studying the event-based optimization problems. Â© 2011 Asian Control Association.
{fenge}
84855678838	Performance optimization of queueing systems with perturbation realization	After the intensive studies of queueing theory in the past decades, many excellent results in performance analysis have been obtained, and successful examples abound. However, exploring special features of queueing systems directly in performance optimization still seems to be a territory not very well cultivated. Recent progresses of perturbation analysis (PA) and sensitivity-based optimization provide a new perspective of performance optimization of queueing systems. PA utilizes the structural information of queueing systems to efficiently extract the performance sensitivity information from a sample path of system. This paper gives a brief review of PA and performance optimization of queueing systems, focusing on a fundamental concept called perturbation realization factors, which captures the special dynamic feature of a queueing system. With the perturbation realization factors as building blocks, the performance derivative formula and performance difference formula can be obtained. With performance derivatives, gradient-based optimization can be derived, while with performance difference, policy iteration and optimality equations can be derived. These two fundamental formulas provide a foundation for performance optimization of queueing systems from a sensitivity-based point of view. We hope this survey may provide some inspirations on this promising research topic. Â© 2011 Elsevier B.V. All rights reserved.
{fenge}
0037211787	Obtaining packet response times for nonblocking ATM switches	In this paper, we propose an approach that yields accurate approximations for the packet response times in a generic ATM switch. The approach combines three existing methodologies: power series algorithm for light traffic, saturation analysis for heavy traffic, and the Newton-PadÃ© rational approximation for curve fitting. This approach works especially well for small to medium size switches, for which the traditional assumption of the Poisson arrival to the transmission channels does not apply well. Numerical samples reveal a close agreement between the approximant and the simulation result. Â© 2003 Elsevier Science B.V. All rights reserved.
{fenge}
0036992818	Gradient-based policy iteration: An example	Recent research indicates that perturbation analysis (PA), Markov decision processes (MDP), and reinforcement learning (RL) are three closely-related areas in discrete event dynamic system optimization. In particular, it was shown that policy iteration in fact chooses the policy that has the steepest performance gradient (provided by PA) for the next iteration. This sensitivity point of view of MDP leads to some new research topics. In this note, we propose to implement policy iteration based on performance gradients. This approach is particularly useful when the actions at different states are correlated and hence the standard policy iteration cannot apply. We illustrate the main ideas with an example of M/G/1/N queue and identify some further research topics.
{fenge}
0037289322	From perturbation analysis to Markov decision processes and reinforcement learning	The goals of perturbation analysis (PA), Markov decision processes (MDPs), and reinforcement learning (RL) are common: to make decisions to improve the system performance based on the information obtained by analyzing the current system behavior. In this paper, we study the relations among these closely related fields. We show that MDP solutions can be derived naturally from performance sensitivity analysis provided by PA. Performance potential plays an important role in both PA and MDPs; it also offers a clear intuitive interpretation for many results. Reinforcement learning, TD(Î»), neuro-dynamic programming, etc., are efficient ways of estimating the performance potentials and related quantities based on sample paths. The sensitivity point of view of PA, MDP. and RL brings in some new insight to the area of learning and optimization. In particular, gradient-based optimization can be applied to parameterized systems with large state spaces, and gradient-based policy iteration can be applied to some nonstandard MDPs such as systems with correlated actions, etc. Potential-based on-line approaches and their advantages are also discussed.
{fenge}
0038307585	Call level performance analysis for multi-services wireless cellular networks	One of the key issues in the next generation wireless cellular networks is to support multiple services, in which call admission control policy has to guarantee the different Quality of Service (QoS) requirement from diverse applications, and at the same time ensure the scarce bandwidth be utilized efficiently. In this paper, we first build upon our proposed Dual Threshold Bandwidth Reservation (DTBR) scheme to integrate more realistic, variable data traffic, and then proceed to analyze the DTBR scheme using two-dimensional Markov process. Both analysis and simulation results indicate that, by keeping target handoff voice call dropping probability, adoption of elastic data traffic model can reduce handoff voice call dropping probability and improve overall system award; by adjusting the threshold values in the DTBR, we demonstrate that it is capable of satisfying different QoS requirements for voice and data traffic while achieving the maximum utility.
{fenge}
0037531281	On handoff performance for an integrated voice/data cellular system	One of the key challenges in the design of bandwidth allocation policies for a multi-services mobile cellular network is to guarantee the potentially different Quality of Service (QoS) requirement from diverse applications, while at the same to ensure that the scarce bandwidth be utilized efficiently. Complete Sharing (CS) and Dynamic Partition (DP) schemes have been shown as viable techniques for managing the bandwidth. However, there has been no study that compares their respective performance, which is the focus of this paper. Specifically, in this paper, through both analysis and simulation, we demonstrate that both schemes can achieve comparable performance by proper manipulation of control parameters. The tradeoff is that DP scheme can more easily achieve the target QoS requirement, at the expense of some over-provisioning, thus can potentially lead to less channel efficiency when comparing to a CS based scheme.
{fenge}
0038631988	Semi-Markov decision problems and performance sensitivity analysis	Recent research indicates that Markov decision processes (MDPs) can be viewed from a sensitivity point of view; and perturbation analysis (PA), MDPs, and reinforcement learning (RL) are three closely related areas in optimization of discrete-event dynamic systems that can be modeled as Markov processes. The goal of this paper is two-fold. First, we develop PA theory for semi-Markov processes (SMPs); and second, we extend the aforementioned results about the relation among PA, MDP, and RL to SMPs. In particular, we show that performance sensitivity formulas and policy iteration algorithms of semi-Markov decision processes (SMDPs) can be derived based on performance potential and realization matrix. Both the long-run average and discounted-cost problems are considered; this approach provides a unified framework for both problems, and the long-run average problem corresponds to the discounted factor being zero. The results indicate that performance sensitivities and optimization depend only on first-order statistics. Single sample path-based implementations are discussed.
{fenge}
84866772576	Event-based optimization for POMDPs and its application in portfolio management	Partially observable Markov decision processes(POMDPs) provide a framework for the optimization of Markov systems when there exist multiple sources of uncertainty: besides the system's stochastic dynamics, there are also observation noises. While POMDPs have many real applications, existing approaches to searching global optimal policy is computationally intractable even for systems with small sizes. In this paper, we apply the idea of the recently developed event-based optimization approach to study POMDP problems with infinite horizon setting. Based on this approach, a perturbation analysis based algorithm can be proposed to search for a local optimal policy. Further more, under a certain condition, a policy iteration type algorithm can be developed. We find that such a condition is satisfied for some partially observable systems in the financial engineering area. As an example, we discuss a portfolio management problem at the end of the paper. Â© 2011 IFAC.
{fenge}
84874275683	Analysis of non-linear behavior - A sensitivity-based approach	One of the important issues in behavioral analysis is that the law of iterated expectation is lost due to the distortion in performance probability. The standard dynamic programming fails to work in this area. In this paper, we propose to use an alternative approach, the sensitivity-based approach, to solve the portfolio management problem in an environment with probability distortion. We show that after changing the underlying probability measure the distorted performance maintains some linearity, and the derivative of the distorted performance is simply the expectation of the sample path based derivative of the performance under this new measure, which can be obtained by perturbation analysis. We also provide simulation algorithms for the derivative of distorted performance. We apply this approach to the initial allocation problem with the distorted performance probability and obtained an optimal policy. We expect that this approach is applicable to other problems in the area of optimization in behavioral analysis. Â© 2012 IEEE.
{fenge}
84886344916	An Introduction to Event-Based Optimization: Theory and Applications	In this chapter, we review the basic idea of event-based optimization (EBO), which is specifically suitable for policy optimization of discrete event dynamic system (DEDS). With decisions based on certain events instead of on the system state, the number of potentials to be estimated is usually much smaller than the size of the state space. Performance difference and derivative formulas are developed for event-based policies. Under certain assumptions, policy iteration algorithms for EBO can be developed and they may converge to a globally optimal event-based policy. However, gradientbased optimization algorithms can always be applied and they usually converge to a local optimum in the parameterized policy space. We illustrate the EBO method by a material handling (MH) problem. We hope this chapter may bring insights for the study of event-based control, decision-making, and optimization in more general situations. Â© 2013 The Institute of Electrical and Electronics Engineers, Inc.
{fenge}
0042689538	Pole assignment for stochastic systems with unknown coefficients	This paper solves the exact pole assignment problem for the single-input stochastic systems with unknown coefficients under the controllability assumption which is necessary and sufficient for the arbitrary pole assignment for systems with known coefficients. The system noise is required to be mutually independent with zero mean and bounded second moment. Two approaches to solving the problem are proposed : One is the iterative learning approach which can be applied when the state at a fixed time can be repeatedly observed with different feedback gains; the other is the adaptive control approach which works when the trajectories satisfy a nondegeneracy condition. Both methods are essentially based on stochastic approximation, and the feedback gains are recursively given without invoking the certainty-equivalency-principle.
{fenge}
84889784415	Stochastic learning and optimization: A sensitivity-based approach	Stochastic learning and optimization is a multidisciplinary subject that has wide applications in modern engineering, social, and financial problems, including those in Internet and wireless communications, manufacturing, robotics, logistics, biomedical systems, and investment science. This book is unique in the following aspects. 1.(Four areas in one book) This book covers various disciplines in learning and optimization, including perturbation analysis (PA) of discrete-event dynamic systems, Markov decision processes (MDP)s), reinforcement learning (RL), and adaptive control, within a unified framework. 2.(A simple approach to MDPs) This book introduces MDP theory through a simple approach based on performance difference formulas. This approach leads to results for the n-bias optimality with long-run average-cost criteria and Blackwell's optimality without discounting. 3.(Event-based optimization) This book introduces the recently developed event-based optimization approach, which opens up a research direction in overcoming or alleviating the difficulties due to the curse of dimensionality issue by utilizing the system's special features. 4.(Sample-path construction) This book emphasizes physical interpretations based on the sample-path construction. Â© 2007 Springer Science+Business Media, LLC. All rights reserved.
{fenge}
84897378636	Partial-information state-based optimization of partially observable Markov decision processes and the separation principle	We propose a partial-information state based approach to the optimization of the long-run average performance in a partially observable Markov decision process (POMDP). In this approach, the information history is summarized (at least partially) by a (or a few) statistic(s), not necessary sufficient, called a partial-information state, and actions depend on the partial-information state, rather than system states. We first propose the 'single-policy based comparison principle,' under which we derive an HJB-type of optimality equation and policy iteration for the optimal policy in the partial-information-state based policy space. We then introduce the Q-sufficient statistics and show that if the partial-information state is Q-sufficient, then the optimal policy in the partial-information state based policy space is optimal in the space of all feasible information state based policies. We show that with some further conditions the well-known separation principle holds. The results are obtained by applying the direct comparison based approach initially developed for discrete event dynamic systems. Â© 1963-2012 IEEE.
{fenge}
84902379426	A tutorial on event-based optimization-a new optimization framework	In many practical systems, the control or decision making is triggered by certain events. The performance optimization of such systems is generally different from the traditional optimization approaches, such as Markov decision processes or dynamic programming. The goal of this tutorial is to introduce, in an intuitive manner, a new optimization framework called event-based optimization. This framework has a wide applicability to aforementioned systems. With performance potential as building blocks, we develop two intuitive optimization algorithms to solve the event-based optimization problem. The optimization algorithms are proposed based on an intuitive principle, and theoretical justifications are given with a performance sensitivity based approach. Finally, we provide a few practical examples to demonstrate the effectiveness of the event-based optimization framework. We hope this framework may provide a new perspective to the optimization of the performance of event-triggered dynamic systems. Â© 2013 Springer Science+Business Media New York.
{fenge}
84907692076	Performance analysis of bandwidth allocations for multi-services mobile wireless cellular networks	One of the key challenges in the design of bandwidth allocation policies for a multi-services mobile cellular network is to guarantee the potentially different quality of service (QoS) requirement from diverse applications, while at the same to ensure that the scarce bandwidth be utilized efficiently. Complete sharing (CS) and dynamic partition (DP) schemes have been shown as viable techniques for managing the bandwidth. However, there has been no study that compares their respective performance, which is the focus of this paper. Specifically, in this paper, through both analysis and simulation, we demonstrate that both schemes can achieve comparable performance by proper manipulation of control parameters. The tradeoff is that DP scheme can more easily achieve the target QoS requirement, at the expense of over-provisioning, thus can potentially lead to less channel efficiency when comparing to a CS based scheme.
{fenge}
11044222936	The potential structure of sample paths and performance sensitivities of Markov systems	We study the structure of sample paths of Markov systems by using performance potentials as the fundamental units. With a sample path-based approach, we show that performance sensitivity formulas (performance gradients and performance differences) of Markov systems can be constructed intuitively, by first principles, with performance potentials (or equivalently, perturbation realization factors) as building blocks. In particular, we derive sensitivity formulas for two Markov chains with possibly different state spaces. The proposed approach can be used to obtain flexibly the sensitivity formulas for a wide range of problems, including those with partial information. These formulas are the basis for performance optimization of discrete event dynamic systems, including perturbation analysis, Markov decision processes, and reinforcement learning. The approach thus provides insight on on-line learning and performance optimization and opens up new research directions. Sample path based algorithms can be developed. Â© 2004 IEEE.
{fenge}
11844254796	Complexity and heuristics for wireless broadcast with noncumulative layered data	Layer transmission generates multiple layers for a video program, enabling a receiver to selectively subscribe to the layers commensurate with its bandwidth. It is an effective solution to the problem of bandwidth heterogeneity in video broadcasting. However, two important issues remain to be addressed. First, how does a receiver select the subset of layers to achieve the highest bandwidth utilization? Second, how does the sender optimally allocate the layer bandwidth to match the diverse bandwidth requirements from the receivers? We formally investigate these problems in noncumulative layered broadcasting, where any subset of the layers can be used to reconstruct the video. We formulate both the optimal layer subscription problem for a receiver and the optimal layer bandwidth allocation problem for the sender. We show that the former has an effective solution, while the latter is computationally intractable. Three efficient heuristic algorithms are then proposed for the allocation problem, and simulation results show that all of them significantly outperform nonadaptive allocation algorithms.
