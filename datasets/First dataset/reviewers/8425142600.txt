{fenge}
30944459957	Super-resolution image restoration based on segmentation	A new algorithm for super-resolution image restoration based on the segmentation is proposed to resolve contradictions of the effect and the complexity of the current algorithm. Firstly, an image segmentation method is presented to obtain two areas according to the quantity of the texture. Then, for the less texture area a progressive wavelet multi-scale interpolation method is used. For the more texture area a neural network method based on the invariable learning set is introduced. So the new algorithm uses the characteristics of the wavelet and the neural network. Experimental results demonstrate that the new algorithm has the properties of good vision effect, less complexity and simple operation.
{fenge}
33749455701	Adaptive spatio-temporal concealment method using fuzzy classifing and mesh warping	When bit errors occur during transmission and cannot be corrected by an error correction scheme, error concealment is needed to mask damaged image at receiver. In this paper, a spatio-temporal error concealment algorithm based on fuzzy classify and mesh warping method is presented. The algorithm include two steps: First, the error blocks which are in the situation of pure translation are reconstructed. If the complicated motion such as rotation and zoom in or out is detected, the internal texture of each block is warped by a mesh-based affine transform, in order to comply with nontranslation. Experimental results show that the PSNR has been improved 1.5 dB than the BMA-MBW, and 3.5 dB than the BMA.
{fenge}
33845515152	Implementation of a prototype real-time multi-mode wireless video transmission system	A novel prototype wireless video transmission system was presented. The characteristic of the design was that the wireless terminal used high performance multimedia DSP as video processing and control core, and the interface board integrates various wireless network interfaces. By software control, not only the system could work in single network mode, but also could select appropriate transmission channel in multi-mode network environment, so as to present best video quality. The system configuration, hardware and software design, as well as the control policy of the wireless terminal were described in details. Experiments show that in the GPRS/WLAN and CDMA/WLAN test conditions, the system can select the proper network and present satisfactory reconstructed video.
{fenge}
34247333821	Super-resolution reconstruction technology for compressed video	Super-Resolution (SR) reconstruction is to estimate High-Resolution (HR) images from Low-Resolution (LR) image sequence, which has been a great focus for compressed video. This paper firstly presents the base of SR reconstruction for compressed video by building the relationships between the HR and LR images and surveying the models of quantization noise and motion vector. Then, the typical algorithms such as MAP, POCS and IBP are described in detail with experimental results. The computation complexity and real-time approaches are also investigated. Finally, aiming at the drawbacks, the research rang of prospects are demonstrated through pointing out the focus on degradation mode, motion estimation, reconstruction algorithm and real-time implementations.
{fenge}
34249341206	Compressed video super-resolution reconstruction based on regularized algorithm	Estimating high-resolution (HR) video from a sequence of low-resolution (LR) compressed observations is the focus of this paper. Based on the theory of regularization, this paper proposes a new form of regularized cost function to control the within-channel balance between received data and prior information, and a channel weight coefficient to control the cross-channel fidelity. The LR frames are adaptively weighted according to their reliability and the regularization parameter is simultaneously estimated for each channel with ameliorating artifacts in compressed video. An iterative gradient descent algorithm is utilized to reconstruction the HR video. Experimental results demonstrate that the proposed algorithm has an improvement in terms of both objective and subjective quality. © 2006 IEEE.
{fenge}
35148872790	A new face recognition method based on 2DWPCA	A new method based on Two-Dimensional Withinclass Principal Component Analysis (2DWPCA) is proposed for face recognition in this paper. First, the within-class image scatter matrix of each class is calculated by using the training face samples in each class, respectively. Then, according to the within-class image scatter matrix of each class, the optimal eigenvectors of each class are computed, and are selected as the optimal projection axes of each class. Finally, a minimal distance classifier is employed to classify the given test samples. The proposed method is evaluated on the NUST603 face database. Experimental results demonstrate that the method proposed in this paper is effective and feasible. © 2007 IEEE.
{fenge}
36348954313	Performance improved method for pixel-domain Wyner-Ziv video coding system	Distributed video coding (DVC) is a new video compression paradigm based on two key information theories: Slepi-an-Wolf and Wyner-Ziv theorems, and it has the advantage of very lightweight encoder, high compression efficiency and inbuilt robustness. In this paper, pixel-domain Wyner-Ziv video algorithm, which is a typical DVC scheme, is analyzed at first. Then a performance improved method for pixel-domain Wyner-Ziv video coding system is presented. The proposed method, without sacrificing the encoder complexity, can calculate high quality side information using bi-directional motion estimation and reconstruct decoding frames using side information by joint iteration function based on Huber-Markov random field. Simulation results show that a better visual quality and 2dB average gain of Power Signal-to-Noise Ratio (PSNR) can be achieved with the proposed method at the decoder.
{fenge}
39149116336	Bayesian super-resolution reconstruction of compressed video	Super-resolution (SR) technique is to reconstruct high-resolution (HR) images from a sequence of low-resolution (LR) image sequence. By exploiting the quantization step size and motion information embedded in the bit-stream, this paper models the DCT quantization noise and motion noise. The proposed novel noise model adaptively adjusts for different quantizers. With a Huber-Markov random field (HMRF) as the prior model, the gradient descent algorithm is proposed under the Bayesian framework. Its performance is also analyzed. Simulations demonstrate that the proposed algorithm converges faster and has an improvement in objective and subjective visual quality, which is applicable to compressed video.
{fenge}
40049096804	Method based on two-dimensional feature extraction in the complex domain for face recognition	A new method based on two-dimensional feature extraction in the complex domain is proposed for face recognition in this paper. First, face images are performed by mirror transform, and the original face samples and the corresponding mirror samples are used to compute the even symmetry samples and the odd symmetry samples, respectively. The even symmetry samples and the odd symmetry samples are used to form complex samples by an odd-even weighted factor. Then the complex image within-class scatter matrix and the complex image between-class scatter matrix are defined in the complex domain, respectively, to calculate a family of optimal complex projection axes, and complex face samples are projected onto the family of optimal complex projection axes to extract the face features. Finally, a nearest neighbor classifier is employed to classify the extracted features. The method in the paper is evaluated on the NUST603 face image database. Experimental results show the proposed method achieves better performance.
{fenge}
39149100943	Research on auto-focusing approaches for different object distances	Currently, there is a lack of investigating the auto-focusing technique for different object distances. This paper proposes an auto-focusing method for solving the problem. First, the imaging relation among many objects of different distances and the properties of image clarity evaluation function for different object distances are analyzed. Then, the image center window method and the two-dimensional weighted DCT coefficient method that is applied to image clarity evaluation function are proposed. Finally, an improved search strategy is employed to focus the images. Experimental results indicate that the proposed method can effectively focus the images at different object distances.
{fenge}
34247576263	A novel algorithm of Super-Resolution reconstruction for compressed video	Super-Resolution (SR) technique means to reconstruct High-Resolution (HR) images from a sequence of Low-Resolution (LR) observations, which has been a great focus for compressed video. Based on the theory of Projection Onto Convex Set (POCS), this paper constructs Quantization Constraint Set (QCS) using the quantization information extracted from the video bit stream. By combining the statistical properties of image and the Human Visual System (HVS), a novel Adaptive Quantization Constraint Set (AQCS) is proposed. Simulation results show that AQCS-based SR algorithm converges at a fast rate and obtains better performance in both objective and subjective quality, which is applicable for compressed video. © Science Press 2007.
{fenge}
77954666985	Spatial-temporal adaptive error concealment algorithm for H. 264 based on accurate scene change detection	Aiming at the performance degradation of H. 264 error concealment (EC) scheme when scene changes (SC), this paper proposes a spatial-temporal adaptive EC scheme based on SC detection. First, our scheme detects if SC occurs in the current corrupted I/P frame using the difference of histogram or Intra MB ratio, and conceals current I/P frame using novel spatial EC algorithm based on mode estimation if SC occurs, otherwise using improved temporal EC algorithm. Experimental results show that our scheme can conceal lost MB by adaptively using temporal/spatial correlation, and improves the recovery quality of current frame and effectively prevents error propagation, thus improves the recovery quality of the whole sequence. The scheme has low computational complexity and is suitable for real-time applications.
{fenge}
79952239137	Wyner-Ziv scalable video coding based on EM algorithm for correlation noise model estimation	Wyner-Ziv scalable video coding method based on EM algorithm for correlation noise model estimation is presented in this paper. Low-complexity correlation noise model parameter estimation of DISCOVER is used in the base layer to guarantee the basic image quality. EM algorithm is used on online learning and setting correlation noise model. The results show that, compared with the DISCOVER's noise model, the rate distortion performance of the Wyner-ziv coder is improved with the noise model estimation algorithm proposed in the paper when the correlation noise has long tails.
{fenge}
80052917732	Robust piecewise planar stereo with modified segmentation cues in urban scenes	This paper proposes a robust piecewise planar multiview stereo (MVS) approach specifically designed for urban scenes. These architectural scenes are problematic for traditional computer vision methods. In our work, we focus on exploiting some useful constraints of artificial structures such as piecewise coplanarity and boundaries of superpixels. Firstly, we reconstruct quasi-dense 3D point clouds of urban scenes using patches-based MVS (PMVS) method. Secondly, a set of 3D candidate planes are generated by the obtained point clouds without any assumption on the normals of planes, unlike famous Manhattan-world assumption. Then, we segment multi-view images with watershed algorithm and modify the contours of superpixels by the classical Douglas-Peucker approximation algorithm to fit the contours to the boundaries of objects in urban scenes as much as possible. Finally, we use the candidate planes as labels and superpixels as nodes to formulate our Markov Random Field (MRF) optimization problem, then a piecewise planar depth map for each view is recovered by solving the optimization problem using graph-cuts. Experiments show that our method outperforms previous approaches in terms of accuracy. © 2011 IEEE.
{fenge}
84861659113	Hierarchical aggregation fast stereo image matching based on Weber perception and guided filtering	This paper presents a hierarchical cost aggregation-based fast stereo image matching method based on Weber's law and guided filtering. Weber local descriptors for each color channel are firstly extracted from stereo pairs, and raw matching costs between the images are initialized by the descriptors. The matching costs are enhanced with guided filtering to extract the subsets of disparity candidates. Joint spatial discrete sampling and adaptive support weight are utilized to implement hierarchical cost aggregation on the candidate subsets. Then initial disparities from the subsets are selected fast and optimally. Modified bilateral filtering and symmetric warping-based post-processing are sequentially exploited in disparity refining to improve effectively ambiguous regions of initial disparity maps. The experimental results indicate that this proposed technique can obtain piecewise smooth, accurate and dense disparity map while eliminating effectively matching ambiguity. Being concise, fast and high efficiency, and it is robust to illumination change.
{fenge}
43749093209	A novel spatial information recovery algorithm based on fuzzy clustering in H.264	As no reference frame can be obtained in Intra-frame error concealment, reducing the degradation of spatial reconstructed image is one of the key techniques in error concealment. In this paper, a novel spatial error concealment algorithm based on fuzzy clustering for Intra-frame in H.264 is proposed. This proposed algorithm gives a new selection of eigenvectors and similarity measurement for fuzzy clustering. The experimental results show that the proposed algorithm can improve the edge details, achieve a better subjective quality of the recovered image and increase PSNR (Peak Signal-to-Noise Ratio) as well. ©2007 IEEE.
{fenge}
45849126892	Super-resolution reconstruction of compressed video based on adaptive quantization constraint set	Super-resolution (SR) technique is to estimate the High-resolution (HR) images by combining the nonredundant information that is available into a set of Low-resolution (LR) images, which has been a great focus for compressed video. Based on the theory of Projection Onto Convex Set (POCS), this paper constructs Quantization Constraint Set (QCS) using the motion between the frames and the quantization information embedded from the video bit stream. By combing the statistical properties of image and the Human Visual System (HVS), a novel Adaptive Quantization Constraint Set (AQCS) is proposed. The proposed algorithm and its performance analysis are also described. Simulation results show that AQCSbased SR algorithm obtains better performance in both objective and subjective quality, which is applicable for compressed video. © 2006 IEEE.
{fenge}
47349089380	A new auto-focusing method based on the center blocking DCT	First, this paper analyses the imaging relations of the lens system and the properties of image clarity evaluation function under the condition where the object distances of many objects are different. Then, a center window method is employed to stand out the interesting objects. Finally, the image clarity evaluation function based on the center blocking DCT (Discrete Cosine Transform / DCT) method is proposed for evaluating the image clarity in this paper. Experimental results indicate that the proposed method can effectively focus the images both under long-short-object-distance situation and under long-object-distance situation. © 2007 IEEE.
{fenge}
51849167857	Spatial error concealment based on judgement on edge information	An efficient spatial error concealment algorithm is proposed for corrupted image by transmission losses in this work. Firstly, information of edges in the neighboring blocks is extracted by judgements on which edges may traverse the loss block. Then, all detected edges are divided into relevant and irrelevant edge. Subsequently, one or more directions for interpolation can be selected from the relevant edge set by minimizing the boundary pixel difference for each direction. The method improves the capability of recovering more high-detailed contents of lost block with low complexity. Experimental results demonstrate the better performance of the proposed methods as compared to previous techniques. © 2008 IEEE.
{fenge}
57749170278	A new auto-focusing method based on WBDCT for many object situations	There are two situations in auto focusing: one is the long-object-distance situation; the other is the long-shortobject-distance situation. The curve of image clarity evaluation function under the long-short-object-distance situation usually has multiple peaks. A new method based on Weighted Blocking Discrete Cosine Transform (WBDCT) is proposed for evaluating the image clarity in this paper. In the method, images are divided into some blocks of the same size. Then, each block is given the corresponding weighted value and is performed by Discrete Cosine Transform (DCT). Finally, the clarity evaluation junction is calculated. The method is tested in the long-object-distance situation and the long-short-object-distance situation, respectively. Experimental results indicate that the proposed method can effectively focus the images under the two situations. © 2008 IEEE.
{fenge}
70449516632	Content-adaptive interpolation for spatial error concealment	When transmitting encoded images over a communication channel, the reconstructed image quality can be substantially degraded by channel errors. This paper presents a spatial error concealment algorithm that utilizes variance of surrounding pixels, and then classifies each error block (EB) into two categories: uniform block and edge block. For uniform block, Nearest Border Prior Spatial Interpolation is adopted to restore missing pixels. We use the Wiener interpolation algorithm and special interpolation sequence for edge block. Experimental results indicate the proposed algorithm can attain well restored quality of intra-frames both subjectively and objectively. Meanwhile, the computational cost of the proposed algorithm can be significantly reduced, compared to Li's method. And the restored quality is almost the same, sometimes even much better. © 2009 IEEE.
{fenge}
71249161257	Fuzzy reasoning based intra frame error concealment for block based color images	A new technique of the fuzzy reasoning based intra frame error concealment (FRBEC) for the block-based RGB color images was proposed in this paper. First, RGB image was converted to YCbCr color space. The pixel matching was applied to the Y component image to get the location of the optimal matching block. In order to reduce computation, we considered this location as the corresponding location of the optimal matching block of R, G, B component image. Then the fuzzy reasoning was applied to R, G, B component image respectively to fuzzy classify the results of pixel matching. And then the developed Pixel correction was processed to modify the pixels of the blocks with low recover exactness degree (RED). The experiment results show that the FRBEC scheme for both color images and gray images gives good results. The PSNR of the color images is lower than that of the gray images.
{fenge}
76549119189	Fuzzy reasoning based temporal error concealment	A novel temporal error concealment based on fuzzy reasoning is proposed in this paper. On temporal error concealment, motion vector (MV) of the lost block can be selected from candidate MVs. Generally, side match distortion (SMD) which reflects the continuity across the boundary and sum of absolute difference (SAD) which shows the degree of similarity of matching area are two widely used criterions to make the decision. Each criterion describes the status partly. Combining these two measures, a refined measure based on fuzzy reasoning is calculated to balance the effects of SMD and SAD. According to the experimental results, our method can perform better than the others. © 2009 IEEE.
{fenge}
77649334894	RETRACTED ARTICLE: Quantum secure communication for wireless sensor networks	According to the security requirement in sensor networks, we propose a quantum secure communication protocol based on authentication for wireless sensor networks (WSN). In authentication process, we use forward shared randomly angles sequences to encrypt our GHZ states, then distribute GHZ states, user can identify each other by comparing the results of each other. It's secure and realize easily. In wireless communication protocol, consider the realistic facts in WSN; we define the third party (Base station) two particles entanglement with others per GHZ state, which improve the transmission efficiency. Analysis shows this protocol is secure against the eavesdropping and disguising attacks. ©2009 IEEE.
{fenge}
77749343206	Image complexity adaptive intra-frame rate control algorithm for H.264/AVC	Aiming at the bad effect of intra-frame rate control (RC) of H.264, this paper proposed an image complexity adaptive intra-frame RC algorithm. First, in order to acquire intra-frame coding complexity more accurately, our algorithm analyzes intra-frame by Sobel operator and establishes edge direction histogram for each 4x4 block, then gets the most probable intra prediction mode and corresponding reconstructed blocks, finally obtains the residual picture which is close to the actual coding residual. The mean absolute value of residual picture was used to represent the intra-frame coding complexity, combined with our empirical rate-quantization (R-Q) model and target bits allocation method from exhaustive experiments, and the intra QP was determined accurately. Extensive experimental results show that our algorithm not only obtains more accurate intra-frame output bitrate, more consistent subjective quality and more steady PSNR fluctuation compared with existing algorithm, but also prevents buffer overflow and frame skip effectively. © 2009 IEEE.
{fenge}
77749343298	A new human hand-image tracking method	Hand gesture recognition has been widely used in surveillance systems. And human hand image tracking is the foundation of the recognition, and it is also an important step. This paper proposes a new human hand tracking method in video surveillance based on color and shape. In the hand detection step, it proposes a detection method based on chromatic adaptive thresholding and the circular degree. In the hand tracking step, it uses a modified formula of SAD (Sum of Absolute Differences) to implement the matching method in order to track the hand. The results suggest that the method is accurate and simple. Additionally, this method also has lower computational complexity and it can be uses in most scenes. © 2009 IEEE.
{fenge}
77949474373	Error concealment for stereoscopic images using boundary smooth degree	Error concealment can be regarded as a sort of error resilient coding techniques. This paper proposes a method to recover lost blocks in stereoscopic images. We first utilize the correlation to perform disparity estimation to match the corresponding blocks for lost ones. And then we calculate the boundary smooth degree (BSD) for each recovered block. If BSD exceeds the threshold, it means that the boundary is discontinuous which mainly results from high detailed blocks, edge blocks or occluded blocks. So we consider neighboring blocks' BSD and estimate the content of a lost block, and adaptively use different methods to conceal it. Experimental results show that the proposed algorithm can greatly improve the subjective and objective quality of the reconstructed image. ©2009 IEEE.
{fenge}
77955047405	A novel temporal error concealment method based on fuzzy reasoning for H.264	In this paper, a fuzzy reasoning based temporal error concealment method is proposed. The basic temporal error concealment is implemented by estimating Motion Vector (MV) of the lost MacroBlock (MB) from its neighboring MVs. Which MV is the most proper one is evaluated by some criteria. Generally, two criteria are widely used, namely Side Match Distortion (SMD) and Sum of Absolute Difference (SAD) of corresponding MV. However, each criterion could only partly describe the status of lost block. To accomplish the judgement more accurately, the two measures are considered together. Thus a refined measure based on fuzzy reasoning is adopted to balance the effects of SMD and SAD. Terms SMD and SAD are regarded as fuzzy input and the term 'similarity' as output to complete fuzzy reasoning. Result of fuzzy reasoning represents how the tested MV is similar to the original one. And k-means clustering technique is performed to define the membership function of input fuzzy sets adaptively. According to the experimental results, the concealment based on new measure achieves better performance. © 2010 Science Press, Institute of Electronics, CAS and Springer-Verlag Berlin Heidelberg.
{fenge}
78650278460	Gait recognition based on improved dynamic Bayesian networks	In this paper, we proposed an improved two-level dynamic Bayesian network layered time series model (LTSM), which aims to solve the limitations hindering the application of available dynamic Bayesian networks, the hidden Markov model (HMM) and the dynamic texture (DT) model to gait recognition. In the first level, a gait silhouette or feature cycle is divided into several temporally adjacent clusters. Each cluster is modeled by a DT or logistic DT (LDT). In the second level, HMM is built to describe the relationship among the DTs/LDTs. Besides LTSM, LDT is also an improved dynamic Bayesian network presented in this paper to describe the binary image sequence, which introduces the logistic principle component analysis (PCA) to learning its parameters. We demonstrated the validity of LTSM with experiments on both the CMU Mobo gait database and CASIA gait database (dataset B), and that of LDT on the CMU Mobo gait database. Experimental results showed the superiority of the improved dynamic Bayesian networks. © 2010 Elsevier Ltd. All rights reserved.
{fenge}
78650032429	Image complexity adaptive intra-frame Rate Control algorithm for H.264	To address the bad effect of intra-coding Rate Control (RC) of H.264, a novel image complexity adaptive I-frame RC algorithm is proposed. First, the gradient of luma pixel is detected in I-frame with Sobel operator and the edge direction histogram is established for each 4×4 block, hereby the most probable intra prediction mode and corresponding reconstructed block are got. Finally, the residual picture which is close to the actual coding residual is obtained. The mean absolute value of residual is used to represent I-frame coding complexity, then an empirical Rate-Quantization (R-Q) model is proposed, and the optimal intra-QP is accurately determined for each GOP according to allocated target bits by considering simultaneously buffer status and sequence characteristic. Experimental results show that the proposed scheme obtains more accurate I-frame output bit-rate and more steady video quality. Buffer overflow and frame skip are effectively prevented, and sequence PSNR fluctuation has reduced by 60%.
{fenge}
78651080626	Logistic dynamic texture model for human activity and gait recognition	In this paper, a logistic dynamic texture model (LDT) is proposed to characterize binary image sequences. Dynamic texture model (DT) is one of the most efficient and successful methods in modeling dynamic sequences. It learns the parameters through a closed-form solution and commonly uses principal component analysis (PCA) to obtain the observation function. PCA assumes a Gaussian distribution over a set of observations. However, the binary image sequences subject to Bernoulli distribution. The LDT introduces logistic PCA to learn the observation function. The proposed model is capable of describing the binary image sequences accurately by processing the pixels of 1 and 0 separately. The model is demonstrated by image reconstructing and activity/gait recognition experiments. Experimental results illustrate the effectiveness of our model. © 2010 IEEE.
{fenge}
78651112997	Wyner-Ziv coding of video using compressive sensing without feedback channel	In this paper, we propose a novel Wyner-Ziv coding of video using compressive sensing (CS) without using feedback channel. Firstly, the proposed joint sparse model of inter frames is presented. Then, the CS based Wyner- Ziv (WZ) frame coding method is introduced. In proposed method, WZ frame is coded by block based CS measure, quantization, and entropy coding, with rate-distortion (RD) optimization through adaptive measurement collection. In order to obtain a better recover performance, WZ frame jointly reconstructed using side information (SI) based on inter-frame joint sparse representation at the decoder. Finally, experimental results are reported to demonstrate the effectiveness of the proposed coding method. © 2010 IEEE.
{fenge}
78650789513	Wyner-Ziv spatial scalable video coding using compressive sensing in ubiquitous networks	A novel Wyner-Ziv spatial scalable video coding using compressive sensing was proposed for the ubiquitous networks. At the encoder, both the base layer and enhancement layer encode the video signal independent, in which down-sampling video was coded by H.264 in the based layer and original video was coded with adaptive compressive sensing measurement, quantization and entropy coding in the enhancement layer. At the decoder, the base layer and enhancement layer jointly recovered the video signal using compressive sensing approach based on joint sparse model of inter frames. Theoretical analysis and experimental results show that the proposed video coding method can flexibly adjust the bit stream, and has better rate-distortion performance and the robustness of transmission.
{fenge}
79951737948	Error and erasure control via rank-metric codes in random network coding	Error and erasure control of random network coding has recently received a lot of attention due to its solution can increase robustness and reliability of data transmission. To achieve this, additional overhead is needed for error correction. In this paper, we design an efficient and secure correcting scheme to solve this problem. This scheme reduces the computation overhead dramatically by employing efficient algorithm to detect and delete linearly dependent received packets in destination node. Meanwhile, it can simultaneously correct α+z - β row erasures and z pollution packets provided that 2τ+α+β < d. Finally, security and performance analysis validate our theory. © 2010 IEEE.
{fenge}
79951743650	SSIM-based content adaptive frame skipping for low bit rate H.264 video coding	Conventional rate control schemes for H.264/AVC video coding usually regulate output bit rate to match channel bandwidth by adjusting quantization parameter at fixed full frame rate, and the passive frame skipping to avoid buffer overflow usually occurs when scene changes or high motions exist in video sequences especially at low bit rate, which degrades spatial-temporal quality and causes jerky effect. In this paper, an active content adaptive frame skipping scheme is proposed instead of passive methods, which skips subjectively trivial frames by structural similarity (SSIM) measurement. The saved bits from skipped frames are allocated to coded key ones to enhance their spatial quality, and the skipped frames are well recovered from adjacent key ones at the decoder side to maintain constant frame rate. Experimental results show that the proposed scheme acquires better and more consistent spatial-temporal quality both in objective (PSNR) and subjective (SSIM) sense with low complexity compared to classic fixed frame rate control methods JVT-G012. © 2010 IEEE.
{fenge}
79951747475	Wyner-Ziv coding of image using compressed sensing	Compressed sensing (CS) is a technique for acquiring and reconstructing a signal utilizing the prior knowledge that it is sparse or compressible. In this paper, we present a Wyner-Ziv image coding framework, which combines the traditional image coding and compressed sensing. In our method, the image separate into two parts according to pixel location: the down-sampling image is encoded by traditional intra-frame coding and the rest part is encoded through CS method. In order to obtain a better recover performance, the whole image is jointly reconstructed using the two part data based on image sparse representation. The experimental results are reported to demonstrate the effectiveness of the proposed coding method. © 2010 IEEE.
{fenge}
79952172902	A low complexity mb layer rate control algorithm based on motion similarity for H.264	This paper presents a simple but effective macroblock (MB) layer rate control (RC) scheme for H.264/AVC with low complexity. First, to reduce computation cost and inaccuracy of linear mean absolute difference (MAD) prediction at MB layer adopted in JVT-G012, MAD is computed directly according to the difference between current original MB and the reference blocks pointed by estimated MV using intensive motion similarity. Then, MB header bits are predicted based on spatial-temporal correlation because it is not constant due to complicated coding modes and high compression efficiency of H.264. Finally, MB target bit rate is allocated according to its complexity and the parameters of quadratic R-D model are updated using coded MBs with high spatial-temporal correlation and motion similarity not the last coded data points. Simulation results show that the proposed scheme achieves an average PSNR gain of 0.37 dB, meets better with target bit rate, produces more consistent quality for the MBs in a frame and thus improves visual quality compared to classic JVT-H017 RC algorithm, simultaneously has lower computation complexity and suits for real-time application. ©2010 IEEE.
{fenge}
79953645281	Fuzzy recognition based intra frame error concealment for block based images	A new technique for fuzzy recognition based error concealment (FRBEC) on the block-based images is proposed aimed at gray level images. The fuzzy recognition is applied to fuzzy classify for the results of surrounding pixel matching. Then, the corresponding correction is processed to modify the results of the forgoing classification. The developed pixel correction is processed to modify the pixels of the inaccurately-covered blocks with the smooth texture, and pixel re-matching is processed aimed at those with the complex texture. Experimental results show the effectiveness of the proposed method for the images with complex texture and fine details. The subjective effect is satisfactory and the PSNR is higher.
{fenge}
79957659827	Region based stereo matching algorithm using line growing method	Image stereo matching is one of the most important issues in stereo vision. Reliability of depth maps and computational cost of algorithm is the key point for implementing real time robust applications. In the paper, a region based stereo matching algorithm is developed for extracting depth information from a color stereo image pair, which is based on region growing. The algorithm includes two parts, i. e. root selection process and region growing process, and needs less calculation time to obtain disparity map. Filtering is adopted to increase the reliability of disparity map. Finally, the obtained results using this algorithm are presented and compared.
{fenge}
79959864039	Structural SIMilarity optimal MB layer rate control algorithm for H.264	Conventional Rate Control (RC) schemes take mostly objective metric as distortion measurement, which can not acquire optimal subjective quality. This paper applies Structural SIMilarity (SSIM) based subjective distortion to Rate Distortion Optimization (RDO) and RC in H.264 video coding, and proposes a SSIM optimal MacroBlock (MB) layer RC algorithm. First, an empirical SSIM linear distortion model is put forward. Then an improved quadratic Rate-Quantization (R-Q) model is combined to obtain the close-form solution of SSIM optimal MB layer quantization step by Lagrange multiplier. Experimental results show that the proposed method preserves much more image structural information and thus acquires better subjective quality compared with objective quality optimal MB layer RC scheme JVT-O016.
{fenge}
79960539346	Motion vector recovery method based on Mean Shift procedure	This letter presents a novel Motion Vector (MV) recovery method which is based on Mean Shift (MS) procedure. According to motion continuity, MVs in local area should be similar. If projecting MV into 2-D feature space, local MVs in the feature space tend to cluster closely. To estimate the lost MVs in local area, recovery of lost MVs is modeled as clustering operation. MS procedure is applied to enforce each lost MV in the feature space to shift to the position where dominant MVs are gathered. Meanwhile, bandwidth estimation is statistically characterized by the variation of local standard deviations; weighted value calculation is determined by estimation of overall standard deviation. Simulation results demonstrate their better performance when compared with other MV recovery approaches and low computation cost. © 2010 Science Press, Institute of Electronics, CAS and Springer-Verlag Berlin Heidelberg.
{fenge}
80052989907	Learning based adaptive denoising approach for image interpolation	In this paper, we propose an effective image interpolation framework through learning based adaptive denoisng approach. In the local area, error pattern between original image and interpolated image is treated as stationary Gaussian distribution. Under the initial estimation, the proposed method apply the patch as the basic unit, in which Multiclass SVM classifier is used to determine iteration number and denoise parameters. There are two steps in iterative processing, including adaptive denoise and data fusion. Experiment results shown the proposed method can significantly improve the interpolated image quality both subjectively and objectively. © 2011 IEEE.
{fenge}
80053022644	Subjective quality optimized intra mode selection for H.264 I frame coding based on SSIM	H.264/AVC adopts rate distortion optimization (RDO) technique to select optimal macroblock (MB) coding mode and achieves higher compression efficiency, but the traditional RDO framework employs pixelwise mean square error (MSE) and the like as objective distortion metric, which can not acquire optimal subjective quality. This paper applies structural similarity (SSIM) based subjective distortion to RDO-based intra mode decision in H.264 I frame coding, and further proposes a frame layer adaptive Lagrange multiplier adjustment scheme to get better tradeoff between rate and SSIM distortion. Experimental results show that, the proposed scheme encodes more image structural information and thus acquires better subjective quality and coding efficiency compared with MSE-based RDO method. © 2011 IEEE.
{fenge}
80053032044	Single image super resolution method based on edge preservation	In this paper, we present a novel super resolution (SR) framework based on edge preservation. The iterative back-projection algorithm (IBP) is a classical SR method and has low computational complexity, which can be applied in real time applications. However, it often produces many artifacts especially along the strong edges. To reduce the jaggy artifacts, our approach has three steps. First, we improve the initial estimate using bilateral filtering to strengthen the true edges. Second, we learn the structural content of low resolution pixel and the correlation among the pixels with similar structure. Third, we use the correlation to guide the output image reconstructed by the IBP algorithm. The experimental result proved that our proposed method can remove the artifacts and obtain clear and sharp edges in visual perception. © 2011 IEEE.
{fenge}
80054695472	Adaptive rate selection scheme for video transmission to resolve IEEE 802.11 performance anomaly	Multi-rate transmission may lead to performance anomaly in an IEEE 802.11 network. It will decrease the throughputs of all the higher rate stations. This paper proposes an adaptive rate selection scheme for video service when performance anomaly occurs. Considering that video has the characteristic of tolerance to packet loss, we actively drop several packets so as to select the rates as high as possible for transmitting packets. Experiment shows our algorithm can decrease the delay and jitter of video, and improve the system throughput as well. © 2011 Copyright Society of Photo-Optical Instrumentation Engineers (SPIE).
{fenge}
83355169275	A novel cross-layer strategy of video transmission to solve performance anomaly in multi-rate IEEE 802.11 networks	When wireless hosts use different rates to transmit data in IEEE 802. 11 networks, it will take on the state of performance anomaly which will severely decrease the throughputs of all the higher rate hosts. Hence, it is bad for video service transmission. Considering that video is very sensitive to packet delivery delay but can tolerate some packet losses, we propose a novel cross-layer scheme which takes these two characteristics into consideration. Firstly, the maximum number of retransmissions for a video Medium Access Control (MAC) frame is computed in MAC layer according to video frame rate requirement of application layer and current access delay of MAC layer. Secondly, within the margin of the tolerant Packet Loss Rate (PLR) of application layer, several video MAC frames are allowed to drop so that we can adaptively select the transmission rate as high as possible for the rest of video MAC frames in terms of current channel quality and the maximum number of retransmissions. Experiment results show that the proposed method can reduce the delay and jitter of video service and improve the throughputs of fast hosts. Therefore, it increases the quality of reconstructed video to a certain extent and relieves the performance anomaly of network effectively. © 2011 Science Press, Institute of Electronics, CAS and Springer-Verlag Berlin Heidelberg.
{fenge}
84555171078	Improved SAI method using non-local spatial constraint for image interpolation	This paper proposes an improved image interpolation method based on the soft-decision adaptive interpolation (SAI) algorithm. Natural images often contain repeatable patterns and structures throughout the image, which is called non-local property. We can use this non-local strategy to improve the interpolation quality by better estimating the model parameters and Lagrangian multiplier. There are two steps in our method. In the first step, similar patches of the given block are found in the initialized high resolution image, and the model parameters can be determined properly using the expanded piecewise auto regression (PAR) model and non-local spatial constraint. In the second step, the self-similarity of patches across the high and low resolution images is exploited to solve the Lagrangian multiplier , thus to make the data estimation robust. Experiments indicate that the improved method can achieve good results both subjectively and objectively. © 2011 IEEE.
{fenge}
84555186951	Vehicle color recognition using monocular camera	This paper introduces a novel moving vehicle color recognition method. By processing videos recorded by monocular camera on traffic, we get single color image of vehicles which are crossed the traffic in any direction. First, paper employed a H-S two dimension histogram method to detect the color of the vehicles, and distinguish red, yellow, green and blue four color vehicles. Due to deal with the vehicles that do not satisfy above 4 colors, Regional Color Judgment method is proposed. This method consists of the following five steps: Firstly, position the color detection region by identifying the travelling direction of the vehicle. Then pick out the candidate color extraction region used to vehicle recognition. At last extract the color of the candidate region and match the color with the templates we predefined, the color of the best fit template is the color of the vehicle. © 2011 IEEE.
{fenge}
84555191947	An adaptive image denoising method for mixture Gaussian noise	In real applications, different regions in the image will often be corrupted by different noise. This paper discusses this problem and proposes an adaptive image denoising method for mixture Gaussian noise in an image. There are two phases in our proposed method: noise estimation and noise removal. To estimate different noise standard deviations in different regions, a high-pass filter using two-order difference is applied first. Then we divide the filtered image into a number of blocks and compute the histogram of all the blocks' standard deviations. An averaging over the peak will estimate the noise standard deviation in one region. Finally, we combine data fusion with an existent denoising method to remove noise. Experiments with test images show that our proposed method leads to good results. © 2011 IEEE.
{fenge}
84863016097	Joint spatial-temporal quality improvement scheme for H.264 low bit rate video coding via adaptive frameskip	Conventional rate control (RC) schemes for H.264 video coding usually regulate output bit rate to match channel bandwidth by adjusting quantization parameter (QP) at fixed full frame rate, and the passive frame skipping to avoid buffer overflow usually occurs when scene changes or high motions exist in video sequences especially at low bit rate, which degrades spatial-temporal quality and causes jerky effect. In this paper, an active content adaptive frame skipping scheme is proposed instead of passive methods, which skips subjectively trivial frames by structural similarity (SSIM) measurement between the original frame and the interpolated frame via motion vector (MV) copy scheme. The saved bits from skipped frames are allocated to coded key ones to enhance their spatial quality, and the skipped frames are well recovered based on MV copy scheme from adjacent key ones at the decoder side to maintain constant frame rate. Experimental results show that the proposed active SSIM-based frameskip scheme acquires better and more consistent spatial-temporal quality both in objective (PSNR) and subjective (SSIM) sense with low complexity compared to classic fixed frame rate control method JVT-G012 and prior objective metric based frameskip method. © 2012 KSII.
{fenge}
84863196227	Fast keypoint extraction and matching robust to illumination changes	An integral images-based fast keypoint extraction and matching method being robust to illumination changes is presented. First, robust illumination local features are fast extracted by multi-scale up-sampling and filtering the Riemann integral of the stretched contrast responses using integral images, and multi-scale interest feature keypoints are detected based on local maximum of them in a multi-resolution framework. Secondly, covariance descriptors are constructed with integral images for the center-symmetrical rectangular regions around the obtained points, then the Log-Euclidean metrics are adopted to measure the difference between the covariance matrices around the keypoints from two matching scenes. Finally, automatic matching between two feature point sets is implemented with the sparse matching strategy. Experimental results prove that the proposed method is of simple structure, fast and efficient computation with high accuracy, while being adaptive for illumination changes.
{fenge}
84863345235	Adaptive dictionary learning for distributed compressive video sensing	Compressive sensing (CS) is a new technique for data sampling and compression simultaneously. In this paper, we propose a novel distributed video coding algorithm with dynamic measurement rate allocation based on compressive sensing principles, where almost all computation burdens can be shifted to the decoder, resulting in a very low-complexity encoder. So the proposed algorithm can be useful in those video applications that require very low complex encoders. At the decoder, the compressed video can be efficiently reconstructed with adaptive dictionary learning. The simulation results show that the proposed algorithm outperforms the distributed compressive video sensing with non-adaptive learning local dictionary and global dictionary.
{fenge}
84863348775	A video code based on distribution compressive sensing	Compressed sensing (CS) is a new technique for simultaneous data sampling and compression. In this paper, we propose a new video coding algorithm based on Distributed Compressive Sampling(DCS) principles, where almost all computation burdens can be shifted to the decoder, resulting in a very lowcomplexity encoder. At the decoder, compressed video can be efficiently reconstructed. Our algorithm can be useful in those video applications that require very low complex encoders. Simulation results show that our scheme compares favorably with existing schemes at a much lower implementation cost. © 2011 Published by Elsevier Ltd.
{fenge}
84863249261	Subjective rate-distortion performance improvement scheme for H.264 based on SSIM	H.264 takes objective metric as distortion criteria to perform Rate Control (RC) and Rate Distortion Optimization (RDO)-based mode decision, which can not acquire optimal subjective quality. Base on our previous research results, this paper applies Structural SIMilarity (SSIM) based subjective distortion to RDO-based inter mode decision in H.264 video coding, and further proposes an analytic MacroBlock (MB) layer Lagrange multiplier adjustment scheme to adaptively balance the tradeoff between rate and SSIM distortion better. Experimental results show that, at given target bit rate, the proposed method encodes image structural information more effectively, and thus acquires better subjective RDO performance and image quality compared with objective quality based encoding scheme and SSIM-based RC method (without performing SSIM-based RDO inter prediction).
{fenge}
84864114118	A Wyner-Ziv Video Coding method utilizing mixture correlation noise model	In Wyner-Ziv (WZ) Distributed Video Coding (DVC), correlation noise model is often used to describe the error distribution between WZ frame and the side information. The accuracy of the model can influence the performance of the video coder directly. A mixture correlation noise model in Discrete Cosine Transform (DCT) domain for WZ video coding is established in this paper. Different correlation noise estimation method is used for direct current and alternating current coefficients. Parameter estimation method based on expectation maximization algorithm is used to estimate the Laplace distribution center of direct current frequency band and Mixture Laplace-Uniform Distribution Model (MLUDM) is established for alternating current coefficients. Experimental results suggest that the proposed mixture correlation noise model can describe the heavy tail and sudden change of the noise accurately at high rate and make significant improvement on the coding efficiency compared with the noise model presented by DIStributed COding for Video sERvices (DISCOVER). © 2012 Science Press, Institute of Electronics, CAS and Springer-Verlag Berlin Heidelberg.
{fenge}
84867603832	Fast local stereo matching via DAISY descriptor and modified weight kernel	A fast stereo matching based on DAISY feature descriptor and modified weight kernel is proposed to eliminate the ambiguity of binocular stereo problem. Firstly, the local DAISY feature descriptors of both stereo pairs are constructed fast and densely for initial matching costs being calculated from the features; two-pass aggregation with Epanechnikov weight kernel for the reliable costs are applied to resolve ambiguity of matching feature similarities; each pixel's initial disparity is obtained via Winner-Takes-All optimization from them. Secondly, in order to improve the quality of disparity map, we adopt sequentially the refining procedures with modified bilateral filtering, symmetric consistency check and multi-directional weighted disparity extrapolation. The experiments indicate that this technique with concise structure and low complexity can improve effectively the matching accuracy and obtain comparably accurate and piecewise smooth dense disparity map.
{fenge}
84868226650	Fast stereo matching via illumination invariant features and modified support weights	A fast stereo matching method based on illumination invariant features and modified support weights is proposed to determine the correspondences in different images of the same scene taken from different viewpoints. Firstly, illumination invariant features are constructed densely for the stereo pairs and initial matching costs are calculated from the invariant features; robust matching costs are obtained based on two-pass aggregation with tri-cube weight kernels; and initial disparities are selected using Winner-Takes-All optimization method. Secondly, intelligent disparity inpainting procedures are in turn implemented or executed with modified bilateral filtering based on multi-directional neighbor tri-cube weight kernels, occlusion detection and disparity error concealment. Experiments indicate that this technique with low computational burden, can produce comparably satisfactory dense disparity map, and can improve the adaptability to illumination variations.
{fenge}
84868564437	Error concealment techniques for video transmission over error-prone channels: a survey	Efficient video transmission over unreliable channels may encounter huge challenge due to unavoidable bit error or packets loss. Error concealment (EC) techniques at the decoder side have been developed to recover the damaged regions utilizing spatial or temporal redundant information without changing the encoder structure or adding extra bandwidth. In this work the classic EC techniques and their developments are first reviewed, high-level semantics based EC schemes are also surveyed, and then the emphasis is focused on new EC features introduced by H.264/AVC. Finally, the challenges and future development directions in EC for advanced video coding schemes such as scalable video coding (SVC), multiple description coding (MDC), multi-view video coding (MVC) and stereo video coding are prospected, and future research directions are also indicated according to the current research status and existent problems. © 2012 Binary Information Press.
{fenge}
84872445749	A fast compressed-sensing image reconstruction algorithm based on best linear estimate	Because of existing Compressed-Sensing (CS) reconstruction algorithms have high computing complexity, a fast algorithm based on best linear estimate is proposed. It adaptively measures image data with a block-by-block manner at encoder, and reconstructs each block at decoder using the best linear operator which is constituted by statistical autocorrelation function matrix estimated according to various statistical property of image block. This algorithm replaces lots of nonlinear iterations in traditional CS reconstruction algorithm with linear projection, therefore it shorten the time of recovering image. Simulation experimental results indicate that the proposed algorithm not only reduces the time of rebuilding image, but also is better than the current popular CS reconstruction algorithm for images containing uncomplicated textures on the reconstructed image quality.
{fenge}
84872148226	Stereo matching using aggregated likelihood and multi-scale prior	This paper proposes a novel global stereo matching method using aggregated likelihoods and multi-scale priors. The likelihoods of dense stereo correspondences as data term can be robustly expressed by aggregated matching costs based on Weber feature descriptors in an asymmetrical linear filtering model. The multi-scale priors on disparity surface are designed to capture scene smooth term from larger neighborhood besides 4-connected neighborhood. The presented stereo approach being relatively simple does not rely on image segmentation and any scene semantic analysis. Experiments demonstrate that the proposed stereo matching algorithm can produce the dense smooth disparity results comparable to those of excellent stereo matching techniques. © 2012 IEEE.
{fenge}
84874557194	A cost construction via MSW and linear regression for stereo matching	This paper proposes a new cost construction method with multiscale Weber (MSW) descriptor and weighted linear regression for robust stereo matching in a two-layer hierarchical structure. Firstly, the MSW descriptors extracted from stereo pairs are utilized to combined raw matching costs to reduce the disparity search range. Secondly, the indispensable matching costs on the subsets of disparity candidates are aggregated by spatial moving discrete sampling and weighted least square. The proposed cost technique can provide an effective and efficient way to reflect robust visual dissimilarity measure for local stereo approach. Experimental results on the Middlebury benchmark datasets demonstrate the validity of this cost construction which can eliminate effectively the ambiguity of stereo matching. © 2012 ICPR Org Committee.
{fenge}
84874566859	A PCA-based smoothed projected Landweber algorithm for block compressed sensing image reconstruction	This paper presents a smoothed projected Landweber (SPL) algorithm using Principal Component Analysis (PCA) for Block Compressed sensing (BCS). In order to overcome the defect that traditional SPL algorithms using directional transforms are not appropriate for any kind of images on account of their pre-specified property, we fully exploit PCA to train an orthonormal transformation matrix adapted to the content of image, and then use it do hard thresholding to replace the bivariate shrinkage existing in traditional methods. Since the orthonormal transformation matrix is adapted to the content of image, the process of hard thresholding can efficiently reduce noise and enforce the sparsity of image so as to improve the quality of reconstructed image. Experimental results reveal the proposed algorithm outperforms the SPL algorithms using directional transforms in aspect of Peak Signal-to-Noise Ratio (PSNR), although our proposed algorithm is a little slower than them. © 2012 IEEE.
{fenge}
84874571928	Novel neighbor embedding super resolution method for compressed images	In this paper, we focus on the super resolution (SR) reconstruction for compressed images. Compressed images have low quality by suffering from quantization errors and compression artifacts. We propose a novel learning-based SR method that is based on the local linear embedding (LLE). A new feature vector using the discrete cosine transform coefficients of the norm luminance is proposed. It represents the character of the image patch in the transform domain. Compared with several existing feature selections, this new feature vector can preserve edges better and capture more details. It is more suitable for the compressed image. We also optimize the training set. Experimental results show that our method gets better performance both in objective and subject. © 2012 IEEE.
{fenge}
84874719248	Side information extrapolation using motion-aligned auto regressive model for compressed sensing based Wyner-Ziv codec	In this paper, we propose a compressed sensing (CS) based Wyner-Ziv (WZ) codec using motion-aligned auto regressive model (MAAR) based side information (SI) extrapolation to improve the compression performance of low-delay distributed video coding (DVC). In the CS based WZ codec, the WZ frame is divided into small blocks and CS measurements of each block are acquired at the encoder, and a specific CS reconstruction algorithm is proposed to correct errors in the SI using CS measurements at the decoder. In order to generate high quality SI, a MAAR model is introduced to improve the inaccurate motion field in auto regressive (AR) model, and the Tikhonov regularization on MAAR coefficients and overlapped block based interpolation are performed to reduce block effects and errors from over-fitting. Simulation experiments show that our proposed CS based WZ codec associated with MAAR based SI generation achieves better results compared to other SI extrapolation methods. © 2013 KSII.
{fenge}
84875441687	Dynamic measurement rate allocation for distributed compressive video sensing	A novel distributed video coding scheme with dynamic measurement rate allocation is proposed based on compressive sensing principle. It features in simple encoder, strong bit error resistant ability and high encoding efficiency. At the encoder, key frame and non-key frame are encoded independently. The former employs compressive sensing measurement with high sampling rate and the latter employs adaptive compressive sensing measurement. At the decoder, key frame and non-key frame are jointly reconstructed through compressive sensing using non-local sparsity model and dictionary learning update algorithm. Experimental results have shown that the proposed encoding algorithm can achieve quite good rate distortion performance and subjective image quality.
{fenge}
84875461556	An improved super-resolution reconstruction algorithm with locally linear embedding	An improved super resolution reconstruction algorithm is proposed with locally linear embedding. The improvement includes three aspects. Firstly, the DCT coefficients of low resolution image patches are taken as the feature representative instead of the first order and second order gradients, which will reduce the effect of noise. Secondly, the number of adjacent blocks is chosen adaptively according to the relationship between the input low resolution image patch and its neighbors, which will avoid the possibility of choosing a distant patch as neighbor. Thirdly, the training sample of the high resolution image is taken as the residual image resulting from the difference between the high resolution image and the corresponding low resolution one. This can not only avoid the disturbance of low frequency components, but also reduce the number of smoothness computation. The experimental results have shown that the improved algorithm can achieve a better reconstruction effect with improved PSNR of 4.07 dB and improved SSIM of 0.0654 compared to the existing LLE algorithm, and improved PSNR of 0.62 dB and improved SSIM of 0.0066 compared to the sparse representation algorithm. In addition, using DCT coefficients as the feature representative reduces the computational complexity in that the number of the extracted features needed is only a quarter of that using the first order and second order gradients.
{fenge}
84876462316	Adaptive video back projection super-resolution method using non-local prior	In this paper, a novel video back projection super-resolution method using non-local prior is proposed. Our approach has three steps. First, we make initial motion estimation with block-matching and fine block matching to search for the pixels with similar structural content from video sequences. In this process, an adaptive technique is introduced to avoid redundant search. Second, we do initial interpolation to the input video sequences and a bilateral filtering is applied to the interpolation frames to achieve edge-preserving image smoothing. Third, a video non-local means filter is applied to modify the error image in iteration step of the iterative back projection. The experimental result shows that the proposed method can increase image details, moreover, the chessboard effect and ringing effect along image edges can be removed and sharp and clear edges in visual perception will be obtained. © 2012 IEEE.
{fenge}
84876485256	Novel colorization method based on correlation neighborhood similarity pixels priori	Colorization is a computer-aided process of automatically adding colors to grayscale images or videos according to the colors scribbled on by the user. In this paper, we propose a novel colorization method which based on correlation neighborhood similarity pixels priori. First, according to a key observation that similar intensities neighboring pixels have similar colors, our method searches the similarity neighborhood pixels group. Then, we compute the weighted coefficients of the neighborhood pixels in the luminance image and transmit the weighted coefficients to the chrominance. Finally, we obtain the chrominance values by solving a quadratic optimization problem which uses the colors scribbled on by the user as the linear constraints. The experimental results show that our approach is quite effective especially in the boundary parts. Moreover, our method can give better visually results when only a few colors scribbled on. © 2012 IEEE.
{fenge}
84876490912	Free viewpoint action recognition based on self-similarities	Action recognition is an important topic in computer vision and most current work focuses on view-dependent representations. In this paper, we develop a novel free viewpoint action recognition based on Self-similarity matrix (SSM), which tends to be stable across views. We choose Local Self-similarity (LSS) descriptor as our low-level feature, then SSM is calculated by computing the similarity between any pair of frame features. Each video sequence is represented using a diagonal descriptor vector extracted from the SSM. Support Vector Machines (SVM) is employed for classification. The encouraging experimental results on the public IXMAS multi-view data set demonstrate effectiveness of the proposed method. © 2012 IEEE.
{fenge}
84876493530	Stereo matching based on robust likelihoods and MST leveraged smoothness priors	This paper proposes a global stereo correspondence using robust matching likelihoods and minimum spanning tree (MST) leveraged smooth priors in a probabilistic graphical model framework. The matching likelihoods of the stereo correspondence can be robustly constructed as data term by aggregating initial matching costs from Weber local descriptors using an unsymmetrical guided filtering in a linear model. The disparity priors are devised as smooth term to characterize the smoothness constraints leveraged by the MST structure. The presented stereo approach provides an effective and efficient way to reflect robust visual dissimilarity and resolve local and regional discontinuities. Experiments demonstrate that the proposed global stereo matching method can produce piecewise smooth, accurate and dense disparity map, while removing effectively the visual ambiguity of the stereo matching problem. © 2012 IEEE.
{fenge}
84876497971	Image demosaicing by non-local similarity and local correlation	Conventional single-chip digital cameras use color filter arrays(CFA) to sample different spectral components. Image demosaicing is a problem of interpolating these data to complete red, green, and blue values for each image pixel, to produce an RGB image. Many color demosaicing(CDM) methods assume that the high local spatial redundancy exists among the color samples. Such an assumption, however, may be fail for images with high color saturation and sharp color transitions. This paper presents an adaptive demosaicing algorithm by exploiting both the non-local similarity and the local correlation(NLS-LC) in the color filter array image. First, the most flattest nonlocal image patches are searched in the searching window centered on the estimated pixel. Second, the patch, which is the most similar to the current patch, is selected among the most smoothest nonlocal patches. Third, according to the similar degree and the local correlation degree, the obtained nonlocal image patch and the current patch are adaptively chosen to estimate the missing color samples. Experimental results indicate that the proposed method exhibits superior performance over many state-of-the-art color interpolation methods. © 2012 IEEE.
{fenge}
84876499419	Super-resolution algorithm through neighbor embedding with new feature selection and example training	An improved super-resolution algorithm through neighbor embedding with new feature selection and example training is proposed for single image super resolution reconstruction. Firstly, we take the DCT coefficients as the feature vectors, and then adaptively choose neighbors by k-means clustering algorithm. Finally, we learn the neighborhood relationship between interpolated image from low resolution image and its corresponding high resolution image. The experimental results show that the improved algorithm can not only achieve a better recovery of a single low resolution image comparing with the original neighbor embedding algorithm, but also reduce the computational complexity. © 2012 IEEE.
{fenge}
84877669021	Flexible planes extraction for interactive-friendly multiview stereo in architectural scenes	This paper proposes an automatic planes extraction approach to recover hypothesis planes of architectural scenes, being easily adopted in interactive-friendly multiview reconstruction systems. There exist many interactive scene reconstruction algorithms designed to model these real worlds, but they are very labor-intensive and difficult to verify whether the resulting 3D models are accurate or not. Motivated by the strongly piecewise planar property of architectural scenes, the hypothesis 3D planes can be generated automatically and flexibly in our work, being faster, more accurate and labor-saving than that of manually processing. Firstly, initial oriented points are reconstructed by using structure-from-motion and patch-based multiview stereo. Secondly, non-parametric density-based clustering technique is exploited to extract plane normal vectors without any presumption on the prior distributions of the normals of the planes, unlike famous Manhattan-world assumption. Then, the offsets of the planes can be estimated to specify the locations of the assumed 3D planes. Each group of the normal vectors and offset distances along the corresponding normals can determine certain candidates of plane structures. The obtained hypothesis planes are very beneficial to interactive-friendly multiview reconstruction with its efficiency and labor-saving, without measuring the sites, locating and digitizing architectural planes or converting existing CAD data. © 2012 IEEE.
{fenge}
84878222395	Joint motion-compensated interpolation using eight-neighbor block motion vectors	Novel joint motion-compensated interpolation using eight-neighbor block motion vectors (8J-MCI) is presented. The proposed method uses bi-directional motion estimation (BME) to obtain the motion vector field of the interpolated frame and adopts motion vectors of the interpolated block and its 8-neighbor blocks to jointly predict the target block. Since the smoothness of the motion vector filed makes the motion vectors of 8-neighbor blocks quite close to the true motion vector of the interpolated block, the proposed algorithm has the better fault-tolerancy than traditional ones. Experiments show that the proposed algorithm outperforms the motion-aligned auto-regressive algorithm (MAAR, one of the state-ofthe-art frame rate up-conversion (FRUC) schemes) in terms of the average PSNR for the test image sequence and offers better subjective visual quality. Copyright © 2013 The Institute of Electronics, Information and Communication Engineers.
{fenge}
84878769874	An error concealment algorithm for stereoscopic images based on local reliable disparities	In order to minimize the transmission errors for stereoscopic images, we propose an error concealment algorithm based on local reliable disparities. First, taking the block loss and the factors of color similarity and geometric distance proximity into account, we design a base-point-biased window to conduct the adaptive weight disparity matching. Second, local reliable disparities are calculated according to the disparity constancy and left-right consistency. Finally, the Winner-Takes-All (WTA) strategy is adopted to estimate the disparity of lost block which will be used to get the data of corresponding block for error concealment. Experimental results show that compared with other algorithms, the proposed method can produce better PSNR and subjective quality of reconstructed image while the computational complexity is almost the same.
{fenge}
84879754008	Edge classification based DCT coefficients reorganization for Wyner-Ziv distributed video coding	Distributed video coding (DVC) is a novel video coding paradigm. One approach to DVC is Wyner-Ziv distributed video coding. Quantization step (QS) is one of the most important factors deciding encoder's coding efficiency. In this paper, an edge classification based Discrete Cosine Transform (DCT) coefficients reorganization method was proposed. The block was first classified into horizontal-edge block, vertical-edge block and other block. Then different scanning order was applied to each class of blocks. In this way, larger coefficients might be grouped together and QS for Alternating Current (AC) coefficients might be reduced. Experimental results show that compared with DISCOVER's method, the proposed method makes PSNR of reconstructed image increase about 0.5dB at high bit rate. © (2013) Trans Tech Publications, Switzerland.
{fenge}
84880293677	Sampling adaptive block compressed sensing reconstruction algorithm for images based on edge detection	In this paper, a sampling adaptive for block compressed sensing with smooth projected Landweber based on edge detection (SA-BCS-SPL-ED) image reconstruction algorithm is presented. This algorithm takes full advantage of the characteristics of the block compressed sensing, which assigns a sampling rate depending on its texture complexity of each block. The block complexity is measured by the variance of its texture gradient, big variance with high sampling rates and small variance with low sampling rates. Meanwhile, in order to avoid over-sampling and sub-sampling, we set up the maximum sampling rate and the minimum sampling rate for each block. Through iterative algorithm, the actual sampling rate of the whole image approximately equals to the set up value. In aspects of the directional transforms, discrete cosine transform (DCT), dual-tree discrete wavelet transform (DDWT), discrete wavelet transform (DWT) and Contourlet (CT) are used in experiments. Experimental results show that compared to block compressed sensing with smooth projected Landweber (BCS-SPL), the proposed algorithm is much better with simple texture images and even complicated texture images at the same sampling rate. Besides, SA-BCS-SPL-ED-DDWT is quite good for the most of images while the SA-BCS-SPL-ED-CT is likely better only for more-complicated texture images. © 2013 The Journal of China Universities of Posts and Telecommunications.
{fenge}
84880996170	Error concealment algorithm for stereoscopic images based on boundary smoothness criteria	An error concealment algorithm based on boundary smoothness criteria is proposed in order to solve the problem of errors in stereoscopic images. Considering the factors of color similarity and geometric distance proximity, we conduct the adaptive-weight disparity matching for the reference blocks of the lost blocks according to the disparity relativity. We give the cost function of boundary smoothness and select the block with the most smooth boundary as the preliminary concealment result. Finally, we carry out different algorithms to refine the preliminary concealment result according to the property of the lost block which is judged by the boundary smoothness criteria again. Experiment results show that the proposed method can outperform other algorithms in terms of the subjective and objective quality.
{fenge}
84885065683	Colorization-based single frame color image super-resolution	For single-frame color image super-resolution, most techniques use super-resolution reconstruction only on the Y-channel. Usually directly use interpolation algorithms for the chrominance channels (U, V) which decide the color. Because interpolation algorithm often produces "jaggy" and "ringing" artifacts, this paper integrated colorization into color image SR using the colorization algorithm to enhance the low-resolution (LR) chrominance channels and the iterative back-projection (IBP) method to improve the accuracy of the LR chrominance information. This paper also proposed a colorization-based IBP (CIBP) algorithm to enhance the traditional interpolation-based IBP algorithm. Experimental results demonstrated that compared with the bicubic-interpolation algorithm and the latest colorization-based chrominance process algorithm, the proposed algorithm can reconstruct the high-resolution (HR) chrominance channels with higher Peak Signal Noise Ratio (PSNR) and Structural Similarity (SSIM).
{fenge}
84885067981	The research on compressive sensing based still image compression in wireless sensor network	The traditional still image compression standard JPEG and JPEG2000 are not appropriate for a camera sensor in the wireless sensor network since it is limited by the power consumption, costs and wireless transmission environment. In order to meet the "light encoding and heavy decoding" characteristic of the wireless sensor network, this paper proposes a novel still image compression scheme based on the compressive sensing (CS). The scheme measures each image block at the encoder and adaptively assign the number of measurement for each block in terms of their edge information. At the decoder, the scheme uses the measurements of each block to reconstruct the whole image. Simulation results show that the proposed scheme can effectively reduce the cost of CS measuring in comparison with the existing CS based image compression schemes, and it can also remove edge blurs and blocking artifacts in the reconstructed image.
{fenge}
84886794490	Joint overlapped block motion compensation using eight-neighbor block motion vectors for frame rate up-conversion	The traditional block-based motion compensation methods in framerate up-conversion(FRUC) only use a single uniquely motion vector field. However, there will always be some mistakes in the motion vector field whether the advancedmotion estimation (ME) and motion vector analysis (MA) algorithmsare performed or not.Once the motion vector field hasmany mistakes, the quality of the interpolated frame is severely affected. In order to solve the problem, this paper proposesa novel joint overlapped block motion compensation method(8J-OBMC)which adopts motion vectors of the interpolated block and its 8-neighbor blocks to jointly interpolatethe target block. Since the smoothness of motion filed makes the motion vectors of 8-neighbor blocks around the interpolated block quite close to the true motion vector of the interpolated block, the proposed compensation algorithmhas the better fault-tolerant capability than traditional ones. Besides, the annoying blocking artifacts can also be effectively suppressed by using overlapped blocks. Experimental results show that the proposed method is not only robust to motion vectorsestimated wrongly, but also can to reduce blocking artifactsin comparisonwith existing popular compensationmethods. © 2013 KSII.
{fenge}
84889240507	Novel reconstruction based image super resolution	In this paper, a novel reconstruction based single image super-resolution method is proposed. The proposed method have two step in the iterative manner. Firstly, the back-projection process is used to reconstruct the high resolution image. Then, adaptive kernel regression denoising in the modifying process can strengthen the true edges. Moreover, only the the edge area of the high resolution image is filtered in proposed method. In this way, the algorithm has low complexity, while maintaining performance. Experimental results demonstrate that the proposed method can reconstruct high quality images in both the measure of objective quality and the subjective perception. © 2013 Binary Information Press.
{fenge}
84889675281	Distortion measurement based dynamic packet scheduling of video stream over IEEE 802.11e WLANs	In H.264, three different data partition types are used, which have unequal importance to the reconstructed video quality. To improve the performance of H.264 video streaming transmission over IEEE 802.11e Wireless Local Area Networks, a prioritization mechanism that categorizes different partition types to different priority classes according to the calculated distortion within one Group of Pictures. In the proposed scheme, video streams have been encoded based on the H.264 codec with its data partition enabled. The dynamic scheduling scheme based on Enhanced Distributed Channel Access has been configured to differentiate the data partitions according to their distortion impact and the queue utilization ratio. Simulation results show that the proposed scheme improves the received video quality by 1dB in PSNR compared with the existing Enhanced Distributed Channel Access static mapping scheme. © 2013 KSII.
{fenge}
84892844798	Segment based depth extraction approach for monocular image with linear perspective	In this paper, a segment-guided depth extraction approach is proposed for monocular image with linear perspective. Firstly, foreground depth is learned from a RGBD database with segment-based calibration to adjust the initial coarse depth, and background depth is estimated from linear perspective by vanishing cues. Then, the foreground depth and background one are linearly combined with a statistically optimal balance factor to obtain a holistic fused depth map. Lastly, bilateral filter is exploited to suppress the depth disturbance with edge-preserving. Experiments demonstrate that the proposed technique can produce accurate and dense depths with distinct object boundaries and correct relation among the object positions for a single image. © 2013 Springer-Verlag Berlin Heidelberg.
{fenge}
84893567703	Intra mode decision and frame layer Lagrange multiplier adjustment scheme for H.264 based on structural similarity	H.264 takes rate distortion optimisation (RDO) technique to perform intra and inter mode decision and achieves higher coding efficiency, but the objective distortion metric such as mean square error (MSE) is employed in traditional RDO framework, which cannot acquire optimal subjective quality. In this paper, structural similarity (SSIM)-based subjective distortion is applied to RDObased intra mode decision in H.264 I frame video coding, and a linear SSIM distortion model is firstly proposed and SSIM-based rate distortion cost function for intra mode decision is defined. Furthermore, a content adaptive frame layer Lagrange multiplier adjustment scheme is proposed to balance the tradeoff between rate and SSIM distortion better. Experimental results show that, the proposed method encodes image structural information more effectively and thus acquires better perceptual quality and subjective RDO performance compared with objective distortionbased RDO method. Under the same perceptual quality, our scheme achieves about 8.03% I frame bit rate reduction on average for various sequences over MSE-based RDO employed in JM reference software. © 2014 RPS.
{fenge}
84894715178	Advances in rate distortion optimization and rate control techniques for H.264 video coding	Based on the researches of rate distortion optimization (RDO) and rate control (RC) techniques for H.264, this paper divides the development of RDO and RC into three phases based on RC intention, namely rate distortion modeling, considering the effect of quality fluctuation on subjective quality, subjective distortion guided RC; analyzes the characteristics of representative RC techniques of each phase, and focuses on the key and difficult issues of RC needed to be further researched. Then summarizes the RC schemes for transmission oriented error resilient video coding, scalable video coding (SVC) and multiple description coding (MDC) as well as stereo and multi-view video coding, and analyzes further research trends. Finally, how to develop the RC schemes for high efficiency video coding (HEVC) is discussed.
{fenge}
84894456717	Super-resolution based on two dictionary-pairs	For learning-based super-resolution reconstruction, the selection and training of dictionary play an important role in improving image reconstruction quality. A super-resolution algorithm based on two dictionary-pairs is proposed in this paper. This algorithm selects image's high- and mid-frequency components as the features of high- and low-resolution patches respectively, and gets the first dictionary-pair, i.e. joint-basic high/low-resolution dictionary-pair, by means of joint training. Then it calculates the difference between original high/mid-frequency components and reconstructed high/mid-frequency components with the first dictionary-pair, and composes the second dictionary-pair, i.e. residual high- and low-resolution dictionary-pair. During super-resolution reconstruction, the high-frequency component and residual high-frequency component of low-resolution image are reconstructed respectively with the above two dictionary-pairs. The experiment results show that, the subjective and objective reconstruction quality could be effectively improved by our proposed algorithm. © 2013 IFSA.
{fenge}
84897741525	Adaptive joint nonlocal means denoising back projection for image super resolution	In this paper, we present a novel adaptive joint nonlocal means de-noising back projection super resolution method. The iteration of our SR method consists of two steps: ordinary back projection and the high-frequency data filtering for the reconstruction image by using joint nonlocal means denoising, in which self-similarity structures are obtained by the bicubic interpolation image. Furthermore, the content-adaptive filtering and fast self-similarity search strategy are very help for reduce computation complexity, while maintaining the performance. Despite our method conceptual simplicity, the experimental result show the proposed method can achieve comparable performance to other leading algorithms. © 2013 IEEE.
{fenge}
84897486096	Block compressed sensing reconstruction of video combined with temporal-spatial characteristics	To improve the rate-distortion performance of video Compressed Sensing (CS) reconstruction, the temporal-spatial characteristics of video are used to jointly recover the video signal in this paper. At the collection terminal, each block in a single-frame is measured at the fixed sampling rates to advoid excessive complexity. At the reconstruction terminal, two regularization terms are respectively added to the minimum Total Variation (TV) reconstruction model to advance the performance of prediction-residual reconstruction, and the terms are constructed in terms of temporal-spatial Auto-Regressive (AR) model and Multiple Hypothesis (MH) model. In addition, considering that the statistics of video source are dynamically varying in spatial and temporal domain, it is discussed how the five different inter-prediction modes impact on precision and computational complexity of reconstruction. Simulation results show that the proposed algorithms effectively improve the quality of reconstructed video at the cost of the computational complexity, and the improvement of inter-prediction mode enhances reconstruction quality in some extent.
{fenge}
84899017456	Human action recognition using labeled Latent Dirichlet Allocation model	Recognition of human actions has already been an active area in the computer vision domain and techniques related to action recognition have been applied in plenty of fields such as smart surveillance, motion analysis and virtual reality. In this paper, we propose a new action recognition method which represents human actions as a bag of spatiooral words extracted from input video sequences and uses L-LDA (labeled Latent Dirichlet Allocation) model as a classifier. L-LDA is a supervised model extended from LDA which is unsupervised. The L-LDA adds a label layer on the basis of LDA to label the category of the train video sequences, so L-LDA can assign the latent topic variable in the model to the specific action categorization automatically. What's more, due to above characteristic of L-LDA, it can help to estimate the model parameters more reasonably, accurately and fast. We test our method on the KTH and Weizmann human action dataset and the experimental results show that L-LDA is better than its unsupervised counterpart LDA as well as SVMs (support vector machines). © 2013 IEEE.
{fenge}
84900467820	Image super-resolution based on sparse representation and nonlocal regularization	To solve the super-resolution reconstruction problem for single-frame image, an algorithm based on sparse representation and nonlocal regularization is proposed. By training the joint dictionaries, this algorithm looks for sparse representation in low-resolution dictionary for the input low-resolution image patch, and maps the sparse representation to high-resolution dictionary to construct high-resolution image patch. Then the reconstructed image patch is further regularized by the image's nonlocal self-similarity a priori information. Experimental results show that this algorithm can effectively ensure the quality of the reconstructed image, and greatly reduce the computation time. © 2014 Binary Information Press.
{fenge}
84900547765	Single image super resolution through neighbor embedding with non-local means and field of experts	Super resolution (SR) through neighbor embedding is recognized as an effective way to produce a high resolution (HR) image. However, this learning-based method is clumsy at preserving sharper edges and suppressing unwanted artifacts. To reduce these artifacts, in this paper we proposed a novel single image super resolution through neighbor embedding with non-local means (NLM) and field of experts. The proposed SR approach is based upon an observation that small patches in natural images tend to redundantly repeat themselves many times, which could be exploited to improve the image reconstruction quality. In addition, considering the existence of un-normal texture in the reconstruction of HR images, which reduce the accuracy of the search process, we apply the Field of Experts model to remove the un-normal texture, which could also make the final image match the statistical characteristics of natural images. The experimental results show that the proposed method can achieve comparable performance to other leading algorithms. © 2014 Binary Information Press.
{fenge}
84906848363	Distributed video compressive sensing reconstruction by adaptive PCA sparse basis and nonlocal similarity	To improve the rate-distortion performance of distributed video compressive sensing (DVCS), the adaptive sparse basis and nonlocal similarity of video are proposed to jointly reconstruct the video signal in this paper. Due to the lack of motion information between frames and the appearance of some noises in the reference frames, the sparse dictionary, which is constructed using the examples directly extracted from the reference frames, has already not better obtained the sparse representation of the interpolated block. This paper proposes a method to construct the sparse dictionary. Firstly, the example-based data matrix is constructed by using the motion information between frames, and then the principle components analysis (PCA) is used to compute some significant principle components of data matrix. Finally, the sparse dictionary is constructed by these significant principle components. The merit of the proposed sparse dictionary is that it can not only adaptively change in terms of the spatial-temporal characteristics, but also has ability to suppress noises. Besides, considering that the sparse priors cannot preserve the edges and textures of video frames well, the nonlocal similarity regularization term has also been introduced into reconstruction model. Experimental results show that the proposed algorithm can improve the objective and subjective quality of video frame, and achieve the better rate-distortion performance of DVCS system at the cost of a certain computational complexity. © 2014 KSII.
{fenge}
84906724530	Adaptive measurement rate setting method in block compressed sensing of images	Traditional block compressed sensing (BCS) of images uses the same measurement rate to measure each block, but some blocking artifacts appear in the reconstructed image on accounting of varying spatial characteristics in an image. This problem can be effectively solved by adaptively setting different measurement rate for every block. However, these existing methods require original digital image at the collector, which cannot be realized by using practical compressive imaging (CI) devices. In order to overcome this shortage, an adaptive measurement rate setting method is proposed and it can be easily achieved though hardware equipments. This method uses the CS measurements acquired at the collector to estimate the sample variance of each block directly, and then adaptively sets measurement rate of each block in terms of their sample variances and realize rate control. Experimental results show that proposed method can obtain a better quality of reconstructed image than non-adaptive scheme, but there is a gap between proposed method and the adaptive scheme using the true block sample variance since the sample variance estimated in the measurement domain has some deviations.
{fenge}
84910066491	Image multi-description coding method based on equally grouping and block compressive sensing strategy	An image multiple description coding method is proposed based on compressive sensing theory. It measures the image by block compressive sensing technology on the encoding side, and then divides the result matrix into many descriptions by grouping equally in the rows. In the decoding side, it reconstructs the image by received descriptions. The more the descriptions are received, the better the quality of the reconstructed image is. Dividing the result matrix into groups directly can generate many descriptions easily and reduce computational complexity on the encoding side. Experimental results show that, in the same experimental conditions, the proposed method exhibits faster encoding speed and higher reconstruction image quality than other methods.
{fenge}
84910603936	Multi-channel mixed-pattern based frame rate up-conversion using spatio-temporal motion vector refinement and dual-weighted overlapped block motion compensation	In this paper, a novel motion compensated frame rate up-conversion (MC-FRUC) algorithm is proposed to enhance the visual quality of video sequences. First of all, the multi-channel mixed pattern (MCMP) is proposed to design a block matching criterion which uses a few computations to reveal the variances of one luminance channel and two chrominance channels in a video frame. Second, in basis of the forward and backward initial motion vector fields (MVFs) estimated by a variant of 3DRS algorithm, the spatio-temporal motion vector refinement (ST-MVR) algorithm is proposed to obtain the more smoother MVF by implicitly adding the spatio-temporal smooth constraint into the process of motion vector refinement, and then the highly fault-tolerant motion vector smoothing (HFT-MVS) algorithm is proposed to prevent the emergence of outliers in MVF. Finally, in order to reduce the edge blurring and occlusions, the proposed dual-weighted overlapped block motion compensation (DW-OBMC) algorithm uses the forward and backward MVFs to jointly produce the interpolated frame. Experimental results show that the proposed algorithm can significantly improve both objective and subjective quality of the interpolated frame with a low computational complexity, and provide the better performance than the existing algorithms.
{fenge}
84920877566	A luminance referenced color image super resolution	The common procedure for color image Super-resolution (SR) is to transform the images from the RGB color space to YUV or some other color spaces that separate the luminance from chrominance components, and implement SR operation only on the luminance image (Y). The chrominance components (U, V), are usually directly up-sampled using simple interpolation algorithms. This procedure often brings color aberration in the reconstructed high resolution (HR) color image. This paper proposes an approach using the reconstructed HR luminance image as reference to accomplish the color assignment operation. Our approach involves colorization process and guided image filer both luminance referenced, and integrates guided image filter theory into the iterative back-projection framework. Experimental results indicated that compared with the common utilized bi-cubic interpolation method and the colorization- based color assignment method which has the same focus as ours, our approach can reconstruct the HR chrominance images with better results measured with PSNR, SSIM and CIEDE2000 color difference metric.
{fenge}
84921684156	Simple and effective image quality assessment based on edge enhanced mean square error	Simple and effective image quality assessment (IQA) method is very desirable in many image and video processing applications, such as coding, transmission, restoration and enhancement. Classic pixel absolute error based objective IQA metrics such as mean square error (MSE) and corresponding peak signal to noise ratio (PSNR) are widely used for various applications due to low computation and clear physical meanings, but have also been criticized for poorly correlated with subjective evaluation. Inspired by that human visual system (HVS) is more sensitive to image local edge distortion than flat or texture areas, in this paper, we propose a novel edge enhanced MSE (EE-MSE) to emphasize edge distortion effects on IQA. Experimental results on LIVE database release 2 show that the proposed EE-MSE IQA metric is competitive with state-of-the-art HVS-based IQA metrics, while has lower computational complexity and is more suitable for optimization task.
