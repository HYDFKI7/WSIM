{fenge}
84935018518	Applications of the representative points in statistical simulations	The paper gives a new approach to statistical simulation and resampling by the use of number-theoretic methods and representative points. Resempling techniques take samples from an approximate population. The bootstrap suggests to use a random sample to form an approximate population. We propose to construct some approximate population distribution by the use of two kinds of representative points, and samples are taken from these approximate distributions. The statistical inference is based on those samples. The statistical inference in this paper involves estimation of mean, variance, skewness, kurtosis, quantile and density of the population distribution. Our results show that the new method can significantly improve the results by the use of Monte Carlo methods.
{fenge}
15044352226	Uniformity pattern and related criteria for two-level factorials	In this paper, the study of projection properties of two-level factorials in view of geometry is reported. The concept of uniformity pattern is defined. Based on this new concept, criteria of uniformity resolution and minimum projection uniformity are proposed for comparing two-level factorials. Relationship between minimum projection uniformity and other criteria such as minimum aberration, generalized minimum aberration and orthogonality is made explicit. This close relationship raises the hope of improving the connection between uniform design theory and factorial design theory. Our results provide a justification of orthogonality, minimum aberration, and generalized minimum aberration from a natural geometrical interpretation.
{fenge}
1642264983	A note on the mixed geographically weighted regression model	A mixed, geographically weighted regression (GWR) model is useful in the situation where certain explanatory variables influencing the response are global while others are local. Undoubtedly, how to identify these two types of the explanatory variables is essential for building such a model. Nevertheless, It seems that there has not been a formal way to achieve this task. Based on some work on the GWR technique and the distribution theory of quadratic forms in normal variables, a statistical test approach is suggested here to identify a mixed GWR model. Then, this note mainly focuses on simulation studies to examine the performance of the test and to provide some guidelines for performing the test in practice. The simulation studies demonstrate that the test works quite well and provides a feasible way to choose an appropriate mixed GWR model for a given data set. © Blackwell Publishing, Inc. 2004.
{fenge}
1542438928	A new approach to construction of nearly uniform designs	The uniform design is one of space filling designs and has been widely used in computer and industrial experiments. Many methods for construction of uniform designs or nearly uniform designs, such as the glp method, optimisation method etc., have been proposed. A nearly uniform design is a design with low-discrepancy, where the discrepancy is a measure of uniformity. Various discrepancies have been suggested. To find a uniform design for n runs and s factors under a given discrepancy is a NP hard problem in the sense of computation complexity when n → ∞ and s > 1. In this paper we propose a new method, called the cutting method, for construction of nearly uniform designs. It shows that the computation load of the new method is light and designs obtained by the new approach have better uniformity.
{fenge}
17644408412	Some results on resolvable incomplete block designs	This paper is concerned with the uniformity of a certain kind of resolvable incomplete block (RIB for simplicity) design which is called the PRIB design here. A sufficient and necessary condition is obtained, under which a PRIB design is the most uniform in the sense of a discrete discrepancy measure, and the uniform PRIB design is shown to be connected. A construction method for such designs via a kind of U-type designs is proposed, and an existence result of these designs is given. This method sets up an important bridge between PRIB designs and U-type designs.
{fenge}
1842759773	Structural interpretation of a topological index. 1. External Factor Variable Connectivity Index (EFVCI)	The external factor variable connectivity index (EFVCI) is interpreted by mining out the structural features hidden in the space spanned by the EFVCI indices through projection pursuit combining with number-theory net (NT-net) on the unit sphere U(Us). Projection pursuit is concerned with "interesting" projections of high-dimensional data sets to machine-pick "interesting" low-dimensional projections of a high-dimensional point cloud by numerically maximizing a certain objective function or projection index. At first, the optimal EFVCI index reaches to -0.80 in the correlation with a retention index of 207 hydrocarbons produced by insects. The EFVCI indices, with regression results of R = 0.99998, 5 = 3.49, RMSECV = 3.90, and F = 7.9560e+005, obtain high regression quality. The model is proven valid by leave-one-out cross validation. Second, the EFVCI index is interpreted by the structure information, that is, size, branch number, graph center, and branching position of topological structures, which is searched out on the unit sphere U(U
{fenge}
2042439721	Construction of optimal supersaturated designs by the packing method	A supersaturated design is essentially a factorial design with the equal occurrence of level property and no fully aliased factors, in which the number of main effects is greater than the number of runs. It has received much recent interest because of its potential in factor screening experiments. A packing design is an important object in combinatorial design theory. In this paper, a strong link between the two apparently un-related kinds of designs is shown. Several criteria for comparing supersaturated designs are proposed, and their properties and connections with other criteria are discussed. A combinatorial approach, the packing method, for constructing optimal supersaturated designs is presented, and the properties of the resulting designs are also investigated. Comparisons between the new designs and other designs are given, which show that our construction method and the newly constructed designs have good properties.
{fenge}
20444425838	A generalized boosting algorithm and its application to two-class chemical classification problem	Boosting is one of the most important recent developments in classification methodology. It can significantly improve the prediction performance of any single classification algorithm and has been successfully applied to many different fields including problems in chemometrics. Boosting works by sequentially applying a classification algorithm to reweighted versions of the training data, and then taking a weighted majority vote of the sequence of classifiers thus produced. In this paper, we proposed a generalized boosting algorithm via Bayes optimal decision rule. Using Bayes optimal decision rule, we adjust the weights of the sequence of classifiers in the voting process of boosting algorithm. The two types of errors are introduced into the generalized boosting and make the voting process more sensible. Meanwhile, the weights of the training samples are also correspondingly adjusted according to some criterion. The generalized boosting is applied to the binary classification for chemical data. Experimental results show that it can improve the predict accuracy compared with AdaBoost algorithm especially when the difference between the two types of errors for classification is large. © 2005 Elsevier B.V. All rights reserved.
{fenge}
20444476778	Estimation of poisson intensity in the presence of dead time	Phase Doppler interferometry (PDI) is a nonintrusive technique frequently used to obtain information about spray characteristics. Understanding spray characteristics is of critical importance in many areas of science, including liquid fuel spray combustion, spray coatings, fire suppression, and pesticides. PDI measures the size and velocity of individual droplets in a spray. Due to the design of the instrument, recordings of the PDI contain gaps, called dead times. The presence of recurring dead times greatly complicates estimation of the diffusion rate of the droplets. Modeling the spray process as a homogeneous Poisson process, we construct consistent and asymptotic normal estimators of the diffusion rate (Poisson intensity) under various conditions. Simulation produced a good agreement between our estimators (in the presence of dead time) and the maximum likelihood estimates obtained without dead time. We use experimental data to illustrate the estimation method. © 2005 American Statistical Association.
{fenge}
0000045173	Application of Threshold-Accepting to the Evaluation of the Discrepancy of A Set of Points	Efficient routines for multidimensional numerical integration are provided by quasiMonte Carlo methods. These methods are based on evaluating the integrand at a set of representative points of the integration area. A set may be called representative if it shows a low discrepancy. However, in dimensions higher than two and for a large number of points the evaluation of discrepancy becomes infeasible. The use of the efficient multiple-purpose heuristic threshold-accepting offers the possibility to obtain at least good approximations to the discrepancy of a given set of points. This paper presents an implementation of the threshold-accepting heuristic, an assessment of its performance for some small examples, and results for larger sets of points with unknown discrepancy.
{fenge}
0004364301	Sequential number-theoretic optimization (SNTO) method applied to chemical quantitative analysis	A sequential number-theoretic optimization (SNTO) method recently developed in statistics was introduced as a global optimization procedure in constrained background bilinearization (CBBL) for the quantification of real two-way bilinear data. SNTO searches for the global optimum among points uniformly scattered in the search space and convergence of the algorithm is quickened through sequential contraction of that space. Since the global optimization performance of SNTO is closely related to the number of points scattered, a new practical approach for selection of the number of points scattered in the original search space by trial tests is proposed in this paper in order to increase the possibility of locating the global optimum. The performance of SNTO has also been tested with mathematical models with multiple local optima. In comparison with another global optimization method, variable step size simulated annealing (VSGSA), SNTO achieved satisfactory results for both mathematical models and a real analytical system. The clarity and simplicity of the idea of SNTO together with its convenience for implementation make SNTO a promising tool in chemometrics. © 1997 by John Wiley & Sons, Ltd.
{fenge}
0005874151	A stratified sampling model in spherical feature inspection using coordinate measuring machines	A coordinate measuring machine (CMM) is a computer-controlled device that uses a probe to obtain measurements on a manufactured part's surface. In the process of collecting, analyzing and interpreting CMM data, many statistical problems arise. One of them is to choose a model describing the relationship between the location and shape parameters of the part and CMM data and representing the effects of the various sources of randomness of these data. This article suggests a linear model for a stratified sampling scheme, which is one of the most commonly discussed in the CMM literature, in fitting a spherical surface. A feasible generalized least-squares estimator of the part's spherical parameter set is given and its property is studied. Our theoretical results indicate that stratified sampling performs better than random sampling. A similar conclusion was also obtained by Caskey et al. (1990, Design Manufacturing Systems Conf. 779-786) and Xu (1992, M.S. thesis, University of Texas - EI Paso, Mechanical and Industrial Engineering Department, unpublished) using the Monte Carlo experiments for some quite different situations. © 2001 Elsevier Science B.V.
{fenge}
0009872147	Multiple outlier detection in multivariate data using projection pursuit techniques	Using projection pursuit techniques, in this paper we propose a procedure to detect multiple outliers in multivariate data. The basic idea behind this procedure is to project the multivariate data to univariate observations and then to apply an appropriate univariate outlier identifier to the projected data. The projected outlier identifier forms a centered Gaussian process on the high-dimensional unit sphere. When a set of directions is generated on the unit sphere, the projected outlier identifier on these directions then follows a multivariate normal distribution. In this way, an outlier identifier in the multivariate data with χ
{fenge}
0000835483	Testing multinormality based on low-dimensional projection	A method based on properties of left-spherical matrix distributions and affine invariant statistics is employed to construct projection tests for multivariate normality. The projection tests are indirectly dependent on the dimension of raw data. As a result, the projection tests can be performed for arbitrary dimension d and sample size n even if n<d in high-dimensional case as soon as the projection dimension is suitably chosen. By Monte Carlo simulation, we show that the projection tests significantly improve the power of existing tests for multinormality in the case of high dimension with a small sample size. Analysis on a practical example shows that the projection tests are useful complements to existing tests for multinormality. © 1999 Elsevier Science B.V.
{fenge}
0029739648	Robust multivariate calibration algorithm based on least median of squares and sequential number theory optimization method	With the help of constraints on the concentrations to be estimated in direct multivariate calibration, an algorithm for least median of squares (LMS) was developed. The sequential number theory optimization (SNTO) method developed in Statistics was used for robust multivariate calibration in order to reach the global optimization. The computational complexity of LMS is dramatically reduced by means of the constraints on the concentrations to be estimated and the SNTO method. The algorithm was applied to a simulated data Set and to two sets of real data from two- and/or three-component analytical systems. Comparisons with the least squares technique show that the proposed method is efficient in terms of computational complexity and is robust to a large number of outliers in the data.
{fenge}
0031807237	Uniform design applied to nonlinear multivariate calibration by ANN	In this paper, a new experimental design called uniform design (UD) has been introduced as a promising candidate for experimental design in nonlinear multivariate calibration by ANN. In its application to ANN, the UD has the following merits:it is capable of producing samples with high representativeness;it imposes no strong assumption on the model; andit allows many levels for each factor.A comparative study has been made among UD, orthogonal array design (OAD) and central composite design (CCD). The results by UD in simulated and real-fluorescence systems are satisfactory. Copyright (C) 1998 Elsevier Science B.V.
{fenge}
27144510143	Lower bounds for wrap-around L2-discrepancy and constructions of symmetrical uniform designs	The wrap-around L2-discrepancy has been used in quasi-Monte Carlo methods, especially in experimental designs. In this paper, explicit lower bounds of the wrap-around L2-discrepancy of U-type designs are obtained. Sufficient conditions for U-type designs to achieve their lower bounds are given. Taking advantage of these conditions, we consider the perfect resolvable balanced incomplete block designs, and use them to construct uniform designs under the wrap-around L2-discrepancy directly. We also propose an efficient balance-pursuit heuristic, by which we find many new uniform designs, especially with high levels. It is seen that the new algorithm is more powerful than existing threshold accepting ones in the literature. © 2005 Elsevier Inc. All rights reserved.
{fenge}
26044464096	Assessing phylogenetic relationships of Lycium samples using RAPD and entropy theory	Aim: To evaluate the phylogenetic relationships among related species of Lycium samples. Methods: Random amplified polymorphic DNA (RAPD) fingerprinting and lab-on-a-chip electrophoresis techniques were used to analyze the characteristics of Lycium species. Seven species and 3 varieties of Lycium were studied. Based on RAPD fingerprint data obtained from 11 primers, we proposed a new index, called dispersivity, using entropy theory and projection methods to depict the diversity of the DNA fingerprints. Results: Using the proposed dispersivity, primers were sorted and the dendrograms of the 7 species and 3 varieties of Lycium were constructed synthetically by merging primer information. Conclusion: Phylogenetic relationships among Lycium samples were constructed synthetically based on RAPD fingerprint data generated from 11 primers. ©2005 CPS and SIMM.
{fenge}
33646082977	Use of three-color cDNA microarray experiments to assess the therapeutic and side effect of drugs	A novel microarray strategy, three-color cDNA microarray experiment, is originally applied to assess drug effects on gene expression patterns of "target disease." By adding Alexa 594 as a dye-label for the third target sample, it is made possible to monitor changes in gene expression in response to disease and generate clues to gene function with therapeutic intervention only on one array. A new kind of graph, hexaMplot, is constructed to illustrate the meaningful expression patterns of normal-disease-drug in three-color experiment. The therapeutic and side effect of drugs can be understood and indicated by the different regions of hexaMplot. And the testing of correlation coefficient is explored as a statistical tool of the assessment. Such a methodology may prove useful in shortening the cycle, reducing the cost, and improving the efficiency of drug discovery and development. © 2005 Elsevier B.V. All rights reserved.
{fenge}
33646096959	Critical value determination on similarity of fingerprints	A chemical or DNA fingerprint can be treated as a multi-dimensional vector. Correlation coefficient between two fingerprints which is easy to understand and simple to compute has been widely used to assess the similarity of fingerprints in chemical and Chinese Medicine. In the process of fingerprint examination, we are often confronted with such question on how to assess whether a new tested fingerprint is qualified or not. Usually, the mean or median fingerprint of a group of representative fingerprints measured accurately is regarded as a standard fingerprint, then correlation coefficient between the standard fingerprint and a new tested fingerprint is calculated. The critical value for the correlation coefficient is for assessment of a new tested fingerprint whether it is qualified or not. In this study, a bootstrap method is used to estimate the sampling distribution of the correlation coefficient between the standard fingerprint and a new tested fingerprint under the hypothesis that the new tested fingerprint belongs to the same group with the fingerprints used to construct standard fingerprint. Furthermore, using the simulated distribution we obtain the corresponding critical value as the criteria for fingerprint examination. This method is illustrated using Chinese Angelica (CA) fingerprint data. © 2005 Elsevier B.V. All rights reserved.
{fenge}
33748695525	The application of Kriging and empirical Kriging based on the variables selected by SCAD	The commonly used approach for building a structure-activity/property relationship consists of three steps. First, one determines the descriptors for the molecular structure, then builds a metamodel by using some proper mathematical methods, and finally evaluates the meta-model. Some existing methods only can select important variables from the candidates, while most metamodels just explore linear relationships between inputs and outputs. Some techniques are useful to build more complicated relationship, but they may not be able to select important variables from a large number of variables. In this paper, we propose to screen important variables by the smoothly clipped absolute deviation (SCAD) variable selection procedure, and then apply Kriging model and empirical Kriging model for quantitative structure-activity/property relationship (QSAR/QSPR) research based on the selected important variables. We demonstrate the proposed procedure retains the virtues of both variable selection and Kriging model. © 2006 Elsevier B.V. All rights reserved.
{fenge}
33748891246	CONSTRUCTING UNIFORM DESIGNS WITH TWO- OR THREE-LEVEL* * This work was partially supported by the NNSF of China(10441001), the Project sponsored by SRF for ROCS (SEM) and the NSF of Hubei Province. The second author's research was also partially supported by the Pre-studies Project of NBRP (2003CCA2400).	When the number of runs is large, to search for uniform designs in the sense of low-discrepancy is an NP hard problem. The number of runs of most of the available uniform designs is small (≤ 50). In this article, the authors employ a kind of the so-called Hamming distance method to construct uniform designs with two- or three-level such that some resulting uniform designs have a large number of runs. Several infinite classes for the existence of uniform designs with the same Hamming distances between any distinct rows are also obtained simultaneously. Two measures of uniformity, the centered L
{fenge}
33750627507	A CASE STUDY IN THE APPLICATION OF SUPERSATURATED DESIGNS TO COMPUTER EXPERIMENTS	Supersaturated design is essentially a fractional factorial design in which the number of potential effects is greater than the number of runs. In this article, the supersaturated design is applied to a computer experiment through an example of steady current circuit model problem. A uniform mixed-level supersaturated design and the centered quadratic regression model are used. This example shows that supersaturated design and quadratic regression modeling method are very effective for screening effects and building the predictor. They are not only useful in computer experiments but also in industrial and other scientific experiments. © 2006 Wuhan Institute of Physics and Mathematics.
{fenge}
34147175614	On the Student's t-distribution and the t-statistic	In this paper we provide rather weak conditions on a distribution which would guarantee that the t-statistic of a random vector of order n follows the t-distribution with n - 1 degrees of freedom. The results sharpen the earlier conclusions of Mauldon [Characterizing properties of statistical distributions, Quart. J. Math. 2(7) (1956) 155-160] and the more recent advances due to Bondesson [When is the t-statistic t-distributed, Sankhyā, Ser. A 45 (1983) 338-345]. The basic tool involved in the derivations is the vertical density representation originally suggested by Troutt [A theorem on the density of the density ordinate and an alternative interpretation of the Box-Muller method, Statistics 22(3) (1991) 463-466; Vertical density representation and a further remark on the Box-Muller method, Statistics 24 (1993) 81-83]. Several illustrative examples are presented. © 2006 Elsevier Inc. All rights reserved.
{fenge}
34547894651	Empirical Kriging models and their applications to QSAR	A general Kriging model consists of two additive components: a parametric term and a stochastic error process. It is known that Kriging is an interpolating predictor and allows for a better fit to the data, but suffers from a decreasing ability to generalize to unseen data. By incorporating a disturbing or an independent random error term into Kriging model, the resulting model, which is called empirical Kriging model in the literature, may provide more accurate prediction for the highly noisy data than the Kriging model. This paper presents an extensive survey of the empirical Kriging model for quantitative structure-activity relationship (QSAR) research and extends the parameters estimation technique with highly efficiency. In addiction, QSAR models are established by combining Kriging model or empirical Kriging model with principal components regression (PCR) and partial least squares regression (PLSR). We demonstrate for the real data set that the suggested empirical Kriging model can significantly improve the prediction ability of some commonly used models, including the Kriging model. Copyright © 2007 John Wiley & Sons, Ltd.
{fenge}
34548831077	Lower bounds of various criteria in experimental designs	Criterion is essential for measuring the goodness of an experimental design. In this paper, lower bounds of various criteria in experimental designs will be reviewed according to methodology of their construction. The criteria include most well-known ones which are frequently used as benchmarks for orthogonal array, uniform design, supersaturated design and other types of designs. To derive the lower bounds of these criteria, five different approaches are explored. Some new results are given. Throughout the paper, some relationships among different types of lower bounds are also discussed. © 2007 Elsevier B.V. All rights reserved.
{fenge}
0033416923	Bayesian local influence in growth curve model with unstructured covariance	From the Bayesian point of view, a local influence approach is developed to diagnose the adequacy of the growth curve model with an unstructured covariance. Based on the Kullback-Leibler divergence, the Bayesian Hessian matrices of the parameters in the model are studied under an abstract perturbation scheme and the eigenvector associated with the largest eigenvalue of the Hessian matrix is used to identify influential observations. For illustration, the covariance-weighted perturbation, a commonly encountered perturbation, is considered particularly and used to analyze a practical data set. Comparisons with the likelihood-based local influence are also made.
{fenge}
0034248857	Uniform design: Theory and application	A uniform design (UD) seeks design points that are uniformly scattered on the domain. It has been popular since 1980. A survey of UD is given in the first portion: The fundamental idea and construction method are presented and discussed and examples are given for illustration. It is shown that UD's have many desirable properties for a wide variety of applications. Furthermore, we use the global optimization algorithm, threshold accepting, to generate UD's with low discrepancy. The relationship between uniformity and orthogonality is investigated. It turns out that most UD's obtained here are indeed orthogonal.
{fenge}
4043112708	Structural interpretation of the topological index. 2. The molecular connectivity index, the Kappa index, and the atom-type E-State index	The structural interpretation is extended to the topological indices describing cyclic structures. Three representatives of the topological index, such as the molecular connectivity index, the Kappa index, and the atom-type E-State index, are interpreted by mining out, through projection pursuit combining with a number theory method generating uniformly distributed directions on unit sphere, the structural features hidden in the spaces spanned by the three series of indices individually. Some interesting results, which can hardly be found by individual index, are obtained from the multidimensional spaces by several topological indices. The results support quantitatively the former studies on the topological indices, and some new insights are obtained during the analysis. The combinations of several molecular connectivity indices describe mainly three general categories of molecular structure information, which include degree of branching, size, and degree of cyclicity. The cyclicity can also be coded by the combination of chi cluster and path/cluster indices. The Kappa shape indices encode, in combination, significant information on size, the degree of cyclicity, and the degree of centralization/separation in branching. The size, branch number, and cyclicity information has also been mined out to interpret atom-type E-State indices. The structural feature such as the number of quaternary atoms is searched out to be an important factor. The results indicate that the collinearity might be a serious problem in the applications of the topological indices.
{fenge}
32044463321	Restricted expected multivariate least squares	A new approach of estimating parameters in multivariate models is introduced. A fitting function will be used. The idea is to estimate parameters so that the fitting function equals or will be close to its expected value. The function will be decomposed into two parts. From one part, which will be independent of the mean parameters, the dispersion matrix is estimated. This estimator is inserted in the second part which then yields the estimators of the mean parameters. The Growth Curve model, extended Growth Curve model and a multivariate variance components model will illustrate the approach. © 2005 Elsevier Inc. All rights reserved.
{fenge}
34249941552	Orthogonality and D-optimality of the U-type design under general Fourier regression models	Riccomagno et al. [1997. Lattice-based D-optimum design for Fourier regression. Ann. Statist. 25, 2313-2317] gave a comprehensive study on D-optimality under a symmetric Fourier regression model and gave a characterization on orthogonality, complete orthogonality and D-optimality of lattice designs under a symmetrical Fourier model. This paper extends their results to asymmetric Fourier regression models. We give some necessary condition for the orthogonality and complete orthogonality of U-type designs under general Fourier regression models that involve symmetrical and asymmetrical Fourier models and prove that a U-type design, which is completely orthogonal, is not D-optimal for an asymmetrical Fourier model. © 2007.
{fenge}
0034551876	Statistical inference for truncated Dirichlet distribution and its application in misclassification	This paper is concerned with the statistical inference of a truncated Dirichlet distribution (TDD) arising in the general context of misclassified multinomial models (such as medical screening or diagnostic tests) and experimental design with mixtures. By employing the conditional distribution method, we offer a generating procedure for the TDD. Alternatively, a sampling-based approach using the Gibbs sampler was provided as a means for developing the posterior moments of interest. Finding the mode of a TDD is equivalent to extracting the constrained maximum likelihood estimate (MLE) of parameter vector in a multinomial model. Based upon a theoretic result, we propose an algorithm to calculate the constrained MLE. Applications in misclassification are presented.
{fenge}
0034684047	The effects of different experimental designs on parameter estimation in the kinetics of a reversible chemical reaction	The common methods used by chemists to obtain the estimates of the kinetic rate constants are deterministic ones. The statistical methods, such as D-optimum design (DOD), can offer a better way to deal with this problem. But the kinetic model of a reversible reaction is nonlinear, the DOD is locally optimal at the value of the initial chosen parameters. The goal of this article is to try to put different experimental design techniques, i.e., uniform design (UD), orthogonal design (OD) and DOD into a common framework, and to attempt to gain some insight on when, where and which of these three experimental methods can be expected to work well. The extensive Monte Carlo experiments have been done in order to compare the performances of these methods. The results show that the DOD often gives the best performance, but it is easy to break down in estimation of parameters, when the initial parameters are far away from the true parameters. The OD also breaks down in some situations. The UD is the most stable, and it works well in all situations. (C) 2000 Elsevier Science B.V.
{fenge}
84877243513	Statistical models for space filling designs and optimalities of uniform designs	Computer experiments are very useful for exploring complicated physical phenomena in various research fields of science and engineering. Construction of computer experiments is a crucial step during the planning of experiments. There are many space filling designs for computer experiments. The uniformity and low-discrepancy sets have played an important role in the construction of designs for computer experiments. To understand the reasons why space filling designs have good performance in computer experiments, in this paper, we compare several statistical models from different statistical points of view. The overall sample mean model has been employed in the development of the Latin hypercube sampling and uniform design. However, this model considers only the overall mean of the response and is far not enough for the need in practice. In this paper, we systematically studies some alternative approaches to the uniform design, such as nonparametric regression model, goodness-of-fit, robustness against model specification and decision theory. These approaches show that the uniform design is an optimal one from several aspects. Furthermore, these approaches illustrate the advantages and potential applications of the uniform design. Copyright © 2003 SAE International.
{fenge}
4644299293	Identification of differentially expressed genes with multivariate outlier analysis	DNA microarray offers a powerful and effective technology to monitor the changes in the gene expression levels for thousands of genes simultaneously. It is being widely applied to explore the quantitative alternation in gene regulation in response to a variety of aspects including diseases and exposure of toxicant. A common task in analyzing microarray data is to identify the differentially expressed genes under two different experimental conditions. Because of the large number of genes and small number of arrays, and higher signal-noise ratio in microarray data, many traditional approaches seem improper. In this paper, a multivariate mixture model is applied to model the expression level of replicated arrays, considering the differentially expressed genes as the outliers of the expression data. In order to detect the outliers of the multivariate mixture model, an effective and robust statistical method is first applied to microarray analysis. This method is based on the analysis of - kurtosis coefficient (KC) of the projected multivariate data arising from a mixture model so as to identify the outliers. We utilize the multivariate KC algorithm to our microarray experiment with the control and toxic treatment. After the processing of data, the differential genes are successfully identified from 1824 genes on the UCLA M07 microarray chip. We also use the RT-PCR method and two robust statistical methods, minimum covariance determinant (MCD) and minimum volume ellipsoid (MVE), to verify the expression level of outlier genes identified by KC algorithm. We conclude that the robust multivariate tool is practical and effective for the detection of differentially expressed genes.
{fenge}
49149106909	Some necessary uniform tests for spherical symmetry	While spherical distributions have been used in many statistical models for high-dimensional data analysis, there are few easily implemented statistics for testing spherical symmetry for the underlying distribution of high-dimensional data. Many existing statistics for this purpose were constructed by the theory of empirical processes and turn out to converge slowly to their limiting distributions. Some existing statistics for the same purpose were given in the form of high-dimensional integrals that are not easily evaluated in numerical computation. In this paper, we develop some necessary tests for spherical symmetry based on both univariate and multivariate uniform statistics. These statistics are easily evaluated numerically and have simple limiting distributions. A Monte Carlo study is carried out to demonstrate the performance of the statistics on controlling type I error rates and power. © 2007 The Institute of Statistical Mathematics.
{fenge}
0035402388	Optimal multi-criteria designs for Fourier regression models	Riccomagno, Schwabe and Wynn (RSW) (1997) have given a necessary and sufficient condition for obtaining a complete Fourier regression model with a design based on lattice points that is D-optimal. However, in practice, the number of factors to be considered may be large, or the experimental data may be restricted or not homogeneous. To address these difficulties we extend the results of RSW to obtain a sufficient condition for an incomplete interaction Fourier model design based on lattice points that is D-, A-, E- and G-optimal. We also propose an algorithm for finding such optimal designs that requires fewer design points than those obtained using RSW's generators when the underlying model is a complete interaction model. © 2001 Elsevier Science B.V.
{fenge}
0035965016	Uniform design and its applications in chemistry and chemical engineering	Experimental designs are very important in chemometrics, since chemistry, until now, is still essentially a field of science strongly dependent on chemical experiments. So, for a long time, chemists have been trying to use the techniques of experimental design developed in statistics to improve experimental works. Three major methods of experimental design, such as factorial design including fractional factorial design and orthogonal design (OD), D-optimal design and uniform design (UD), and their applications in chemistry and chemical engineering are reviewed and compared. The features of uniform design are especially addressed. Uniformity of space filling is the most important and essential feature of the uniform design. Based on this feature, its cost-efficiency, robustness and flexibility make it very useful in the fields of chemistry and chemical engineering. Examples of successful applications of uniform design on improving technologies of various fields such as textile industry, pharmaceuticals, fermentation industry and others have been consistently reported in China since the 1980s. More recently, several various cases applying uniform design to chemical researches showed that the uniform design is indeed a very promising and powerful experimental design method. © 2001 Elsevier Science B.V. All rights reserved.
{fenge}
0036334962	The meta-elliptical distributions with given marginals	Based on an analysis of copulas of elliptically contoured distributions, joint densities of continuous variables with given strictly increasing marginal distributions are constructed. A method utilized for this procedure is to embed the spherical distribution quantile transformation of each variable into an elliptically contoured distribution. The new class of distributions is then called meta-elliptical distributions. The corresponding analytic forms of the density, conditional distribution functions, and dependence properties are derived. This new class of distributions has the same Kendall's rank correlation coefficient as meta-Gaussian distributions. As an extension of elliptically contoured distributions, some new classes of distributions are also obtained. © 2002 Elsevier Science (USA).
{fenge}
0036964550	Theory, method and applications of the uniform design	In modern techniques and science one meets design problems for multi-factor experiments in a large experimental region where the underlying model is unknown. These problems needs space filling designs. The uniform experimental design seeks its design points to be uniformly scattered on the experimental domain and is one kind of space filling designs that can be used for computer experiments and also for industrial experiments when the underlying model is unknown. In this paper we shall introduce the theory and method of the uniform design and related data analysis and modelling methods. Applications of the uniform design to industry and other areas are discussed.
{fenge}
0037389675	The effective dimension and quasi-Monte Carlo integration	Quasi-Monte Carlo (QMC) methods are successfully used for high-dimensional integrals arising in many applications. To understand this success, the notion of effective dimension has been introduced. In this paper, we analyse certain function classes commonly used in QMC methods for empirical and theoretical investigations and show that the problem of determining their effective dimension is analytically tractable. For arbitrary square integrable functions, we propose a numerical algorithm to compute their truncation dimension. We also consider some realistic problems from finance: the pricing of options. We study the special structure of the corresponding integrands by determining their effective dimension and show how large the effective dimension can be reduced and how much the accuracy of QMC estimates can be improved by using the Brownian bridge and the principal component analysis techniques. A critical discussion of the influence of these techniques on the QMC error is presented. The connection between the effective dimension and the performance of QMC methods is demonstrated by examples. © 2003 Elsevier Science (USA). All rights reserved.
{fenge}
0037438178	A note on construction of nearly uniform designs with large number of runs	Uniform designs have been used in computer experiments (Fang et al., Technometrics 42 (2000) 237). A uniform design seeks its design points to be uniformly scattered on the experimental domain. When the number of runs is large, to search a related uniform design is a NP hard problem. Therefore, the number of runs of most existing uniform designs is small (≤ 50). In this article, we propose a way to construct nearly uniform designs with large number of runs by collapsing two uniform designs in the sense of low-discrepancy. The number of runs of the novel design is the product of the two numbers of runs of both original designs. Two measures of uniformity, the centered L
{fenge}
0038054208	Two-step multivariate adaptive regression splines for modeling a quantitative relationship between gas chromatography retention indices and molecular descriptors	The relationship between retention indices and molecular descriptors of alkanes is established by two-step multivariate adaptive regression splines (TMARS). TMARS combines linear regression with multivariate adaptive regression splines (MARS). It is demonstrated for the present data set that using linear regression or MARS modeling alone causes lack of fit. TMARS avoids lack of fit and appreciably improves the prediction ability for the model. The use of this combined approach permits the development of additional understanding of the adaptive nature in MARS modeling. © 2003 Elsevier Science B.V. All rights reserved.
{fenge}
84870587935	Uniform design in computer and physical experiments	Computer experiments have been widely used in various fields of industry, system engineering, and others because many physical phenomena are difficult or even impossible to study by conventional experimental methods. Design and modeling of computer experiments have become a hot topic since late Seventies of the Twentieth Century. Almost in the same time two different approaches are proposed for design of computer experiments: Latin hypercube sampling (LHS) and uniform design (UD). The former is a stochastic approach and the latter is a deterministic one. A uniform design is a low-discrepancy set in the sense of the discrepancy, the latter is a measure of uniformity. The uniform design can be used for computer experiments and also for physical experiments when the underlying model is unknown. In this paper we review some developments of the uniform design in the past years. More precisely, review and discuss relationships of fractional factorial designs including orthogonal arrays, supersaturated designs and uniform designs. Some basic knowledge of the uniform design with a demonstration example will be given.
{fenge}
84876544253	An empirical likelihood method for semiparametric linear regression with right censored data	This paper develops a new empirical likelihood method for semiparametric linear regression with a completely unknown error distribution and right censored survival data. The method is based on the Buckley-James (1979) estimating equation. It inherits some appealing properties of the complete data empirical likelihood method. For example, it does not require variance estimation which is problematic for the Buckley-James estimator. We also extend our method to incorporate auxiliary information. We compare our method with the synthetic data empirical likelihood of Li and Wang (2003) using simulations. We also illustrate our method using Stanford heart transplantation data. © 2013 Kai-Tai Fang et al.
{fenge}
0042233438	Uniform designs for mixture-amount experiments and for mixture experiments under order restrictions	With order statistics of the uniform distribution on [0,1], exponential and beta distributions, a stochastic representation is obtained for the uniform distribution over various domains, where A-type domains are closely associated with reliability growth analysis, order restricted statistical inference and isotonic regression theory, V-type domains are connected with the mixture-amount experiments, and T-type domains are well related to mixture experiments. With these stochastic representations, the corresponding uniform distribution and number-theoretic nets can be generated. This approach seems to be new and is called order statistics method. Some examples on reliability growth analysis and experimental design are presented.
{fenge}
0042688757	Influential observation in the growth curve model with unstructured covariance matrix	Under a normal assumption, Liski (Biometrics 47 (1991) 659-668) gave some measurements for assessing influential observations in the growth curve model (GCM) with a known covariance. For the GCM with an unstructured covariance matrix (UCM), i.e., the covariance is an arbitrary positive definite matrix, the problems of detecting influential observations are discussed in this paper. Based on the empirical influence function of the regression coefficient, a generalized Cook's distance is proposed to measure the influence of a subset of observations on the MLE's fit. In order to make comparison with the generalized Cook's distance, some other diagnostic measurements for assessing the influence are investigated too, which are based on the change of the confidence ellipsoid's volume after deleting the observation's subset. In addition, the influences on some linear combinations of the regression coefficient are discussed. For illustration purpose, a numerical example is provided and the analysis results show that the approaches presented in this paper are useful in practice.
{fenge}
0345562981	Construction of minimum generalized aberration designs	Supersaturated designs have become increasingly popular in recent years because of their potential in saving run size and the technical novelty. In this paper, the minimum generalized aberration (MGA) criterion proposed by Ma and Fang (2001) (and another two equivalent criteria proposed by Xu and Wu (2001) and Xu (2001b) respectively) for comparing non-regular symmetrical designs is used for evaluating supersaturated designs. A new construction method for MGA symmetrical supersaturated designs via resolvable balanced incomplete block designs is proposed, and some infinite classes for the existence of such MGA designs are obtained simultaneously, along with the investigation of properties of the resulting designs. The construction method shows a strong connection between these two different kinds of designs. © Springer-Verlag 2003.
{fenge}
10044263477	New approach by kriging models to problems in QSAR	Most models in quantitative structure and activity relationship (QSAR) research, proposed by various techniques such as ordinary least squares regression, principal components regression, partial least squares regression, and multivariate adaptive regression splines, involve a linear parametric part and a random error part. The random errors in those models are assumed to be independently identical distributed. However, the independence assumption is not reasonable in many cases. Some dependence among errors should be considered just like Kriging. It has been successfully used in computer experiments for modeling. The aim of this paper is to apply Kriging models to QSAR. Our experiments show that the Kriging models can significantly improve the performances of the models obtained by many existing methods.
{fenge}
10244261585	Structural features hidden in the degree distributions of topological graphs	on a basic element, vertex degree, of topological graphs, insights are obtained on the structural features hidden in the degree distributions (DD) of saturated hydrocarbons. The investigation shows that the cyclicity and branching features are mainly coded by the different mathematical characteristics of the degree distributions. Surprisingly, the center (or mathematical expectation) of a degree distribution corresponds to the cyclicity of a saturated hydrocarbon, and the dispersion (mean absolute deviation or MAD) around its center of a distribution is a measure of branching. The structural feature such as number of quaternary atoms is also mined out as a special case of branching. The cyclicity and branching information in the present work is with least human intervention, and an interesting thing is that the two features can be unified into the mathematical characteristics of a degree distribution. By the strict mathematical characteristics of a distribution, the structure features within the degree distributions (DD somer domains) are studied. The space spanned by the size (number of carbons), mathematical expectation, and MAD shows some enlightening results. The results also give a new idea on how to model the properties of diverse structures.
{fenge}
0347761417	Improving the classification accuracy in chemistry via boosting technique	One of the main tasks of chemometrics is to classify chemical objects to one of several distinct predefined categories. There are many classification methods in data mining, one of which is the boosting technique that can improve predicate performance of a given classifier and it is one of the most powerful methods in classification methodology. In this paper, we apply boosting neural network (NN) and boosting tree in classification for chemical data. Experimental results show that boosting can significantly improve the prediction performance of any single classification method. Two techniques to interpret the model are also introduced in order to help us better understand the experimental results. © 2003 Elsevier B.V. All rights reserved.
{fenge}
12344294678	Impersonality of the connectivity index and recomposition of topological indices according to different properties	The connectivity index χ can be regarded as the sum of bond contributions. In this article, boiling point (bp)-oriented contributions for each kind of bond are obtained by decomposing the connectivity indices into ten connectivity character bases and then doing a linear regression between bps and the bases. From the comparison of bp-oriented contributions with the contributions assigned by χ, it can be found that they are very similar in percentage, i.e. the relative importance of each particular kind of bond is nearly the same in the two forms of combinations (one is obtained from the regression with boiling point, and the other is decided by the constructor of the χ index). This coincidence shows an impersonality of χ on bond weighting and may provide us another interpretation of the efficiency of the connectivity index on many quantitative structure-activity/property relationship (QSAR or QSPR) results. However, we also found that χ's weighting formula may not be appropriate for some other properties. In fact, there is no universal weighting formula appropriate for all properties/activities. Recomposition of some topological indices by adjusting the weights upon character bases according to different properties/activities is suggested. This idea of recomposition is applied to the first Zagreb group index M
