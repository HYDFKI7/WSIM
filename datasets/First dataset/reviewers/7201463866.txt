{fenge}
8744311336	Analysing regional industrialisation in Jiangsu province using geographically weighted regression	Industry is the most important sector in the Chinese economy. To identify the spatial interaction between the level of regional industrialisation and various factors, this paper takes Jiangsu province of China as a case study. To unravel the existence of spatial nonstationarity, geographically weighted regression (GWR) is employed in this article. Conventional regression analysis can only produce 'average' and 'global' parameter estimates rather than 'local' parameter estimates which vary over space in some spatial systems. Geographically weighted regression (GWR), on the other hand, is a relatively simple, but useful new technique for the analysis of spatial nonstationarity. Using the GWR technique to study regional industrialisation in Jiangsu province, it is found that there is a significant difference between the ordinary linear regression (OLR) and GWR models. The relationships between the level of regional industrialisation and various factors show considerable spatial variability. © Springer-Verlag 2002.
{fenge}
15044339729	An environmental decision-support system for the management of water pollution in a tidal river network	This paper is about the development of a decision-support system for water-pollution management and environmental planning. More specifically, the paper first presents the overall concept and the system architecture of a generic environmental decision-support system (EDSS) and then develops an EDSS especially for analysing the tidal flow pattern and water quality of China's Pearl River Delta. The EDSS developed here employs the object-oriented approach to design the environmental database and utilizes the system integration technology to develop the overall user-friendly system that operates in the Windows environment. Furthermore, the system can be expanded to facilitate automated model selection and analysis. The EDSS should be of value for managing water quality of river networks with complicated flow patterns, such as that found in the Pearl River Delta. © 2005 Taylor & Francis Group Ltd.
{fenge}
15044347609	A development shell for intelligent spatial decision support systems: 1. Concepts and tools	This is the first of two papers that are designed for a development shell for intelligent spatial decision support systems in this paper. Basic concepts and tools of the shell will be introduced and its key functionalities will be discussed in the present part. The shell is capable of handling spatial data and models in an integrative and interactive manner in addition to rule-based inference under certainty and uncertainty. It runs on the Windows environment with extensive use of the DLL and DDE technologies for dynamic model and data communication. It can be employed to build efficiently a large variety of spatial decision support systems with GIS, models, and domain-specific knowledge as integrative components. © 1997 OPA (Overseas Publishers Association) Amsterdam B.V. Published in The Netherlands under license by Gordon and Breach Science Publishers.
{fenge}
15044364197	A development shell for intelligent spatial decision support systems: 2. An application in flood simulation and damage assessment	As a real-life application, a flood simulation and damage assessment decision support system is built with the development shell examined in the first of the two papers. The system is successfully applied to simulate and assess a flooding situation in Sun Hugou watershed in China. It demonstrates the way flood process models (simulation models), rule-based evaluations, and various types of spatial data can be intelligently utilized in an integrative and interactive environment. The application illustrates that the shell developed has great potential in developing decision support systems for complex spatial problems. © 1997 OPA (Overseas Publishers Association) Amsterdam B.V. Published in The Netherlands under license by Gordon and Breach Science Publishers.
{fenge}
16244396746	Knowledge acquisition in incomplete information systems: A rough set approach	This paper deals with knowledge acquisition in incomplete information systems using rough set theory. The concept of similarity classes in incomplete information systems is first proposed. Two kinds of partitions, lower and upper approximations, are then formed for the mining of certain and association rules in incomplete decision tables. One type of "optimal certain" and two types of "optimal association" decision rules are generated. Two new quantitative measures, "random certainty factor" and "random coverage factor", associated with each decision rule are further proposed to explain relationships between the condition and decision parts of a rule in incomplete decision tables. The reduction of descriptors and induction of optimal rules in such tables are also examined. © 2004 Elsevier B.V. All rights reserved.
{fenge}
1542606505	Identifiability of mixture models for mining regression classes	Complex and massive data usually appear as a mixture of multiple classes of structures, mixture model of regression classes is a description of such mixture. In this paper, we consider three cases on regression variables: (1) fixed explanatory variables; (2) random explanatory variables; and (3) fixed explanatory variables and specified class parameters. Based on the finite mixture distribution theory from statistics and the related results on identifiability, we discuss the identifiability of mixture models for mining general regression classes in these three cases and give the corresponding sufficient conditions in which mixture models of regression classes with the same regression function are identifiable. All of these conditions are related with a class of sets of explanatory variables. The sets are uniquely determined by the regression function and regression parameters, and their elements make different regression parameters to have the same values of regression function. In particular, when regression functions are linear, these sets become hyperplanes in explanatory variables spaces.
{fenge}
1642554515	Changing the shape of ZnO nanostructures by controlling Zn vapor release: From tetrapod to bone-like nanorods	Different morphologies of ZnO nanostructures were fabricated by changing the type of starting material (ZnO powder vs. ZnO nanoparticles, graphite vs. carbon nanotubes). The structure of deposited materials was investigated by X-ray diffraction, field emission scanning electron microscopy, transmission electron microscopy and selected area electron diffraction. The obtained shapes and sizes of ZnO nanostructures were found to be strongly dependent on the type and quantity of starting materials, which control the release of Zn vapor and thusly control the diameter and shape of fabricated structures. © 2004 Elsevier B.V. All rights reserved.
{fenge}
20444488080	An uncertainty measure in partition-based fuzzy rough sets	This paper extends Pawlak's rough set onto the basis of a fuzzy partition of the universe of discourse. Some basic properties of partition-based fuzzy approximation operators are examined. To measure uncertainty in generalized fuzzy rough sets, a new notion of entropy of a fuzzy set is introduced. The notion is demonstrated to be adequate for measuring the fuzziness of a fuzzy event. The entropy of a fuzzy partition and conditional entropy are also proposed. These kinds of entropy satisfy some basic properties similar to those of Shannon's entropy. It is proved that the measure of fuzziness of a partition-based fuzzy rough set, FR(A), is equal to zero if and only if the set A is crisp and definable. © 2005 Taylor & Francis Ltd.
{fenge}
19044390948	On characterizations of (script I sign script T Sign)-fuzzy rough approximation operators	In rough set theory, the lower and upper approximation operators defined by a fixed binary relation satisfy many interesting properties. Various fuzzy generalizations of rough approximations have been made in the literature. This paper proposes a general framework for the study of (I,T)-fuzzy rough approximation operators within which both constructive and axiomatic approaches are used. In the constructive approach, a pair of lower and upper generalized fuzzy rough approximation operators, determined by an implicator I and a triangular norm T, is first defined. Basic properties of (I,T)-fuzzy rough approximation operators are investigated. The connections between fuzzy relations and fuzzy rough approximation operators are further established. In the axiomatic approach, an operator-oriented characterization of rough sets is proposed, that is, (I,T)-fuzzy approximation operators are defined by axioms. Different axiom sets of T-upper and I-lower fuzzy set-theoretic operators guarantee the existence of different types of fuzzy relations which produce the same operators. Finally, an open problem proposed by Radzikowska and Kerre in (Fuzzy Sets and Systems 126 (2002) 137) is solved. © 2005 Elsevier B.V. All rights reserved.
{fenge}
22644434131	CuO nanostructures prepared by a chemical method	We investigated the properties of CuO nanostructures fabricated from copper(II) nitrate hydrate solutions as a function of synthesis temperature, concentration, and pH value of the solution. The properties of the fabricated nanostructures were studied using scanning electron microscopy, X-ray diffraction, and transmission electron microscopy. We found that the morphology of the obtained structures is strongly dependent on both pH value of the solution and the synthesis temperature. Synthesis conditions, such as solution concentration, temperature, and pH value, also affect the adhesion of the fabricated structures to the substrate, which is of importance for practical applications. © 2005 Elsevier B.V.
{fenge}
23144439759	Study of excitonic emission in highly faceted ZnO rods	We report a detailed photoluminescence study of ZnO rods which exhibit 18 side surfaces. The photoluminescence studies reveal excellent optical quality of the rods, comparable to that of thin films in spite of their large surface area. The low-temperature PL spectra are dominated by a narrow and very intense bound exciton emission. Time resolved PL results show very long decay time of spontaneous emission, with the time constants of biexponential decay equal to 116 ps and 1.2 ns. The stimulated emission spectra reveal very narrow lasing modes with widths of 0.4-0.5 nm and decay times of 4-5 ps. © 2005 Elsevier B.V. All rights reserved.
{fenge}
0031399692	Point-in-Polygon Analysis under Certainty and Uncertainty	The point-in-polygon query in geographical information systems under certainty and uncertainty is formally analyzed in this paper. It is argued that points and polygons can be precise, fuzzy (imprecise), and random (with error) with different schemes of representations. Under certainty, points and polygons can generally be represented by their characteristic functions. Under imprecision induced uncertainty, they can be represented by fuzzy sets characterized by membership functions. If uncertainty is induced by randomness, points and polygons can be described by locational error models in which probability arguments are employed. Points and polygons under certainty turn out to be a special case of that under imprecision and randomness induced uncertainty. Since points and polygons may be precisely, imprecisely or randomly captured or recognized within a spatial information system, the point-in-polygon query is then rather complicated, and its entertainment is not straight forward. In general, the point-in-polygon query can be entertained under nine basic situations. It consists of the queries of whether a precise or fuzzy or random point is in a precise or fuzzy or random polygon. As a consequence, the answer to the query may take on various forms with certain types of uncertainty arguments attached. It involves the integrative utilization of fuzzy set and probability theories to derive the results. The present analysis clarifies some unresolved issues of the point-in-polygon query and provides a generalization to its entertainment. Furthermore, it sheds light on the way certainty and uncertainty can be addressed and implemented in spatial information systems.
{fenge}
0031143271	Neural networks for convex hull computation	Computing convex hull is one of the central problems in various applications of computational geometry. In this paper, a convex hull computing neural network (CHCNN) is developed to solve the related problems in the N-dimensional spaces. The algorithm is based on a two-layered neural network, topologically similar to ART, with a newly developed adaptive training strategy called excited learning. The CHCNN provides a parallel on-line and real-time processing of data which, after training, yields two closely related approximations, one from within and one from outside, of the desired convex hull. It is shown that accuracy of the approximate convex hulls obtained is around O[K
{fenge}
0031162584	Adaptive weighted outer-product learning associative memory	Associative-memory neural networks with adaptive weighted outer-product learning are proposed in this paper. For the correct recall of a fundamental memory (FM), a corresponding learning weight is attached and a parameter called signal-to-noise-ratio-gain (SNRG) is devised. The sufficient conditions for the learning weights and the SNRG's are derived. It is found both empirically and theoretically that the SNRG's have their own threshold values for correct recalls of the corresponding FM's. Based on the gradient-descent approach, several algorithms are constructed to adaptively find the optimal learning weights with reference to global- or local-error measure. © 1997 IEEE.
{fenge}
0031236881	Degree of population diversity - A perspective on premature convergence in genetic algorithms and its Markov chain analysis	In this paper, a concept of degree of population diversity is introduced to quantitatively characterize and theoretically analyze the problem of premature convergence in genetic algorithms (GA's) within the framework of Markov chain. Under the assumption that the mutation probability is zero, the search ability of the GA's is discussed. It is proved that the degree of population diversity converges to zero with probability one so that the search ability of a GA decreases and premature convergence occurs. Moreover, an explicit formula for the conditional probability of allele loss at a certain bit position is established to show the relationships between premature convergence and the GA parameters, such as population size, mutation probability, and some population statistics. The formula also partly answers the questions of to where a GA most likely converges. The theoretical results are all supported by the simulation experiments. © 1997 IEEE.
{fenge}
0031257993	A note on the fluctuation of flows under the entropy principle	The present paper examines two neglected issues: fluctuation of flows and probability of occurrence, in entropy-based spatial interaction analysis. Variance of the estimated flow is derived to study its fluctuation. It is shown that unless a lower level of accuracy is acceptable, entropy estimates may not be appropriate especially when the scale of a spatial interaction system is small. It is further shown that the probability of having the most probable distribution under the entropy principle is in fact very small. These two findings shed light on the application of entropy-based models. © 1997 Elsevier Science Ltd.
{fenge}
0031668111	A genetic-algorithms based evolutionary computational neural network for modelling spatial interaction data	Building a feedforward computational neural network model (CNN) involves two distinct tasks: determination of the network topology and weight estimation. The specification of a problem adequate network topology is a key issue and the primary focus of this contribution. Up to now, this issue has been either completely neglected in spatial application domains, or tackled by search heuristics (see Fischer and Gopal 1994). With the view of modelling interactions over geographic space, this paper considers this problem as a global optimization problem and proposes a novel approach that embeds backpropagation learning into the evolutionary paradigm of genetic algorithms. This is accomplished by interweaving a genetic search for finding an optimal CNN topology with gradient-based backpropagation learning for determining the network parameters. Thus, the model builder will be relieved of the burden of identifying appropriate CNN-topologies that will allow a problem to be solved with simple, but powerful learning mechanisms, such as backpropagation of gradient descent errors. The approach has been applied to the family of three inputs, single hidden layer, single output feedforward CNN models using interregional telecommunication traffic data for Austria, to illustrate its performance and to evaluate its robustness. © Springer-Verlag 1998.
{fenge}
0032208708	A genetic algorithm for the multiple destination routing problems	The multiple destination routing (MDR) problem can be formulated as finding a minimal cost tree which contains designated source and multiple destination nodes so that certain constraints in a given communication network are satisfied. This is a typical NP-hard problem, and therefore only heur istic algorithms are of practical value. As a first step, a new genetic algorithm is developed to solve the MDR problems without constraints. It is based on the transformation of the underlying network of an MDR problem into its distance complete form, a natural chromosome representation of a minimal spanning tree (an individual), and a completely new computation of the fitness of individual. Compared with the known genetic algorithms and heuristic algorithms for the same problem, the proposed algorithm has several advantages. First, it guarantees convergence to an optimal solution with probability one. Second, not only are the resultant solutions all feasible, the solution quality is also much higher than that obtained by the other methods (indeed, in almost every case in our simulations, the algorithm can find the optimal solution of the problem). Third, the algorithm is of low computational complexity, and this can be decreased dramatically as the number of destination nodes in the problem increases. The simulation studies for the sparse and dense networks all demonstrate that the proposed algorithm is highly robust and very efficient in the sense of yielding high-quality solutions. © 1998 IEEE.
{fenge}
0032598066	Estimating the relationship between isoseismal area and earthquake magnitude by a hybrid fuzzy-neural-network method	Utilizing information diffusion method and artificial neural networks, we propose in this paper a hybrid fuzzy neural network to estimate the relationship between isoseismal area and earthquake magnitude. We focus on the study of incompleteness and contradictory nature of patterns in scanty historical earthquake records. Information diffusion method is employed to construct fuzzy relationships which are equal to the number of observations. Integration of the relationships can change the contradictory patterns into more compatible ones which, in turn, can smoothly and quickly train the feedforward neural network with backpropagation algorithm (BP) to obtain the final relationship. A practical application is employed to show the superiority of the model.
{fenge}
2442690727	A dual neural network for solving entropy-maximising models	The entropy-maximixing model has been applied with varying degrees of success in the analysis and planning of origin - destination types of spatial interaction. Although theoretical underpinnings and solution methods have been developed over the years, there are still outstanding problems that need to be thoroughly investigated. From the practical point of view, solving this model directly and in real time has high theoretical and pragmatic value. In this paper we propose a neural network for solving the dual problem of this model in real time. The size of the proposed network is very small and its structure is very simple, so it can be implemented in hardware. From the theoretical perspective, we solve the seldom investigated issue of convergence to the optimal solution of the entropy-maximising model. We strictly prove that the proposed dual neural network is Lyapunov stable and that each of its trajectories can converge asymptotically to an exact solution of the dual problem. The validity and transient behaviour of the proposed neural network are demonstrated by numerical examples. It is also demonstrated that the proposed network approach renders for the first time a tight integration of an entropy-maximising model and a neural network, and offers a general representation and solution to a large variety of entropy-maximising models.
{fenge}
24044535718	Variable programming: A generalized minimax problem. Part I: Models and theory	In this two-part series of papers, a new generalized minimax optimization model, termed variable programming (VP), is developed to solve dynamically a class of multi-objective optimization problems with non-decomposable structure. It is demonstrated that such type of problems is more general than existing optimization models. In this part, the VP model is proposed first, and the relationship between variable programming and the general constrained nonlinear programming is established. To illustrate its practicality, problems on investment and the low-side-lobe conformal antenna array pattern synthesis to which VP can be appropriately applied are discussed for substantiation. Then, theoretical underpinnings of the VP problems are established. Difficulties in dealing with the VP problems are discussed. With some mild assumptions, the necessary conditions for the unconstrained VP problems with arbitrary and specific activated feasible sets are derived respectively. The necessary conditions for the corresponding constrained VP problems with the mild hypotheses are also examined. Whilst discussion in this part is concentrated on the formulation of the VP model and its theoretical underpinnings, construction of solution algorithms is discussed in Part II. © 2005 Springer Science + Business Media, Inc.
{fenge}
24044536577	Variable programming: A generalized minimax problem. Part II: Algorithms	In this part of the two-part series of papers, algorithms for solving some variable programming (VP) problems proposed in Part I are investigated. It is demonstrated that the non-differentiability and the discontinuity of the maximum objective function, as well as the summation objective function in the VP problems constitute difficulty in finding their solutions. Based on the principle of statistical mechanics, we derive smooth functions to approximate these non-smooth objective functions with specific activated feasible sets. By transforming the minimax problem and the corresponding variable programming problems into their smooth versions we can solve the resulting problems by some efficient algorithms for smooth functions. Relevant theoretical underpinnings about the smoothing techniques are established. The algorithms, in which the minimization of the smooth functions is carried out by the standard quasi-Newton method with BFGS formula, are tested on some standard minimax and variable programming problems. The numerical results show that the smoothing techniques yield accurate optimal solutions and that the algorithms proposed are feasible and efficient. © 2005 Springer Science + Business Media, Inc.
{fenge}
24144434463	Titania bicontinuous network structures for solar cell applications	We report fabrication of a Ti O2 interconnected network structure for photovoltaic applications, which was obtained using polystyrene-block-polyethylene oxide diblock copolymer as the templating agent. The synthetic method is simple and highly reproducible. The pore size of the structure is controlled by the amount of Ti precursor provided. The heterojunction solar cells consisting of a Ti O2 porous network structure and poly (2-methoxy-5- (2′ -ethyl-hexyloxy)-p-phenylene vinylene) (MEH-PPV) showed improved performance with a short circuit current of 3.25 mA cm2 under AM 1.5 solar illumination. The achieved maximum external quantum efficiency for optimum MEH-PPV thickness was 34%. © 2005 American Institute of Physics.
{fenge}
24644487435	Time-resolved photoluminescence study of the stimulated emission in ZnO nanoneedles	ZnO nanoneedles were fabricated by thermal evaporation of Zn nanoparticles at 800 °C and atmospheric pressure. The samples showed strong ultraviolet photoluminescence and weak orange defect luminescence. Time-resolved photoluminescence (TRPL) was measured using the Kerr-gated fluorescence technique in order to probe the ultrafast carrier dynamics in exciton-exciton scattering and electron hole plasma (EHP) regimes. In both regimes, the decay time of the photoluminescence is very fast (∼1 ps). Even though no structure is detected in the time-integrated spectra of the EHP emission, the TRPL reveals the coexistence of the excitons and free carriers. Possible reasons for the observed phenomena are discussed. © 2005 American Institute of Physics.
{fenge}
27544470485	Stimulated emission in ZnO nanostructures: A time-resolved study	Stimulated emission was studied using time-integrated and time-resolved photoluminescence in ZnO comb, tetrapod, and rod nanostructures. All the measurements were performed on ensembles of the nanostructures. The nanostructures were fabricated by vapor deposition (combs, tetrapods) and hydrothermal methods (rods). While stimulated emission was detected in all of the nanostructures, significant differences in the behavior of the stimulated emission, as well as the lasing threshold power, were found for different morphologies. The differences in the time evolution of the lasing spectra were particularly pronounced. The observed differences in the stimulated emission spectra of the three types of nanostructures in both exciton-exciton scattering and electron-hole plasma regimes are discussed. © 2005 American Chemical Society.
{fenge}
27944447998	Time-resolved photoluminescence from ZnO nanostructures	Different ZnO nanostructures (tetrapods, shells, rods, and highly faceted rods) were characterized by photoluminescence (PL) and time-resolved PL measurements. It was found that different nanostructures exhibit very different optical properties in terms of defect emission and decay times of the spontaneous emission. No correlation was found between the PL decay times and defect emission intensities and defect emission positions. The short decay times of the UV emission are most likely due to nonradiative defects that are correlated with the crystalline quality and do not contribute to the visible emission. Neither short PL decay times nor intense defect emissions rule out achievement of stimulated emission. © 2005 American Institute of Physics.
{fenge}
29144484684	Ultrafast spectroscopy of stimulated emission in single ZnO tetrapod nanowires	Stimulated emission from single ZnO tetrapod nanowires was studied by time-resolved photoluminescence (TRPL) spectroscopy. The samples were excited by a 300 fs pulse and the emission spectra collected as a function of time. The spectra exhibit a change in the position and the shape of the emission peak with time. The time evolution of the emission spectra was studied for different pump excitation fluences. The spectra exhibited a blue shift with increasing pump fluence, while for all pump fluences a red shift of the peaks with time was obtained. Possible reasons for the observed behaviour are discussed.
{fenge}
27744447321	A highly robust estimator for regression models	It is well known that classical robust estimators tolerate only less than fifty percent of outliers. However, situations with more than fifty percent of outliers often occur in practice. The efficient identification of objects from a noisier background is thus a difficult problem. In this paper, a highly robust estimator is formulated to tackle such a difficulty. The proposed estimator is called the regression density decomposition (RDD) estimator. The computational analysis of the estimator and its properties are discussed and a simulated annealing algorithm is proposed for its implementation. It is demonstrated that the RDD estimator can resist a very large proportion of noisy data, even more than fifty percent. It is successfully applied to some simulated and real-life noisy data sets. It appears that the estimator can solve efficiently and effectively general regression problems, pattern recognition, computer vision and data mining problems. © 2005 Elsevier B.V. All rights reserved.
{fenge}
30344471243	Transformations for nonideal uniform circular arrays operating in correlated signal environments	The Davies transformation is a method to transform the steering vector of a uniform circular array (UCA) to one with Vandermonde form. As such, it allows techniques such as spatial smoothing for direction-of-arrival (DOA) estimation in a correlated signal environment, developed originally for uniform linear arrays, to be applied to UCAs. However, the Davies transformation can be highly sensitive to perturbations of the underlying array model. This paper presents a method for deriving a more robust transformation using optimization techniques. The effectiveness of the method is illustrated through a number of DOA estimation examples. © 2006 IEEE.
{fenge}
32844462438	A mathematical morphology based scale space method for the mining of linear features in geographic data	This paper presents a spatial data mining method MCAMMO and its extension L_MCAMMO designed for discovering linear and near linear features in spatial databases. L_MCAMMO can be divided into two basic steps: first, the most suitable re-segmenting scale is found by MCAMMO, which is a scale space method with mathematical morphology operators; second, the segmented result at this scale is re-segmented to obtain the final linear belts. These steps are essentially a multi-scale binary image segmentation process, and can also be treated as hierarchical clustering if we view the points under each connected component as one cluster. The final number of clusters is the one which survives (relatively, not absolutely) the longest scale range, and the clustering which first realizes this number of clusters is the most suitable segmentation. The advantages of MCAMMO in general and L_MCAMMO in particular, are: no need to pre-specify the number of clusters, a small number of simple inputs, capable of extracting clusters with arbitrary shapes, and robust to noise. The effectiveness of the proposed method is substantiated by the real-life experiments in the mining of seismic belts in China. © 2005 Springer Science+Business Media, Inc.
{fenge}
33645066931	Influence of the carrier gas on the luminescence of ZnO tetrapod nanowires	ZnO tetrapod nanowires were prepared by thermal evaporation of Zn in the flow of different carrier gases (argon, nitrogen, humidified argon and humidified nitrogen). The optical properties of the tetrapod nanowires were investigated by low-temperature photoluminescence measurements, reflectance measurements and X-ray photoelectron spectroscopy (XPS). It was found that the type of gas significantly affects the optical properties of the fabricated tetrapod nanowires. The origin of the differences in the photoluminescence spectra of tetrapod nanowires fabricated with different carrier gases is discussed. The addition of water vapor to the carrier gas affected the photoluminescence and XPS spectra for both N
{fenge}
33645538523	Optical properties of highly faceted ZnO rods	Highly faceted ZnO rods with 18 side surfaces were synthesized. Their optical properties were characterized by variable temperature photoluminescence, time-resolved photoluminescence, and time-integrated photoluminescence. Low-temperature photoluminescence is dominated by a narrow donor bound exciton peak, while at room temperature ultraviolet emission and green emission can be observed. In spite of the presence of the defect emission, the samples have excellent crystal quality based on the long lifetime of spontaneous emission, with the time constants of biexponential decay equal to 116ps and 1.2ns. With increasing pump fluence, stimulated emissions due to excitonic and electron-hole plasma effects were observed. The lasing dynamics in both emission regimes is discussed. © 2006 American Institute of Physics.
{fenge}
33745685326	Tailoring and modifications of a ZnO nanostructure surface by the layer-by-layer deposition technique	Different ZnO nanostructures have been modified using the layer-by-layer polyelectrolyte deposition process. The polymer multilayers were deposited on free standing ZnO tetrapods, ZnO tetrapods on a substrate and ZnO nanorod arrays. In addition, attachment of metallic (Au) nanoparticles to the ZnO nanostructure surface using layer-by-layer deposition was demonstrated. The properties of the ZnO nanostructures with modified surfaces were investigated by electron microscopy, absorption and photoluminescence measurements. A linear increase in polymer thickness with the number of polymer multilayers was confirmed by absorption and transmission electron microscopy. The technique can be readily extended to different nanoparticles and different morphologies of ZnO. © 2006 IOP Publishing Ltd.
{fenge}
33745698342	Unidimensional scaling classifier and its application to remotely sensed data	Unidimensional Scaling (UDS) is to arrange n objects on the real line so that there inter-points distances are as close as possible to their observed distances. In this paper, we apply this new method to remotely sensed data, and then improve on this method according to the characteristics of remotely sensed data. For validating this method, we make use of simulation data and remotely sensed data and compare the classification result with the method of K-Means. The result of comparison makes clear that UDS is succinctness and more understandable, and it can not only obtain the classification result of higher accuracy, but also be of the characteristics that it is not necessary the prior information of class numbers and independent on the structure of data classified. At the same time, it has advantage over the nonlimitness of high dimension of feature space. © 2005 IEEE.
{fenge}
33746364810	Truth-value transmittal fuzzy reasoning interpolator	In this paper, we firstly associate fuzzy reasoning algorithm with the interpolation algorithm and discuss the limitation of defuzzification methods used commonly in the fuzzy reasoning algorithm. Secondly, we give a new fuzzy reasoning algorithm in case of single input, called the truth-value transmittal method, and discuss its properties. Finally, we analyze the rationality to adopy the truth-value transmittal method as the defuzzification method of full implication triple I method, and show that although CRI and triple I fuzzy reasoning method are different from fuzzy output set, they are uniform finally under the truth-value transmittal defuzzification method. Copyright by Science in China Press 2005.
{fenge}
33746772771	Surface modification of nanosized zinc oxide tetrapods by layer-by-layer deposition method and their optical properties	The fabrication of a rhenium containing hyperbranched polymer (1) and poly[2-(3-thienyl)ethoxy-4-butylsulfonate] (PTEBS) multilayer on different ZnO nanostructures, including free standing ZnO tetrapods and ZnO nanorod arrays using layer-by-layer approach was demonstrated. The growth of the multilayer film and the attachment of the metal nanoparticles on the ZnO surface were investigated by scanning electron microscopy (SEM) and high resolution transmission electron microscopy (HRTEM). The results show that accurate control in multilayer film growth can be achieved. This paper presents a versatile method in modifying the surface of different ZnO nanostructures.
{fenge}
33747304485	Optical properties of ZnO nanostructures	We present a review of current research on the optical properties of ZnO nanostructures. We provide a brief introduction to different fabrication methods for various ZnO nanostructures and some general guidelines on how fabrication parameters (temperature, vapor-phase versus solution-phase deposition, etc.) affect their properties. A detailed discussion of photo-luminescence, both in the UV region and in the visible spectral range, is provided. In addition, different gain (excitonic versus electron hole plasma) and feedback (random lasing versus individual nanostructures functioning as Fabry-Perot resonators) mechanisms for achieving stimulated emission are described. The factors affecting the achievement of stimulated emission are discussed, and the results of time-resolved studies of stimulated emission are summarized. Then, results of nonlinear optical studies, such as second-harmonic generation, are presented. Optical properties of doped ZnO nanostructures are also discussed, along with a concluding outlook for research into the optical properties of ZnO. © 2006 Wiley-VCH Verlag GmbH & Co. KGaA.
{fenge}
33749476390	Green photoluminescence in ZnO nanostructures	In photoluminescence (PL) spectrum of ZnO, typically one or more peaks in the visible spectral range due to defect emission can be observed in addition to one UV peak due to band edge emission. The origin of the defect emission is controversial and several mechanisms have been proposed. In this work, we fabricated ZnO nanostructures with different methods (evaporation and chemical synthesis). We found that the preparation method influences the peak position of the defect emission. Different hypotheses for the origin of the green emission in our nanostructured samples are discussed. © 2005 American Institute of Physics.
{fenge}
33749483732	Synthesis and properties of ZnO nano-ribbon and comb structures	ZnO is of great interest for photonic applications due to its wide band gap (3.37 eV) and large exciton binding energy (60 meV). A large variety of fabrication methods and nanostructure morphologies was reported up to date for this material. Obtained morphologies include nanobelts or nanoribbons, nanowires, nanorods, tetrapod nanostructures, etc. Novel nanostructures like hierarchical nanostructures, nanobridges and nanonails have also been fabricated. In this work, we report a simple method for fabrication of nanoribbon and nanocomb structures. The structures are fabricated by evaporation of a mixture of ZnO and carbon nanotubes (CNT) at 1050°C, and the deposition products have been collected on Si substrates in the temperature range 750-800°C. The growth mechanism of obtained structures is discussed. © 2005 American Institute of Physics.
{fenge}
33750347661	A modification to the new version of the price's algorithm for continuous global optimization problems	This paper presents an algorithm for finding a global minimum of a multimodal, multivariate and nondifferentiable function. The algorithm is a modification to the new version of the Price's algorithm given in Brachetti et al. [J. Global Optim. 10, 165-184 (1997)]. Its distinguishing features include: (1) The number-theoretic method is applied to generate the initial population so that the points in the initial population are uniformly scattered, and therefore the algorithm could explore uniformly the region of interest at the initial iteration; (2) The simplified quadratic approximation with the three best points is employed to improve the local search ability and the accuracy of the minimum function value, and to reduce greatly the computational overhead of the algorithm. Two sets of experiments are carried out to illustrate the efficiency of the number-theoretic method and the simplified quadratic model separately. The proposed algorithm has also been compared with the original one by solving a wide set of benchmark problems. Numerical results show that the proposed algorithm requires a smaller number of function evaluations and, in many cases, yields a smaller or more accurate minimum function value. The algorithm can also be used to deal with the medium size optimization problems. © Springer Science+Business Media B.V. 2006.
{fenge}
33750617069	Modelling for registration of remotely sensed imagery when reference control points contain error	Reference control points (RCPs) used in establishing the regression model in the registration or geometric correction of remote sensing images are generally assumed to be "perfect". That is, the RCPs, as explanatory variables in the regression equation, are accurate and the coordinates of their locations have no errors. Thus ordinary least squares (OLS) estimator has been applied extensively to the registration or geometric correction of remotely sensed data. However, this assumption is often invalid in practice because RCPs always contain errors. Moreover, the errors are actually one of the main sources which lower the accuracy of geometric correction of an uncorrected image. Under this situation, the OLS estimator is biased. It cannot handle explanatory variables with errors and cannot propagate appropriately errors from the RCPs to the corrected image. Therefore, it is essential to develop new feasible methods to overcome such a problem. This paper introduces a consistent adjusted least squares (CALS) estimator and proposes relaxed consistent adjusted least squares (RCALS) estimator, with the latter being more general and flexible, for geometric correction or registration. These estimators have good capability in correcting errors contained in the RCPs, and in propagating appropriately errors of the RCPs to the corrected image with and without prior information. The objective of the CALS and proposed RCALS estimators is to improve the accuracy of measurement value by weakening the measurement errors. The conceptual arguments are substantiated by a real remotely sensed data. Compared to the OLS estimator, the CALS and RCALS estimators give a superior overall performance in estimating the regression coefficients and variance of measurement errors. © Science in China Press 2006.
{fenge}
33751296959	Defects in ZnO nanorods prepared by a hydrothermal method	ZnO nanorod arrays were fabricated using a hydrothermal method. The nanorods were studied by scanning electron microscopy, photoluminescence (PL), time-resolved PL, X-ray photoelectron spectroscopy, and positron annihilation spectroscopy before and after annealing in different environments and at different temperatures. Annealing atmosphere and temperature had significant effects on the PL spectrum, while in all cases the positron diffusion length and PL decay times were increased. We found that, while the defect emission can be significantly reduced by annealing at 200°C, the rods still have large defect concentrations as confirmed by their low positron diffusion length and short PL decay time constants. © 2006 American Chemical Society.
{fenge}
33750724449	Influence of annealing on stimulated emission in ZnO nanorods	Vertically aligned ZnO nanorod arrays with rod lengths in the range of 200-1500 nm were fabricated by a hydrothermal method. No stimulated emission was observed in as grown nanorods. Annealing of the rods in forming gas and oxygen significantly affected their optical properties and enabled the achievement of stimulated emission. The lowest lasing threshold and defect emission as well as the longest spontaneous emission decay times were obtained for nanorods annealed in oxygen flow. This indicates that interstitial oxygen, which is commonly assumed to be the cause of yellow-green defect emission, is not the dominant defect in hydrothermally grown nanorods. © 2006 American Institute of Physics.
{fenge}
33845247764	A new method for feature mining in remotely sensed images	Extending on the method of regression-class mixture decomposition (RCMD), a RCMD-based feature mining model with genetic algorithm (coined RFMM-GA) is proposed in this paper for the extraction of features in complex remotely sensed images with a large proportion of noise. Within the framework of RFMM-GA, different features in the feature space correspond to different components of a mixture in which each of its components can be specified by a certain type of parametric distribution and the suitable parameter sets. The model captures nicely the overlapping and noisy conditions usually encountered in remotely sensed images. Features are successfully mined when the corresponding parameter sets are appropriately estimated. Through the embedded GA, features with the assumed components are hierarchically mined until the data set is decomposed into a group of feature patterns. Compared to conventional methods, the RFMM-GA has several distinct advantages: (1) The initial number of features does not need to be specified a priori. The procedure terminates after all relevant features have been unravelled. (2) Large proportion of noisy data in the mixture can be tolerated. (3) Parameter estimations of individual features are virtually independent of each other. (4) Variabilities in shapes and sizes of the features in the mixture are accounted for. Three experimental results on the extraction of ellipsoidal and linear features demonstrate the effectiveness of the RFMM-GA model for feature mining in noisy data with mixed feature distribution. © Springer Science + Business Media, LLC 2006.
{fenge}
33947220433	The minimal sets of axioms characterizing rough fuzzy approximation operators	Axiomatic characterization of rough approximation operators is one of the important aspects in the study of rough set theory. In axiomatic approach, various classes of rough approximation operators are characterized by different sets of axioms. Axioms of approximation operators guarantee the existence of certain types of binary relations producing the same operators. In this paper, the approximation operators determined by a triangular norm are studied, the independence of axioms characterizing rough fuzzy approximation operators is examined, and then the minimal sets of axioms for the characterization of fuzzy approximation operators are presented. © 2006 IEEE.
{fenge}
33947510248	Defect emissions in ZnO nanostructures	Defects in three different types of ZnO nanostructures before and after annealing under different conditions were studied. The annealing atmosphere and temperature were found to strongly affect the yellow and orange-red defect emissions, while green emission was not significantly affected by annealing. The defect emissions exhibited a strong dependence on the temperature and excitation wavelength, with some defect emissions observable only at low temperatures and for certain excitation wavelengths. The yellow emission in samples prepared by a hydrothermal method is likely due to the presence of OH groups, instead of the commonly assumed interstitial oxygen defect. The green and orange-red emissions are likely due to donor acceptor transitions involving defect complexes, which likely include zinc vacancy complexes in the case of orange-red emissions. © IOP Publishing Ltd.
{fenge}
34548559200	A rough set approach to the discovery of classification rules in spatial data	This paper proposes a novel rough set approach to discover classification rules in real-valued spatial data in general and remotely sensed data in particular. A knowledge induction process is formulated to select optimal decision rules with a minimal set of features necessary and sufficient for a remote sensing classification task. The approach first converts a real-valued or integer-valued decision system into an interval-valued information system. A knowledge induction procedure is then formulated to discover all classification rules hidden in the information system. Two real-life applications are made to verify and substantiate the conceptual arguments. It demonstrates that the proposed approach can effectively discover in remotely sensed data the optimal spectral bands and optimal rule set for a classification task. It is also capable of unraveling critical spectral band(s) discerning certain classes. The framework paves the road for data mining in mixed spatial databases consisting of qualitative and quantitative data.
{fenge}
34548635046	Granular computing and dual Galois connection	A covering model for granular computing in a set-theoretic setting is studied in this paper. Under this model, a zooming-in operator is redefined. Combinations of the zooming-in and zooming-out operators form two pairs of approximation operators of the original and the granulated universe of discourse. Their properties are examined in detail. For the two pairs of lower and upper approximation operators, it is proved that the duality is always true. For a generalized approximation space, the approximation representations are just the combination operators formed on the basis of the zooming-out and zooming-in operators. Relationships between these combination operators and the dual Galois connection are also analyzed. © 2007 Elsevier Inc. All rights reserved.
{fenge}
36248994777	A rough set approach for the discovery of classification rules in interval-valued information systems	A novel rough set approach is proposed in this paper to discover classification rules through a process of knowledge induction which selects decision rules with a minimal set of features for classification of real-valued data. A rough set knowledge discovery framework is formulated for the analysis of interval-valued information systems converted from real-valued raw decision tables. The minimal feature selection method for information systems with interval-valued features obtains all classification rules hidden in a system through a knowledge induction process. Numerical examples are employed to substantiate the conceptual arguments. © 2007 Elsevier Inc. All rights reserved.
{fenge}
0032715904	Processing of major ABO-incompatible bone marrow for transplantation by using dextran sedimentation	BACKGROUND: Various open and semi-closed methods are used for red cell (RBC) depletion and hematopoietic progenitor cell (HPC) enrichment of bone marrow (BM) in vitro, but with variable efficacy. A simple, efficient, and safe method using dextran 110k was developed. STUDY DESIGN AND METHODS: An equal volume of 4.5-percent dextran was applied to major ABO-incompatible BM in transfer bags and sedimentation was allowed for 30 minutes. RBCs, nucleated cells (NCs), and mononuclear cells (MNCs) from BM allografts before and after dextran sedimentation (DS) were counted. Flow cytometry, short-term cultures, and long-term cultures were performed to assay the respective recovery of CD34+ cells, colony-forming units (CFUs), and long-term culture- initiating cells (LTC-ICs). RESULTS: Sixteen BM collections were processed. The mean volume was 666 mL (range, 189-1355 mL). The mean ± 1 SD post-DS NC, MNC, CD34+ cell, and CFU counts per kg of the recipient's body weight were 4.11 ± 1.74 x 10
{fenge}
0032831077	A generic concept-based object-oriented geographical information system	Unlike most of the current object-oriented geographical information systems (OOGISs) whose designs are based on the traditional spatial conceptual model emphasizing the processing of geometric features, the concept-based OOGIS proposed in this paper provides a spatial conceptual model which comprises rich spatial semantics fundamental to spatial analysis, and an object-oriented data model (OODM) which provides an appropriate and effective representation of the spatial conceptual model for efficient database management. By structuring the cognition of space through three interrelated hierarchies: namely the spatial conceptual hierarchy, the entity hierarchy and the feature hierarchy, the generic concept-based OOGIS renders an appropriate framework for the scientific investigation of space and the design of an efficient object-oriented database management system. In addition to its generic nature, the proposed OOGIS is in line with our commonsense conceptualization of space. Furthermore, it can entertain multiple-representations, and can facilitate data integration and generalization. The present investigation thus advances an effective way for OOGIS research in general and design in particular.
{fenge}
0033691093	New algorithm for estimating the risk of natural disasters with incomplete data	In this paper, we propose a new algorithm for estimating the risk of natural disaster based on incomplete data. To guarantee reliability in theory, we prove in this paper that the estimator obtained by the algorithm is asymptotically unbiased and mean squared consistent. We also give two simulation experiments showing the advantage of the algorithm. To demonstrate its practicality, we further employ the new algorithm to estimate, with only 9 observations, the risk of flood, drought and wind in Changsha county of Hunan Province in China. All results show that the new algorithm, which can unravel fuzzy information in incomplete data, is better than the main existing methods for risk estimation of natural disaster with small samples.
{fenge}
0034034461	Testing for spatial autocorrelation among the residuals of the geographically weighted regression	Geographically weighted regression (GWR) is a useful technique for exploring spatial nonstationarity by calibrating, for example, a regression model which allows different relationships to exist at different points in space. In this line of research, many spatial data sets have been successfully analyzed and some statistical tests for spatial variation have been developed. However, an important assumption in these studies is that the disturbance terms of the GWR model are uncorrelated and of common variance. Similar to the case in the ordinary linear regression, spatial autocorrelation can invalidate the standard assumption of homoscedasticity of the disturbances and mislead the results of statistical inference. Therefore, developing some statistical methods to test for spatial autocorrelation is a very important issue. In this paper, two kinds of the statistical tests for spatial autocorrelation among the residuals of the GWR model are suggested. Also, an efficient approximation method for calculating the p-values of the test statistics is proposed. Some simulations are run to examine the performances of the proposed methods and the results are encouraging. The study not only makes it possible to test for spatial autocorrelation among the GWR residuals in a conventional statistical manner, but also provides a useful means for model validation.
{fenge}
0034094265	Statistical tests for spatial nonstationarity based on the geographically weighted regression model	Geographically weighted regression (GWR) is a way of exploring spatial nonstationarity by calibrating a multiple regression model which allows different relationships to exist at different points in space. Nevertheless, formal testing procedures for spatial nonstationarity have not been developed since the inception of the model. In this paper the authors focus mainly on the development of statistical testing methods relating to this model. Some appropriate statistics for testing the goodness of fit of the GWR model and for testing variation of the parameters in the model are proposed and their approximated distributions are investigated. The work makes it possible to test spatial non-stationarity in a conventional statistical manner. To substantiate the theoretical arguments, some simulations are run to examine the power of the statistics for exploring spatial nonstationarity and the results are encouraging. To streamline the model, a stepwise procedure for choosing important independent variables is also formulated. In the last section, a prediction problem based on the GWR model is studied, and a confidence interval for the true value of the dependent variable at a new location is also established. The study paves the path for formal analysis of spatial nonstationarity on the basis of the GWR model.
{fenge}
38349003447	On generalized rough fuzzy approximation operators	This paper presents a general framework for the study of rough fuzzy sets in which fuzzy sets are approximated in a crisp approximation space. By the constructive approach, a pair of lower and upper generalized rough fuzzy approximation operators is first defined. The rough fuzzy approximation operators are represented by a class of generalized crisp approximation operators. Properties of rough fuzzy approximation operators are then discussed. The relationships between crisp relations and rough fuzzy approximation operators are further established. By the axiomatic approach, various classes of rough fuzzy approximation operators are characterized by different sets of axioms. The axiom sets of rough fuzzy approximation operators guarantee the existence of certain types of crisp relations producing the same operators. The relationship between a fuzzy topological space and rough fuzzy approximation operators is further established. The connections between rough fuzzy sets and Dempster-Shafer theory of evidence are also examined. Finally multi-step rough fuzzy approximations within the framework of neighborhood systems are analyzed. © Springer-Verlag Berlin Heidelberg 2006.
{fenge}
31844442243	Defect emissions in ZnO nanostructures	Zinc oxide (ZnO) is of great interest in photonic applications due to its wide bandgap (3.37 eV) and high exciton binding energy (60 meV). In the photoluminescence (PL) spectrum of ZnO, typically one U V band-edge emission peak and one or more peaks at the visible spectral range due to defect emission are observed. The PL emission of ZnO is commonly green, but other colors like yellow and orange are also reported. Out of the different visible peaks, the origin of the green one is the most controversial. The most commonly cited explanation for it is the transition between a singly oxidized oxygen vacancy and a photoexcited hole [K. Vanheusden, C. H. Seager, W. L. Warren, D. R. Tallant, and J. A. Voigt, Appl. Phys. Lett. 68, 403 (1996).]. However, this hypothesis is established on ZnO phosphors but not on nanostructured samples. In this work, several ZnO nanostructures (nanorods, nanoneedles, nanoshells and tetrapod nanorods) were synthesized by thermal evaporation and chemical methods. The obtained nanostructures were examined by scanning electron microscopy (SEM), X-ray diffraction (XRD), photoluminescence (PL), and electron paramagnetic resonance spectroscopy (EPR). It was found that fabrication methods significantly affect the defect emissions of the nanostructures. For different fabrication conditions, defect emissions in the green, yellow, and orange spectral ranges were observed. No correlation was found between the deep levels responsible for the visible emission and the EPR signal. Origins of the different defect emissions are discussed.
{fenge}
33644882228	Green, yellow, and orange defect emission from ZnO nanostructures: Influence of excitation wavelength	ZnO commonly exhibits luminescence in the visible spectral range due to different intrinsic defects. In order to study defect emissions, photoluminescence from ZnO nanostructures prepared by different methods (needles, rods, shells) was measured as a function of excitation wavelength and temperature. Under excitation at 325 nm, needles exhibited orange-red defect emission, rods exhibited yellow defect emission, while shells exhibited green defect emission. Obvious color change from orange to green was observed for needles with increasing excitation wavelengths, while nanorods (yellow) showed smaller wavelength shift and shells (green) showed no significant spectral shift. Reasons for different wavelength dependences are discussed. © 2006 American Institute of Physics.
{fenge}
4143107090	Zinc oxide ribbon and comb structures: Synthesis and optical properties	ZnO ribbon and comb structures have been synthesized in high yield from the mixture of ZnO powder and single-walled carbon nanotubes. The influence of the fabrication temperature and the substrate on the morphology and yield of the obtained products was investigated. It was found that the substrate used significantly affected the yield and morphology of the obtained nanostructures. The structure of the deposited materials was investigated by X-ray diffraction, field emission scanning electron microscopy, transmission electron microscopy, selected area electron diffraction and photoluminescence. The ribbon/comb structures exhibit strong UV photoluminescence and weak green emission indicating excellent crystal quality. © 2004 Elsevier B.V. All rights reserved.
{fenge}
40849083398	Improving geodesic distance estimation based on locally linear assumption	Geodesic distance estimation for data lying on a manifold is an important issue in many applications of nonlinear dimensionality reduction. In this paper, a method aiming at improving the precision of geodesic distance estimation is proposed. The method is constructed on the basic principle, locally linear assumption, underlying the manifold data. It presumes that the locally linear patch, expressed as a convex combination of neighbors of a vertex, approximately resides on the manifold, as well as the local neighborhood edge does. The proposed method essentially extends the search area from local edges, employed by existing methods, to local patches. This naturally leads to a more accurate geodesic distance estimation. An efficient algorithm for the method is constructed, and its computational complexity is also analyzed. Experiment results also show that the proposed method outperforms the existing methods in geodesic distance estimation. © 2008 Elsevier B.V. All rights reserved.
{fenge}
77954169131	Multifractal temporally weighted detrended fluctuation analysis and its application in the analysis of scaling behavior in temperature series	Detrended fluctuation analysis (DFA) is a method widely used for the study of long-range correlation and fractal scaling properties of time series. Based on DFA, multifractal detrended fluctuation analysis (MF-DFA) was proposed to give a full description of more complicated time series. However, the removal of local trends in DFA is based on discontinuous polynomial fitting. It has been shown that oscillations in the fluctuation function and significant errors in crossover locations can be introduced in actual implementations. In terms of time series, it is generally natural that points near in time are more related than points some distance apart. Such principles can help us circumvent the above problems in the detrending step of MF-DFA. Based on this rationale, the ideas of moving windows and weighted moving windows are proposed for smoothing the log-log plot of the fluctuation function F(s) versus the scale s so that local effects can be taken into consideration and crossover timescales, particularly large timescales, can be effectively detected. The multifractal moving-window detrended fluctuation analysis (MF-MWDFA) and the more general multifractal temporally weighted detrended fluctuation analysis (MF-TWDFA) are proposed in this paper. Numerical simulations and the analysis of a real-life daily temperature time series are performed in order to substantiate the arguments and evaluate the performance. With the help of MF-TWDFA, two more crossover points, which cannot be found by the conventional MF-DFA, have been found in the annual-detrended temperature series by the proposed model. The crossover timescales appear to correspond rather closely with the actual variation of temperature over time under different climate regimes. © 2010 IOP Publishing Ltd.
{fenge}
42649139990	Cities and globalization: An international cities perspective	This paper adopts an international cities perspective for the study of major cities in the world, using data on 100 service firms in 314 cities provided by the Globalization and World Cities Study Group and Network (GaWC). Firms and cities have different degrees of internationalization, with many firms, for example, having only a regional focus with modest global coverage. Many international cities, in turn, also show only partial evidence of internationalization; only a few quofy as truly "world cities" that function as dominant command centers of the world economy. There is a good correspondence between regional firms and regional clusters of cities (e.g., Asia-oriented firms and Asian open cities). Copyright © 2007 by V. H. Winston & Son, Inc. All rights reserved.
{fenge}
44649158883	Antibacterial activity of ZnO nanorods prepared by a hydrothermal method	We investigated antibacterial activity of ZnO nanorods prepared by a hydrothermal method against a gram-negative bacterium Escherichia coli and a gram-positive bacterium Bacillus atrophaeus. Antibacterial activity of ZnO nanorod coatings was studied on solid substrates covered with nutrient agar, as well as in liquid nutrient broth for different concentrations of ZnO nanorods, nanoparticles, and powder. ZnO exhibited antibacterial activity against both E. coli and B. atrophaeus, but it was considerably more effective in the latter case (at 15 mM vs. 5 mM concentration, respectively, showing zero viable cell count). For both organisms, damage of the cell membranes was found, and the effect was more pronounced for B. atrophaeus. Chemiluminescence analysis has been used to detect the release of hydrogen peroxide from ZnO structures, and the effect of H
{fenge}
45049086776	Generalized fuzzy rough approximation operators based on fuzzy coverings	This paper focuses on the generalization of covering-based rough set models via the concept of fuzzy covering. Based on a fuzzy covering of a universe of discourse, two pairs of generalized lower and upper fuzzy rough approximation operators are constructed by means of an implicator I and a triangular norm T. Basic properties of the generalized fuzzy rough approximation operators are investigated. Topological properties of the generalized fuzzy rough approximation operators and characterizations of the fuzzy T -partition by the generalized upper fuzzy rough approximation operators are further established. When fuzzy coverings are a family of R-foresets or R-aftersets of all elements of a universe of discourse with respect to a fuzzy binary relation R, the corresponding generalized fuzzy rough approximation operators degenerate into the fuzzy-neighborhood-oriented fuzzy rough approximation operators. Combining with the fuzzy-neighborhood-operator-oriented fuzzy rough approximation operators, conditions under which some or all of these approximation operators are equivalent are subsequently determined. © 2008 Elsevier Inc. All rights reserved.
{fenge}
46149088477	Simple fabrication method for ZnO nanoneedle structures	In this work, we demonstrated a simple synthesis method for ZnO nanoneedle structures which were fabricated at atmospheric pressure. Nanoneedles with diameter in the range 20-40 nm were synthesized in a tube furnace maintained at 800°C by evaporation of Zn nanoparticles in humidified Ar flow at 0.25 1pm. The nanostructures were grown on Si substrates at 725-750°C without any catalyst. The fabricated needle structures show strong UV photoluminescence and weak yellow/orange emission, which indicates the excellent crystal quality of the nanostructures. X-ray diffraction (XRD) found only peaks corresponding to hexagonal ZnO. No peaks from Zn or other impurities were found. © 2005 IEEE.
{fenge}
45649084633	Generalized fuzzy rough sets determined by a triangular norm	The theory of rough sets has become well established as an approach for uncertainty management in a wide variety of applications. Various fuzzy generalizations of rough approximations have been made over the years. This paper presents a general framework for the study of T-fuzzy rough approximation operators in which both the constructive and axiomatic approaches are used. By using a pair of dual triangular norms in the constructive approach, some definitions of the upper and lower approximation operators of fuzzy sets are proposed and analyzed by means of arbitrary fuzzy relations. The connections between special fuzzy relations and the T-upper and T-lower approximation operators of fuzzy sets are also examined. In the axiomatic approach, an operator-oriented characterization of rough sets is proposed, that is, T-fuzzy approximation operators are defined by axioms. Different axiom sets of T-upper and T-lower fuzzy set-theoretic operators guarantee the existence of different types of fuzzy relations producing the same operators. The independence of axioms characterizing the T-fuzzy rough approximation operators is examined. Then the minimal sets of axioms for the characterization of the T-fuzzy approximation operators are presented. Based on information theory, the entropy of the generalized fuzzy approximation space, which is similar to Shannon's entropy, is formulated. To measure uncertainty in T-generalized fuzzy rough sets, a notion of fuzziness is introduced. Some basic properties of this measure are examined. For a special triangular norm T = min, it is proved that the measure of fuzziness of the generalized fuzzy rough set is equal to zero if and only if the set is crisp and definable. © 2008 Elsevier Inc. All rights reserved.
{fenge}
49049085246	Nonlinear dimensionality reduction of data lying on the multicluster manifold	A new method, which is called decomposition-composition (D-C) method, is proposed for the nonlinear dimensionality reduction (NLDR) of data lying on the multicluster manifold. The main idea is first to decompose a given data set into clusters and independently calculate the low-dimensional embeddings of each cluster by the decomposition procedure. Based on the intercluster connections, the embeddings of all clusters are then composed into their proper positions and orientations by the composition procedure. Different from other NLDR methods for multicluster data, which consider associatively the intracluster and intercluster information, the D-C method capitalizes on the separate employment of the intracluster neighborhood structures and the intercluster topologies for effective dimensionality reduction. This, on one hand, isometrically preserves the rigid-body shapes of the clusters in the embedding process and, on the other hand, guarantees the proper locations and orientations of all clusters. The theoretical arguments are supported by a series of experiments performed on the synthetic and real-life data sets. In addition, the computational complexity of the proposed method is analyzed, and its efficiency is theoretically analyzed and experimentally demonstrated. Related strategies for automatic parameter selection are also examined. © 2008 IEEE.
{fenge}
54249166530	A study of the partially adaptive concentric ring array	Concentric ring arrays can provide effective beamforming and achieve frequency invariant beampatterns. For long range signal acquisition, the array has a large number of array elements, and partial adaptation is often necessary to increase tracking ability and reduce computation. The topic of this paper is the study of a partially adaptive concentric ring array for three-dimensional audio signal acquisition. We develop the partially adaptive array through partition matrix formulation, provide the associated adaptive structure, and derive the steady state residual interference and noise power that can serve as a criterion to evaluate different partition structures. A comparison of several partition schemes using the criterion is given, and the theoretical results are supported by simulations. © Birkhäuser Boston 2008.
{fenge}
55649087778	Dependence-space-based attribute reductions in inconsistent decision information systems	In rough set theory, attribute reduction is an important mechanism for knowledge discovery. This paper mainly deals with attribute reductions of an inconsistent decision information system based on a dependence space. Through the concept of inclusion degree, a generalized decision distribution function is first constructed. A decision distribution relation is then defined. On the basis of this decision distribution relation, a dependence space is proposed, and an equivalence congruence based on the indiscernibility attribute sets is also obtained. Applying the congruences on a dependence space, new approaches to find a distribution consistent set are formulated. The judgement theorems for judging distribution consistent sets are also established by using these congruences and the decision distribution relation. © 2008 Elsevier Inc. All rights reserved.
{fenge}
56649115847	Nonlinear dimensionality reduction for data on manifold with rings	Isomap has attracted attentions recently due to its prominent performance on nonlinear dimensionality reduction. However, how to implement effective learning for data on manifold with rings is still a remaining problem. To solve this problem, a systemic strategy is presented in this study. Based on the intrinsic implementation principle of Isomap, a theorem is presented which gives a sufficient and necessary condition to judge whether a manifold is with rings. Besides, an algorithm for detecting ring structures in the manifold is constructed and a nonlinear dimensionality reduction strategy is developed through polar coordinates transformation. A series of simulation results implemented on a series of synthetic and real-world data sets generated by manifolds with or without rings verify the prominent performance of the new method.
{fenge}
6444233032	Photoluminescence and electron paramagnetic resonance of ZnO tetrapod structures	ZnO tetrapod nanostructures have been prepared by the evaporation of Zn in air (no flow), dry and humid argon flow, and dry and humid nitrogen flow. Their properties have been investigated using scanning electron microscopy (SEM), X-ray diffraction (XRD), photoluminescence (PL) and photoluminescence excitation (PLE) spectroscopies (at different temperatures), and electron paramagnetic resonance (EPR) spectroscopy at -160 °C and room temperature. It is found that the fabrication conditions significantly influence the EPR and PL spectra obtained. While a g=1.96 EPR signal is present in some of the samples, green PL emission can be observed from all the samples. Therefore, the green emission in our samples does not originate from the commonly assumed transition between a singly charged oxygen vacancy and a photoexcited hole [K. Vanheusden, C. H. Seager, W. L. Warren, D. R. Tallant, J. A. Voigt, Appl. Phys. Lett. 1996, 68, 403]. However, the green emission can be suppressed by coating the nanostructures with a surfactant for all fabrication conditions, which indicates that this emission originates from surface defects.
{fenge}
65549108457	On generalized fuzzy belief functions in infinite spaces	Determined by a fuzzy implication operator, a general type of fuzzy belief structure and its induced dual pair of fuzzy belief and plausibility functions in infinite universes of discourse are first defined. Relationship between the belief-structure-based and the belief-space-based fuzzy Dempster-Shafer models is then established. It is shown that the lower and upper fuzzy probabilities induced by the fuzzy belief space yield a dual pair of fuzzy belief and plausibility functions. For any fuzzy belief structure, there must exist a fuzzy belief space such that the fuzzy belief and plausibility functions defined by the given fuzzy belief structure are just the lower and upper fuzzy probabilities induced by the fuzzy belief space, respectively. Essential properties of the fuzzy belief and plausibility functions are also examined. The fuzzy belief and plausibility functions are, respectively, a fuzzy monotone Choquet capacity and a fuzzy alternating Choquet capacity of infinite order. © 2009 IEEE.
{fenge}
70349314328	Granular computing and knowledge reduction in formal contexts	Granular computing and knowledge reduction are two basic issues in knowledge representation and data mining. Granular structure of concept lattices with application in knowledge reduction in formal concept analysis is examined in this paper. Information granules and their properties in a formal context are first discussed. Concepts of a granular consistent set and a granular reduct in the formal context are then introduced. Discernibility matrices and Boolean functions are, respectively, employed to determine granular consistent sets and calculate granular reducts in formal contexts. Methods of knowledge reduction in a consistent formal decision context are also explored. Finally, knowledge hidden in such a context is unraveled in the form of compact implication rules. © 2006 IEEE.
{fenge}
0034506441	Clustering by scale-space filtering	In pattern recognition and image processing, the major application areas of cluster analysis, human eyes seem to possess a singular aptitude to group objects and find important structures in an efficient and effective way. Thus, a clustering algorithm simulating a visual system may solve some basic problems in these areas of research. From this point of view, we propose a new approach to data clustering by modeling the blurring effect of lateral retinal interconnections based on scale space theory. In this approach, a data set is considered as an image with each light point located at a datum position. As we blur this image, smaller light blobs merge into larger ones until the whole image becomes one light blob at a low enough level of resolution. By identifying each blob with a cluster, the blurring process generates a family of clusterings along the hierarchy. The advantages of the proposed approach are: 1) The derived algorithms are computationally stable and insensitive to initialization and they are totally free from solving difficult global optimization problems. 2) It facilitates the construction of new checks on cluster validity and provides the final clustering a significant degree of robustness to noise in data and change in scale. 3) It is more robust in cases where hyperellipsoidal partitions may not be assumed. 4) It is suitable for the task of preserving the structure and integrity of the outliers in the clustering process. 5) The clustering is highly consistent with that perceived by human eyes. 6) The new approach provides a unified framework for scale-related clustering algorithms recently derived from many different fields such as estimation theory, recurrent signal processing on self-organization feature maps, information theory and statistical mechanics, and radial basis function neural networks.
{fenge}
0035119388	A new method for mining regression classes in large data sets	Extracting patterns and models of interest from large databases is attracting much attention in a variety of disciplines. Knowledge discovery in databases (KDD) and data mining (DM) are areas of common interest to researchers in machine learning, pattern recognition, statistics, artificial intelligence, and high performance computing. An effective and robust method, coined regression-class mixture decomposition (RCMD) method, is proposed in this paper for the mining of regression classes in large data sets, especially those contaminated by noise. A new concept, called "regression class" which is defined as a subset of the data set that is subject to a regression model, is proposed as a basic building block on which the mining process is based. A large data set is treated as a mixture population in which there are many such regression classes and others not accounted for by the regression models. Iterative and genetic-based algorithms for the optimization of the objective function in the RCMD method are also constructed. It is demonstrated that the RCMD method can resist a very large proportion of noisy data, identify each regression class, assign an inlier set of data points supporting each identified regression class, and determine the a priori unknown number of statistically valid models in the data set. Although the models are extracted sequentially, the final result is almost independent of the extraction order due to a novel dynamic classification strategy employed in the handling of overlapping regression classes. The effectiveness and robustness of the RCMD method are substantiated by a set of simulation experiments and a real-life application showing the way it can be used to fit mixed data to linear regression classes and nonlinear structures in various situations. © 2001 IEEE.
{fenge}
0035439797	A new gradient-based neural network for solving linear and quadratic programming problems	In this paper, a new gradient-based neural network is constructed on the basis of the duality theory, optimization theory, convex analysis theory, Lyapunov stability theory, and LaSalle invariance principle to solve linear and quadratic programming problems. In particular, a new function F(x, y) is introduced into the energy function E(x, y) such that the function E(x, y) is convex and differentiable, and the resulting network is more efficient. This network involves all the relevant necessary and sufficient optimality conditions for convex quadratic programming problems. For linear programming (LP) and quadratic programming (QP) problems with unique and infinite number of solutions, we have proven strictly that for any initial point, every trajectory of the neural network converges to an optimal solution of the QP and its dual problem. The proposed network is different from the existing networks which use the penalty method or Lagrange method, and the inequality (including nonnegativity) constraints are properly handled. The theory of the proposed network is rigorous and the performance is much better. The simulation results also show that the proposed neural network is feasible and efficient.
{fenge}
77955421786	Approaches to attribute reduction in concept lattices induced by axialities	This paper investigates approaches to attribute reduction in concept lattices induced by axialities. Based on an axiality, a type of covariant Galois connection between power sets, or equivalently a binary relation between the ground sets, the lattice of all concepts associated with a formal context is studied. Some judgment theorems for attribute reduction in such a lattice are proposed and proved. Extended from the idea of knowledge reduction in rough set theory, a Boolean approach to calculating all reducts of a context is formulated via the use of discernibility function. Finally, all attributes are classified into three types by their significance in constructing the concept lattice. The characteristics of these types of attributes are also analyzed. © 2010 Elsevier B.V. All rights reserved.
{fenge}
7944231537	An elliptical basis function network for classification of remote sensing images	An elliptical basis function (EBF) network is employed in this study for the classification of remotely sensed images. Though similar in structure, the EBF network differs from the well-known radial basis function (RBF) network by incorporating full covariance matrices and employing the expectation-maximization (EM) algorithm to estimate the basis functions. Since remotely sensed data often take on mixture-density distributions in the feature space, the network not only possesses the advantage of the RBF mechanism, but also utilizes the EM algorithm to compute the maximum likelihood estimates of the mean vectors and covariance matrices of a Gaussian mixture distribution in the training phase. Experimental results show that the EM-based EBF network is more effective in training and simpler in structure than an RBF network constructed for the same task. © Springer-Verlag 2004.
{fenge}
0035747071	A genetic-based method for training fuzzy systems	In this paper, a genetic-based method for training fuzzy classification systems is proposed. The genetic algorithm, called genetic algorithm with no genetic operators (GANGO), neither needs to use the conventional genetic operators nor to store the population throughout the evolution process, but still has the same search mechanisms as conventional genetic algorithms. The novelty of the proposed training approach lies in (a) the new scheme of encoding a fuzzy system based on the interpretation of the values of the components of a fuzzy relationship matrix as the sample probabilities of genes; this, together with no requirement on storing the population, contributes to a dramatic decrease in storage requirement and computational cost; (b) the automatic elimination of irrelevant fuzzy rules using a fitness reassignment strategy at the gene level and a weight truncation strategy. The proposed training method is successfully applied to train a fuzzy system for the classification of real-world remote sensing data.
{fenge}
0036383775	Scale-space theory based regionalization for spatial cells	Traditional regional partitioning model for spatial cells is only built upon the information of attributes in every cell. However, the spatial relationships and their spatial interaction between cells are not considered sufficiently. In this study, based on scale-space theory a new approach for regional partitioning or regionalization for spatial cells is proposed so that the elements of spatial relationship between cells could be integrated besides considering the information of attributes. By this approach, regional partitioning in multiple scale can be accomplished on the basis of the spatial clustering algorithm that at certain scale the spatial cells could be melted into one class if their connective direction is the same within the road transformation system that is built upon by a spatial interactive model. Finally, according to the social and economic statistical data of 18 years from 1978 to 1995, the experiments of regional partitioning for social and economic development level of Jiangsu Province are achieved. In the experiments, despite only the simple spatial correlative model is used as the spatial interactive model for the scale-space clustering algorithm the regional partitioning results are highly accordant with real situations.
{fenge}
0036647542	A new method for image recognition	An efficient target recognition method for remote sensing image is proposed in this paper, which is based on the moment invariant, the self-organizing map neural network and the support vector machine. Firstly, seven Hu's invariant moments are extracted as feature vectors, then a self-organizing map neural network is used to cluster feature vectors. Finally, a support vector machine is applied to recognize targets of planes and ships on binary remote sensing images. The test show that the recognition results of the new method are better, and the training time is shorter than those by using the support vector machines only.
{fenge}
0036824075	Efficient target recognition method for large scale data	An efficient target recognition method for large scale data was proposed, based on self-organizing map neural network and support vector machine. The target data set is divided into clusters by self-organizing map. Then, the support vector machine is applied to classify targets. This method can be used to classify the complex XOR problem and Iris and Appendicitis data. The experimental results show that this method can obtain better recognition results for the complex pattern classification of large scale data, and the training time is shorter than that by the support vector machine method only.
{fenge}
0036824087	A neural network for solving nonlinear programming problems	A neural network for solving convex nonlinear programming problems is proposed in this paper. The distinguishing features of the proposed network are that the primal and dual problems can be solved simultaneously, all necessary and sufficient optimality conditions are incorporated, and no penalty parameter is involved. Based on Lyapunov, LaSalle and set stability theories, we prove strictly an important theoretical result that, for an arbitrary initial point, the trajectory of the proposed network does converge to the set of its equilibrium points, regardless of whether a convex nonlinear programming problem has unique or infinitely many optimal solutions. Numerical simulation results also show that the proposed network is feasible and efficient. In addition, a general method for transforming nonlinear programming problems into unconstrained problems is also proposed.
{fenge}
0037653654	Statistical test for local patterns of spatial association	In recent years, there has been a growing interest in the use of local measures such as Anselin's LISAs and Ord and Getis G statistics to identify local patterns of spatial association. The statistical significance test based on local statistics is one of the most important aspects in performing this kind of analysis, and a randomized permutation approach and normal approximation are commonly used to derive the p-values of the statistics. To circumvent some of the shortcomings of these existing methods and to offer a more formal approach in line with classical statistical framework, we develop in this paper an exact method for computing the p-values of the local Moran's I
{fenge}
0037809690	Maximal consistent block technique for rule acquisition in incomplete information systems	In this paper, the concept of a maximal consistent block is applied to formulate a new approximation to an object set in incomplete information systems with higher level of accuracy. Similar to the method in [Inform. Sci. 112 (1998) 39, 113 (1999) 271], the proposed rough-set-based rule acquisition method does not require change in the size of the original incomplete system. It, however, has the additional advantage of using a set of simpler discernibility functions of an incomplete system. This means that it can provide a more efficient computation for knowledge acquisition, especially in large incomplete systems. © 2003 Published by Elsevier Science Inc.
{fenge}
0242385735	Connections between rough set theory and Dempster-Shafer theory of evidence	In rough set theory there exists a pair of approximation operators, the upper and lower approximations, whereas in Dempster-Shafer theory of evidence there exists a dual pair of uncertainty measures, the plausibility and belief functions. It seems that there is some kind of natural connection between the two theories. The purpose of this paper is to establish the relationship between rough set theory and Dempster-Shafer theory of evidence. Various generalizations of the Dempster-Shafer belief structure and their induced uncertainty measures, the plausibility and belief functions, are first reviewed and examined. Generalizations of Pawlak approximation space and their induced approximation operators, the upper and lower approximations, are then summarized. Concepts of random rough sets, which include the mechanisms of numeric and non-numeric aspects of uncertain knowledge, are then proposed. Notions of the Dempster-Shafer theory of evidence within the framework of rough set theory are subsequently formed and interpreted. It is demonstrated that various belief structures are associated with various rough approximation spaces such that different dual pairs of upper and lower approximation operators induced by the rough approximation spaces may be used to interpret the corresponding dual pairs of plausibility and belief functions induced by the belief structures.
{fenge}
0242625745	An Elliptical Basis Function Network for Classification of Remote-Sensing Images	An elliptical basis function (EBF) network is proposed in this study for the classification of remotely sensed images. Though similar in structure, the EBF network differs from the well-known radial basis function (RBF) network by incorporating full covariance matrices and uses the expectation-maximization (EM) algorithm to estimate the basis functions. Since remotely sensed data often take on mixture-density distributions in the feature space, the proposed network not only possesses the advantage of the RBF mechanism but also utilizes the EM algorithm to compute the maximum likelihood estimates of the mean vectors and covariance matrices of a Gaussian mixture distribution in the training phase. Experimental results show that the EM-based EBF network is faster in training, more accurate, and simpler in structure.
{fenge}
10444222592	A general framework for error analysis in measurement-based GIS Part 3: Error analysis in intersections and overlays	This is the third of a four-part series on the development of a general framework for error analysis in measurement-based geographic information systems (MBGIS). In this paper, we study the characteristics of error structures in intersections and polygon overlays. When locations of the endpoints of two line segments are in error, we analyze errors of the intersection point and obtain its error covariance matrix through the propagation of the error covariance matrices of the endpoints. An approximate law of error propagation for the intersection point is formulated within the MBGIS framework. From simulation experiments, it appears that both the relative positioning of two line segments and the error characteristics of the endpoints can affect the error characteristics of the intersection. Nevertheless, the approximate law of error propagation captures nicely the error characteristics under various situations. Based on the derived results, error analysis in polygon-on-polygon overlay operation is also performed. The relationship between the error covariance matrices of the original polygons and the overlaid polygons is approximately established. © Springer-Verlag Berlin Heidelberg 2004.
{fenge}
10444227320	A general framework for error analysis in measurement-based GIS Part 2: The algebra-based probability model for point-in-polygon analysis	This is the second paper of a four-part series of papers on the development of a general framework for error analysis in measurement-based geographic information systems (MBGIS). In this paper, we discuss the problem of point-in-polygon analysis under randomness, i.e., with random measurement error (ME). It is well known that overlay is one of the most important operations in GIS, and point-in-polygon analysis is a basic class of overlay and query problems. Though it is a classic problem, it has, however, not been addressed appropriately. With ME in the location of the vertices of a polygon, the resulting random polygons may undergo complex changes, so that the point-in-polygon problem may become theoretically and practically ill-defined. That is, there is a possibility that we cannot answer whether a random point is inside a random polygon if the polygon is not simple and cannot form a region. For the point-in-triangle problem, however, such a case need not be considered since any triangle always forms an interior or region. To formulate the general point-in-polygon problem in a suitable way, a conditional probability mechanism is first introduced in order to accurately characterize the nature of the problem and establish the basis for further analysis. For the point-in-triangle problem, four quadratic forms in the joint coordinate vectors of a point and the vertices of the triangle are constructed. The probability model for the point-in-triangle problem is then established by the identification of signs of these quadratic form variables. Our basic idea for solving a general point-in-polygon (concave or convex) problem is to convert it into several point-in-triangle problems under a certain condition. By solving each point-in-triangle problem and summing the solutions, the probability model for a general point-in-polygon analysis is constructed. The simplicity of the algebra-based approach is that from using these quadratic forms, we can circumvent the complex geometrical relations between a random point and a random polygon (convex or concave) that one has to deal with in any geometric method when probability is computed. The theoretical arguments are substantiated by simulation experiments. © Springer-Verlag Berlin Heidelberg 2004.
{fenge}
10444286704	A general framework for error analysis in measurement-based GIS Part 4: Error analysis in length and area measurements	This is the final of a series of four papers on the development of a general framework for error analysis in measurement-based geographic information systems (MBGIS). In this paper, we discuss the error analysis problems in length and area measurements under measurement error (ME) of the defining points. In line with the basic ME model constructed in Part 1 of this series, we formulate the ME models for length and area measurements. For length measurement and perimeter measurement, the approximate laws of error propagation are derived. For area measurement, the exact laws of error propagation are obtained under various conditions. An important result is that area measurement is distributed as a linear combination of independent non-central chi-square variables when the joint ME vectors of vertices coordinates are normal. In addition, we also give a necessary and sufficient condition under which the area measurement estimator is unbiased. As a comparison, the approximate law of error propagation in area measurement is also considered and its approximation is substantiated by numerical experiments. © Springer-Verlag Berlin Heidelberg 2004.
{fenge}
10444289789	A general framework for error analysis in measurement-based GIS Part 1: The basic measurement-error model and related concepts	This is the first of a four-part series of papers which proposes a general framework for error analysis in measurement-based geographical information systems (MBGIS). The purpose of the series is to investigate the fundamental issues involved in measurement error (ME) analysis in MBGIS, and to provide a unified and effective treatment of errors and their propagation in various interrelated GIS and spatial operations. Part 1 deals with the formulation of the basic ME model together with the law of error propagation. Part 2 investigates the classic point-in-polygon problem under ME. Continuing to Part 3 is the analysis of ME in intersections and polygon overlays. In Part 4, error analyses in length and area measurements are made. In this present part, a simple but general model for ME in MBGIS is introduced. An approximate law of error propagation is then formulated. A simple, unified, and effective treatment of error bands for a line segment is made under the name of "covariance-based error band". A new concept, called "maximal allowable limit", which guarantees invariance in topology or geometric-property of a polygon under ME is also advanced. To handle errors in indirect measurements, a geodetic model for MBGIS is proposed and its error propagation problem is studied on the basis of the basic ME model as well as the approximate law of error propagation. Simulation experiments all substantiate the effectiveness of the proposed theoretical construct. © Springer-Verlag Berlin Heidelberg 2004.
{fenge}
10644266815	On knowledge reduction in inconsistent decision information systems	Due to issues such as noise in data, compact representation and prediction capability, many types of knowledge reduction and decision rules have been proposed and applied in inconsistent decision information systems. It is thus important to clarify the interrelationships among the existing types of knowledge reduction. In this paper, the relationships, particularly those suggested in [1], are reconsidered and rectified, and some related results are theoretically improved. In terms of two new types of redacts proposed in this paper together with other existing ones, the method for optimizing all types of decision rules is also discussed in details.
{fenge}
0742268988	A high-performance feedback neural network for solving convex nonlinear programming problems	Based on a new idea of successive approximation, this paper proposes a high-performance feedback neural network model for solving convex nonlinear programming problems. Differing from existing neural network optimization models, no dual variables, penalty parameters, or Lagrange multipliers are involved in the proposed network. It has the least number of state variables and is very simple in structure. In particular, the proposed network has better asymptotic stability. For an arbitrarily given initial point, the trajectory of the network converges to an optimal solution of the convex nonlinear programming problem under no more than the standard assumptions. In addition, the network can also solve linear programming and convex quadratic programming problems, and the new idea of a feedback network may be used to solve other optimization problems. Feasibility and efficiency are also substantiated by simulation examples.
{fenge}
0347506112	A knowledge-integrated stepwise optimization model for feature mining in remotely sensed images	The selection of features, including spectral, texture, shape, size, and signal strength, is an important step in computerized information analysis of remotely sensed images. A feature space, which can be generally understood as a multidimensional space consisting of multiple individual features, can be modelled by estimating the distribution of the whole space with prior assumed probability distribution functions (PDFs) once only. However, due to the inter-overlapping phenomenon among points or the confusing influence from surrounding discrete points, it is very difficult to obtain the subtle and procedural structure of the mixture distributions of feature space, and so as to degrade the accuracy and interpretability of the results in further analysis. Extending on the method of Gaussian mixture modelling and decomposition (GMDD), a new feature mining method-stepwise optimization model (SOM) with genetic algorithms (GA) was proposed in this study for the extraction of tree-like hierarchical structure of unknown feature distributions in a feature space. To approximate reality accurately, integration of SOM-GA with symbolic geographical knowledge is essential in the feature mining and classification of remotely sensed images. Knowledge-integrated SOM-GA model that combines the power of SOM-GA and logic reasoning of rule-based inference was therefore proposed. The paper presents conceptual and technical discussions of the model in detail, along with the result of practical application test on a district in Hong Kong region.
{fenge}
12744277358	ZnO nanostructures prepared by different methods	ZnO is of great interest for photonic applications due to its wide band gap (3.37 eV) and large exciton binding energy (60 meV). Variety of preparation methods and obtained morphologies (such as nanorods, tetrapod nanorods, nanowires, nanoribbons, hierarchical structures, nanobridges, and nanonails) were reported for this material. In this work, the morphology and optical properties of ZnO nanostructures prepared by three different methods were studied. ZnO nanostructures were prepared by oxidation of Zn (no catalyst) at 950°C, heating of a mixture of ZnO:graphite (1:1) at 1100°C, and chemical method (from solution of zinc nitrate hydrate and hexamethylenetetramine at 90°C). The properties of obtained products were examined using scanning electron microscopy, transmission electron microscopy, selected area electron diffraction, X-ray diffraction, room temperature photoluminescence and electron paramagnetic resonance spectroscopy. Chemical synthesis method produced different morphology compared to heating of Zn and ZnO:graphite. In the former case, straight rods are obtained, while in the latter case ZnO tetrapod structures are formed. The ZnO tetrapods, both from Zn and ZnO:graphite, exhibit similar photoluminescence spectra with UV peak and characteristic broad green emission but they have different EPR spectra. The EPR signal g≈1.96 is clearly visible in ZnO tetrapods synthesized from ZnO:graphite, while it is at noise level in ZnO tetrapods synthesized from Zn. Therefore, it can be concluded that the type of intrinsic defects in ZnO nanostructures is strongly dependent on the fabrication conditions, and that the green photoluminescence is not necessarily related to g≈1.96 EPR peak which is commonly assigned to shallow donors.
{fenge}
13244273429	ZnO nanostructures prepared from ZnO:CNT mixtures	Due to its wide band gap (3.37 eV) and large exciton binding energy (60 meV), ZnO is of great interest for photonic applications. A number of different morphologies, such as nanobelts, nanowires, tetrapod nanostructures, tubular nanostructures, hierarchical nanostructures, nanobridges, nanonails, oriented nanorod arrays, nanoneedles, nanowalls, and nanosheets, were reported. A range of synthesis methods for fabrication of ZnO nanostructures was reported as well. A common method is evaporation from mixture of ZnO and carbon, which is usually in the form of graphite. In this work, we studied the morphology of the ZnO nanostructures fabricated from the mixture of ZnO (micron-sized and nanoparticles) and carbon (graphite, single-wall carbon nanotubes). When graphite and ZnO powders were used, tetrapod structures were obtained. If one of the reactants was nanosized, the diameter of the tetrapod arms was no longer constant. Finally, when both reactants were nanosized, novel morphologies were obtained. We studied the dependence of the morphology on the amount of starting material and the type of carbon used. The ZnO nanostructures were studied using field emission scanning electron microscopy, transmission electron microscopy, selected area electron diffraction, and X-ray diffraction. Growth mechanism and factors affecting the morphologies are discussed.
{fenge}
13644276160	Growth of N, N′-di(naphthalene-1-yl)-N, N′-diphenyl-benzidine dome structures	N,N′-di(naphthalene-1-yl)-N,N′-diphenyl-benzidine samples exhibiting interesting nano/microstructure were fabricated by thermal evaporation in a tube furnace under Ar gas flow. We investigated the influence of the substrate type, substrate temperature, source temperature, and the gas flow rate on the obtained morphology. The deposited material was investigated using scanning electron microscopy, x-ray diffraction, and photoluminescence. We found that the substrate temperature was the factor which significantly affected the obtained morphology, while other factors such as substrate type, source temperature, and gas flow mainly affected the size distribution of the features but not the type of morphology observed. © 2005 American Institute of Physics.
{fenge}
1242293127	Neural networks for nonlinear and mixed complementarity problems and their applications	This paper presents two feedback neural networks for solving a nonlinear and mixed complementarity problem. The first feedback neural network is designed to solve the strictly monotone problem. This one has no parameter and possesses a very simple structure for implementation in hardware. Based on a new idea, the second feedback neural network for solving the monotone problem is constructed by using the first one as a subnetwork. This feedback neural network has the least number of state variables. The stability of a solution of the problem is proved. When the problem is strictly monotone, the unique solution is uniformly and asymptotically stable in the large. When the problem has many solutions, it is guaranteed that, for any initial point, the trajectory of the network does converge to an exact solution of the problem. Feasibility and efficiency of the proposed neural networks are supported by simulation experiments. Moreover, the feedback neural network can also be applied to solve general nonlinear convex programming and nonlinear monotone variational inequalities problems with convex constraints. © 2003 Elsevier Ltd. All rights reserved.
