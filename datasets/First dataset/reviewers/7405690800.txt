{fenge}
15944374321	A comparison study of tropical Pacific Ocean state estimation: Low-resolution assimilation vs. high-resolution simulation	A comparison study is performed to contrast the improvements in the tropical Pacific oceanic state of a low-resolution model respectively via data assimilation and by an increase in horizontal resolution. A low resolution model (LR) (1°lat by 2°lon) and a high-resolution model (HR) (0.5°lat by 0.5°lon) are employed for the comparison. The authors perform 20-yr numerical experiments and analyze the annual mean fields of temperature and salinity. The results indicate that the low-resolution model with data assimilation behaves better than the high-resolution model in the estimation of ocean large-scale features. From 1990 to 2000, the average of HR's RMSE (root-mean-square error) relative to independent Tropical Atmosphere Ocean project (TAO) mooring data at randomly selected points is 0.97°C compared to a RMSE of 0.56°C for LR with temperature assimilation. Moreover, the LR with data assimilation is more frugal in computation. Although there is room to improve the high-resolution model, the low-resolution model with data assimilation may be an advisable choice in achieving a more realistic large-scale state of the ocean at the limited level of information provided by the current observational system.
{fenge}
1542465985	Estimating open boundary conditions from coastal tidal observations by adjoint approach	A numerical study for estimating the tidal open boundary conditions of a shelf current model from the coastal tidal observations is presented. The method is based on the optimal control/adjoint method. A least square fitting of the model state to simulated data is used. Two ideal domains and coastlines are considered. Using the IAP shallow water model and its adjoint model, some identical twin experiments are carried out to test efficiency and limitation of the method. The results show that the adjoint method can efficiently estimate the open boundary conditions well for gulf/bay like domains. The adjoint method seems to have great potential to improve the accuracy of tide and shelf current modeling in coastal regions.
{fenge}
18544408579	Salinity estimation using the T-S relation in the context of variational data assimilation	A salinity adjustment scheme using statistics of the temperature-salinity (T-S) relationship is proposed in the framework of variational data assimilation. The scheme not only considers the mean T-S diagram but also takes the variance of the T-S relations into consideration. To test performance of the scheme, a 1-D mixed layer model of the Mellor-Yamada type and a conductivity-temperature-depth (CTD) data set in the western tropical Pacific are used in two experiments. The CTD data set contains intensive temperature and salinity observations. In the experiments, first, the mean T-S diagram and its variance are obtained from temperature and salinity observations over the assimilation period; then, temperature and salinity profiles are adjusted by minimizing a cost function that contains four terms: the temperature observation term, the background terms for both temperature and salinity, and a term measuring the distance between the salinity and the inferred salinity from the temperature via the mean T-S diagram. A simpler scheme, which first adjusts the temperature profile by assimilating temperature data and then replaces the model salinity profile using the mean T-S diagram and the newly updated temperature profile, is also tested for comparison. The proposed scheme shows good skill in reconstructing salinity variations at most levels and performs slightly better than the simpler scheme with overall improvements of 4-10%. The applicability of the method is also discussed. Copyright 2004 by the American Geophysical Union.
{fenge}
0012547151	The Improvement Made by a Modified TLM in 4DVAR with a Geophysical Boundary Layer Model	The strong nonlinearity of boundary layer parameterizations in atmospheric and oceanic models can cause difficulty for tangent linear models in approximating nonlinear perturbations when the time integration grows longer. Consequently, the related 4-D variational data assimilation problems could be difficult to solve. A modified tangent linear model is built on the Mellor-Yamada turbulent closure (level 2.5) for 4-D variational data assimilation. For oceanic mixed layer model settings, the modified tangent linear model produces better finite amplitude, nonlinear perturbation than the full and simplified tangent linear models when the integration time is longer than one day. The corresponding variational data assimilation performances based on the adjoint of the modified tangent linear model are also improved compared with those adjoints of the full and simplified tangent linear models.
{fenge}
26644451619	Evaluation of mid-depth currents of NCEP reanalysis data in the tropical Pacific using ARGO float position information	The global project of the Array for Real-time Geostrophic Oceanography (ARGO) provides a unique opportunity to observe the absolute velocity in mid-depths of the world oceans. A total of 1597 velocity vectors at 1000 (2000) db in the tropical Pacific derived from the ARGO float position information during the period November 2001 to October 2004 are used to evaluate the intermediate currents of the National Centers for Environmental Prediction reanalysis. To derive reliable velocity information from ARGO float trajectory points, a rigorous quality control scheme is applied, and by virtue of a correction method for reducing the drift error on the surface in obtaining the velocity vectors, their relative errors are less than 25%. Based on the comparisons from the quantitative velocity vectors and from the space-time average currents, some substantial discrepancies are revealed. The first is that the velocities of the reanalysis at mid-depths except near the equator are underestimated relative to the observed velocities by the floats. The average speed difference between NCEP and ARGO values ranges from about -2.3 cm s
{fenge}
33646512446	Study of death cause of the 254 patients with diabetes	Objective: To understand causes of death of diabetic inpatients and provide evidence for diabetic prevention and control. Methods: Analysis of the death causes was carried out in the dead cases of diabetic inpatients in the First and Second Affiliated Hospital of Medical School, Xi'an Jiaotong University from 1991 to 2003. Results: Numbers of dead diabetic inpatients of the two hospitals were 254, which accounted for 3.2% of the total dead inpatients; the main death causes of diabetic inpatients were diabetic chronic complications, taking up to 42. 5% of all the causes (28. 3% of cerebro-cardiovascular and 14.2% of diabetic renalfailure), tumor (20.1%), infection (11.4%), acute complications(6. 7%) and hepaticcirrhosis (6.3%); in vascular complications, 72 cases with hypertension (66.7%). Conclusion: The chronic complications have been the main death cause of diabetes, and cerebro-cardiovascular diseases are most important death cause; Hypertension is the main risk factor which increases the mortality of diabetic vascular diseases. Therefore, strict control of both blood sugar and blood pressure is very important in decreasing the mortality of diabetic cerebro-cardiovascular diseases.
{fenge}
33646516401	Internet GIS for distributing massive geospatial data	Timely and accurate spatial data has been regularly available in many fields such as land cover and land use, urban planning, etc. Internet GIS is the technology to distribute massive geospatial data composed of aerial, satellite, and topographic images which is stored in RDBMS such as Oracle or SQL Server. Internet GIS is predominantly designed under a 'thin-client/fat-server' pattern. The pure thin-client technique provides the ability to access large geospatial database via the Internet by graphical web browser without any plug-ins. Server-side's overload because of frequently geospatial data access and geocomputing process is the bottleneck. Some key techniques, such as image-tower compression, multi-factorial dynamic load-balancing and multi-level caching, are elaborately designed to overcome the disadvantages in the paper. A Multi-tier architecture of Internet GIS based on the techniques is designed to adapt adequately over low-speed (28.8kbps) network.
{fenge}
33744904227	'Two-point'-bound supramolecular complexes from semi-rigidified dipyridine receptors and zinc porphyrins	Two linear compounds 1 and 2 have been designed and synthesized as new receptors for zinc porphyrins. Both compounds consist of two folded aromatic amide moieties, which are connected with an acetylene linker in 1 or directly in 2. The rigid conformations of their folded moieties are stabilized by intramolecular tri-centered hydrogen bonding, while the whole molecule adopts a 'S'- or 'C'-styled conformation depending on the relative orientation of the two rigid moieties. Two pyridine units are introduced at the ends of 1 and 2 for the complexation of zinc porphyrin guests. Although the
{fenge}
33746331387	Adjoint method for the optimum planning of industrial pollutant sources	The optimum planning of industrial pollutant sources, which optimizes the economic object without violating environmental constraints, is an important and hard task to be conquered. In this paper, an adjoint method is developed to solve the problem. The penalty function is introduced to deal with the environmental inequality constraints, and Lagrange function is constructed to derive the adjoint equation and the gradient of the object function. In this means, the gradient of the object function can be calculated by solving the adjoint equation, and the information from the gradient is used to make the object function descend and approach to an optimal solution after some iterations. A two-dimensional, simplified model is used for numerical experiments. The theoretical derivations are verified by the results of the experiments. Furthermore, the adjoint method is shown to be of excellent convergence and efficiency, which is adaptive to the fast development of air quality numerical models and super computers. Copyright by Science in China Press 2005.
{fenge}
33746786347	Improved ENSO forecasts by assimilating sea surface temperature observations into an intermediate coupled model	A simple method for initializing intermediate coupled models (ICMs) using only sea surface temperature (SST) anomaly data is comprehensively tested in two sets of hindcasts with a new ICM. In the initialization scheme, both the magnitude of the nudging parameter and the duration of the assimilation are considered, and initial conditions for both atmosphere and ocean are generated by running the coupled model with SST anomalies nudged to the observations. A comparison with the observations indicates that the scheme can generate realistic thermal fields and surface dynamic fields in the equatorial Pacific through hindcast experiments. An ideal experiment is performed to get the optimal nudging parameters which include the nudging intensity and nudging time length. Twelve-month-long hindcast experiments are performed with the model over the period 1984-2003 and the period 1997-2003. Compared with the original prediction results, the model prediction skills are significantly improved by the nudging method especially beyond a 6-month lead time during the two different periods. Potential problems and further improvements are discussed regarding the new coupled assimilation system.
{fenge}
33748921252	Relationship between real meridional volume transport and Sverdrup transport in the North Subtropical Pacific	The oceanic meridional volume transport (MVT) in the North Subtropical Pacific is calculated directly from an observed velocity field (real MVT) and indirectly from wind stress based on Sverdrup balance, respectively. It is confirmed that the Sverdrup MVT is a good approximation to the real MVT for the North Subtropical Pacific except in the western boundary region, where the difference is expected because of frictional and nonlinear effects. The time evolution of the MVT derived from a revised Sverdrup balance, in which a time delay due to the propagation of the first baroclinic Rossby wave is considered, is well correlated with that of the real MVT on decadal time scale, especially near the western boundary region. It is suggested that the Sverdrup balance can be used to study not only the mean climatology of the oceanic circulation, but also the time-dependent oceanic circulation of the North Subtropical Pacific when the Rossby wave propagation is taken into account. © Science in China Press 2006.
{fenge}
33750446971	An optimal weather condition dependent approach for emission planning in urban areas	The urban air quality strongly depends on the weather conditions. When unfavorable weather conditions are forecasted, it is desirable to reduce a certain amount of pollutant emissions to maintain a given level of air quality. In this paper, we propose and demonstrate a new approach to find the optimal reduction, and we contribute to the methodology of decision support of short-term emission control. This approach is based on weather forecasts and state-of-the-art 3-dimensional numerical air-quality prediction models by solving an optimal control problem with the emission cuts as the control variables. The objective of the optimal problem is to minimize the total cost due to the emission cuts, subject to feasibility constraints, system-governing model constraints, and target constraints. When a high-resolution numerical model is used as the state constraint, the problem can become a very high dimensional one. A practical approach to solving this problem with high dimension is proposed, based on the adjoint technique. The proposed approach is demonstrated with two computational test cases in Jinan, China for the control of sulfur dioxide. The results show the capability and computational efficiency of the method and suggest a promising potential for emission planning applications based on weather forecasts. © 2006 Elsevier Ltd. All rights reserved.
{fenge}
33750585383	Nonlinear balance constraints in 3DVAR data assimilation	In many applications of 3DVAR, the balance constraints can be considered via two main approaches: weak constraint method which adds penalty terms to the cost function; and proper definition of the background error covariance matrix with non-zero cross-correlation sub-matrices. The weak constraint approach requires determining the weighting matrices of the penalty terms. The background error covariance approach does not require determining those additional weighting matrices. However, it is only applicable to those linear or linearized balance constraints. A novel approach is proposed based on the background error covariance approach by generalizing the so-called Derber-Bouttier formulation. An assimilation experiment of estimating temperature and salinity from the sea surface dynamic height observation is given to illustrate the proposed treatments of nonlinear balance constraints. © Science in China Press 2006.
{fenge}
33845804764	Estimating ocean middle-depth velocities from ARGO floats: Error estimation and application to pacific	The Array for Real-time Geostrophic Oceanography (ARGO) project creates a unique opportunity to estimate the absolute velocity at mid-depths of the global oceans. However, the estimation can only be made based on float surface trajectories. The diving and resurfacing positions of the float are not available in its trajectory file. This surface drifting effect makes it difficult to estimate mid-depth current. Moreover, the vertical shear during decent or ascent between parking depth and the surface is another major error source. In this presentation, we first quantify the contributions of the two major error sources using the current estimates from Estimating the Climate and Circulation of the Ocean (ECCO) and find that the surface drifting is a primary error source. Then, a sequential surface trajectory prediction/estimation scheme based on Kalman Filter is introduced and implemented to reduce the surface drifting error in the Pacific during November 2001 to October 2004. On average, the error of the estimated velocities is greatly reduced from 2.7 to 0.2 cm s
{fenge}
33846484854	A three-dimensional variational ocean data assimilation system: Scheme and preliminary results	A new 3DVAR-based Ocean Variational Analysis System (OVALS) is developed. OVALS is capable of assimilating in situ sea water temperature and salinity observations and satellite altimetry data. As a component of OVALS, a new variational scheme is proposed to assimilate the sea surface height data. This scheme considers both the vertical correlation of background errors and the nonlinear temperature-salinity relationship which is derived from the generalization of the linear balance constraints to the nonlinear in the 3DVAR. By this scheme, the model temperature and salinity fields are directly adjusted from the altimetry data. Additionally, OVALS can assimilate the temperature and salinity profiles from the ARGO floats which have been implemented in recent years and some temperature and salinity data such as from expendable bathythermograph, moored ocean buoys, etc. A 21-year assimilation experiment is carried out by using OVALS and the Tropical Pacific circulation model. The results show that the assimilation system may effectively improve the estimations of temperature and salinity by assimilating all kinds of observations. Moreover, the root mean square errors of temperature and salinity in the upper depth less than 420 m reach 0.63°C and 0.34 psu. © Science in China Press 2006.
{fenge}
33846119129	Influenza Virus Database (IVDB): An integrated information resource and analysis platform for influenza virus research	Frequent outbreaks of highly pathogenic avian influenza and the increasing data available for comparative analysis require a central database specialized in influenza viruses (IVs). We have established the Influenza Virus Database (IVDB) to integrate information and create an analysis platform for genetic, genomic, and phylogenetic studies of the virus. IVDB hosts complete genome sequences of influenza A virus generated by Beijing Institute of Genomics (BIG) and curates all other published IV sequences after expert annotation. Our Q-Filter system classifies and ranks all nucleotide sequences into seven categories according to sequence content and integrity. IVDB provides a series of tools and viewers for comparative analysis of the viral genomes, genes, genetic polymorphisms and phylogenetic relationships. A search system has been developed for users to retrieve a combination of different data types by setting search options. To facilitate analysis of global viral transmission and evolution, the IV Sequence Distribution Tool (IVDT) has been developed to display the worldwide geographic distribution of chosen viral genotypes and to couple genomic data with epidemiological data. The BLAST, multiple sequence alignment and phylogenetic analysis tools were integrated for online data analysis. Furthermore, IVDB offers instant access to pre-computed alignments and polymorphisms of IV genes and proteins, and presents the results as SNP distribution plots and minor allele distributions. IVDB is publicly available at http://influenza.genomics.org.cn. © 2007 Oxford University Press.
{fenge}
33947126947	Design and fabrication of an automated microchip-based cell separation device	A microchip-based cell separation system was developed and fabricated by integrating traveling-wave dielectrophoresis and laminar flow on a single biochip-based device. Numerical simulations regarding the geometric model of the planar electrode and microfluidic channel were performed primarily for electric-field and field-flow analysis. The fabrication processes of microelectrodes and microfluidic channels were investigated, and an automated method of measurement was developed for cell characterization. The function of the device was demonstrated by separating viable human myelogenous HL-60 cells from non-viable ones. The preliminary data achieved with this device indicated that cells in different physiological states could be effectively separated. The present chip, which is capable of separating and manipulating various kinds of bio-particle mixtures with different traveling-wave dielectrophoresis responses, shows promise for applications in high-throughput integrated biological analysis systems. Copyright © Taylor & Francis Group, LLC.
{fenge}
33846890655	Reduced-Order Modeling of the Upper Tropical Pacific Ocean Model using Proper Orthogonal Decomposition	The proper orthogonal decomposition (POD) is shown to be an efficient model reduction technique for simulating physical processes governed by partial differential equations. In this paper, we make an initial effort to investigate problems related to POD reduced modeling of a large- scale upper ocean circulation in the tropic Pacific domain. We construct different POD models with different choices of snapshots and different number of POD basis functions. The results from these different POD models are compared with that of the original model. The main findings are: (1) the large-scale seasonal variability of the tropic Pacific obtained by the original model is well captured by a low dimensional system of order 22, which is constructed using 20 snapshots and 7 leading POD basis functions. (2) the RMS errors for the upper ocean layer thickness of the POD model of order 22 are less than 1 m that is less than 1% of the average thickness and the correlation between the upper ocean layer thickness with that from the POD model is around 0.99. (3) Retaining modes that capture 99% energy is necessary in order to construct POD models yielding a high accuracy. © 2006 Elsevier Ltd. All rights reserved.
{fenge}
34047219706	Ensemble hindcasts of SST anomalies in the tropical Pacific using an intermediate coupled model	[1] Ensemble hindcasts of sea surface temperature (SST) anomalies in the tropical Pacific are studied using an intermediate coupled model (ICM), in which an ensemble Kalman filter (EnKF) data assimilation system is implemented to provide the initial ensemble. A linear, first-order Markov stochastic model is adopted to represent model errors. Parameters in the stochastic model are estimated by comparing observation-minus-forecast values over 30 years. Twelve-month, 120 ensemble hindcasts are performed over the period 1995-2004, each with 100 ensemble members. This ensemble technique provides a simple method of extending the standard ICM forecasts to the probabilistic domain. The results show that the prediction skill of the ensemble mean is better than that of one single deterministic forecast using the same ICM. For the probabilistic perspective, those ensemble forecasts have their ensembles following observed SST anomaly variations well. Copyright 2006 by the American Geophysical Union.
{fenge}
34249717739	Impacts of XBT, TAO, altimetry and ARGO obsevations on the tropical Pacific Ocean data assimilation	This study aims at assessing the relative impacts of four major components of the tropical Pacific Ocean observing system on assimilation of temperature and salinity fields. Observations were collected over a period between January 2001 through June 2003 including temperature data from the expendable bathythermographs (XBT), thermistor data from the Tropical Ocean Global Atmosphere Tropical Atmosphere-Ocean (TOGA-TAO) mooring axray, sea level anomalies from the Topex/Poseidon and Jason-1 altimetry (T/P-J), and temperature and salinity profiles from the Array for Real-time Geostrophic Oceanography (ARGO) floats. An efficient three-dimensional variational analysis-based method was introduced to assimilate the above data into the tropical-Pacific circulation model. To evaluate the impact of the individual component of the observing system, four observation system experiments were carried out. The experiment that assimilated all four components of the observing system was taken as the reference. The other three experiments were implemented by withholding one of the four components. Results show that the spatial distribution of the data influences its relative contribution. XBT observations produce the most distinguished effects on temperature analyses in the off-equatorial region due to the large amount of measurements and high quality. Similarly, the impact of TAO is dominant in the equatorial region due to the focus of the spatial distribution. The Topex/Poseidon-Jason-1 can be highly complementary where the XBT and TAO observations axe sparse. The contribution of XBT or TAO on the assimilated salinity is made by the model dynamics because no salinity observations from them are assimilated. Therefore, T/P-J, as a main source for providing salinity data, has been shown to have greater impacts than either XBT or TAO on the salinity analysis. Although ARGO includes the subsurface observations, the relatively smaller number of observation makes it have the smallest contribution to the assimilation system.
{fenge}
34548380342	Finite difference scheme based on proper orthogonal decomposition for the nonstationary Navier-Stokes equations	The proper orthogonal decomposition (POD) and the singular value decomposition (SVD) are used to study the finite difference scheme (FDS) for the nonstationary Navier-Stokes equations. Ensembles of data are compiled from the transient solutions computed from the discrete equation system derived from the FDS for the nonstationary Navier-Stokes equations. The optimal orthogonal bases are reconstructed by the elements of the ensemble with POD and SVD. Combining the above procedures with a Galerkin projection approach yields a new optimizing FDS model with lower dimensions and a high accuracy for the nonstationary Navier-Stokes equations. The errors between POD approximate solutions and FDS solutions are analyzed. It is shown by considering the results obtained for numerical simulations of cavity flows that the error between POD approximate solution and FDS solution is consistent with theoretical results. Moreover, it is also shown that this validates the feasibility and efficiency of POD method. © 2007 Science in China Press.
{fenge}
34548548880	Development of a confocal optical system design for molecular imaging applications of biochip	A novel confocal optical system design and a dual laser confocal scanner have been developed to meet the requirements of highly sensitive detection of biomolecules on microarray chips, which is characterized by a long working distance ( wd >3.0 mm), high numerical aperture ( NA=0.72), and only 3 materials and 7 lenses used. This confocal optical system has a high scanning resolution, an excellent contrast and signal-to-noise ratio, and an efficiency of collected fluorescence of more than 2-fold better than that of other commercial confocal biochip scanners. The scanner is as equally good for the molecular imaging detection of enclosed biochips as for the detection of biological samples on a slide surface covered with a cover-slip glass. Some applications of gene and protein imagings using the dual laser confocal scanner are described.
{fenge}
34548634390	Impact of altimetry data on ENSO ensemble initializations and predictions	The El Niño/Southern Oscillation (ENSO) predictions strongly depend on the accuracy and dynamical consistency of the coupled initial conditions. Based on the proposed ensemble Kalman filter (EnKF), a new initialization scheme for the ENSO ensemble prediction system (EPS) was designed and tested in an intermediate coupled model (ICM). The inclusion of this scheme in the ICM leads to substantial improvements in ENSO prediction skill via the successful assimilation of both observed sea surface temperature (SST) and TOPEX/Poseidon/Jason-1 (T/P/J) altimeter data into the initial ensemble conditions. Comparisons with the original ensemble hindcast experiment show that the ensemble prediction skills were significantly improved out to a 12-month lead time by improving sea level (SL) initial conditions for better parameterization of subsurface thermal effects. It is clearly demonstrated that improvement in forecast skill can result from the multivariate and multi-observational ensemble data assimilation. Copyright 2007 by the American Geophysical Union.
{fenge}
34548147305	F⋯H - N and MeO⋯H - N hydrogen-bonding in the solid states of aromatic amides and hydrazides: A comparison study	Four intramolecularly F⋯H - N hydrogen-bonded aromatic amide and hydrazide derivatives have been prepared. Their crystal structures are investigated and compared with those of their MeO⋯H - N hydrogen-bonded analogues. It is found that all the F⋯H - N hydrogen-bonded molecules form intermolecular C=O⋯H - N hydrogen bonding and, for two of them, weak F⋯H - C interactions. In contrast, the MeO⋯H - N hydrogen-bonded molecules display only very weak intermolecular C - H-π interactions. The hydrogen-bonded amide units in the fluorine-bearing molecules exhibit large torsion from the connecting benzene units. This has been attributed to the weaker ability of fluorine as a hydrogen-bonding acceptor, its smaller size (relative to the MeO group), and consequently the strengthened intermolecular NH⋯O=C hydrogen bonding. The results also suggest that, although the weakness of fluorine as a hydrogen-bonding acceptor has been mainly attributed to its low polarizability and tightly contracted lone pairs, the great tendency of fluorine-bearing aromatic amides to form intermolecular C=O⋯H - N hydrogen bonding may also play a role. © 2007 American Chemical Society.
{fenge}
34547660515	Proper orthogonal decomposition approach and error estimation of mixed finite element methods for the tropical Pacific Ocean reduced gravity model	In this paper, the tropical Pacific Ocean reduced gravity model is studied using the proper orthogonal decomposition (POD) technique of mixed finite element (MFE) method and an error estimate of POD approximate solution based on MFE method is derived. POD is a model reduction technique for the simulation of physical processes governed by partial differential equations, e.g., fluid flows or other complex flow phenomena. It is shown by numerical examples that the error between POD approximate solution and reference solution is consistent with theoretical results, thus validating the feasibility and efficiency of POD method. © 2007 Elsevier B.V. All rights reserved.
{fenge}
35548982585	Microbe identification using gene chip and reapplication	Biochips provide important molecular biology detection methods for scientific research and for medical applications. This research investigates that biochips can be reused. A new microbe identification method was developed using gene chips. Escherichia Coli and Xanthonwnas_Campestris were used as examples for the gene chips design to identify microbes with a microarray scanner built to test if the gene chip can be reused. Tests show that the gene chip can identify the microbes and that a tight joint is formed between the biological probe and the surface modification molecule. The fluorescence signal is still strong even after the gene chip has gone through five cycles of hybrid and washing, which shows the feasibility of reusing gene chips. Except for clinic applications which need to consider cross pollution, biochips can be reused to reduce costs. To further extend the biochip lifetime, this paper also analyzed the biochip design and fluorescent marker.
{fenge}
35648969938	Newly developed optical systems and their potential applications	Since microscope was invented in 17 century, optical instruments have continued to be an important tool for advanced investigations in biology and medicine. The step by step development of optical technology has also preceded the realization of macroscopic and microscopic biology, providing new advances that help better understanding of these fields. Even today it is necessary to build new optical devices to foster the advancement of frontier biological research, and for new applications in medical research. Here in this paper, we describe two new advanced optical systems for biological detection, which are already used in a series of new instrument products, such as the confocal scanner, the digital imaging scanning system.
{fenge}
35649010899	Computer-aided measurements of cell electrorotation by image analysis techniques	Electrorotation (ROT) is widely used for the investigation of the dielectric properties of biological cells. Traditionally the tedious measurements of the rotational rates of the cells are handled manually. In this paper, a ROT chip detection platform equipped with computer-aided measuring system is presented. The rotational motions of the cells are captured by CCD camera and an algorithm is implemented to automatically estimate the rotational rates by analyzing the captured image. The acquired data is verified by a comparison with manual stop-watch measurements. The experimental results are accurate and robust against variations in illumination and cellular deformation within maximum 5% deviation from the manual measurements. Thus the platform as a whole can be employed to detect changes in the cellular membrane dielectric properties caused by external stimulation, or those occurring naturally.
{fenge}
37049021350	Application of altimetry data assimilation on mesoscale eddies simulation	Mesoscale eddy plays an important role in the ocean circulation. In order to improve the simulation accuracy of the mesoscale eddies, a three-dimensional variation (3DVAR) data assimilation system called Ocean Variational Analysis System (OVALS) is coupled with a POM model to simulate the mesoscale eddies in the Northwest Pacific Ocean. In this system, the sea surface height anomaly (SSHA) data by satellite altimeters are assimilated and translated into pseudo temperature and salinity (T-S) profile data. Then, these profile data are taken as observation data to be assimilated again and produce the three-dimensional analysis T-S field. According to the characteristics of mesoscale eddy, the most appropriate assimilation parameters are set up and testified in this system. A ten years mesoscale eddies simulation and comparison experiment is made, which includes two schemes: assimilation and non-assimilation. The results of comparison between two schemes and the observation show that the simulation accuracy of the assimilation scheme is much better than that of non-assimilation, which verified that the altimetry data assimilation method can improve the simulation accuracy of the mesoscale dramatically and indicates that it is possible to use this system on the forecast of mesoscale eddies in the future. © Science in China Press 2008.
{fenge}
38049129140	Discrete formulation of mixed finite element methods for vapor deposition chemical reaction equations	The vapor deposition chemical reaction processes, which are of extremely extensive applications, can be classified as a mathematical model by the following governing nonlinear partial differential equations containing velocity vector, temperature field, pressure field, and gas mass field. The mixed finite element (MFE) method is employed to study the system of equations for the vapor deposition chemical reaction processes. The semidiscrete and fully discrete MFE formulations are derived. And the existence and convergence (error estimate) of the semidiscrete and fully discrete MFE solutions are demonstrated. By employing MFE method to treat the system of equations for the vapor deposition chemical reaction processes, the numerical solutions of the velocity vector, the temperature field, the pressure field, and the gas mass field can be found out simultaneously. Thus, these researches are not only of important theoretical means, but also of extremely extensive applied vistas. © 2007 Editorial Committee of Appl. Math. Mech.
{fenge}
0032840333	Optimal control of sedimentation in navigation channels	Many hydraulic engineering projects concern the control of sedimentation. For some large engineering projects, such as construction of a navigation channel over many kilometers in a shallow estuary, comprehensive control of sedimentation is extremely costly. An optimal-control approach is presented. It determines optimal locations and scheduling of dredging to minimize total cost and to obtain a channel where water depths are not less than specified values. The optimal-control problem is formulated and a method is developed. The optimization problem is solved by the conjugate gradient method, and the gradient of the cost function is calculated by solving the adjoint problem. A simulation study is conducted using a 2D numerical model to demonstrate the method. The significance of the adjoint problem is also illustrated in sensitivity analysis experiments. ©ASCE,.
{fenge}
0034060469	An adaptive variational method for data assimilation with imperfect models	The solutions of the weak constraint data assimilation problems depend on a priori error covariance. If a priori error covariance have poor quality, a posteriori evaluation may have negative impact and solutions are not optimal. A novel variational data assimilation method is proposed, which does not assume the model is perfect, and can adaptively adjust model state without knowing explicitly the model error covariance matrix. Not by adjusting the initial condition in 4D-VAR, but by adjusting a steady gain matrix in a class of filters in this approach to yield a filter solution that minimize the norm of analysis innovation vector in a given span of time interval. The method enables very flexible ways to form some reduced order problems. A proper reduced-order problem not only reduces computational burden but leads to corrections that are more consistent with the model dynamics that trends to produce better forecast. It is shown that the optimal nudging can be reinterpreted as an example of the reduced order problems. The method is demonstrated using a simple nonlinear model (Burgers equation model) and simulated data. Full and several reduced order forms of the adaptive variational method are performed and compared with a simplified strong constraint 4D-VAR and the space variable optimal nudging scheme in assimilation-forecast experiments.
{fenge}
0033941460	The role of time step size in numerical stability of tangent linear models	It is found that some stable time-integration schemes for some nonlinear models do not guarantee stable integrations of the associated tangent linear models with the same time step size. These problems usually occur when the nonlinear models describe vertical diffusion processes and are numerically implemented by semiimplicit time-integration schemes that are unconditionally stable. The direct linearization procedure performed on such numerical schemes of nonlinear models can be interpreted as some conditionally stable numerical schemes of the underlying linearized equations. Numerical experiments using a simple, illustrative model and a realistic ocean mixed layer model and their tangent linear models showed instabilities in the tangent linear models. Several methods are tried to reduce the nonphysical noise caused by the numerical instabilities. This study suggests that reducing time step size can give good results compared to some other methods that either are not accurate enough or change too much from the original nonlinear model.
{fenge}
0033949846	Analysis on observing optimization for the wind-driven circulation by an adjoint approach	The adjoint approach is a variational method which is often applied to data assimilation widely in meteorology and oceanography. It is used for analyses on observing optimization for the wind-driven Sverdrup circulation. The adjoint system developed by Thacker and Long (1992), which is based on the GFDL Byran-Cox model, includes three components, i. e. the forward model, the adjoint model and the optimal algorithm. The GFDL Byran-Cox model was integrated for a long time driven by a batch of ideal wind stresses whose meridional component is set to null and zonal component is a sine function of latitudes in a rectangle box with six vertical levels and 2 by 2 degree horizontal resolution. The results are regarded as a 'real' representative of the wind-driven Sverdrup circulation, from which the four dimensional fields are allowed to be sampled in several ways, such as sampling at the different levels or along the different vertical sections. To set the different samples, the fields of temperature, salinity and velocities function as the observational limit in the adjoint system respectively where the same initial condition is chosen for 4D VAR data assimilation. By examining the distance functions which measure the misfit between the circulation field from the control experiment of the adjoint system with a complete observation and those from data assimilation of adjoint approach in these sensitivity experiments respectively, observing optimizations for the wind-driven Sverdrup circulation will be suggested under a fixed observational cost.
{fenge}
38149095663	Galerkin-Petrov least squares mixed element method for stationary incompressible magnetohydrodynamics	The Galerkin-Petrov least squares method is combined with the mixed finite element method to deal with the stationary, incompressible magnetohydrodynamics system of equations with viscosity. A Galerkin-Petrov least squares mixed finite element format for the stationary incompressible magnetohydrodynamics equations is presented. And the existence and error estimates of its solution are derived. Through this method, the combination among the mixed finite element spaces does not demand the discrete Babuška-Brezzi stability conditions so that the mixed finite element spaces could be chosen arbitrartily and the error estimates with optimal order could be obtained. © 2007 Editorial Committee of Appl. Math. Mech.
{fenge}
38849157784	An optimizing reduced order FDS for the tropical Pacific Ocean reduced gravity model	Proper orthogonal decomposition (POD) and singular value decomposition (SVD) methods are used to study a finite difference discretization scheme (FDS) for the tropical Pacific Ocean reduced gravity model. Ensembles of data are compiled from transient solutions computed from the discrete equation system derived by FDS for the tropical Pacific Ocean reduced gravity model. The optimal orthogonal bases are used to reconstruct the elements of the ensemble with POD and SVD. Combining the above approach with a Galerkin projection procedure yields a new optimizing FDS model of lower dimensions and high accuracy for the tropical Pacific Ocean reduced gravity model. An error estimate of the new reduced order optimizing FDS model is then derived. Numerical examples are presented illustrating that the error between the POD approximate solution and the full FDS solution is Consistent with previously obtained theoretical results, thus validating the feasibility and efficiency of POD method. Copyright © 2007 John Wiley & Sons, Ltd.
{fenge}
58149457608	Regional relationship between the Jiang-Huai Meiyu and the equatorial surface-subsurface temperature anomalies	The Jiang-Huai Meiyu rainy season can be distinguished into the Jiangnan Meiyu spell and the Huaihe Meiyu spell. The Jiangnan Meiyu spell appears on the last ten days in June and the Huaihe Meiyu spell lasts from early July to middle July. An inter-decadal transition was observed in 1998 respectively from the anomalies of Jiangnan Meiyu rainfall, the sea surface temperature (SST), and the subsurface temperature in the equatorial Pacific. Since the beginning of the 21st century, opposite trends and biennial oscillations of the Meiyu rainfall are observed in the Jiangnan and Huaihe basins. Before the strong La Niña of 1999-2000, the positive SST anomalies usually occurred in the eastern equatorial Pacific. Since the beginning of the 21st century, a precursory warming signal of SST anomaly comes from the subsurface temperature which is centrally exposed near the dateline in the central equatorial Pacific. The above-normal Meiyu rainfall in 2003, 2005 and 2007 over the Huaihe basin followed the prior winterspring positive SST anomaly near the dateline. A relationship shows that the more Jiangnan (Huaihe) Meiyu follows the winter-spring warm water in the eastern (central) equatorial Pacific. © 2008 Science in China Press and Springer-Verlag GmbH.
{fenge}
0034633625	Data assimilation and its applications	In data assimilation, one prepares the grid data as the best possible estimate of the true initial state of a considered system by merging various measurements irregularly distributed in space and time, with a prior knowledge of the state given by a numerical model. Because it may improve forecasting or modeling and increase physical understanding of considered systems, data assimilation now plays a very important role in studies of atmospheric and oceanic problems. Here, three examples are presented to illustrate the use of new types of observations and the ability of improving forecasting or modeling.
{fenge}
0034728790	An SP1-like cis-element is the major DNA motif for differential expression regulation of the adipocyte amino acid transporter	Adipocyte amino acid transporter (AAAT) is induced during the 3T3-L1 preadipocyte differentiation process. In the -1819-bp 5'-upstream flanking region of the AAAT genomic gene, six DNase I protected sites were identified by using the 3T3-L1 adipocyte nuclear extract. Results of chloramphenicol acetyltransferase (CAT) expression from the chimeric AAAT promoter-driven CAT reporter gene indicated that one protein binding site, from -68 to -26, was essential for the promoter activity. However, this protein binding site does not contain recognition sites of the transcription factors important for adipocyte differentiation, i.e., the C/EBP or PPAR family. Further analysis revealed that the DNA sequence, TTCAAGTCCCGCCCTCCGCT from -65 to -46, was the cis-element essential and partially sufficient for inducible activity of the AAAT gene promoter. (C) 2000 Academic Press.
{fenge}
77954145381	Spring predictability barrier of ENSO events from the perspective of an ensemble prediction system	Based on an ENSO (El Niño-Southern Oscillation) ensemble prediction system (EPS), the seasonal variations in the predictability of ENSO are examined in both a deterministic and a probabilistic sense. For the deterministic prediction skills, the skills of the ensemble-mean are sensitive to the month in which the forecast was initiated. The anomaly correlations decrease rapidly during the Northern Hemisphere (NH) spring, and the root mean square (RMS) errors have the largest values and the fastest growth rates initialized before and during the NH spring. However, the probabilistic predictions based on the verification methods of the relative operating character (ROC) curve and area both show that there are no strong seasonal variations for the two extreme (warm and cold) ENSO events. For the near-normal events, the seasonal variations of the probabilistic skills are much more obvious, and the ROC areas of the ensemble forecasts made in the spring are clearly smaller than those of the ensemble forecasts that began during other seasons.At the same time, the probabilistic prediction skills of the EPS for all three events that only consider the initial perturbations are also clearly sensitive to the initial months. This was indicated by the fact that the most rapid decrease of the ROC area skill occurs as the hindcasts proceed through the spring season. A further signal-to-noise ratio analysis reveals that potential sources of the predictability barrier in the probabilistic skills for the EPS are namely that the spring is the period when stochastic initial error effects can be expected to strongly degrade forecast skill, and that small predicted signals can render the system noisier by further limiting the predictability. However, reasonable considerations of the model-error perturbations during the ensemble forecast process can alleviate the barrier caused by initial uncertainties through coordinately simulating the seasonal variations of the forecast uncertainty in order to significantly improve the probabilistic prediction skills and then to disorder the seasonal predictability related to the SPB. © 2010 Elsevier B.V.
{fenge}
77954244145	Synthesis of ZnO clusters within ZSM-5 crystals by thermal diffusion method	The thermal diffusion method is employed for ZnO loading into ZSM-5 crystals (ca. 120μm along c axis) which is regarded as a good host material for guest encapsulation. Optical microscopy photographs and X-ray powder diffraction spectra are obtained and show that the ZnO clusters are infiltrated into ZSM-5 crystals, instead of locating on the surface of the crystals. An intense porosity analysis based on density functional theory is used to illustrate the pore texture of the ZnO-loaded samples. The sample prepared at 650 °C has ZnO clusters existing mainly in the external surface of ZSM-5. As for the sample prepared at 750 °C, the micropores of ZSM-5 have been occupied. © 2009 Elsevier B.V. All rights reserved.
{fenge}
77954817463	Responses of rice yields to recent climate change in China: An empirical assessment based on long-term observations at different spatial scales (1981-2005)	This empirical study (i) assessed rice yield responses to recent climate change at experiment stations, in counties and in provinces of China for the period of 1981-2005 and (ii) identified the climatic drivers determining the trend of yields at each spatial scale. Our empirical results, based on 20 experiment stations during study periods of 14-25 years, indicate that rice yields were positively correlated to solar radiation, which primarily drives yield variation. At most stations, yields were positively correlated to temperature and there was no significant negative correlation between them. Therefore, our empirical results argue against the often-cited hypothesis of lower yields with higher temperature. We explain this by the positive correlation between temperature and radiation at our stations. Empirical analysis to yield at a regional scale (20 counties and 22 provinces) indicates a varying climate to yield relationships. In some places, yields were positively regressed with temperature when they were also positively regressed with radiation, showing the similar pattern at above experiment stations. But, in others, lower yield with higher temperature was accompanied by positive correlation between yield and rainfall, which was not happened at stations. We explain this by irrigation water availability, which played a crucial role in determining climatic effects (radiation or rainfall) on yield variability at a regional scale in China. However, temperature's negative effect is still weak at any scale.This study showed how rice yields respond to recent climate change from 1981 to 2005 at station and regional scales in China and identifies the major climatic driver for yield variation. The empirical findings presented here provide a foundation for anticipating climate change impacts on rice production in China. © 2010.
{fenge}
79952305405	The application of simulating WAves Nearshore model for wave height simulation at Bangkhuntien shoreline	Problem statement: In this study, the significant wave height at the Upper Gulf of Thailand and the change of wave height at Bangkhuntien shoreline were simulated by using the Simulating WAves Nearshore Model (SWAN) version 40.51. Approach: The simulated significant wave height by the SWAN model at Petchburi buoy station and Ko Srichang buoy station were compared with the observed significant wave height at these stations for the model verification. The significant wave height by the SWAN model at Bangkhuntien shoreline from 1981-2004 were simulated. Results: The simulated results show that the maximum significant wave height at Bangkhuntien shoreline was in a range of 0.95-2.05 m while the average maximum significant wave height was 1.47 m. The average significant wave height were in a range of 0.29-0.48 m while the average significant wave height of 21 years simulated data at Bangkhuntien shoreline was 0.35 m. Conclusion: The findings of this study could be useful for the erosive calculation, shoreline protection and coastal zone management activities & copy; 2010 Science Publications.
{fenge}
84867338415	Gene and Genome Parameters of Mammalian Liver Circadian Genes (LCGs)	The mammalian circadian system controls various physiology processes and behavior responses by regulating thousands of circadian genes with rhythmic expressions. In this study, we redefined circadian-regulated genes based on published results in the mouse liver and compared them with other gene groups defined relative to circadian regulations, especially the non-circadian-regulated genes expressed in liver at multiple molecular levels from gene position to protein expression based on integrative analyses of different datasets from the literature. Based on the intra-tissue analysis, the liver circadian genes or LCGs show unique features when compared to other gene groups. First, LCGs in general have less neighboring genes and larger in both genomic and 3′-UTR lengths but shorter in CDS (coding sequence) lengths. Second, LCGs have higher mRNA and protein abundance, higher temporal expression variations, and shorter mRNA half-life. Third, more than 60% of LCGs form major co-expression clusters centered in four temporal windows: dawn, day, dusk, and night. In addition, larger and smaller LCGs are found mainly expressed in the day and night temporal windows, respectively, and we believe that LCGs are well-partitioned into the gene expression regulatory network that takes advantage of gene size, expression constraint, and chromosomal architecture. Based on inter-tissue analysis, more than half of LCGs are ubiquitously expressed in multiple tissues but only show rhythmical expression in one or limited number of tissues. LCGs show at least three-fold lower expression variations across the temporal windows than those among different tissues, and this observation suggests that temporal expression variations regulated by the circadian system is relatively subtle as compared with the tissue expression variations formed during development. Taken together, we suggest that the circadian system selects gene parameters in a cost effective way to improve tissue-specific functions by adapting temporal variations from the environment over evolutionary time scales. © 2012 Wu et al.
{fenge}
84897978514	Theoretical study on fluorescence spectra of four kinds of p-substituted curcumin analogues	Four kinds of p-substituted curcumin analogues were optimized at B3LYP/6-31G (d, p) level. On this basis, the excited states geometry structure was optimized by the CIS method, and finally the fluorescence emission spectra were calculated through the TD-DFT method. The results showed that: the four compounds, a large conjugated system, is preferably coplanar structure. Because of introducing hydroxyl and halogen atom on the benzene ring, the molecular II-electron conjugation is relatively larger, emission wavelength is relatively longer, and fluorescence spectra show different degrees of red shift. As the electron donating group is hydroxy, the fluorescence phenomenon is more obviously red shifted.
{fenge}
43749087646	Evaluation of a 3dVAR system for the South China Sea	The authors evaluate a three-dimensional variational (3dVAR) system for the South China Sea (SCS) in this study. The assimilation method applied in the system takes into consideration error correlation along each ground track and uses recursive filter for optimization. Data from three R/V cruises during the spring and summer of 1998 and the summer of 2000 are used to evaluate the system. The root-mean-square error and bias are reduced significantly and when the altimeter data are assimilated, the distribution of the error is much closer to the Gaussian distribution. Precipitation and river discharge in the southwestern SCS are reproduced, and the variability of sea surface height is efficiently transferred to the subsurface. The 3dVAR system performs well for each of the three cruises, suggesting that it is steady for routine usage.
{fenge}
43749108373	Correlation changes between rice yields in North and Northwest China and ENSO from 1960 to 2004	The correlations between ENSO (El Niño/Southern Oscillation) and crops in China have been recognized, but the research focusing on the causes behind the correlations still remains incomplete. In this study, we concentrate on the causal relationship between ENSO and rice yields in North and Northwest China. We found that there was an inconsistency in the observed correlation between rice yields and the occurrence of ENSO events during various periods from 1960 to 2004 in most provinces. Rice was vulnerable to El Niño events before 1980, while it seemed to benefit from the occurrence of such events following 1980. We established the reason for the change through a combination of mechanistic modeling and empirical statistical analysis. We concluded that much of this inconsistency in yield responses to ENSO can be attributed to the development of water supply systems throughout our study region. The meteorological impacts associated with ENSO events varied with water regime. This important finding provided a key explanation into the interaction processes between ENSO climate variability and the water supply in the rice production system, and further confirmed the importance of considering interactive effects between climate variability and human adaptation practices when assessing climate change impacts on agricultural variability. © 2008 Elsevier B.V. All rights reserved.
{fenge}
44449142514	Assessment and inter-comparison of five high-resolution sea surface temperature products in the shelf and coastal seas around China	Recently the global ocean data assimilation experiment (GODAE) High-Resolution SST Pilot Project (GHRSST-PP) has delivered several sea surface temperature (SST) products based on satellite remote-sensing observations. These cloud-free, high spatial (up to 2-5 km) and temporal resolution (daily or 6-hourly) SST products provide important data sources for operational ocean forecast of both global and shelf/coastal seas. Before applying the GHRSST products to initialization or data assimilation for ocean forecasting of shelf and coastal seas, it is necessary to make inter-comparison and assessment of these products. In this paper, five products were investigated by means of inter-comparison and comparison to in situ observations at the shelf and coastal sea around China and in the northwest Pacific over 1-year period (from October 2005 to September 2006). The inter-comparison shows that in the coastal and the shelf sea around China, there are some significant differences among these products. Some have warm bias with reference to the five-member mean, while some have cold biases. In shelf seas around China, the spread of the five products is between 0.4 and 0.6 °C. In the coastal sea (shallower than 40 m), the spread increases dramatically to 0.95 °C. Further, the comparison of daily GHRSST products with in situ night-time SST observations from surface drifters and ship reports indicated that most of these SST products are excellent in deep water region. The root mean square differences (RMSDs) of some products with reference to in situ observations are less than 0.4 °C. But near the coastal, relatively large bias and RMSD exist in all five products. In order to reduce the bias and RMSD in near coast, a simple, depth-dependent bias correction scheme is applied to two of the five products. After correction their biases can be reduced, and their RMSDs could be also decreased about 6-14%. This study suggests that the GHRSST products can be used for operational ocean forecasting with proper error estimation for shelf seas and the open ocean. For the coastal seas where the depths are shallower than 40 m, large uncertainties exist in these products. Improvements are needed for future application in the coastal seas. © 2008 Elsevier Ltd. All rights reserved.
{fenge}
44349127575	Modeling transcriptome based on transcript-sampling data	Background: Newly-evolved multiplex sequencing technology has been bringing transcriptone sequencing into an unprecedened depth. Millions of transcript tags now can be acquired in a single experiment through parallelization. The significant increase in throughput and reduction in cost required us to address some fundamental such as how many transcript tags do we have to sequence for a given transcriptome? How could we estimate the total number of unique transcripts for different cell types (transcriptome diversity) and the distribution of their copy numbers transcriptome dynamics)? What is the probability that a transcript with a given expression level to detected at a certain sampling depth? Methodology/Principal Findings: We developed a statistical model to evaluate these parameters based on transcriptome sampling data. Three mixture models were exploited for their potentials to model the sampling frequencies. We demonstrated that relative abundances of all transcipts in a transcriptome follow the generalized inverse Gaussian distribution. The widely known beta and gamma distriutions failed to fulfill the singular characteristics of relative abundance distribution, i.e., highly skewed toward zero and with a long tail. An estimator of transcriptome diversity and an analytical form of sampling growth curve were proposed in a coherent framework. Experimental data fitted this model very well and Monte Carlo simulations based on this model replicated sampling experiments in a remarkable precision. Conclusion: Taking human embryonic stem cell as a prototype, we demonstrated tens of thousands of transcript tags in an ordinary EST/ SAGE experiment was far from sufficient. In order to fully characterize a human transcriptome, millions of transript tags had to be sequenced. This model lays a statistical basis for transcriptome-sampling experiments and in essense can be used in all sampling-based data. © 2008 Zhu et al.
{fenge}
44349158988	How many human genes can be defined as housekeeping with current expression data?	Background: Housekeeping (HK) genes are ubiquitously expressed in all tissue/cell types and constitute a basal transcriptome for the maintenance of basic cellular functions. Partitioning transcriptomes into HK and tissue-specific (TS) genes relatively is fundamental for studying gene expression and cellular differentiation. Although many studies have aimed at large-scale and thorough categorization of human HK genes, a meaningful consensus has yet to be reached. Results: We collected two latest gene expression datasets (both EST and microarray data) from public databases and analyzed the gene expression profiles in 18 human tissues that have been well-documented by both two data types. Benchmarked by a manually-curated HK gene collection (HK408), we demonstrated that present data from EST sampling was far from saturated, and the inadequacy has limited the gene detectability and our understanding of TS expressions. Due to a likely over-stringent threshold, microarray data showed higher false negative rate compared with EST data, leading to a significant underestimation of HK genes. Based on EST data, we found that 40.0% of the currently annotated human genes were universally expressed in at least 16 of 18 tissues, as compared to only 5.1% specifically expressed in a single tissue. Our current EST-based estimate on human HK genes ranged from 3,140 to 6,909 in number, a ten-fold increase in comparison with previous microarray-based estimates. Conclusion: We concluded that a significant fraction of human genes, at least in the currently annotated data depositories, was broadly expressed. Our understanding of tissue-specific expression was still preliminary and required much more large-scale and high-quality transcriptomic data in future studies. The new HK gene list categorized in this study will be useful for genome-wide analyses on structural and functional features of HK genes. © 2008 Zhu et al; licensee BioMed Central Ltd.
{fenge}
46649086924	Initial ensemble generation and validation for ocean data assimilation using HYCOM in the Pacific	A method to initialize an ensemble, introduced by Evensen (Physica, D 77:108-129, 1994a; J Geophys Res 99(C5):10143-10162, 1994b; Ocean Dynamics 53:343-367, 2003), was applied to the Ocean General Circulation Model (OGCM) HYbrid Coordinate Ocean Model (HYCOM) for the Pacific Ocean. Taking advantage of the hybrid coordinates, an initial ensemble is created by first perturbing the layer interfaces and then running the model for a spin-up period of 1 month forced by randomly perturbed atmospheric forcing fields. In addition to the perturbations of layer interfaces, we implemented perturbations of the mixed layer temperatures. In this paper, we investigate the quality of the initial ensemble generated by this scheme and the influence of the horizontal decorrelation scale and vertical correlation on the statistics of the resulting ensemble. We performed six ensemble generation experiments with different combinations of horizontal decorrelation scales and with/without perturbations in the mixed layer. The resulting six sets of initial ensembles are then analyzed in terms of sustainability of the ensemble spread and realism of the correlation patterns. The ensemble spreads are validated against the difference between model and observations after 20 years of free run. The correlation patterns of six sets of ensemble are compared to each other. This study shows that the ensemble generation scheme can effectively generate an initial ensemble whose spread is consistent with the observed errors. The correlation pattern of the ensemble also exhibits realistic features. The addition of mixed layer perturbations improves both the spread and correlation. Some limitations of the ensemble generation scheme are also discussed. We found that the vertical shift of isopycnal coordinates provokes unrealistically large deviations in shallow layers near the islands of the West Pacific. A simple correction circumvents the problem. © 2008 Springer-Verlag.
{fenge}
46749086268	Trends and scales of observed soil moisture variations in China	A new soil moisture dataset from direct gravimetric measurements within the top 50-cm soil layers at 178 soil moisture stations in China covering the period 1981-1998 are used to study the long-term and seasonal trends of soil moisture variations, as well as estimate the temporal and spatial scales of soil moisture for different soil layers. Additional datasets of precipitation and temperature difference between land surface and air (TDSA) are analyzed to gain further insight into the changes of soil moisture. There are increasing trends for the top 10 cm, but decreasing trends for the top 50 cm of soil layers in most regions. Trends in precipitation appear to dominantly influence trends in soil moisture in both cases. Seasonal variation of soil moisture is mainly controlled by precipitation and evaporation, and in some regions can be affected by snow cover in winter. Timescales of soil moisture variation are roughly 1-3 months and increase with soil depth. Further influences of TDSA and precipitation on soil moisture in surface layers, rather than in deeper layers, cause this phenomenon. Seasonal variations of temporal scales for soil moisture are region-dependent and consistent in both layer depths. Spatial scales of soil moisture range from 200-600 km, with topography also having an affect on these. Spatial scales of soil moisture in plains are larger than in mountainous areas. In the former, the spatial scale of soil moisture follows the spatial patterns of precipitation and evaporation, whereas in the latter, the spatial scale is controlled by topography. © Science Press 2008.
{fenge}
46149098662	Automated dielectrophoretic cell fractionation system using MEMS technology	A novel method for constructing an automated cell fractionation system was developed by integrating travelingwave dielectrophoresis (twDEP) and laminar flow on a single biochip-based device. Novel electrodes designs on Indium Tin Oxide (ITO) glass and pre-molded poly(dimethylsiloxane) (PDMS) microfluidic chamber, as well as an automated cell tracking method based on a computer-assisted image analysis method were designed and developed. The functioning of the device was demonstrated by isolating viable human myelogenous HL-60 cells from the dead ones. The simulation of the electric field and fluidic field, together with the experimental results confirmed our theoretical predictions. The preliminary data achieved with this device indicated that cells of different types could be effectively separated. ©2006 IEEE.
{fenge}
48149088425	A novel developed detection and analysis method of DNA microarray hybridization using FRET technique	Florescence Resonance Energy Transfer (FRET) is a distance-sensitive energy transfer process which is widely used in probing molecular interaction in the 1-10 nm range. DNA microarray chip technique is a high throughput analysis method in molecular biology research. In this paper, we explored a novel detection and analysis method of DNA microarray hybridization using FRET technique. In our study, TMR dye labeled DNA oligomer was immobilized on the microarray chips and hybridized with complementary DNA oligomer labeled with Cy5 dye. We successfully detected and analysed the FRET signal of the hybridized DNA microarray. The variation of FRET signal intensity and the efficiency of FRET in response to the concentration of the sample were studied. © 2007 IEEE.
{fenge}
48349115435	Estimation of the surface and mid-depth currents from Argo floats in the Pacific and error analysis	With the large deployment, the Array for Real-time Geostrophic Oceanography program has great potential for measuring the ocean currents both on the surface and at mid-depth. However the positioning error of fixes in a trajectory varies from 150 m to 1000 m, and thus created difficulty for accurate estimations of the surface and mid-depth currents. Also the reliability of the estimated surface and mid-depth currents requires accurate error estimations. In this study a new sequential method of Argo float surface trajectory tracking and extrapolating is proposed based on Kalman Filter (KF), under the presumption that a surface trajectory of Argo float is dominated by a constant current plus inertial oscillation. This trajectory tracking and extrapolating method is able to reduce the positioning uncertainties of Argo surface trajectories and provides error estimations. When this method was applied to extrapolate the positions when float resurfacing and descending, the estimation error of the mid-depth currents can be reduced. Utilizing this method in the Pacific, surface and mid-depth currents were estimated from surface trajectories of Argo floats from 2001 to 2004, along with their detailed error estimations. The average error for surface currents is about 4.4 cm s
{fenge}
49849096634	Non-stationary thermal time accumulation reduces the predictability of climate change effects on agriculture	Current modeling studies on the impacts of climate change on agriculture widely assume that thermal time accumulation of crops during the growing season remains constant under various climate conditions. However, in this study, a 20-year single rice variety, experimental dataset indicates that the thermal time accumulation for the entire growing season is not constant. As a result, a crop model based on constant thermal time accumulation significantly underestimates the observed phenological trend exhibited over the two decades of research-despite comparably accurate simulations of short periods. This deviation can result in misleading yield simulations, whereas the model simulations, using observed phenology data, show a similar yield trend as the observation. This study casts serious doubt on the assumptions of constant thermal time accumulation made in previous modeling studies, and, moreover, it highlights the critical requirements needed to improve phenology simulations on a larger scale so that predictions of the eventual yield trends due to climate change can more accurately reflect the results of yield trends in reality. © 2008 Elsevier B.V. All rights reserved.
{fenge}
51649104682	Digital imaging scanning system and biomedical applications for biochips	Biochips have been an advanced technology for biomedical applications since the end of the 20th century. Optical detection systems have been a very important tool in biochip analysis. Microscopes are often inadequate for high resolution and big view-area detection of microarray chips, thus some new optical instruments are required. In this work, a novel digital imaging scanning system with dark-field irradiation is developed for some biomedical applications for microarray chips, characterized by analyzing genes and proteins of clinical samples with high specific, parallel, and nanoliter samples. The novel optical system has a high numerical aperture (NA=0.72), a long working distance (w
{fenge}
51749126074	Balanced multivariate model errors of an intermediate coupled model for ensemble Kalman filter data assimilation	The ensemble Kalman filter (EnKF) depends on a set of ensemble forecasts to calculate the background error covariances. Without model error perturbations and the inflation of forecast ensembles, the spread of the ensemble forecasts can collapse rapidly. There are several ways to generate model perturbations, i.e., perturbations in model parameters/ parameterizations, perturbations in the forcing fields of the model and adding some error terms to the right-hand side of the model equations. In this paper, we focus on the "adding model error terms" approach, which utilizes a first-order Markov chain model. This approach is suitable to those unforced models, such as the coupled atmosphere-ocean models. However, for a multivariate model, the balance between different model variables could be an important issue in building its model-error model. In this paper, we focus on building a balanced error model for an intermediate coupled model for El Niño-Southern Oscillation (ENSO) predictions. A simple approach to build such a model-error model is proposed on the basis of the multivariate empirical orthogonal functions method. EnKF data assimilation experiments with different configurations of multivariate model error treatments (no model errors, unbalanced and balanced model errors) are performed using realistic sea surface temperature (SST) and sea level (SL) observations. Results show that it is necessary to develop balanced, multivariate model-error models in order to successfully assimilate both SST and SL observations. The hindcasts initialized from these different assimilation experiment results also demonstrate that the balanced model errors can yield more balanced initial conditions that lead to improved predictions of ENSO events. Copyright 2008 by the American Geophysical Union.
{fenge}
54049094704	Berberine inhibits SDF-1-induced AML cells and leukemic stem cells migration via regulation of SDF-1 level in bone marrow stromal cells	Berberine plays a prominent role on the control of tumor cell invasion and migration. SDF-1 is a homeostatic chemokine that signals through CXCR4 which is expressed by hematopoietic tumor cells. The SDF-1/CXCR4 axis is involved in the migration process of leukemic cells. In this study, we investigated the effects of berberine on the SDF-1-induced HL-60 cells, primary acute myeloid leukemia (AML) cells and leukemic stem cells (LSCs) migration. Transwell migration chambers (8 μm) were used to assess the role of berberine on leukemic cell migration; Flow cytometry was used to analyze the role of berberine on the CXCR4 expression; SDF-1 protein level secreted by bone marrow stromal cells (BMSCs) was evaluated by ELISA. Results demonstrated that berberine could partly inhibit SDF-1-induced AML cells as well as LSCs migration. Berberine could reduce SDF-1 protein level secreted by BMSCs in the microenvironment but not affect CXCR4 expression on HL-60 cell membrane, and we hypothesized that berberine could inhibit AML cells migration partly by reducing the secreting of SDF-1 by BMSCs and inhibiting HERG1 K
{fenge}
54049157876	Gene clone, recombination and expression of CTLA-4, TCRV β 8 of human T lymphocyte	Objective: To clone CTLA-4 and TCRVβ8 gene from T lymphocyte of thyroid of Graves' disease (GD) patients, recombine to form CTLA-4-TCRVβ 8 fusion gene and express the fusion protein. Methods: CTLA-4 and TCRVβ 8 gene was cloned from T lymphocyte of thyroid of GD patients by RT-PCR. Then it was recombined with expression plasmid in order. The correct plasmids were obtained after the restriction analysis and DNA sequencing. Prokaryotic expression of the fusion protein in E. coli, SDS-PAGE and Western Blotting were used to verify the fusion protein. Results: Restriction analysis and DNA sequencing confirmed the correct sequence and insertion site of the recombinant plasmid. The recombinant fusion protein was successfully expressed in E. coli, which was consistent with the predicted putative calculating molecular weight. Conclusion: CTLA-4-TCRVβ 8 gene was constructed and expressed successfully, providing gene product and application theory for immune tolerance therapy of GD.
{fenge}
55349105150	Climatic features of cloud water distribution and cycle over China	Analyses of cloud water path (CWP) data over China available from the International Satellite Cloud Climatology Project (ISCCP) are performed for the period 1984-2004. Combined with GPCP precipitation data, cloud water cycle index (CWCI) is also calculated. The climatic distributions of CWP are found to be dependent on large-scale circulation, topographical features, water vapor transport and similar distribution features which are found in CWCI except in the Sichuan Basin. Influenced by the Asia monsoon, CWP over China exhibits very large seasonal variations in different regions. The seasonal cycles of CWCI in different regions are consistent and the largest CWCI occurs in July. The long-term trends of CWP and CWCI are investigated, too. Increasing trends of CWP are found during the period with the largest increase found in winter. The decreasing trends of CWCI dominate most regions of China. The differences in long-term trends between CWP and CWCI suggest that CWP only can influence the variation of CWCI to a certain extent and that other factors need to be involved in cloud water cycle researches. This phenomenon reveals the complexity of the hydrological cycle related to cloud water. © Science Press 2008.
{fenge}
57749089612	A comparison between 3DVAR and EnOI techniques for satellite altimetry data assimilation	Two conceptually different assimilation schemes, three dimensional variational (3DVAR) assimilation and Ensemble Optimum Interpolation (EnOI) are compared in the context of satellite altimetric data assimilation. Similarities and differences of the two schemes are briefly discussed and their impacts on the model simulation are investigated. With a tropical Pacific ocean model, two assimilation experiments of sea level anomaly (SLA) data from TOPEX/Poseidon are performed for 5 years from 1997 to 2001. Annual mean states of temperature and salinity fields are compared with analysis data and some independent observations. It is found that EnOI generally produces moderate improvements on both temperature and salinity fields, while changes induced by 3DVAR assimilation are strong and vary remarkably in different areas. For instance, 3DVAR tends to excessively modify the temperature field along the thermocline depth and even deteriorate the simulation, but it is more effective than EnOI below the thermocline depth. However, for the salinity field 3DVAR outperforms EnOI nearly for almost the whole layer. As the difference relative to the WOA01 analysis is compared, it is apparently reduced to below 0.3 psu in most areas in the 3DVAR experiment. On the other hand, the pattern of difference in the EnOI experiment resembles that of the simulation and the magnitude is only diminished to some extent. One advantage of EnOI is that it yields more consistent improvements even in areas where there are large model errors. It is more reliable than 3DVAR in such a sense. It is also revealed that the T-S relation plays a very important role in altimetric data assimilation. Further, the distinct performance of the two schemes can be partly accounted for by their inherent assumptions and settings. © 2008 Elsevier Ltd. All rights reserved.
{fenge}
63649137097	Quantitative fluorescence correction incorporating Förster resonance energy transfer and its use for measurement of hybridization efficiency on microarrays	Fluorescence detection using two spectrally distinct fluo-rophores has long been used for the determination of the relative abundance of biomolecules, but overlap between the fluorescence spectra of each fluorophore can result in nonradiative Förster resonance energy transfer (FRET) and distorting the signals detected by fluorescence channels. Thus conventional methods for quantifying the relative abundance of fluorophores by fluorescence emission will not be accurate if FRET can occur. In this paper we report the development of a quantitative fluorescence correction method incorporating FRET to measure the relative abundance of fluorophores in dual-labeling experiments. The quantitative fluorescence correction method incorporating FRET is accurate, comprehensive, and convenient for the measurement of the relative abundance of fluorophores in dual-labeling experiments and can also correct the FRET distortion and provide accurate, quantitative, and convenient measurement of the hybridization efficiencies on microarrays. © 2009 American Chemical Society.
{fenge}
67349118504	Performance of four sea surface temperature assimilation schemes in the South China Sea	Four existing sea surface temperature (SST) assimilation schemes are evaluated in terms of their performances in assimilating the advanced very high resolution radiometer pathfinder best SST data in the South China Sea using the Princeton Ocean Model. Schemes 1 and 2 project SST directly to subsurface according to model-based correlations between SST and subsurface temperature. The difference between these two schemes is related to the order of vertical projection and horizontal optimal interpolation (OI). In Scheme 1, the spatially non-uniform SST observations are first projected to subsurface levels, followed by horizontal OI at each level. While in Scheme 2, the remotely sensed SSTs are first optimally interpolated to all grid points at the surface, followed by projecting gridded SSTs to subsurface levels. Scheme 3 assumes that the mixed layer is well mixed and has a uniform temperature vertically. In Scheme 4, SST is propagated to subsurface levels using a linear relationship of temperature between any two neighboring depths (Scheme 4a) or between surface and subsurface (Scheme 4b), which is derived by empirical orthogonal function (EOF) technique. To verify the results of the four schemes, the authors use the hydrographic data from two cruises during the South China Sea Monsoon Experiment in April and June 1998. It was shown that all four schemes could improve the SST field by reducing about 50% of the root mean square errors (RMSEs). All but Scheme 3 can improve model thermocline structure that is too diffused otherwise, though the RMSEs increase in the thermocline, especially for Scheme 2 when the model has opposite bias between upper layers and lower layers. Scheme 3 fails in the subsurface depth by increasing the thermocline depth, especially when there is a cold model bias. Projecting SST downward by EOF technique can deepen the depth of assimilation especially in Scheme 4a. Both Schemes 4a and b can correct the bias in the mixed layer and do not change the vertical thermal structure. © 2009 Elsevier Ltd. All rights reserved.
{fenge}
67649961644	An optimizing reduced PLSMFE formulation for non-stationary conduction-convection problems	In this paper, proper orthogonal decomposition (POD) is combined with the Petrov-Galerkin least squares mixed finite element (PLSMFE) method to derive an optimizing reduced PLSMFE formulation for the non-stationary conduction-convection problems. Error estimates between the optimizing reduced PLSMFE solutions based on POD and classical PLSMFE solutions are presented. The optimizing reduced PLSMFE formulation can circumvent the constraint of Babuška-Brezzi condition so that the combination of finite element subspaces can be chosen freely and allow optimal-order error estimates to be obtained. Numerical simulation examples have shown that the errors between the optimizing reduced PLSMFE solutions and the classical PLSMFE solutions are consistent with theoretical results. Moreover, they have also shown the feasibility and efficiency of the POD method. Copyright © 2008 John Wiley & Sons, Ltd.
{fenge}
68749089503	Assimilating temperature and salinity profile observations using an anisotropic recursive filter in a coastal ocean model	In order to improve the ocean forecasting in the North Sea and Baltic Sea, an assimilation scheme based on a bottom-topography-dependent anisotropic recursive filter has been used in this study. This scheme can stretch or flatten the shape of a local representative contour surface of the background error covariance function into the form of an ellipse. Furthermore, the computing efficiency has been largely improved due to implicit computation of the background error covariance. A two-month experiment has been used for verifying the impact of assimilating ocean profile observations on ocean forecasting. The results indicate that the use of temperature and salinity profiles can largely improve the oceanic forecasting. The root mean square differences between the forecasts and observations for temperature and salinity have been reduced by 36% and 18% in the experiment period, respectively. Moreover, it is found that the anisotropic recursive filter approach is especially efficient in areas with complex coastlines and sharp fronts, e.g., inner Danish waters. The results also show that the propagation of observation information from an observation position to its neighboring grid points is closely related to currents. © 2009 Elsevier Ltd. All rights reserved.
{fenge}
68749098114	Toward a global ocean data assimilation system based on ensemble optimum interpolation: Altimetry data assimilation experiment	A global ocean data assimilation system based on the ensemble optimum interpolation (EnOI) has been under development as the Chinese contribution to the Global Ocean Data Assimilation Experiment. The system uses a global ocean general circulation model, which is eddy permitting, developed by the Institute of Atmospheric Physics of the Chinese Academy of Sciences. In this paper, the implementation of the system is described in detail. We describe the sampling strategy to generate the stationary ensembles for EnOI. In addition, technical methods are introduced to deal with the requirement of massive memory space to hold the stationary ensembles of the global ocean. The system can assimilate observations such as satellite altimetry, sea surface temperature (SST), in situ temperature and salinity from Argo, XBT, Tropical Atmosphere Ocean (TAO), and other sources in a straightforward way. As a first step, an assimilation experiment from 1997 to 2001 is carried out by assimilating the sea level anomaly (SLA) data from TOPEX/Poseidon. We evaluate the performance of the system by comparing the results with various types of observations. We find that SLA assimilation shows very positive impact on the modeled fields. The SST and sea surface height fields are clearly improved in terms of both the standard deviation and the root mean square difference. In addition, the assimilation produces some improvements in regions where mesoscale processes cannot be resolved with the horizontal resolution of this model. Comparisons with TAO profiles in the Pacific show that the temperature and salinity fields have been improved to varying degrees in the upper ocean. The biases with respect to the independent TAO profiles are reduced with a maximum magnitude of about 0.25°C and 0.1 psu for the time-averaged temperature and salinity. The improvements on temperature and salinity also lead to positive impact on the subsurface currents. The equatorial under current is enhanced in the Pacific although it is still underestimated after the assimilation. © 2009 Springer-Verlag.
{fenge}
70349334318	ENSO ensemble prediction: Initial error perturbations vs. model error perturbations	Based on our developed ENSO (El Niño-Southern Oscillation) ensemble prediction system (EPS), the impacts of stochastic initial-error and model-error perturbations on ENSO ensemble predictions are examined and discussed by performing four sets of 14-a retrospective forecast experiments in both a deterministic and probabilistic sense. These forecast schemes are differentiated by whether they considered the initial or model stochastic perturbations. The comparison results suggest that the stochastic model-error perturbations, which are added into the modeled physical fields to mainly represent the uncertainties of the physical model, have significant, positive impacts on improving the ensemble prediction skills during the entire 12-month forecast process. However, the stochastic initial-error perturbations have relatively small impacts on the ensemble prediction system, and its impacts are mainly focusing on the first 3-month predictions. © 2009 Science in China Press and Springer-Verlag GmbH.
{fenge}
70849091205	Dust storm ensemble forecast experiments in East Asia	The ensemble Kalman filter (EnKF), as a unified approach to both data assimilation and ensemble forecasting problems, is used to investigate the performance of dust storm ensemble forecasting targeting a dust episode in the East Asia during 23-30 May 2007. The errors in the input wind field, dust emission intensity, and dry deposition velocity are among important model uncertainties and are considered in the model error perturbations. These model errors are not assumed to have zero-means. The model error means representing the model bias are estimated as part of the data assimilation process. Observations from a LIDAR network are assimilated to generate the initial ensembles and correct the model biases. The ensemble forecast skills are evaluated against the observations and a benchmark/control forecast, which is a simple model run without assimilation of any observations. Another ensemble forecast experiment is also performed without the model bias correction in order to examine the impact of the bias correction. Results show that the ensemble-mean, as deterministic forecasts have substantial improvement over the control forecasts and correctly captures the major dust arrival and cessation timing at each observation site. However, the forecast skill decreases as the forecast lead time increases. Bias correction further improved the forecasts in down wind areas. The forecasts within 24 hours are most improved and better than those without the bias correction. The examination of the ensemble forecast skills using the Brier scores and the relative operating characteristic curves and areas indicates that the ensemble forecasting system has useful forecast skills. © 2009 Chinese National Committee for International Association of Meteorology and Atmospheric Sciences, Institute of Atmospheric Physics, Science Press and Springer Berlin Heidelberg.
{fenge}
70849116482	Model bias correction for dust storm forecast using ensemble Kalman filter	First attempt to correct model bias in a dust transport model using ensemble Kalman filter (EnKF) assimilation targeting heavy dust episodes during the period of 15-24 March 2002 over north China is successfully performed. The uncertainty of dust emissions and surface wind fields are taken into account individually and simultaneously to correct their biases. The 24-h surface forecasts are significantly improved with the root mean square error reduced by more than 45% on 20 March and by 50% on 21 March after correcting the biases. The results indicate that there are high biases due to the dust emissions and surface wind fields. These biases converge to the values similar with those obtained in previous sensitivity analyses indicating that the EnKF can accurately correct the bias. The corrected total dust emissions are decreased more than 33%. However, when considered simultaneously, they do not converge to the same results as those considered individually. This indicates that the two biases can compensate for each other in terms of predicted surface dust concentration. Copyright 2008 by the American Geophysical Union.
{fenge}
70849120388	Ensemble hindcasts of ENSO events over the past 120 years using a large number of ensembles	Based on an intermediate coupled model (ICM), a probabilistic ensemble prediction system (EPS) has been developed. The ensemble Kalman filter (EnKF) data assimilation approach is used for generating the initial ensemble conditions, and a linear, first-order Markov-Chain SST anomaly error model is embedded into the EPS to provide model-error perturbations. In this study, we perform ENSO retrospective forecasts over the 120 year period 1886-2005 using the EPS with 100 ensemble members and with initial conditions obtained by only assimilating historic SST anomaly observations. By examining the retrospective ensemble forecasts and available observations, the verification results show that the skill of the ensemble mean of the EPS is greater than that of a single deterministic forecast using the same ICM, with a distinct improvement of both the correlation and root mean square (RMS) error between the ensemble-mean hindcast and the deterministic scheme over the 12-month prediction period. The RMS error of the ensemble mean is almost 0.2°C smaller than that of the deterministic forecast at a lead time of 12 months. The probabilistic skill of the EPS is also high with the predicted ensemble following the SST observations well, and the areas under the relative operating characteristic (ROC) curves for three different ENSO states (warm events, cold events, and neutral events) are all above 0.55 out to 12 months lead time. However, both deterministic and probabilistic prediction skills of the EPS show an interdecadal variation. For the deterministic skill, there is high skill in the late 19th century and in the middle-late 20th century (which includes some artificial skill due to the model training period), and low skill during the period from 1906 to 1961. For probabilistic skill, for the three different ENSO states, there is still a similar interdecadal variation of ENSO probabilistic predictability during the period 1886-2005. There is high skill in the late 19th century from 1886 to 1905, and a decline to a minimum of skill around 1910-50s, beyond which skill rebounds and increases with time until the 2000s. © 2009 Chinese National Committee for International Association of Meteorology and Atmospheric Sciences, Institute of Atmospheric Physics, Science Press and Springer-Verlag GmbH.
{fenge}
70849122711	A "dressed" Ensemble Kalman Filter using the Hybrid Coordinate Ocean Model in the Pacific	The computational cost required by the Ensemble Kalman Filter (EnKF) is much larger than that of some simpler assimilation schemes, such as Optimal Interpolation (OI) or three-dimension variational assimilation (3DVAR). Ensemble optimal interpolation (EnOI), a crudely simplified implementation of EnKF, is sometimes used as a substitute in some oceanic applications and requires much less computational time than EnKF. In this paper, to compromise between computational cost and dynamic covariance, we use the idea of "dressing" a small size dynamical ensemble with a larger number of static ensembles in order to form an approximate dynamic covariance. The term "dressing" means that a dynamical ensemble seed from model runs is perturbed by adding the anomalies of some static ensembles. This dressing EnKF (DrEnKF for short) scheme is tested in assimilation of real altimetry data in the Pacific using the HYbrid Coordinate Ocean Model (HYCOM) over a four-year period. Ten dynamical ensemble seeds are each dressed by 10 static ensemble members selected from a 100-member static ensemble. Results are compared to two EnKF assimilation runs that use 10 and 100 dynamical ensemble members. Both temperature and salinity fields from the DrEnKF and the EnKF are compared to observations from Argo floats and an OI SST dataset. The results show that the DrEnKF and the 100-member EnKF yield similar root mean square errors (RMSE) at every model level. Error covariance matrices from the DrEnKF and the 100-member EnKF are also compared and show good agreement. © 2009 Chinese National Committee for International Association of Meteorology and Atmospheric Sciences, Institute of Atmospheric Physics, Science Press and Springer Berlin Heidelberg.
{fenge}
0035003876	Design of new selective inhibitors of cyclooxygenase-2 by dynamic assembly of molecular building blocks	A method of dynamically assembling molecular building blocks - DycoBlock - has been proposed and tested by Liu et al. [1]. This method is based on multiple-copy stochastic dynamics simulation in the presence of a receptor molecule. In this method, a novel algorithm was used to dynamically assemble the molecular building blocks to form candidate compounds. Currently, some new improvements have been incorporated into DycoBlock to make it more efficient. In the new version of DycoBlock, the binding energy and solvent accessible surface area (SASA) can be used to screen the resulting compounds. A simple clustering algorithm based on molecular similarity was developed and used to classify the remaining compounds. The revised DycoBlock was tested by breaking SC-558 - a selective inhibitor of cyclooxygenase-2 (COX-2) - into building blocks and reassembling them in the active site of the enzyme. The accuracy of recovery grew to 58.8% while it was only 16.7% in the previous version. Then, thirty-three kinds of molecular building blocks were used in the design of novel inhibitors and the investigation of diversity. As a result, a total of 1441 compounds was generated with high diversity. After the first screening procedure, there remained 864 reasonable compounds. The results from clustering indicate that the structural motifs in the diarylheterocycle class of COX-2-selective inhibitors [2] have been generated using the revised DycoBlock, and their binding modes were investigated.
{fenge}
0035231780	Genescan analysis of the loss of heterozygosity on the long arm of chromosome 6 in non-small cell lung cancer	To investigate if there are microsatellite loci in the long arm of chromosome 6 that have close relationship with non-small cell lung cancer, Multiple PCR approach was used to analyze the 36 loci in the long arm of chromosome 6. The PCR products were analyzed in PAGE and then the electrophoresis maps were analyzed with Genescan™ and Genotyper™. There is different LOH frequency in different loci. The total frequency of LOH in 41 lung cancers was 78% (32/41) , with the highest frequency of LOH was detected on the locus 065502(75%). There are 14 loci which have LOH frequency more than 20% and the loci are mainly located in 2 regions: 6q16.3 - q21 [6 loci D6S458 (21. 43%), D6S1694 (26. 92%), D6S1717 (35. 71%) , D6S1565 (40%), D6S302 (75%), D6S1706 (36. 36%) and 6q26 - q27 (5 loci D6S1550 (38. 46%.), D6S264 (20%) , D6S1585(25%) , D6S446(33.33%) , D6S281 (30.77%)] , There may be tumor suppressor genes located in the two regions, which have a close relationship with non-small cell lung cancer.
{fenge}
71549123991	How Do Variable Substitution Rates Influence Ka and Ks Calculations?	The ratio of nonsynonymous substitution rate (Ka) to synonymous substitution rate (Ks) is widely used as an indicator of selective pressure at sequence level among different species, and diverse mutation models have been incorporated into several computing methods. We have previously developed a new γ-MYN method by capturing a key dynamic evolution trait of DNA nucleotide sequences, in consideration of varying mutation rates across sites. We now report a further improvement of NG, LWL, MLWL, LPB, MLPB, and YN methods based on an introduction of gamma distribution to illustrate the variation of raw mutation rate over sites. The novelty comes in two ways: (1) we incorporate an optimal gamma distribution shape parameter a into γ-NG, γ-LWL, γ-MLWL, γ-LPB, γ-MLPB, and γ-YN methods; (2) we investigate how variable substitution rates affect the methods that adopt different models as well as the interplay among four evolutional features with respect to Ka/Ks computations. Our results suggest that variable substitution rates over sites under negative selection exhibit an opposite effect on ω estimates compared with those under positive selection. We believe that the sensitivity of our new methods has been improved than that of their original methods under diverse conditions and it is advantageous to introduce novel parameters for Ka/Ks computation. © 2009 Beijing Genomics Institute.
{fenge}
7244247241	Roles of vertical correlations of background error and T-S relations in estimation of temperature and salinity profiles from sea surface dynamic height	A data assimilation scheme based on three-dimensional variational analysis (3DVAR) is proposed to estimate temperature and salinity profiles from surface dynamic height information. The scheme takes into consideration vertical correlations for both temperature and salinity background errors and the nonlinear temperature-salinity (T-S) relation. In this study we designed some one-dimensional test cases to examine the separate and combined impacts of the vertical correlations and the nonlinear T-S relation on estimations of temperature and salinity profiles in comparison with a simplified scheme that considers neither vertical correlations nor T-S relations. Results show that the simplified scheme cannot simultaneously improve temperature and salinity profiles over their backgrounds in some cases and could make the correction seriously nonsmooth at different depths. The consideration of vertical correlations helps to balance the magnitude of the profile correction among all depths and produce smoother results. However, consideration of vertical correlations cannot help much in reducing the root-mean square error of estimation. The consideration of the nonlinear T-S relation can improve both temperature and salinity estimations in all test cases and can significantly reduce the root-mean square error of estimations. The combined effects of both vertical correlations and the nonlinear T-S relation are similar to those of the latter but with vertically smoother results. Copyright 2004 by the American Geophysical Union.
{fenge}
76549102867	ChIP-seq data plays an important role in a cytosine-based DNA methylation prediction model	DNA methylation was found previously related with histone modifications. The relationship among DNA methylation and histone modifications is potentially identifiable by integrating ChIP-seq and methylation data. However, little has been addressed on this issue in literature. Predicting DNA methylation can largely avoid the high cost of bisulfite-converted DNA experiments and drawbacks of microarray-based approaches. The most important, biological studies can be designed in a more economical manner. In this study, we found the DNA methylation was strongly influenced by surrounding combinatorial enriched ChIP-seq derived features in genome-wide scale. As an application, a cytosine-based methylation prediction model is proposed to predict the methylation status. As a result, we found Lymph-specific genes were distinct from other kinds of genes around Transcription Start Sites, which confirmed that our model is tissue-specific. © 2009 IEEE.
{fenge}
75549084321	HHMD: The human histone modification database	Histone modifications play important roles in chromatin remodeling, gene transcriptional regulation, stem cell maintenance and differentiation. Alterations in histone modifications may be linked to human diseases especially cancer. Histone modifications including methylation, acetylation and ubiquitylation probed by ChIP-seq, ChIP-chip and qChIP have become widely available. Mining and integration of histone modification data can be beneficial to novel biological discoveries. There has been no comprehensive data repository that is exclusive for human histone modifications. Therefore, we developed a relatively comprehensive database for human histone modifications. Human Histone Modification Database (HHMD, http://bioinfo.hrbmu.edu.cn/hhmd) focuses on the storage and integration of histone modification datasets that were obtained from laboratory experiments. The latest release of HHMD incorporates 43 location-specific histone modifications in human. To facilitate data extraction, flexible search options are built in HHMD. It can be searched by histone modification, gene ID, functional categories, chromosome location and cancer name. HHMD also includes a user-friendly visualization tool named HisModView, by which genome-wide histone modification map can be shown. HisModView facilitates the acquisition and visualization of histone modifications. The database also has manually curated information of histone modification dysregulation in nine human cancers. © The Author(s) 2009. Published by Oxford University Press.
{fenge}
77649336015	Backbone Model of an Aquareovirus Virion by Cryo-Electron Microscopy and Bioinformatics	Grass carp reovirus (GCRV) is a member of the aquareovirus genus in the Reoviridae family and has a capsid with two shells-a transcription-competent core surrounded by a coat. We report a near-atomic-resolution reconstruction of the GCRV virion by cryo-electron microscopy and single-particle reconstruction. A backbone model of the GCRV virion, including seven conformers of the five capsid proteins making up the 1500 molecules in both the core and the coat, was derived using cryo-electron microscopy density-map-constrained homology modeling and refinement. Our structure clearly showed that the amino-terminal segment of core protein VP3B forms an ∼ 120-Å-long α-helix-rich extension bridging across the icosahedral 2-fold-symmetry-related molecular interface. The presence of this unique structure across this interface and the lack of an external cementing molecule at this location in GCRV suggest a stabilizing role of this extended amino-terminal density. Moreover, part of this amino-terminal extension becomes invisible in the reconstruction of transcription-competent core particles, suggesting its involvement in endogenous viral RNA transcription. Our structure of the VP1 turret represents its open state, and comparison with its related structures at the closed state suggests hinge-like domain movements associated with the mRNA-capping machinery. Overall, this first backbone model of an aquareovirus virion provides a wealth of structural information for understanding the structural basis of GCRV assembly and transcription. © 2009.
{fenge}
77649336168	Building and Refining Protein Models within Cryo-electron Microscopy Density Maps Based on Homology Modeling and Multiscale Structure Refinement	Automatic modeling methods using cryoelectron microscopy (cryoEM) density maps as constraints are promising approaches to building atomic models of individual proteins or protein domains. However, their application to large macromolecular assemblies has not been possible largely due to computational limitations inherent to such unsupervised methods. Here we describe a new method, EM-IMO (electron microscopy-iterative modular optimization), for building, modifying and refining local structures of protein models using cryoEM maps as a constraint. As a supervised refinement method, EM-IMO allows users to specify parameters derived from inspections so as to guide, and as a consequence, significantly speed up the refinement. An EM-IMO-based refinement protocol is first benchmarked on a data set of 50 homology models using simulated density maps. A multiscale refinement strategy that combines EM-IMO-based and molecular dynamics-based refinement is then applied to build backbone models for the seven conformers of the five capsid proteins in our near-atomic-resolution cryoEM map of the grass carp reovirus virion, a member of the Aquareovirus genus of the Reoviridae family. The refined models allow us to reconstruct a backbone model of the entire grass carp reovirus capsid and provide valuable functional insights that are described in the accompanying publication [Cheng, L., Zhu, J., Hui, W. H., Zhang, X., Honig, B., Fang, Q. & Zhou, Z. H. (2010). Backbone model of an aquareovirus virion by cryo-electron microscopy and bioinformatics. J. Mol. Biol. (this issue). doi:10.1016/j.jmb.2009.12.027.]. Our study demonstrates that the integrated use of homology modeling and a multiscale refinement protocol that combines supervised and automated structure refinement offers a practical strategy for building atomic models based on medium- to high-resolution cryoEM density maps. © 2010 Elsevier Ltd. All rights reserved.
{fenge}
77950615319	Deducing causal relationships among different histone modifications, DNA methylation and gene expression	Histone modifications and DNA methylation are two major epigenetic factors regulating gene expression. However, the mechanism in which DNA methylation and histone modifications co-regulate gene expression was little studied. In our study, classifications of DNA methylaion and gene expression showed the complicated relationship between gene expression and epigenetic factors. A Bayesian network was constructed by using the high-resolution maps of histone modifications, DNA methylation and gene expression in human CD4+ T cells to deduce causal and combinatorial relationships among them. PolII was found as the only direct regulator to gene expression, which was not found in prior studies. Our Bayesian network showed that epigenetic factors such as H3K4me3, H3K27me3 and DNA methylation are key regulators of gene expression, though indirectly. However they were considered to combinatorially stablize the state and structure of chromatin. © 2009 IEEE.
{fenge}
77951682635	KaKs_Calculator 2.0: A Toolkit Incorporating Gamma-Series Methods and Sliding Window Strategies	We present an integrated stand-alone software package named KaKs_Calculator 2.0 as an updated version. It incorporates 17 methods for the calculation of nonsynonymous and synonymous substitution rates; among them, we added our modified versions of several widely used methods as the gamma series including γ-NG, γ-LWL, γ-MLWL, γ-LPB, γ-MLPB, γ-YN and γ-MYN, which have been demonstrated to perform better under certain conditions than their original forms and are not implemented in the previous version. The package is readily used for the identification of positively selected sites based on a sliding window across the sequences of interests in 5' to 3' direction of protein-coding sequences, and have improved the overall performance on sequence analysis for evolution studies. A toolbox, including C++ and Java source code and executable files on both Windows and Linux platforms together with a user instruction, is downloadable from the website for academic purpose at https://sourceforge.net/projects/kakscalculator2/. © 2010 Beijing Genomics Institute.
{fenge}
77953494549	Assimilating altimetry data into a HYCOM model of the Pacific: Ensemble optimal interpolation versus ensemble Kalman filter	The ensemble Kalman filter (EnKF) has proven its efficiency in strongly nonlinear dynamical systems but is demanding in its computing power requirements, which are typically about the same as those of the fourdimensional variational data assimilation (4DVAR) systems presently used in several weather forecasting centers. A simplified version of EnKF, the so-called ensemble optimal interpolation (EnOI), requires only a small fraction of the computing cost of the EnKF, but makes the crude assumption of no dynamical evolution of the errors. How do both these two methods compare in realistic settings of a Pacific Ocean forecasting system where the computational cost is a primary concern? In this paper the two methods are used to assimilate real altimetry data via a Hybrid Coordinate Ocean Model of the Pacific. The results are validated against the independent Argo temperature and salinity profiles and show that the EnKF has the advantage in terms of both temperature and salinity and in all parts of the domain, although not with a very striking difference. © 2010 American Meteorological Society.
{fenge}
77953579321	Assessment of fluorescence resonance energy transfer for two-color DNA microarray platforms	Two-color DNA microarray platforms are widely used for determining differential amounts of target sequences in parallel between sample pairs. However, the fluorescence (or Förster) resonance energy transfer (FRET) between two fluorophores can potentially result in the distortions of the measured fluorescence signals. Here we assessed the influence of FRET on the two-color DNA microarray platform and developed a reliable and convenient method for the correction of FRET distortion. Compared to current methods of normalization based on the statistical analysis and the hypothesis that only a small part of target sequences are differentially presented between sample pairs, our FRET correction method can recover the undistorted signals by the compensation of fluorescence emission, without considering the number of target sequences differentially presented. The correction method was validated with samples at different target ratios and with microarrays spotted in different probe concentrations. We also applied the FRET correction method to gene expression profiling arrays, and the results show that FRET was present when the content of target sequence was beyond a threshold amount and that the process incorporating our FRET correction method can improve the reliability of the gene expression profiling microarray platform in comparison with the current process without FRET correction. © 2010 American Chemical Society.
{fenge}
77952941839	Hybridization of long pyridine-dicarboxamide oligomers into multi-turn double helices: Slow strand association and dissociation, solvent dependence, and solid state structures	Oligoamides of 2,6-diamino- pyridine and 2,6-pyridinediearboxylie aeid eomprised of 5, 7, 9, 11, or 13 units and bearing 4-isobutoxyehains on all pyridine rings and tert-butyl-earba- mate terminal groups have been synthesized stepwise, along with an 11 mer having benzyl-earbamate terminal groups. The erystal strueture of all five Boe-terminated eompounds has been obtained and shows a highly regular and eonserved double helieal hybridization motif of up to 3 eomplete turns for the 13 mer. Four pyridine units span one helieal turn and define a helix piteh of ca 7 Å. Solution studies in CDCl
{fenge}
77952957150	Ensemble optimal interpolation schemes for assimilating Argo profiles into a hybrid coordinate ocean model	To develop a capable ensemble-based scheme for operationally assimilating Argo profile observations into a hybrid coordinate ocean model (HYCOM), we compared some different ensemble optimal interpolation (EnOI) schemes, which can be divided into two different kinds. The first kind is straightforward, i.e., updating the model variables (i.e., layer thickness, layer velocity and layer temperature/salinity) at the same time from the temperature and salinity profiles observed from Argo floats. In the second kind of schemes (will be referred as the modified schemes), which are based on Thacker and Esenkov (2002), the Argo profiles are first converted to the " observations" of layer thicknesses and they are assimilated to adjust the model layer thickness and model velocity fields. Then the T (or S) profiles are assimilated to adjust the model layer temperatures (or salinities), followed by deriving the model layer salinity (or temperature) from the equation of seawater state.In this study we showed that the two kinds of EnOI schemes can be implemented in various setups. Firstly for the straightforward schemes an analysis can be done using the thinned (to model layers) observations of Argo profiles or using the full vertical information provided by the Argo profiles. Secondly one can make an analysis applying or not applying localization vertically. Thirdly for the modified schemes either the temperature or the salinity field can be diagnosed. Then we designed six assimilation experiments, each is attached to a different setup in order to test and compare their performances. In all experiments, Argo profiles were assimilated into HYCOM in the Pacific for a four-year period (January, 2004-December, 2007). A large amount of Argo profiles were withheld to validate the assimilation results. The results show the significant improvement by the modified schemes over the straightforward schemes. The best setup of the modified scheme is to diagnose the temperature and to apply the vertical localization at the step of assimilating the layer temperatures. © 2010 Elsevier Ltd.
{fenge}
77955681592	Detection and application of microfluidic isothermal amplification on chip	Loop-mediated isothermal amplification (LAMP) is a novel nucleic acid amplification method. Compared with the widely utilized polymerase chain reaction (PCR), LAMP has higher speed and efficiency as well as lower requirement for system temperature control because the whole amplification process is isothermal and no efforts are needed to switch between different temperatures. In this paper, we designed and fabricated different kinds of polycarbonate (PC) microfluid chips, explored appropriate reaction condition for LAMP in microenvironment (1 nL → 10 μL), and developed a microfluidic isothermal amplification detection system. The DNA optimal amplification temperature is obtained; the starting time of exponential amplification of DNA is put forward farther. The optimal condition of DNA amplification in microenvironment, with a little reaction materials and early starting exponential amplification time of DNA are very important for clinic DNA detection and the application of Lab-on-a-Chip. © 2008 World Scientific Publishing Company.
{fenge}
77955519678	A model-based observation-thinning scheme for the assimilation of high-resolution SST in the shelf and coastal seas around China	The use of high-density remote sensing buoys and ship-based observations play an increasingly crucial role in the operational assimilation and forecast of oceans. With the recent release of several high-resolution observation datasets, such as the Global Ocean Data Assimilation Experiment (GODAE) high-resolution SST (GHRSST) datasets, the development of observation-thinning schemes becomes important in the process of data assimilation because the huge quantity and dense spatial-temporal distributions of these datasets might make it expensive to assimilate the full dataset into ocean models or even decay the assimilation result. In this paper, an objective model simulation ensemble-based observation-thinning scheme is proposed and applied to a Chinese shelf-coastal seas eddy-resolving model. A successful thinning scheme should select a subset of observations yielding a small analysis error variance (AEV) while keeping the number of observations to as few as possible. In this study, the background error covariance (BEC) is estimated using the historical ensemble and then the subset of observations to minimize the AEV is selected, which is estimated from the Kalman theory. The authors used this method in the GHRSST product to cover the shelf and coastal seas around China and then verified the result with an estimation function and assimilation-forecast systems. © 2010 American Meteorological Society.
{fenge}
77956336624	A novel role for minimal introns: Routing mRNAs to the Cytosol	Background: Introns and their splicing are tightly coupled with the subsequent mRNA maturation steps, especially nucleocytoplasmic export. A remarkable fraction of vertebrate introns have a minimal size of about 100 bp, while majority of introns expand to several kilobases even megabases in length. Principal Findings: We carried out analyses on the evolution and function of minimal introns (50-150 bp) in human and mouse genomes. We found that minimal introns are conserved in terms of both length and sequence. They are preferentially located toward 3' end of mRNA and non-randomly distributed among chromosomes. Both the evolutionary conservation and non-random distribution are indicative of biological relevance. We showed that genes with minimal introns have higher abundance, larger size, and tend to be universally expressed as compared to genes with only large introns and intron-less genes. Genes with minimal introns replicate earlier and preferentially reside in the vicinities of open chromatin, suggesting their unique nuclear position and potential relevance to the regulation of gene expression and transcript export. Conclusions: Based on these observations, we proposed a nuclear-export routing model, where minimal introns play a regulatory role in selectively exporting the highly abundant and large housekeeping genes that reside at the surface of chromatin territories, and thus preventing entanglement with other genes located at the interior locations. © 2010 Zhu et al.
{fenge}
77956795020	Impacts of typhoon on wave height at Bangkhuntien shoreline	Problem statement: In this study, the changing of wave height at Bangkhuntien during a passage of typhoon LINDA was simulated by using the Simulating WAves Nearshore Model (SWAN) version 40.41. The study domain covered from 99-101°E longitude and 12-14°N in latitude with resolution of 2.4×2.4 km. The simulation covered 10 days during typhoon LINDA entering into the Upper Gulf of Thailand. The wave height and its changing through the Bangkhuntien shoreline were simulated. The simulated significant wave height by the SWAN model at Petchburi and Ko Srichang buoy stations were compared with the observed significant wave height at these stations for the model verification. Approach: The significant wave height at Bangkhuntien shoreline during a passage of typhoon LINDA was simulated. Results: The results indicated that the significant wave height simulated by SWAN model were in good agreement with the observed data. The average simulated significant wave height at Bangkhuntien shoreline was 0.36 m and the significant wave height was in a range of 0.1-0.5 m. before typhoon LINDA entering into the Upper Gulf of Thailand. The significant wave height increased to 2.16, 2.22 and 1.66 m at 26, 18 and 5.7 m sea water depth respectively at the Bangkhuntien shoreline during typhoon LINDA passed. Conclusion: The findings of this study could be useful for the rising wave height, erosive calculation, shoreline protection and coastal zone management when typhoons passed through the Upper Gulf of Thailand. © 2010 Science Publications.
{fenge}
77958090344	Coupled assimilation for an intermediated coupled ENSO prediction model	The value of coupled assimilation is discussed using an intermediate coupled model in which the wind stress is the only atmospheric state which is slavery to model sea surface temperature (SST). In the coupled assimilation analysis, based on the coupled wind-ocean state covariance calculated from the coupled state ensemble, the ocean state is adjusted by assimilating wind data using the ensemble Kalman filter. As revealed by a series of assimilation experiments using simulated observations, the coupled assimilation of wind observations yields better results than the assimilation of SST observations. Specifically, the coupled assimilation of wind observations can help to improve the accuracy of the surface and subsurface currents because the correlation between the wind and ocean currents is stronger than that between SST and ocean currents in the equatorial Pacific. Thus, the coupled assimilation of wind data can decrease the initial condition errors in the surface/subsurface currents that can significantly contribute to SST forecast errors. The value of the coupled assimilation of wind observations is further demonstrated by comparing the prediction skills of three 12-year (1997-2008) hindcast experiments initialized by the ocean-only assimilation scheme that assimilates SST observations, the coupled assimilation scheme that assimilates wind observations, and a nudging scheme that nudges the observed wind stress data, respectively. The prediction skills of two assimilation schemes are significantly better than those of the nudging scheme. The prediction skills of assimilating wind observations are better than assimilating SST observations. Assimilating wind observations for the 2007/2008 La Niña event triggers better predictions, while assimilating SST observations fails to provide an early warning for that event. © 2010 Springer-Verlag.
{fenge}
77957786479	Crystal structure of group II chaperonin in the open state	Thermosomes are group II chaperonins responsible for protein refolding in an ATP-dependent manner. Little is known regarding the conformational changes of thermosomes during their functional cycle due to a lack of high-resolution structure in the open state. Here, we report the first complete crystal structure of thermosome (rATcpnβ) in the open state from Acidianus tengchongensis. There is a ∼30° rotation of the apical and lid domains compared with the previous closed structure. Besides, the structure reveals a conspicuous hydrophobic patch in the lid domain, and residues locating in this patch are conserved across species. Both the closed and open forms of rATcpnβ were also reconstructed by electron microscopy (EM). Structural fitting revealed the detailed conformational change from the open to the closed state. Structural comparison as well as protease K digestion indicated only ATP binding without hydrolysis does not induce chamber closure of thermosome. © 2010 Elsevier Ltd.
{fenge}
78649956430	Discovering cooperative relationships of chromatin modifications in human T cells based on a proposed closeness measure	Background: Eukaryotic transcription is accompanied by combinatorial chromatin modifications that serve as functional epigenetic markers. Composition of chromatin modifications specifies histone codes that regulate the associated gene. Discovering novel chromatin regulatory relationships are of general interest. Methodology/Principal Findings: Based on the premise that the interaction of chromatin modifications is hypothesized to influence CpG methylation, we present a closeness measure to characterize the regulatory interactions of epigenomic features. The closeness measure is applied to genome-wide CpG methylation and histone modification datasets in human CD4+T cells to select a subset of potential features. To uncover epigenomic and genomic patterns, CpG loci are clustered into nine modules associated with distinct chromatin and genomic signatures based on terms of biological function. We then performed Bayesian network inference to uncover inherent regulatory relationships from the feature selected closeness measure profile and all nine module-specific profiles respectively. The global and module-specific network exhibits topological proximity and modularity. We found that the regulatory patterns of chromatin modifications differ significantly across modules and that distinct patterns are related to specific transcriptional levels and biological function. DNA methylation and genomic features are found to have little regulatory function. The regulatory relationships were partly validated by literature reviews. We also used partial correlation analysis in other cells to verify novel regulatory relationships. Conclusions/Significance: The interactions among chromatin modifications and genomic elements characterized by a closeness measure help elucidate cooperative patterns of chromatin modification in transcriptional regulation and help decipher complex histone codes. © 2010 Lv et al.
{fenge}
78650076613	Quantitative proteomics discloses MET expression in mitochondria as a direct target of MET kinase inhibitor in cancer cells	Cancer cells with MET overexpression are paradoxically more sensitive to MET inhibition than cells with baseline MET expression. The underlying molecular mechanisms are incompletely understood. Here, we have traced early responses of SNU5, a MET-overexpressing gastric cancer cell line, exposed to sublethal concentration of PHA-665752, a selective MET inhibitor, using iTRAQ-based quantitative proteomics. More than 1900 proteins were quantified, of which >800 proteins were quantified with at least five peptides. Proteins whose expression was perturbed by PHA-665752 included oxidoreductases, transfer/carrier proteins, and signaling proteins. Strikingly, 38% of proteins whose expression was confidently assessed to be perturbed by MET inhibition were mitochondrial proteins. Upon MET inhibition by a sublethal concentration of PHA-665752, mitochondrial membrane potential increased and mitochondrial permeability transition pore was inhibited concomitant with widespread changes in mitochondrial protein expression. We also showed the presence of highly activated MET in mitochondria, and striking suppression of MET activation by 50 nM PHA-665752. Taken together, our data indicate that mitochondria are a direct target of MET kinase inhibition, in addition to plasma membrane MET. Effects on activated MET in the mitochondria of cancer cells that are sensitive to MET inhibition might constitute a novel and critical noncanonical mechanism for the efficacy of MET-targeted therapeutics. © 2010 by The American Society for Biochemistry and Molecular Biology, Inc.
{fenge}
78650400672	Berberine inhibits angiogenic potential of Hep G2 cell line through VEGF down-regulation in vitro	Background and Aim: Berberine, an herbal alkaloid, has been reported to have promotion potential of apoptosis and anticancer effect on a variety of human tumor cells. To obtain more specific understanding of those consequences of berberine on hepatocellular carcinoma (HCC) and the tumor microenvironment, we conducted in vitro experiments to investigate the inhibitory effect of berberine on tumor-induced angiogenesis using HCC cells and human umbilical vein endothelial cells (HUVECs).Methods: Human umbilical vein endothelial cell growth was quantified with the CCK-8 cell proliferation assay; cell migration was observed with a Boyden chamber (Transwell, Corning, Lowell, MA, USA), and angiogenesis was assessed by endothelial tube formation in Matrigel in vitro. In addition, VEGF level was determined by ELISA and VEGF mRNA expression by RT-PCR.Results: Berberine inhibited the capacity of HCC to stimulate HUVEC's proliferation, migration and endothelial tube formation, suggesting that berberine could influence the cross-talk between the HCC cell and vascular endothelial cells. These results demonstrate berberine's antiangiogenesis property and its clinical potential as an inhibitor of tumor angiogenesis. Subsequently analyses reveal that berberine prevents secretion of VEGF from HCC and down-regulates VEGF mRNA expression.Conclusion: These findings strongly suggest that berberine is a potential antiangiogenic agent and a promising antitumor drug for HCC. © 2010 Journal of Gastroenterology and Hepatology Foundation and Blackwell Publishing Asia Pty Ltd.
{fenge}
78650685287	An optimizing finite difference scheme based on proper orthogonal decomposition for CVD equations	In this article, an optimizing reduced finite difference scheme (FDS) based on singular value decomposition (SVD) and proper orthogonal decomposition (POD) for the chemical vapor deposit (CVD) equations is presented. And the error estimates between the usual finite difference solution and the reduced POD solution of optimizing FDS are derived. At last, some examples of numerical simulation are given to demonstrate the consistency of the numerical and theoretical results. It is shown that the optimizing reduced FDS based on POD method is of great feasibility and efficiency. © 2009 John Wiley & Sons, Ltd.
{fenge}
79951670343	The 4-D structure of upwelling and Pearl River plume in the northern South China Sea during summer 2008 revealed by a data assimilation model	We analyze four-dimensional structures of upwelling and Pearl River plume in the northern South China Sea (NSCS) during the summer of 2008 based on data assimilation. An Ensemble Kalman Smoother scheme is employed in the Princeton Ocean Model. It is found that the Pearl River plume axis extended eastward along with the surface current and swerved offshore twice near (116°E, 22.6°N) and (117.5°E, 22.8°N) before reaching the Taiwan Strait. The vertical transect of salinity along the plume axis indicates that the Pearl River freshwater could affect salinity distribution down to a depth of 10-20. m. Anomalously warm water is found in the upper layer, which could be attributed to the intensified stratification and suppressed vertical mixing caused by the freshwater of the plume capping the upwelling west of 116°E. The varying winds from upwelling favorable to downwelling favorable could induce a low-salinity water lens at the center of the model domain. Upwelling in the NSCS initially occurred at 114.5°E, to the east of the Pearl River Estuary, intensified eastward, and reached its maximum near Shantou (116.7°E, 23.2°N). Since current-induced upwelling appeared mainly in Shantou due to the widened shelf, it is found that even if the wind-induced upwelling was shut down in Shanwei by downwelling favorable wind on July 4, the upwelling still existed in Shantou. Moreover, because the direction of large-scale current was in favor of upwelling in the NSCS that cannot be reversed by varying local winds over a short time period, the upwelling shutdown time is longer for both wind-induced and current-induced upwelling in Shantou than for mainly wind-induced upwelling in Shanwei. The steeper slope in Shanwei also shortens the upwelling shutdown time there. © 2011 Elsevier Ltd.
{fenge}
79751494767	A new localization implementation scheme for ensemble data assimilation of non-local observations	Localization technique is commonly used in ensemble data assimilation of small-size ensemble members. It effectively eliminates the spurious correlations of the background and increases the rank of the system. However, one disadvantage in current localization schemes is that it is difficult to implement the assimilation of non-local observations. In this paper, we test a new localized implementation scheme that can directly assimilate non-local observations without pinpointing them. A classical local support correlation function matrix is first sampled by a set of local correlation function ensemble members (the size is M). Then, the dynamical ensemble (the size is N) is combined with the local correlation function ensemble to form an N×M ensemble by multiplying each dynamical member with each local correlation function member using the Schur product. The covariance matrix constructed by the N×M members is proved to approximate the Schur product of the local support correlation matrix and the dynamical covariance matrix. This scheme is verified through assimilating both local and non-local observations with a linear advection model and an intermediate coupled model. The analysis results show that this scheme is feasible and effective in providing reasonable and high-quality analysis fields with a relatively small dynamical ensemble size. © 2010 The Authors Tellus A©2010 International Meteorological Institute in Stockholm.
{fenge}
79953779991	Label-free detection of protein microarray with high throughput surface plasmon resonance imaging (SPRI)	A surface plasmon resonance imaging (SPRI) system was developed for the discrimination of proteins on a gold surface. As a label-free and high-throughput technique, SPRI enables simultaneously monitoring of the biomolecular interactions at low concentrations. We used SPRI as a label-free and parallel method to detect different proteins based on protein microarray. Bovine Serum Albumin (BSA), Casein and Immunoglobulin G (IgG) were immobilized onto the Au surface of a gold-coated glass chip as spots forming a 6 × 6 matrix. These proteins can be discriminated directly by changing the incident angle of light. Excellent reproducibility for label-free detection of protein molecules was achieved. This SPRI platform represents a simple and robust method for performing high-sensitivity detection of protein microarray. © 2008 World Scientific Publising Company.
{fenge}
79953192225	A new method to estimate the systematical biases of expendable bathythermograph	A new technique to estimate three major biases of XBT probes (improper fall rate, start-up transient, and pure temperature error) has been developed. Different from the well-known and standard "temperature error free" differential method, the new method analyses temperature profiles instead of vertical gradient temperature profiles. Consequently, it seems to be more noise resistant because it uses the integral property over the entire vertical profile instead of gradients. Its validity and robustness have been checked in two ways. In the first case, the new integral technique and the standard differential method have been applied to a set of simulated XBT profiles having a known fall-rate equation to which various combinations of pure temperature errors, random errors, and spikes have been added for the sake of this simulation. Results indicated that the single pure temperature error has little impact on the fall-rate coefficients for both methods, whereas with the added random error and spikes the simulation leads to better results with the new integral technique than with the standard differential method. In the second case, two sets of profiles from actual XBT versus CTD comparisons, collected near Barbados in 1990 and in the western Mediterranean (2003-04 and 2008-09), have been used. The individual fall-rate coefficients and start-up transient for each XBT profile, along with the overall pure temperature correction, have been calculated for the XBT profiles. To standardize procedures and to improve the terms of comparison, the individual start-up transient estimated by the integral method was also assigned and included in calculations with the differential method. The new integral method significantly reduces both the temperature difference between XBT and CTD profiles and the standard deviation. Finally, the validity of the mean fall-rate coefficients and the mean start-up transient, respectively, for DB and T7 probes as precalculated equations was verified. In this case, the temperature difference is reduced to less than 0.1
{fenge}
79955894722	A phenomenological model for decay process of long-persistent phosphorescence	A sum of two or more exponential decay functions is empirically adopted nowadays to analyze the decay curve of long-persistent phosphor. However, the fitting parameters of this empirical model lack well-defined physical meanings, especially when the number of exponential decay function is greater than two. We propose a phenomenological model to describe the decay curve of long-persistent phosphor based on an analysis of the relationship between carrier concentration and light-emitting intensity. This model has a few fitting parameters with well-defined physical meanings as compared to the current empirical one. With this model, we quantitatively analyze the decay processes of typical long-persistent phosphors of SrAl
{fenge}
79956006215	QDMR: A quantitative method for identification of differentially methylated regions by entropy	DNA methylation plays critical roles in transcriptional regulation and chromatin remodeling. Differentially methylated regions (DMRs) have important implications for development, aging and diseases. Therefore, genome-wide mapping of DMRs across various temporal and spatial methylomes is important in revealing the impact of epigenetic modifications on heritable phenotypic variation. We present a quantitative approach, quantitative differentially methylated regions (QDMRs), to quantify methylation difference and identify DMRs from genome-wide methylation profiles by adapting Shannon entropy. QDMR was applied to synthetic methylation patterns and methylation profiles detected by methylated DNA immunoprecipitation microarray (MeDIP-chip) in human tissues/cells. This approach can give a reasonable quantitative measure of methylation difference across multiple samples. Then DMR threshold was determined from methylation probability model. Using this threshold, QDMR identified 10651 tissue DMRs which are related to the genes enriched for cell differentiation, including 4740 DMRs not identified by the method developed by Rakyan et al. QDMR can also measure the sample specificity of each DMR. Finally, the application to methylation profiles detected by reduced representation bisulphite sequencing (RRBS) in mouse showed the platform-free and species-free nature of QDMR. This approach provides an effective tool for the high-throughput identification of potential functional regions involved in epigenetic regulation. © 2011 The Author(s).
{fenge}
0036175957	Genescan analysis of non-small cell lung cancer in the long arm of chromosome 6	Objective: To investigate if there are microsatellite loci in the long arm of chromosome 6 that have close relationship with non-small cell lung cancer. Methods Multiple PCR approach was used to analyze the 18 loci in the long arm of chromosome 6. The PCR products were analyzed in PAGE, and then the electrophoresis maps were analyzed with Gene Scan™ and Genotyper™. Results There were different frequencies of logs of heterozygosity (LOH) in different loci (varying from 3. 85% to 38. 45%). The total frequency of LOH in 41 gastric cancers was 58.5% (24/41). Eight loci with the LOH frequency higher than 20% were mainly located in 2 regions: 6q24 and 6q27. The accurate location is 6q24-6q25. 3 [D6S1699(35%), D6S409(23.33%), D6S441(33.33%)] and 6q26-27 [D6S1550(38.45%), D6S264 (20%), D6S1585(25%), D6S446(33.33%), D6S281 (30.77%)]. Conclusion There may be tumor suppressor genes located in the region of 6q24 and 6q27, which have close relationship with non-small cell lung cancer.
{fenge}
0035731507	Structure-based ligand design for flexible proteins: Application of new F-DycoBlock	A method of structure-based ligand design - DycoBlock - has been proposed and tested by Liu et al.[1]. It was further improved by Zhu et al. and applied to design new selective inhibitors of cyclooxygenase 2 [2]. In the current work, we present a new methodology - F-DycoBlock that allows for the incorporation of receptor flexibility. During the designing procedure, both the receptor and molecular building blocks are subjected to the multiple-copy stochastic molecular dynamics (MCSMD) simulation [1], while the protein moves in the mean field of all copies. It is tested for two enzymes studied previously - cyclooxygenase 2 (COX-2) and human immunodeficiency type 1 (HIV-1) protease. To identify the applicability of F-DycoBlock, the binding protein structure was used as starting point to explore the conformational space around the bound state. This method can be easily extended to accommodate the flexibility in different degree. Four types of treatment of the receptor flexibility - all-atom restrained, backbone restrained, intramolecular hydrogen-bond restrained and active-site flexible - were tested with or without the grid approximation. Two inhibitors, SC-558 for COX-2 and L700417 for HIV-1 protease, are used in this testing study for comparison with previous results. The accuracy of recovery, binding energy, solvent accessible surface area (SASA) and positional root-mean-square (RMS) deviation are used as criteria. The results indicate that F-DycoBlock is a robust methodology for flexible drug design. It is particularly notable that the protein flexibility has been perfectly associated with each stage of drug design - search for the binding sites, dynamic assembly and optimization of candidate compounds. When all protein atoms were restrained, F-DycoBlock yielded higher accuracy of recovery than DycoBlock (100%). If backbone atoms were restrained, the same ratio of accuracy was achieved. Moreover, with the intramolecular hydrogen bonds restrained, reasonable conformational changes were observed for HIV-1 protease during the long-time MCSMD simulation and L700417 was reassembled at the active site. It makes it possible to study the receptor motion in the binding process.
{fenge}
0036417537	Model study of the effect of soil no emissions on surface ozone	The effect of soil NO emissions on surface ozone in autumn in East China has been studied by using TCTM (Troposphere Chemical Transport Model) with the input of meteorological variables from RAMS. The chemical mechanism for ozone variation caused by soil emissions has also been investigated. The model results reveal that soil NO emissions are important to regional ozone formation and distribution and the effect of soil NO emissions shows spatial inhomogeneity. Ozone over most areas in northern China decreases with maximum average decrement reaching 5 ppb while it increases over most areas of central and southern China with maximum average increment reaching 7 ppb caused by soil NO emissions. This situation of ozone variation is mainly determined by nonlinear photochemical mechanism. For the low NOx areas (≤3 ppb), ozone increases as NOx increases: for the high NOx areas (>3 ppb), ozone decreases as NOx increases. The effect of soil NO emissions on ozone depends on the transition value and NOx concentrations.
{fenge}
79958199896	Global molecular dysfunctions in gastric cancer revealed by an integrated analysis of the phosphoproteome and transcriptome	We integrated LC-MS/MS-based and protein antibody array-based proteomics with genomics approaches to investigate the phosphoproteome and transcriptome of gastric cancer cell lines and endoscopic gastric biopsies from normal subjects and patients with benign gastritis or gastric cancer. More than 3,000 non-redundant phosphorylation sites in over 1,200 proteins were identified in gastric cancer cells. We correlated phosphoproteome data with transcriptome data sets and reported the expression of 41 protein kinases, 5 phosphatases and 65 phosphorylated mitochondrial proteins in gastric cancer cells. Transcriptional expression levels of 190 phosphorylated proteins were >2-fold higher in gastric cancer cells compared to normal stomach tissue. Pathway analysis demonstrated over-presentation of DNA damage response pathway and underscored critical roles of phosphorylated p53 in gastric cancer. This is the first study to comprehensively report the gastric cancer phosphoproteome. Integrative analysis of the phosphoproteome and transcriptome provided an expansive view of molecular signaling pathways in gastric cancer. © 2010 Springer Basel AG.
{fenge}
79961238018	Simultaneous estimation of land surface scheme states and parameters using the ensemble Kalman filter: Identical twin experiments	The performance of the ensemble Kalman filter (EnKF) in soil moisture assimilation applications is investigated in the context of simultaneous state-parameter estimation in the presence of uncertainties from model parameters, soil moisture initial condition and atmospheric forcing. A physically based land surface model is used for this purpose. Using a series of identical twin experiments in two kinds of initial parameter distribution (IPD) scenarios, the narrow IPD (NIPD) scenario and the wide IPD (WIPD) scenario, model-generated near surface soil moisture observations are assimilated to estimate soil moisture state and three hydraulic parameters (the saturated hydraulic conductivity, the saturated soil moisture suction and a soil texture empirical parameter) in the model. The estimation of single imperfect parameter is successful with the ensemble mean value of all three estimated parameters converging to their true values respectively in both NIPD and WIPD scenarios. Increasing the number of imperfect parameters leads to a decline in the estimation performance. A wide initial distribution of estimated parameters can produce improved simultaneous multi-parameter estimation performances compared to that of the NIPD scenario. However, when the number of estimated parameters increased to three, not all parameters were estimated successfully for both NIPD and WIPD scenarios. By introducing constraints between estimated hydraulic parameters, the performance of the constrained three-parameter estimation was successful, even if temporally sparse observations were available for assimilation. The constrained estimation method can reduce RMSE much more in soil moisture forecasting compared to the non-constrained estimation method and traditional non-parameter-estimation assimilation method. The benefit of this method in estimating all imperfect parameters simultaneously can be fully demonstrated when the corresponding non-constrained estimation method displays a relatively poor parameter estimation performance. Because all these constraints between parameters were obtained in a statistical sense, this constrained state-parameter estimation scheme is likely suitable for other land surface models even with more imperfect parameters estimated in soil moisture assimilation applications. © 2011 Author(s).
{fenge}
80052063839	Preparation and characterization of mesoporous silicon spheres directly from MCM-48 and their response to ammonia	The synthesis process of mesoporous silicon spheres directly from MCM-48 through a metal thermal reduction reaction is presented. The MCM-48 spheres were reduced in vacuum at 620 °C, with the spherical shape retained. The synthesized porous silicon spheres were confirmed as crystalline silicon by X-ray diffraction and transmission electron microscope. The silicon spheres have a microstructure different to those of etched silicon films by traditional method. The sample exhibited a slight red shift in PL spectrumafter exposure to ammonia. This shift from 2.00 to 1.98 eV is ascribed to the Si-N adduct which disorder the space charge region in the semiconductor to weaken the quantum confinement effect. This design enables the syntheses of mesoporous nanocrystalline silicon spheres with multifarious three-dimensional shapes inherited from MCM-48 for sensor or optical applications. © 2011 Springer Science+Business Media, LLC.
{fenge}
80053630759	An eddy resolving tidal-driven model of the South China Sea assimilating along-track SLA data using the EnOI	The upper ocean circulation in the South China Sea (SCS) is driven by the Asian monsoon, the Kuroshio intrusion through the Luzon Strait, strong tidal currents, and a complex topography. Here, we demonstrate the benefit of assimilating along-track altimeter data into a nested configuration of the HYbrid Coordinate Ocean Model that includes tides. Including tides in models is important because they interact with the main circulation. However, assimilation of altimetry data into a model including tides is challenging because tides and mesoscale features contribute to the elevation of ocean surface at different time scales and require different corrections. To address this issue, tides are filtered out of the model output and only the mesoscale variability is corrected with a computationally cheap data assimilation method: the Ensemble Optimal Interpolation (EnOI). This method uses a running selection of members to handle the seasonal variability and assimilates the track data asynchronously. The data assimilative system is tested for the period 1994-1995, during which time a large number of validation data are available. Data assimilation reduces the Root Mean Square Error of Sea Level Anomalies from 9.3 to 6.9 cm and improves the representation of the mesoscale features. With respect to the vertical temperature profiles, the data assimilation scheme reduces the errors quantitatively with an improvement at intermediate depth and deterioration at deeper depth. The comparison to surface drifters shows an improvement of surface current by approximately ĝ̂'9% in the Northern SCS and east of Vietnam. Results are improved compared to an assimilative system that does not include tides and a system that does not consider asynchronous assimilation. © 2011 Author(s).
{fenge}
82055172258	Evaluation of an ocean data assimilation system for Chinese marginal seas with a focus on the South China Sea	Data assimilation is a powerful tool to improve ocean forecasting by reducing uncertainties in forecast initial conditions. Recently, an ocean data assimilation system based on the ensemble optimal interpolation (EnOI) scheme and HYbrid Coordinate Ocean Model (HYCOM) for marginal seas around China was developed. This system can assimilate both satellite observations of sea surface temperature (SST) and along-track sea level anomaly (SLA) data. The purpose of this study was to evaluate the performance of the system. Two experiments were performed, which spanned a 3-year period from January 1, 2004 to December 30, 2006, with and without data assimilation. The data assimilation results were promising, with a positive impact on the modeled fields. The SST and SLA were clearly improved in terms of bias and root mean square error over the whole domain. In addition, the assimilations provided improvements in some regions to the surface field where mesoscale processes are not well simulated by the model. Comparisons with surface drifter trajectories showed that assimilated SST and SLA also better represent surface currents, with drifter trajectories fitting better to the contours of SLA field than that without assimilation. The forecasting capacity of this assimilation system was also evaluated through a case study of a birth-and-death process of an anticyclone eddy in the Northern South China Sea (NSCS), in which the anticyclone eddy was successfully hindcasted by the assimilation system. This study suggests the data assimilation system gives reasonable descriptions of the near-surface ocean state and can be applied to forecast mesoscale ocean processes in the marginal seas around China. © 2011 Chinese Society for Oceanology and Limnology, Science Press and Springer Berlin Heidelberg.
{fenge}
84859409884	A multilayered approach of Si/SiO to promote carrier transport in electroluminescence of Si nanocrystals	The electroluminescence (EL) and photoluminescence of Si nanocrystals (Si-nc) from multilayered samples of Si/SiO are investigated. Si-nc are formed within Si and SiO layers after furnace annealing. It is found that the presence of Si interlayers creates extra carrier paths for EL emission. A comparative study is further performed on a multilayered Si/SiO sample and a single-layered one with Si and SiO homogeneously mixed. Both samples have the same ratio of Si to O and the same contents of Si and O. The multilayered sample is found to have higher EL intensity, less turn-on voltage, lower resistance, and higher current efficiency than the single-layered one. The results indicate that Si interlayers in Si/SiO may act as carrier channels, which promote carrier transport and enhance the EL emission of Sinc. © 2012 Li et al.
{fenge}
84862969574	General and reliable quantitative measurement of fluorescence resonance energy transfer using three fluorescence channels	In this paper, we describe a comprehensive general system adapted for quantitative fluorescence resonance energy transfer (FRET) measurement using signals from three channels of a fluorescence instrument. The general FRET measurement system involves two established methods, as well as two novel approaches. Unlike the previous measurements, which can be taken correctly only when the quantity of the acceptor is greater than or equal to that of the donor, one of our novel methods can overcome this obstacle and take quantitative FRET measurements when the donor is in excess of the acceptor. Hence the general FRET measurement system allowed one to determine the exact distance when the donor and acceptor were present in different quantities, and integrated the methods for quantitative FRET measurements. The uniformity of measured values and utility of each method were validated using molecular standards based on DNA oligonucleotide rulers. We also discussed and validated the use of a novel method for estimating the relative quantities of the donor and acceptor fluorophores when they were not known before an appropriate method of this system can be selected. © The Royal Society of Chemistry 2012.
{fenge}
84863055917	Effects of sea level data assimilation by ensemble optimal interpolation and 3D variational data assimilation on the simulation of variability in a tropical pacific model	Sea level anomalies (SLA) from the Ocean Topography Experiment (TOPEX)/Poseidon are assimilated with three-dimensional variational data assimilation (3DVAR) and ensemble optimal interpolation (EnOI) for the period of 1997-2001. When sea level data are assimilated, one major concern is how to project the surface information downward. In 3DVAR, downward projection is usually achieved by minimizing a cost function that computes the relations among temperature, salinity, and sea level. In EnOI, the surface information is propagated to other variables through a stationary ensemble. Their effects on the simulated variability are evaluated in a tropical Pacific Ocean model. When compared with different datasets, it is found that effects of 3DVAR and EnOI are different in several aspects. For sea level, the standard deviation is improved by both methods, but EnOI is more effective in the central/eastern Pacific. The SLA evolution is better reproduced with EnOI than with 3DVAR. For temperature, the model-reanalysis correlations are increased by 0.1-0.2 in the top 200 m with both methods, but EnOI is more effective, especially along the thermocline depth. When compared with the Tropical Atmosphere-Ocean array (TAO) profiles, evolution of the temperature reveals that 3DVAR tends to cause more errors during ENSO events. The correlations with TAO profile are increased by 0.1-0.3 with EnOI and are generally decreased by 0.1-0.3 with 3DVAR. For salinity, both methods have weak impact on the model-reanalysis correlations above the thermocline. Relative to 3DVAR, EnOI can increase the correlation by 0.2 below the thermocline. When compared with the TAO profiles, the differences are reduced to some extent with both methods, but 3DVAR is very negative on the simulated variability. © 2011 American Meteorological Society.
{fenge}
0037046727	Parametrization of a generalized Born/solvent-accessible surface area model and applications to the simulation of protein dynamics	A generalized Born/surface area (GB/SA) water model (Qiu, D.; Shenkin, P.S.; Hollinger, F.P.; Still, W.C. J. Phys. Chem. A 1997, 101, 3005-3014) in combination with the GROMOS96 force field is parametrized with the specific goal of application to protein simulations. The parameters are determined by a combined procedure of fitting to the free energies of solvation of amino acid-mimicking small molecules, rationally considering the effects of the solvent model on hydrogen-bond interactions, and most critically, carrying out long-time trial molecular dynamics simulations on two structurally distinct proteins, the B1 domain of streptococcal protein G and the bovine pancreatic trypsin inhibitor. The refined set of parameters is tested by carrying out a simulation on a third protein, the chymotrysin inhibitor 2. For all three proteins, we report separate 3 ns simulations using, respectively, the re-parametrized GB/SA model, the explicit solvent model, and another implicit solvent model which is mainly based on the solvent-accessible surface area. The simulations with the GB/SA model show excellent agreement with crystal structures and explicit solvent simulations. The root-mean-square error of the final GB/SA model in the free energies of solvation for 16 amino acid analogues is 1.12 kcal/mol. We believe that the procedure of considering structurally distinct proteins in parametrization and running final tests on unrelated proteins is essential for avoiding biasing the model toward stabilizing certain types of protein structures. The results indicate that the model can be widely used in future studies of protein conformations and dynamics.
{fenge}
0037110329	Estimation of air-sea heat flux from ocean measurements: An ill-posed problem	In this paper we addressed that the estimation of ocean surface heat flux from ocean temperature data is an ill-posed inverse problem, just like a well-known ill-posed problem: differentiation of noisy data. We reviewed engineering literature on such problems. Using a Mellor-Yamada level 2.5 closure model and simulated temperature data, we conducted numerical experiments of retrieving heat fluxes using variational data assimilation. This study shows that estimated nonsolar heat fluxes with high time resolution have large errors even if the observation errors are small. We also discussed the ill-posedness based on sensitivity coefficients. However, by applying some regularization methods and a longer assimilation window, it is feasible to estimate heat fluxes with reasonable accuracies, at least at some lower temporal resolution. On the basis of our model and experiment configurations, the high nonlinearity of the ocean mixed layer model also can cause difficulty in optimization when the assimilation window is long (e.g., 7 days). We proposed a modified an adjoint method approach and yielded good results.
{fenge}
0038288533	Assimilation of Satellite Altimetry into a Western North Pacific Operational Model	An ocean data assimilation system, COMPASS-K (the Comprehensive Ocean Modeling, Prediction, Analysis and Synthesis System in the Kuroshio-region), has been developed at the Meteorological Research Institute (MRI). The purposes of the development are understanding ocean variability in the Kuroshio region as a local response to a global climate change with assimilated four-dimensional data sets, development of an operational system in the Japan Meteorological Agency, and for the GODAE (Global Ocean Data Assimilation Experiment) project The model is an eddy permitting version of an MRI-OGCM. Space-time decorrelation scales of ocean variability are estimated with TOPEX / POSEIDON (T / P) altimeter data. Subsurface temperature and salinity fields are projected from the T / P altimeter data with a statistical correlation method and are assimilated into the model with a time-retrospective nudging scheme. Seasonal variation in the western North Pacific is investigated. Realistic space-time distribution of the physical quantities, the path of Kuroshio and its separation from Honshu are captured well The Kuroshio volume transport is well reproduced in a reanalysis experiment of 1993. Preliminary predictability experiments are done in February and March, 1994. Predictability diagram shows the time scale of the predictability for temperature field is about 17 days in the Kuroshio south of Japan. This time scale is smaller than that in the North Atlantic.
{fenge}
0038692924	Molecular dynamics simulation of the unfolding of the human prion protein domain under low pH and high temperature conditions	Four 10-ns molecular dynamics (MD) simulations of the human prion protein domain (HuPrP 125-228) in explicit water solution have been performed. Each of the simulations mimicked a different environment of the protein: the neutral pH environment was simulated with all histidine residues neutral and bearing a ND proton and with other titratable side chains charged, the weakly acidic environment was simulated with all titratable side chains charged, the strongly acidic environment was simulated with all titratable side chains protonated. The protein in neutral pH environment was simulated at both ambient (298 K) and higher (350 K) temperatures. The native fold is stable in the neutral pH/ambient temperature simulation. Through out all other simulations, a quite stable core consisted of 10-20 residues around the disulfide bond retain their initial conformations. However, the secondary structures of the protein show changes of various degrees compared to the native fold, parts of the helices unfolded and the β-sheets extended. Our simulations indicated that the heat-induced unfolding and acid-induced unfolding of HuPrP might follow different pathways: the initial stage of the acid-induced unfolding may include not only changes in secondary structures, but also changes in the tertiary structures. Under the strongly acidic condition, obvious tertiary structure changes take place after 10-ns simulation, the secondary structure elements and the loops becoming more parallel to each other, resulting in a compact state, which was stabilized by a large number of new, non-native side chain-side chain contacts. Such tertiary structure changes were not observed in the higher temperature simulation, and intuitively, they may favor the further extension of the β-sheets and eventually the agglomeration of multiple protein molecules. The driving forces for this tertiary structure changes are discussed. Two additional 10-ns MD simulations, one with Asp202 protonated and the other with Glu196 protonated compared to the neutral pH simulation, were carried out. The results showed that the stability of the native fold is very subtle and can be strongly disturbed by eliminating a single negative charge at one of such key sites. Correlations of our results with previous experimental and theoretical studies are discussed. © 2003 Elsevier Science B.V. All rights reserved.
{fenge}
84870881998	Mixed-solvothermal synthesis, structures, luminescent and surface photovoltage properties of four new transition metal diphosphonates with a 3D supramolecular structure	Four new transition metal(ii) diphosphonates with a 3D supramolecular structure, M(hedpH<inf>2</inf>)<inf>3</inf>·3NH<inf>2</inf>(CH <inf>3</inf>)<inf>2</inf>NH(CH<inf>3</inf>)<inf>3</inf>·3H<inf>2</inf>O (M = Mn (1), Co (2), Ni (3), Zn (4); hedpH<inf>4</inf> = 1- hydroxyethylidenediphosphonate acid) have been synthesized under mixed-solvothermal conditions and structurally characterized. Compounds 1-4 are isomorphous and adopt a three-dimensional supramolecular network structure containing {M(hedpH<inf>2</inf>)<inf>3</inf>}<sup>4-</sup> cluster units. The interconnection of {MO<inf>6</inf>} and {CPO<inf>3</inf>} polyhedra via corner-sharing forms a {M(hedpH<inf>2</inf>)<inf>3</inf>}<sup>4-</sup> cluster, and these isolated clusters are extended by hydrogen bonds to form a two-dimensional layer structure, which are further connected through hydrogen bonding interactions to give rise to a 3D supramolecular structure. Surface photovoltage spectroscopy (SPS) of compounds 1-4 indicates that it possesses positive SPV response in the range of 300-600 nm and shows p-type semiconductor characteristic. Luminescence properties of the four compounds have also been studied. © 2013 The Royal Society of Chemistry and the Centre National de la Recherche Scientifique.
{fenge}
84872612270	POD reduced-order unstructured mesh modeling applied to 2D and 3D fluid flow	A new scheme for implementing a reduced order model for complex mesh-based numerical models (e.g. finite element unstructured mesh models), is presented. The matrix and source term vector of the full model are projected onto the reduced bases. The proper orthogonal decomposition (POD) is used to form the reduced bases. The reduced order modeling code is simple to implement even with complex governing equations, discretization methods and nonlinear parameterizations. Importantly, the model order reduction code is independent of the implementation details of the full model code. For nonlinear problems, a perturbation approach is used to help accelerate the matrix equation assembly process based on the assumption that the discretized system of equations has a polynomial representation and can thus be created by a summation of pre-formed matrices. In this paper, by applying the new approach, the POD reduced order model is implemented on an unstructured mesh finite element fluid flow model, and is applied to 3D flows. The error between the full order finite element solution and the reduced order model POD solution is estimated. The feasibility and accuracy of the reduced order model applied to 3D fluid flows are demonstrated. © 2012 Elsevier Ltd. All rights reserved.
{fenge}
84872613506	Reduced order modeling based on POD of a parabolized Navier-Stokes equations model II: Trust region POD 4D VAR data assimilation	A reduced order model based on Proper Orthogonal Decomposition (POD) 4D VAR (Four-dimensional Variational) data assimilation for the parabolized Navier-Stokes (PNS) equations is derived. Various approaches of POD implementation of the reduced order inverse problem are studied and compared including an ad-hoc POD adaptivity along with a trust region POD adaptivity. The numerical results obtained show that the trust region POD 4D VAR provides the best results amongst all the POD adaptive methods tested in all error metrics for the reduced order inverse problem of the PNS equations. © 2012 Elsevier Ltd. All rights reserved.
{fenge}
84873152415	A successful real-time forecast of the 2010-11 la Niña event	During 2010-11, a La Niña condition prevailed in the tropical Pacific. An intermediate coupled model (ICM) is used to demonstrate a real-time forecast of sea surface temperature (SST) evolution during the event. One of the ICM's unique features is an empirical parameterization of the temperature of subsurface water entrained into the mixed layer (T e). This model provided a good prediction, particularly of the double dip evolution of SST in 2011 that followed the La Niña event peak in October 2010. Thermocline feedback, explicitly represented by the relationship between T e and sea level in the ICM, is a crucial factor affecting the second cooling in 2011. Large negative T e anomalies were observed to persist in the central equatorial domain during 2010-11, inducing a cold SST anomaly to the east during July-August 2011 and leading to the development of a La Niña condition thereafter.
{fenge}
84875899079	Regional ozone data assimilation experiment based on ensemble Kalman filter	A regional air quality data assimilation system (RAQDAS) was established based on ensemble Kalman filter and Nested Air Quality Prediction Model System. This system was employed to assimilate surface ozone observation of Beijing-Tianjin-Hebei areas during the 2008 Beijing Olympics period and to optimize ozone initial conditions. The effects of data assimilation on 24 h ozone forecast were investigated. The results show that the assimilation with 50 ensemble members can improve the ozone forecast not only over observational areas, but also over non-observed areas. On average, the data assimilation can decrease the root mean square error (RMSE) of 24 h ozone forecast by 15%. Furthermore, the ensemble size can be reduced to 20 with similar improvement on forecast capability. In order to solve the problem of filter divergence, inflating ensemble spread and perturbing model error sources were employed. Inflating ensemble spread can solve the problem of filter divergence, but it can hardly improve ozone forecast and lead to an increase of ozone forecast error; perturbing model error sources can avoid filter divergence and also bring improvement of 24 h ozone forecast with the RMSE decreased by 20%.
{fenge}
84876384615	A modified ingrowth core method for measuring fine root production, mortality and decomposition in forests	The ingrowth core method is widely used to assess fine root (diameter < 2 mm) production but has many inherent deficiencies. In this study, we modified this method by adopting mini ingrowth cores (diameter 1.2 cm), extending sample intervals to a growing season, and developing new models to quantify the concurrent production, mortality and decomposition, and applied them to a secondary Mongolian oak (Quercus mongolica Fischer ex Ledebour) forest. Annual fine root production, mortality and decomposition estimated by our method were 2.10 ± 0.23, 1.78 ± 0.20 and 0.85 ± 0.13 t ha
{fenge}
84880695008	The impact of mean dynamic topography on a sea-level anomaly assimilation in the South China Sea based on an eddy-resolving model	The sea-level anomaly (SLA) from a satellite altimeter has a high accuracy and can be used to improve ocean state estimation by assimilation techniques. However, the lack of an accurate mean dynamic topography (MDT) is still a bothersome issue in an ocean data assimilation. The previous studies showed that the errors in MDT have significant impacts on assimilation results, especially on the time-mean components of ocean states and on the time variant parts of states via nonlinear ocean dynamics. The temporal-spatial differences of three MDTs and their impacts on the SLA analysis are focused on in the South China Sea (SCS). The theoretical analysis shows that even for linear models, the errors in MDT have impacts on the SLA analysis using a sequential data assimilation scheme. Assimilation experiments, based on EnOI scheme and HYCOM, with three MDTs from July 2003 to June 2004 also show that the SLA assimilation is very sensitive to the choice of different MDTs in the SCS with obvious differences between the experimental results and observations in the centre of the SCS and in the vicinity of the Philippine Islands. A new MDT for assimilation of SLA data in the SCS was proposed. The results from the assimilation experiment with this new MDT show a marked reduction (increase) in the RMSEs (correlation coefficient) between the experimental and observed SLA. Furthermore, the subsurface temperature field is also improved with this new MDT in the SCS. © 2012 The Chinese Society of Oceanography and Springer-Verlag Berlin Heidelberg.
{fenge}
84886901314	The impact of different vertical diffusion schemes in a three-dimensional oil spill model in the Bohai Sea	Vertical transport is critical to the movement of oil spills in seawater. Breaking waves play an important role by developing a well-defined mixing layer in the upper part of the water column. A three-dimensional (3-D) Lagrangian random walk oil spill model was used here to study the influence of sea surface waves on the vertical turbulence movement of oil particles. Three vertical diffusion schemes were utilized in the model to compare their impact on oil dispersion and transportation. The first scheme calculated the vertical eddy viscosity semi-empirically. In the second scheme, the vertical diffusion coefficient was obtained directly from an Eulerian hydrodynamic model (Princeton Ocean Model, POM2k) while considering wave-caused turbulence. The third scheme was formulated by solving the Langevin equation. The trajectories, percentages of oil particles intruding into water, and the vertical distribution structures of oil particles were analyzed for a series of numerical experiments with different wind magnitudes. The results showed that the different vertical diffusion schemes could generate different horizontal trajectories and spatial distributions of oil spills on the sea surface. The vertical diffusion schemes caused different water-intruding and resurfacing oil particle behaviors, leading to different horizontal transport of oil particles at the surface and subsurface of the ocean. The vertical diffusion schemes were also applied to a realistic oil spill simulation, and these results were compared to satellite observations. All three schemes yielded acceptable results, and those of the third scheme most closely simulated the observed data. © 2013 Chinese National Committee for International Association of Meteorology and Atmospheric Sciences, Institute of Atmospheric Physics, Science Press and Springer-Verlag Berlin Heidelberg.
{fenge}
84886993994	Inversion of CO emissions over Beijing and its surrounding areas with ensemble Kalman filter	Inversion of the carbon monoxide (CO) emissions over Beijing and surrounding areas in the summer of 2010 is carried on the Nested Air Quality Prediction Modeling System (NAQPMS) in coupling with an ensemble Kalman filter. CO emission is estimated through integration of observations data obtained from 25 sites in Beijing and surrounding areas of which 13 sites selected as assimilation sites are used to perform a joint adjustment of both CO concentrations and emissions with hourly surface CO observations, and 12 other sites selected to validate the inversion emission inventory. As a result, estimated CO emissions (Tgyear
{fenge}
0041324848	Nonlinear nonlocal singularly perturbed problems for reaction diffusion equations	A class of nonlinear nonlocal for singularly perturbed Robin initial boundary value problems for reaction diffusion equations is considered. Under suitable conditions, firstly, the outer solution of the original problem is obtained, secondly, by using the stretched variable, the composing expansion method and the expanding theory of power series the initial layer is constructed, finally, using the theory of differential inequalities the asymptotic behavior of solution for the initial boundary value problems are studied and educing some relational inequalities the existence and uniqueness of solution for the original problem and the uniformly valid asymptotic estimation is discussed.
{fenge}
0042921442	How well can we predict native contacts in proteins based on decoy structures and their energies?	One strategy for ab initio protein structure prediction is to generate a large number of possible structures (decoys) and select the most fitting ones based on a scoring or free energy function. The conformational space of a protein is huge, and chances are rare that any heuristically generated structure will directly fall in the neighborhood of the native structure. It is desirable that, instead of being thrown away, the unfitting decoy structures can provide insights into native structures so prediction can be made progressively. First, we demonstrate that a recently parameterized physics-based effective free energy function based on the GROMOS96 force field and a generalized Born/surface area solvent model is, as several other physics-based and knowledge-based models, capable of distinguishing native structures from decoy structures for a number of widely used decoy databases. Second, we observe a substantial increase in correlations of the effective free energies with the degree of similarity between the decoys and the native structure, if the similarity is measured by the content of native inter-residue contacts in a decoy structure rather than its root-mean-square deviation from the native structure. Finally, we investigate the possibility of predicting native contacts based on the frequency of occurrence of contacts in decoy structures. For most proteins contained in the decoy databases, a meaningful amount of native contacts can be predicted based on plain frequencies of occurrence at a relatively high level of accuracy. Relative to using plain frequencies, overwhelming improvements in sensitivity of the predictions are observed for the 4_state_reduced decoy sets by applying energy-dependent weighting of decoy structures in determining the frequency. There, approximately 80% native contacts can be predicted at an accuracy of approximately 80% using energy-weighted frequencies. The sensitivity of the plain frequency approach is much lower (20% to 40%). Such improvements are, however, not observed for the other decoy databases. The rationalization and implications of the results are discussed. © 2003 Wiley-Liss, Inc.
{fenge}
0344041346	Optimal control problems related to the navigation channel engineering	The navigation channel engineering poses optimal control problems of how to find the optimal way of engineering such that the water depth of the channel is maximum under certain budget constraint, or the cost of the engineering is minimum while certain goals are achieved. These are typical control problems of distributed system governed by hydraulic/sedimentation models. The problems and methods of solutions are discussed. Since the models, usually complicated, are nonlinear, they can be solved by solving a series of linear problems. For linear problems the solutions are given. Thus the algorithms are simplified.
{fenge}
84890231788	The error source analysis of oil spill transport modeling: A case study	Numerical modeling is an important tool to study and predict the transport of oil spills. However, the accuracy of numerical models is not always good enough to provide reliable information for oil spill transport. It is necessary to analyze and identify major error sources for the models. A case study was conducted to analyze error sources of a three-dimensional oil spill model that was used operationally for oil spill forecasting in the National Marine Environmental Forecasting Center (NMEFC), the State Oceanic Administration, China. On June 4, 2011, oil from sea bed spilled into seawater in Penglai 19-3 region, the largest offshore oil field of China, and polluted an area of thousands of square kilometers in the Bohai Sea. Satellite remote sensing images were collected to locate oil slicks. By performing a series of model sensitivity experiments with different wind and current forcings and comparing the model results with the satellite images, it was identified that the major errors of the long-term simulation for oil spill transport were from the wind fields, and the wind-induced surface currents. An inverse model was developed to estimate the temporal variability of emission intensity at the oil spill source, which revealed the importance of the accuracy in oil spill source emission time function. © 2013 The Chinese Society of Oceanography and Springer-Verlag Berlin Heidelberg.
{fenge}
84892651048	On the spectral difference between electroluminescence and photoluminescence of Si nanocrystals: A mechanism study of electroluminescence	Spectral shift, especially blueshift, in peak position of electroluminescence (EL) spectrum of Si nanocrystal (Si-nc) with respect to its photoluminescence (PL) counterpart has been often observed. Explanations for the spectral difference are different for different EL mechanisms adopted. To gain a relevant picture of the EL process, in this work, we analyze three EL mechanisms that are mainly applied nowadays, i.e., the model of defect light emission, that of band-filling, and that of Si-nc size selection by the carrier energy. Different Si-nc samples and working conditions are designed and their EL and PL emissions monitored according to the predictions of the three models. It is concluded that the observed EL is mainly of Si-nc-related origin. The experimental results are more consistent with the model of Si-nc size selection. © Springer Science+Business Media Dordrecht 2013.
{fenge}
84894499829	Prevention of cell death by antibodies selected from intracellular combinatorial libraries	One of the most important phenotypes in biology is cell death. One way to probe the mechanism(s) of cell death is to select molecules that prevent it and learn how this was accomplished. Here, intracellular combinatorial antibody libraries were used to select antibodies that protected cells from killing by rhinovirus infection. These rare antibodies functioned by inhibiting the virus-encoded protease that is necessary for viral maturation. Snapshots of the selection process after each round could be obtained by deep sequencing the ever-enriching populations. This detailed analysis of the enrichment process allowed an interesting look at a "test tube" selection process that pitted two replicating systems against each other. Thus, initially a minority of cells containing protective antibodies must compete against a majority of unprotected cells that continue to produce large amounts of virus. © 2014 Elsevier Ltd. All rights reserved.
{fenge}
84895072482	Solvothermal conversion of magadiite into zeolite omega in a glycerol-water system	BACKGROUND: Zeolite omega is used as a catalyst in various fields. Expensive tetramethylammonium cations are the conventional structure-directing agents for the synthesis of zeolite omega. In this work, glycerol was used as both solvent and structure-directing agent instead of expensive quaternary ammonium compounds. Zeolite omega has been obtained through conversion of magadiite in this glycerol-water system. The effects of various parameters such as reaction time, temperature, alkalinity and glycerol content were discussed. RESULTS: Pure zeolite omega could be obtained at 120°C for 10 days with the reactants molar composition of 14 SiO
{fenge}
84896277131	A Rapid Automatic Processing Platform for Bead Label-Assisted Microarray Analysis: Application for Genetic Hearing-Loss Mutation Detection	Molecular diagnostics using microarrays are increasingly being used in clinical diagnosis because of their high throughput, sensitivity, and accuracy. However, standard microarray processing takes several hours and involves manual steps during hybridization, slide clean up, and imaging. Here we describe the development of an integrated platform that automates these individual steps as well as significantly shortens the processing time and improves reproducibility. The platform integrates such key elements as a microfluidic chip, flow control system, temperature control system, imaging system, and automated analysis of clinical results. Bead labeling of microarray signals required a simple imaging system and allowed continuous monitoring of the microarray processing. To demonstrate utility, the automated platform was used to genotype hereditary hearing-loss gene mutations. Compared with conventional microarray processing procedures, the platform increases the efficiency and reproducibility of hybridization, speeding microarray processing through to result analysis. The platform also continuously monitors the microarray signals, which can be used to facilitate optimization of microarray processing conditions. In addition, the modular design of the platform lends itself to development of simultaneous processing of multiple microfluidic chips. We believe the novel features of the platform will benefit its use in clinical settings in which fast, low-complexity molecular genetic testing is required. © 2013 Society for Laboratory Automation and Screening.
{fenge}
84897497423	Effects of interannual salinity variability on the barrier layer in the western-central equatorial Pacific: A diagnostic analysis from Argo	In this paper, interannual variations in the barrier layer thickness (BLT) are analyzed using Argo three-dimensional temperature and salinity data, with a focus on the effects of interannually varying salinity on the evolution of the El Niño-Southern Oscillation (ENSO). The interannually varying BLT exhibits a zonal seesaw pattern across the equatorial Pacific during ENSO cycles. This phenomenon has been attributed to two different physical processes. During El Niño (La Niña), the barrier layer (BL) is anomalously thin (thick) west of about 160°E, and thick (thin) to the east. In the western equatorial Pacific (the western part: 130°-160°E), interannual variations of the BLT indicate a lead of one year relative to those of the ENSO onset. The interannual variations of the BLT can be largely attributed to the interannual temperature variability, through its dominant effect on the isothermal layer depth (ILD). However, in the central equatorial Pacific (the eastern part: 160°E-170°W), interannual variations of the BL almost synchronously vary with ENSO, with a lead of about two months relative to those of the local SST. In this region, the interannual variations of the BL are significantly affected by the interannually varying salinity, mainly through its modulation effect on the mixed layer depth (MLD). As evaluated by a one-dimensional boundary layer ocean model, the BL around the dateline induced by interannual salinity anomalies can significantly affect the temperature fields in the upper ocean, indicating a positive feedback that acts to enhance ENSO. © 2014 Chinese National Committee for International Association of Meteorology and Atmospheric Sciences, Institute of Atmospheric Physics, Science Press and Springer-Verlag Berlin Heidelberg.
{fenge}
84902377222	Abdominal MRI at 3.0 T: LAVA-flex compared with conventional fat suppression T1-weighted images	Purpose To study liver imaging with volume acceleration-flexible (LAVA-Flex) for abdominal magnetic resonance imaging (MRI) at 3.0 T and compare the image quality of abdominal organs between LAVA-Flex and fast spoiled gradient-recalled (FSPGR) T1-weighted imaging. Materials and Methods Our Institutional Review Board approval was obtained in this retrospective study. Sixty-nine subjects had both FSPGR and LAVA-Flex sequences. Two radiologists independently scored the acquisitions for image quality, fat suppression quality, and artifacts and the values obtained were compared with the Wilcoxon signed rank test. According to the signal intensity (SI) measurements, the uniformity of fat suppression, the contrast between muscle and fat and normal liver and liver lesions were compared by the paired t-test. The liver and spleen SI on the fat-only phase were analyzed in the fatty liver patients. Results Compared with FSPGR imaging, LAVA-Flex images had better and more homogenous fat suppression and lower susceptibility artifact (qualitative scores: 4.70 vs. 4.00, 4.86% vs. 7.14%, 4.60 and 4.10, respectively). The contrast between muscle and fat and between the liver and pathologic lesions was significantly improved on the LAVA-Flex sequence. The contrast value of the fatty liver and spleen was higher than that of the liver and spleen. Conclusion The LAVA-Flex sequence offers superior and more homogenous fat suppression of the abdomen than does the FSPGR sequence. The fat-only phase can be a simple and effective method of assessing fatty liver. © 2013 Wiley Periodicals, Inc. © 2013 Wiley Periodicals, Inc.
{fenge}
84902124415	Time, probe type, and temperature variable bias corrections to historical expendable bathythermograph observations	Systematic biases in historical expendable bathythermograph (XBT) data are examined using two datasets: 4151 XBT-CTD side-by-side pairs from 1967 to 2011 and 218 653 global-scale XBT-CTD pairs (within one month and 1°) extracted from the World Ocean Database 2009 (WOD09) from 1966 to 2010. Using the side-by-side dataset, it was found that both the pure thermal bias and the XBT fall rate (from which the depth of observation is calculated) increase with water temperature. Correlations between the terminal velocity A and deceleration B terms of the fall-rate equation (FRE) and between A and the offset from the surface terms are obtained, with A as the dominant term in XBT fall-rate behavior. To quantify the time variation of the XBT fall-rate and pure temperature biases, global-scale XBT-CTD pairs are used. Based on the results from the two datasets, a new correction scheme for historical XBT data is proposed for nine independent probe-type groups. The scheme includes corrections for both temperature and depth records, which are all variable with calendar year, water temperature, and probe type. The results confirm those found in previous studies: a slowing in fall rate during the 1970s and 2000s and the large pure thermal biases during 1970-85. The performance of nine different correction schemes is compared. After the proposed corrections are applied to the XBT data in the WOD09 dataset, global ocean heat content from 1967 to 2010 is reestimated. © 2014 American Meteorological Society.
{fenge}
84902128388	The effect of superparamagnetic iron oxide with iRGD peptide on the labeling of pancreatic cancer cells in vitro: A preliminary study	The iRGD peptide loaded with iron oxide nanoparticles for tumor targeting and tissue penetration was developed for targeted tumor therapy and ultrasensitive MR imaging. Binding of iRGD, a tumor homing peptide, is mediated by integrins, which are widely expressed on the surface of cells. Several types of small molecular drugs and nanoparticles can be transfected into cells with the help of iRGD peptide. Thus, we postulate that SPIO nanoparticles, which have good biocompatibility, can also be transfected into cells using iRGD. Despite the many kinds of cell labeling studies that have been performed with SPIO nanoparticles and RGD peptide or its analogues, only a few have applied SPIO nanoparticles with iRGD peptide in pancreatic cancer cells. This paper reports our preliminary findings regarding the effect of iRGD peptide (CRGDK/RGPD/EC) combined with SPIO on the labeling of pancreatic cancer cells. The results suggest that SPIO with iRGD peptide can enhance the positive labeling rate of cells and the uptake of SPIO. Optimal functionalization was achieved with the appropriate concentration or concentration range of SPIO and iRGD peptide. This study describes a simple and economical protocol to label panc-1 cells using SPIO in combination with iRGD peptide and may provide a useful method to improve the sensitivity of pancreatic cancer imaging. © 2014 Hou Dong Zuo et al.
{fenge}
84902147043	Uncertainties of the ocean heat content estimation induced by insufficient vertical resolution of historical ocean subsurface observations	Assessment of the upper-ocean (0-700 m) heat content (OHC) is a key task for monitoring climate change. However, irregular spatial and temporal distribution of historical subsurface observations has induced uncertainties in OHC estimation. In this study, a new source of uncertainties in calculating OHC due to the insufficiency of vertical resolution in historical ocean subsurface temperature profile observations was diagnosed. This error was examined by sampling a high-vertical-resolution climatological ocean according to the depth intervals of in situ subsurface observations, and then the error was defined as the difference between the OHC calculated by subsampled profiles and the OHC of the climatological ocean. The obtained resolution-induced error appeared to be cold in the upper 100m(with a peak of approximately -0.1°C), warm within 100-700m (with a peak of ~0.1°C near 180 m), and warm when averaged over 0-700-m depths (with a global average of ~0.01°-0.025°C, ~1-2.5 × 10
{fenge}
84903737744	Assimilating the along-track sea level anomaly into the regional ocean modeling system using the ensemble optimal interpolation	The ensemble optimal interpolation (EnOI) is applied to the regional ocean modeling system (ROMS) with the ability to assimilate the along-track sea level anomaly (TSLA). This system is tested with an eddy-resolving system of the South China Sea (SCS). Background errors are derived from a running seasonal ensemble to account for the seasonal variability within the SCS. A fifth-order localization function with a 250 km localization radius is chosen to reduce the negative effects of sampling errors. The data assimilation system is tested from January 2004 to December 2006. The results show that the root mean square deviation (RMSD) of the sea level anomaly decreased from 10.57 to 6.70 cm, which represents a 36.6% reduction of error. The data assimilation reduces error for temperature within the upper 800 m and for salinity within the upper 200 m, although error degrades slightly at deeper depths. Surface currents are in better agreement with trajectories of surface drifters after data assimilation. The variance of sea level improves significantly in terms of both the amplitude and position of the strong and weak variance regions after assimilating TSLA. Results with AGE error (AGE) perform better than no AGE error (NoAGE) when considering the improvements of the temperature and the salinity. Furthermore, reasons for the extremely strong variability in the northern SCS in high resolution models are investigated. The results demonstrate that the strong variability of sea level in the high resolution model is caused by an extremely strong Kuroshio intrusion. Therefore, it is demonstrated that it is necessary to assimilate the TSLA in order to better simulate the SCS with high resolution models. © 2014 The Chinese Society of Oceanography and Springer-Verlag Berlin Heidelberg.
{fenge}
84904357481	The roles of different mechanisms related to the tide-induced fronts in the Yellow Sea in summer	In summer, the Yellow Sea Cold Water Mass (YSCWM) is a stable water mass of low temperature lying at the bottom of the central Yellow Sea (YS). It is fringed by some typical tidal fronts, which separate deep, stratified water on the offshore side from the well-mixed, shallow water on the inshore side. Three striking fronts-Subei Bank Front (SBF), Shandong Peninsula Front (SPF), and Mokpo Front (MKF; a front off the southwestern tip of the Korean Peninsula)-have been identified by various studies from both satellite observations and model results. Tide plays an important role in the formation and maintenance of these fronts. However, it is still a matter of debate as to the roles these two kinds of mechanisms of upwelling and tidal mixing play, and how importance they are in the maintenance processes of the above three fronts. Basing a nested high-resolution model HYCOM (the Hybrid Coordinate Ocean Model), this study focuses on the different mechanisms of tidal effects on the thermal fronts in the YS in summertime. Through comparative experiments with and without tidal forcing, the results indicate that the MKF is mainly driven by tide-induced upwelling. For the SPF, tidal mixing is the dominant factor, when lower cold water is stirred upwards along the sloping topography of the western YS. Meanwhile, the combined effect of upwelling and tidal mixing is the main cause of the formation of the SBF. Diagnostic analysis of thermal balance shows that horizontal nonlinear advection induced by strong tidal currents also contributes to the thermal balance of frontal areas. © 2014 Chinese National Committee for International Association of Meteorology and Atmospheric Sciences, Institute of Atmospheric Physics, Science Press and Springer-Verlag Berlin Heidelberg.
{fenge}
84911361246	Artifacts in variations of ocean heat content induced by the observation system changes	The heat content of the upper ocean is a key climate indicator, contributing to a substantial portion of the global sea level rise. Recent ocean heat content (OHC) calculations have shown a dramatic shift during the period 2001-2003, which is nearly coincident with a major transition in the ocean observation network from a ship-based system to Argo floats. Here we demonstrate that the changes in the spatial sampling of the historical observation network introduced an artificial jump during the initiation of the global Argo array (2001-2003). The start of the Argo program is responsible for such a shift. Considering the sampling bias, new methods to assess long-term trends in the OHC (0-700-m) are proposed that suggest the presence of a continuous upper ocean warming (0.36-±-0.08-W-m<sup>-2</sup>) since 1966. Key Points The transfer of ocean observation system to Argo induces bias in OHC estimationThe horizontal sampling change is responsible for the sampling bias0-700-m upper ocean warming rate is assessed
{fenge}
0346675287	Nonsmooth Optimization Approaches to VDA of Models with on/ off Parameterizations: Theoretical Issues	Some variational data assimilation problems of time- and space-discrete models with on/off parameterizations can be regarded as nonsmooth optimization problems. Some theoretical issues related to those problems is systematically addressed. One of the basic concept in nonsmooth optimization is subgradient, a generalized notation of a gradient of the cost function. First it is shown that the concept of subgradient leads to a clear definition of the adjoint variables in the conventional adjoint model at singular points caused by on/off switches. Using an illustrated example of a multi-layer diffusion model with the convective adjustment, it is proved that the solution of the conventional adjoint model can not be interpreted as Gateaux derivatives or directional derivatives, at singular points, but can be interpreted as a subgradient of the cost function. Two existing smooth optimization approaches are then reviewed which are used in current data assimilation practice. The first approach is the conventional adjoint model plus smooth optimization algorithms. Some conditions under which the approach can converge to the minimal are discussed. Another approach is smoothing and regularization approach, which removes some thresholds in physical parameterizations. Two nonsmooth optimization approaches are also reviewed. One is the subgradient method, which uses the conventional adjoint model. The method is convergent, but very slow. Another approach, the bundle methods are more efficient. The main idea of the bundle method is to use the minimal norm vector of subdifferential, which is the convex hull of all subgradients, as the descent director. However finding all subgradients is very difficult in general. Therefore bundle methods are modified to use only one subgradient that can be calculated by the conventional adjoint model. In order to develop an efficient bundle method, a set-valued adjoint model, as a generalization of the conventional adjoint model, is proposed. It is shown that the significance of the set-valued adjoint model is that at singular points, it can give all supporting subgradients. Therefore using the set-valued adjoint model, it is possible to develop a bundle method that may yield higher convergence scores.
{fenge}
0347517477	A mathematical formulation for optimal control of air pollution	The problem of optimal control of air pollution using weather forecast results and numerical air pollution models is discussed. A mathematical formulation of the problem is presented. The control is an act on pollution sources with feasible constraints. Based on forecasted weather conditions, the objective of the optimal control is to minimize total cost caused by control under the constraint that the pollution concentrations over a certain period and a certain spatial domain are less than some specified values. Using the adjoint method, an effective algorithm is given. Since the optimal solutions are based on weather forecasts, the errors in weather forecasts will cause uncertainties in the optimal solutions. Estimation of impacts of weather forecast errors on the optimal solutions is discussed using the adjoint sensitivity analysis technique that is an approximated, however very effective method. The adjoint sensitivity analysis technique can be used to calculate the impacts of errors in wind, temperature and initial pollutant concentration fields on performances of the optimal control.
{fenge}
13244259460	The impact of location-dependent correlation scales in ocean data assimilation	An approach is proposed to estimate the location-dependent correlation scales for background error covariance matrix used in the 3D-Var data assimilation, and the impact on ocean assimilation is examined. By a nonlinear fitting procedure, the horizontal scales are computed at each model grid point using the outputs of a tropical Pacific OGCM. The derived correlation scales are comparable to those obtained from observations, but present more complicated structures quite different from empirical functions. They vary largely in the horizontal and show a distinct distribution from surface to subsurface. Three ssimilation experiments from 1982 to 2000 are performed to assess the improvement due to the location-dependent correlation scales. The overall root-mean-square errors in the upper ocean are reduced about 0.5°C in the eastern equatorial Pacific and about 0.4°C in the western equatorial Pacific. The improvement shows the location-dependent correlation scales can afford more information of the background error structures. Copyright 2004 by the American Geophysical Union.
