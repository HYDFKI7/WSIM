{fenge}
84942873187	A limited lattice structure for incremental association mining	An association rule typically strives for discovering a dependency among attributes with respect to the externally defined parameters like support threshold and confidence threshold. As an important database discovery method, the kernel of association rule mining is the acquisition of large itemsets. It is an important field of data mining to represent the support and confidence of items that are purchased together in supermarket domain. In this paper, a novel limited concept lattice is first proposed for the transaction data itemsets modeling. Concept lattice is a form of a concept hierarchy in which each node represents a subset of objects (extent) with their common properties (intent). The Hasse diagram of the lattice represents a generalization/specialization relationship between the concepts. Therefore, the lattice and Hasse diagram corresponding to a set of objects described by some properties can be used as an effective tool for symbolic data analysis and knowledge acquisition. Based on this lattice structure, an algorithm, LCLL, is presented to incrementally generate large itemsets visually. The algorithm works by means of attaching frequency information to each lattice node, the corresponding support measure can be obtained with the limited lattice. Besides, the edges in the Hasse diagram of the new lattice must be modified: the generator of a new node is always its child, and original parent of the generator is updated. When a node is deleted till the frequency value turns to zero, the node and the edges between its parents and children are not deleted, but tagged. The key point lies in adding edges when searching for the new node’s parents, the large itemsets can be obtained by judging whether the cardinal and frequency value of the node exceeds the threshold or not. And accordingly, association rules can be identified. The approach is especially efficient when the database is dynamically updated (insertion, deletion or simultaneous insertion and deletion). Compared with K. Hu’s approach [5], our algorithm generates all the association rules with much less time complexity. The time complexity of the proposed algorithm has a relationship of inverse proportion with the cardinal of the transactions, which means the applicability of the approach to the supermarket.
{fenge}
1542362358	Urban road area recognition in ITS based on mean shift method	A color-based visual technique is described based on the mean shift image segmentation method providing relevant information for robust localization of the visible road area in Urban Intelligent Transportation System (U-ITS). The traffic image sequences are firstly trained to extract the background and then segmented into separated parts by the mean shift method as initialization, regions with the number of pixels not less than a threshold and with more uniform surfaces with the same color compared to their environment are filtered as recognized road area. The algorithm given in this paper can present road area recognition with arbitrary shapes, which is fit for unstructured road applications in urban cities very well.
{fenge}
1642290804	Similarity measure of spectral vectors based on set theory and its application in hyperspectral RS image retrieval	Two new similarity measure methods based on set theory were proposed. Firstly, similarity measure of two sets based on set theory and set operation was discussed. This principle was used to spectral vectors, and two approaches were proposed. The first method was to create a spectral polygon corresponding to spectral curve, and similarity of two spectral vectors can be replaced by that of two polygons. Area of spectral polygon was used as quantification function and some effective indexes for similarity and dissimilarity were computed. The second method was to transform the original spectral vector to encoding vector according to absorption or reflectance feature bands, and similarity measure was conducted to encoding vectors. It proved that the spectral polygon-based approach was effective and can be used to hyperspectral RS image retrieval.
{fenge}
1642297278	Natural color image segmentation using integrated mechanism	A new method for natural color image segmentation using integrated mechanism is proposed in this paper. Edges are first detected in term of the high phase congruency in the gray-level image. K-mean cluster is used to label long edge lines based on the global color information to estimate roughly the distribution of objects in the image, while short ones are merged based on their positions and local color differences to eliminate the negative affection caused by texture or other trivial features in image. Region growing technique is employed to achieve final segmentation results. The proposed method unifies edges, whole and local color distributions, as well as spatial information to solve the natural image segmentation problem. The feasibility and effectiveness of this method have been demonstrated by various experiments.
{fenge}
16644384812	Universal method for camera calibration in UITS scenes	A universal approach to camera calibration based on features of some representative lines on traffic ground is presented. It uses only a set of three parallel edges with known intervals and one of their intersected lines with known slope to gain the focal length and orientation parameters of a camera. A set of equations that computes related camera parameters has been derived from geometric properties of the calibration pattern. With accurate analytical implementation, precision of the approach is only decided by accuracy of the calibration target selecting. Final experimental results have showed its validity by a snapshot from real automatic visual traffic surveillance (AVTS) scenes.
{fenge}
19644375651	Gaussian kernel density estimation-based background modeling with noise and shadow suppression	A multimodal nonparametric background model is proposed to detect moving objects by background subtraction. In outdoor surveillance systems, the solution to some of the problems such as illumination changes, initialization of model with moving objects, and shadows are provided. The Gaussian kernel density estimation is exploited to estimate the probability density function of background intensity and to initially classify each pixel as belonging to background or candidate foreground. Pixel's neighbor information is considered to remove noise due to camera jitter and small motion in the scene. The Hue-Max-Min-Diff (HMMD) color information is used to detect and suppress moving cast shadows. That decreases the false positive in object detection. Experimental results demonstrate the robustness to noise and shadow and good detection performance, and it can be used in outdoor environment surveillance systems.
{fenge}
19644390638	Extraction and recognition of characters in images from industrial containers	Character extraction and character recognition in industrial containers are introduced. First, at the stage of character extraction, two approaches of character extraction and complementary Ostu method are proposed. Second, at the stage of recognition, for the first type of characters, TM moments and affine moment invariants are used to extract features respectively and the features are combined into a vector. Then the normalized cross correlation is utilized as the classification technique. For the second type of characters, template matching and cross correlation classifiers based on TM moments and Hu moments are used to recognize characters. To improve the performance of classifiers, voting principle is utilized to combine the results of three individual classifiers. Finally, a series of experiments are made and experimental results show that the proposed scheme is feasible and reasonable.
{fenge}
18744412933	Information characteristics and band combination of landsat TM RS image used to terrestrial surface evolution in mining area	Landsat TM image is the most popular and universal RS information source, and got wide uses in different fields such as resource investigating, environment monitoring, urban planning, disaster preventing and as on. Although TM image has got wide applications, its use in mining area is still in experiment and beginning stage because mining area is a kind of special and complex geographic region. One of the most important issues is to study the information characteristics and determine the most effective band combinations oriented to given region and task.
{fenge}
19744378664	A metasynthetic approach for segmenting handwritten Chinese character strings	In this paper, a metasynthetic method is proposed to segment handwritten Chinese character strings. The Viterbi algorithm is firstly applied to search segmentation paths and several rules are used to remove redundant paths. Then a background-thinning method is further adopted to obtain non-linear segmentation paths. If there are not touching characters, a dynamic programming algorithm is applied to merge components. For touching characters, we apply background and foreground information to obtain candidate segmentation paths and the feature vectors are constructed in terms of peripheral features. Then the mixture probabilistic density function whose parameters are obtained by the EM algorithm is used to choose the best segmentation path. Experimental results demonstrate that the proposed scheme effectively segments handwritten Chinese characters and achieves an improvement over previous methods. © 2004 Elsevier B.V. All rights reserved.
{fenge}
21844450462	Noise reduction algorithm using area and shape suppression in vehicle detection	Vehicle detection is one of the key technologies in Intelligent Transportation System (ITS), and it is an important stage of vehicle tracking in visual surveillance. Due to the clutter of traffic scenes, the captured video sequence has a lot of noise with significant size. This paper defines the non-objects shape and area suppression according to human vision, and proposes a new noise-removing algorithm. In order to improve the compute efficiency, this paper modifies the sequential algorithm to reduce the computational complexity. Experimental results show that this algorithm is effective and efficient in extracting the moving vehicles in clutter scene.
{fenge}
24144465847	Phase transitions in a new car-following traffic flow model	In this paper, we investigate the performance of the well-known optimal velocity car-following model (the OVM) with numerical simulation in describing the acceleration process that is induced by the motion of a leading car with a pre-specified speed profile. Results show that this model is to some extent deficient in performing this process. Modification of the OVM to overcome the deficiency is demonstrated. The linear stability for the modified model is analysed. If the linear stability condition can not be satisfied, phase transitions occur on varying the initial homogeneous headway of the traffic flow. © 2005 Chin. Phys. Soc. and IOP Publishing Ltd.
{fenge}
24344470214	Analysis of error sources for SAM and its improvement algorithms	Based on the analysis of the error sources for spectral angle mapping (SAM), several key elements are pointed out, i.e. the change of wave band location, the change of the attribution ratio, the random change of attribution, and the whole translation of wave band. After the above-mentioned four error sources are analyzed, the authors present several improvement algorithms, viz. calculating the spectral angle with grouping, normalization and intersection. The grouping method can resolve the pseudo-similar problem, because it considers both spectral global features and local features. Calculating spectral angle with normalization restrains those random errors in original data by normalizing the spectral vectors. The intersection method can eliminate the error elicited by the whole wave translation. Therefore, it can be employed to correctly identify spectral class. Experiments show that those improvement algorithms are effective and can be used to process spectral data with errors.
{fenge}
23844472675	Yawning detection for determining driver drowsiness	A system aiming at detecting driver drowsiness or fatigue on the basis of video analysis is presented. The focus of this paper is on how to extract driver yawning. A real time face detector is implemented to locate driver's face region. Subsequently, Kalman filter is adopted to track face region. Further, mouth window is localized within face region and degree of mouth openness is extracted based on mouth features to determine driver yawning in video. The system will reinitialize when occlusion or miss-detection happen. Experiments are conducted to evaluate the validity of the described method. © 2005 IEEE.
{fenge}
27644436524	Robust initialization of level set methods using two-way fast marching	Level Set methods are efficient and robust numerical tools for resolving curve evolution. The paper focuses on two problems while implementing Level Set methods, i.e., how to differentiate between the inward and outward of a shape-arbitrary closed 2D curve, and how to efficiently re-initialize the Level Set Function. For this purpose, the paper firstly extend the Fast Marching methods proposed by Sethian to Two-Way Fast Marching, and based on which an effective approach to construction of the Signed Distance Function is then proposed. As an auxiliary tool for SDF construction, a simple labeling approach based on Fast Marching is developed to effectively tell between the inward and outward region of the closed 2D curve or 3D surface. At last, Region Labeling and SDF construction experiments prove that the two proposed methods are correct and simple, and two experiments of image segmentation using Level Set initialized with the proposed robust initialization methods give satisfying results and show efficiency of the proposed approaches.
{fenge}
2942709920	Research on wavelet-based algorithm for image contrast enhancement	A novel wavelet-based algorithm for image enhancement is proposed in the paper. On the basis of multi-scale analysis, the proposed algorithm solves efficiently the problem of noise over-enhancement, which commonly occurs in the traditional methods for contrast enhancement. The decomposed coefficients at same scales are processed by a nonlinear method, and the coefficients at different scales are enhanced in different degree. During the procedure, the method takes full advantage of the properties of Human visual system so as to achieve better performance. The simulations demonstrate that these characters of the proposed approach enable it to fully enhance the content in images, to efficiently alleviate the enhancement of noise and to achieve much better enhancement effect than the traditional approaches.
{fenge}
3042735758	Compression of hyper-spectral images based on adaptive quantization	An approach for compression of hyper-spectral image based on spectral DPCM and wavelet is proposed. Fully considering non-stationarity in sub-bands, the step of classification in sub-bands is implemented, based on which adaptive predictors are designed to improve the efficiency of spectral decorrelation. Since different statistics appear in different classes, the algorithm adopts spatial varying uniform threshold quantizer (UTQ). Based on the research on rate-distortion characteristics of UTQ over the training samples with different probability density, a method for rate allocation is proposed, by which an optimal in R-D sense UTQ can be designed for each class of coefficients. The experiments show that the approach can efficiently compress hyper-spectral remote sensing images, and the excellent performance of the proposed algorithm is demonstrated.
{fenge}
3042752903	New segmentation model-combined Mumford-shah model with narrow band	A segmentation model that combines the Mumford-Shah (M-S) model and narrow band scheme of level set is presented. The M-S model is a desirable model for image segmentation, but computationally time-consuming. This paper introduces a fast segmentation model, which combines the M-S model and narrow band scheme using new initialization method. The initialization method is based on fast marching method, and the computing time is 0(n). In each iteration step, the segmentation model only deals with the data in narrow band instead of the whole image. Compared M-S model with the narrow band M-S, experiments show that the two models can obtain almost the same segmentation result, but the computing time of the narrow band M-S model is much less than M-S model.
{fenge}
3042814088	Spectral similarity measure based on fuzzy feature contrast model	In the famous feature contrast model (FCM), the similarity measure is a linear combination of the common (similar) features and the distinctive (dissimilar) features. Because of the combination, FCM is better than other similarity models in explaining human perception similarity. However, the feature of FCM is binary. By defining the fuzzy feature set, FCM is extended into fuzzy feature contrast model (FFCM). In this paper, we adapt FFCM to measure spectral similarity. A spectrum is represented as a set including two subsets. The two subsets are characterized by spectral reflectance and spectral absorption, respectively. Meanwhile, the spectral reflectance and absorption are defined as the common (similar) and distinctive (dissimilar) subset in spectral set, respectively. Our spectral similarity model is expressed as a linear combination of the common subset, distinctive subset and their interaction. The difference between our model and FFCM is interaction of two subsets is defined. Moreover, kernel principal component analysis (KPCA) is used to remove the high correlation among different bands before spectral similarity measure. Experiments show that our model is effective in spectral similarity measure. © 2004 Elsevier B.V. All rights reserved.
{fenge}
3042841133	New algorithm of sub-pixels image matching	This paper discusses a algorithm of sub-pixels image matching and analyzes the characteristics of resampling and surface fitting methods. In order to meet the matching demands and alleviate the computation workload, the following improvement algorithms are used. First, resample the model re-times, put out (2n-l) sub-models, and calculate the NCs between each sub-model and image. Then choose the maximum between the sub-model and the displacement corresponding to this sub-model which requires the sub-pixel displacement. Finally, put forward a algorithm that combines the resampling with surface fitting methods. Experimental results show the validity of the algorithm.
{fenge}
32544458804	Robust kernel discriminant analysis and its application to feature extraction and recognition	Subspace analysis is an effective technique for dimensionality reduction, which aims at finding a low-dimensional space of high-dimensional data. In this paper, a novel subspace method called robust kernel discriminant analysis is proposed for dimensionality reduction. An optimization function is firstly defined in terms of the distance between similar elements and the distance between dissimilar elements, which can preserve the structure of the data in the mapping space. Then the optimization function is transformed into an eigenvalue problem and the projection vectors are obtained by solving the eigenvalue problem. Finally, experimental results on face images and handwritten numerical characters demonstrate the effectiveness and feasibility of the proposed method. © 2005 Elsevier B.V. All rights reserved.
{fenge}
33645139095	Non-gyroscope DR and information fusion algorithm used in RDSS/DR device	This paper introduces homemade Beidou satellite navigation and positioning system. In view of the problems existing in the system, a RDSS/DR integrated navigation device is designed. The operating principle and the algorithm of the device are also presented. By operating measured data synthetically, linear observation equation is obtained for the navigation algorithm. This approach avoids model error due to linearizing nonlinear observation equation in the conventional algorithm, so that the stability of navigation algorithm is improved and computation expenses are reduced. Field running experiments show that satisfactory accuracy can be obtained by the proposed navigation model and algorithm for the vehicular RDSS/DR integrated navigation system without gyroscope.
{fenge}
33645452766	Kernel uncorrelated discriminant analysis and its application to handwritten character recognition	Based on uncorrelated discriminant analysis, kernel uncorrelated discriminant analysis is developed. However, computing kernel uncorrelated vectors is computationally expensive due to the utilization of kernel functions. In order to overcome this problem, an effective method for solving kernel uncorrelated discriminant analysis is proposed in this paper. Firstly, the proposed algorithm smartly uses the decomposition of matrices. Then the generalized singular value decomposition on the matrix pair is carried out. At the same time, several related theorems are proposed. Most importantly, the proposed method can overcome the singular problem of matrices in kernel uncorrelated discriminant analysis. In some sense, the proposed method extends existing methods, namely, from linear problems to non-linear problems. Finally, experimental results on handwritten numeral characters show that the proposed method is effective and feasible.
{fenge}
33646514451	Image similarity measures based on weak semantic embedding	To bridge the semantic gap, a novel approach that weak semantic features are embedded into visual features is proposed. Moreover, a novel similarity model is employed to measure the similarity between two images with both semantic and visual features. In interactive image retrieval, similar images are defined as weak semantic features and embedded into the feature vector of the querying image. Therefore, the fixed visual feature vector becomes an expandable feature set, which integrates semantic and visual features. Based on the set-theoretic similarity, the similarity between two images is expressed as the ratio of the measures of semantic features to those of visual features. Experimental results, over Corel image collections, show that the approach is effective in content-based image retrieval.
{fenge}
33744746297	A fast method on locating and segmentation of vehicle plate based on gray image	Based on related characteristics of the horizontal and vertical difference results of gray image, a method to obtain location and segmentation of vehicle plate under complicated traffic background is produced. At first, image noise is filtered by mid-filter after the process of histogram equalization, then candidates of vehicle plate are coarsely segmented by filtering scan line length orderly in the horizontal and vertical directions of the binary image after the operation of horizontal dilation, the precise positions of vehicle plate in the horizontal and vertical directions are selected out among the plate candidates at last according to the related characteristics of scanning projection of the difference image in the vertical direction. With less restriction on background complexity of the image and the plate position, the presented method can be applied with simple and fast implementation, whose validity is proved by the experimental result.
{fenge}
33747429367	Non-gyroscope DR and adaptive information fusion algorithm used in GPS/DR device	In view of the problems existing in GPS, a non-gyroscope DR is introduced. The operating principle and the algorithm of the GPS/DR device are also presented. By operating measured data synthetically, linear observation equations are obtained for the information fusion algorithm. This approach avoids model error due to linearizing nonlinear observation equations in the conventional algorithm, so that the stability of information fusion algorithm is improved and computation expenses are reduced. Field running experiments show that satisfactory accuracy can be obtained by the proposed navigation model and algorithm for the non-gyroscope GPS/DR device.
{fenge}
33749241176	Handwritten Bangla numeral recognition system and its application to postal automation	A recognition system for handwritten Bangla numerals and its application to automatic letter sorting machine for Bangladesh Post is presented. The system consists of preprocessing, feature extraction, recognition and integration. Based on the theories of principal component analysis (PCA), two novel approaches are proposed for recognizing handwritten Bangla numerals. One is the image reconstruction recognition approach, and the other is the direction feature extraction approach combined with PCA and SVM. By examining the handwritten Bangla numeral data captured from real Bangladesh letters, the experimental results show that our proposed approaches are effective. To meet performance requirements of automatic letter sorting machine, we integrate the results of the two proposed approaches with one conventional PCA approach. It has been found that the recognition result achieved by the integrated system is more reliable than that by one method alone. The average recognition rate, error rate and reliability achieved by the integrated system are 95.05%, 0.93% and 99.03%, respectively. Experiments demonstrate that the integrated system also meets speed requirement. © 2006 Pattern Recognition Society.
{fenge}
33750508505	The theoretical analysis of GLRAM and its applications	Matrix-based methods such as two-dimensional principal component analysis (2DPCA) and generalized low rank approximations of matrices (GLRAM) have gained wide attention from researchers due to their computational efficiency. In this paper, we propose a non-iterative algorithm for GLRAM. Firstly, the optimal property of GLRAM is revealed, which is closely related to PCA. Moreover, it also shows that the reconstruction error of GLRAM is not smaller than that of PCA when considering the same dimensionality. Secondly, a non-iterative algorithm for GLRAM is derived. And the proposed method obtains smaller reconstruction error than 2DPCA or GLRAM. Finally, experimental results on face images and handwritten numeral characters show that the proposed method can achieve competitive results with some existing methods such as 2DPCA and PCA in terms of the classification performance or the reconstruction error. © 2006 Pattern Recognition Society.
{fenge}
33750029701	Extracting image features based on psychologic evidence	Extracting the features from the image data is one of the most important issues in image pattern recognition, the approaches dealing with the issue usually depends on how well one know of a specific object; but a man with his vision system deals with the same issue in a more general or universal way. In this paper, the global property based on the psychologic evidence of vision system is discussed at first and then the statistics method that make local original signal into global feature, afterwards to represent the feature a universal scheme MSR (multi-resolution statistics representation) is given by Lebesgue integrate of signal and uncertainty principle, finally the experimental evidences support that MSR is an efficient approximation and also suitable for parallel calculation.
{fenge}
33845757136	Efficient iris recognition system	In recent years, iris recognition has become a pro-active topic in both research and practical applications. In general, a typical iris recognition system includes iris preprocessing, feature extraction, and recognition. In this paper, an efficient iris recognition system is illustrated. The major procedure includes three steps: 1) the geometrical method is used to localize the pupil; 2) in order to reduce computational cost, the outer (or limbus) boundary is localized using the shrunk image with the Hough transform and modified Canny edge detector; 3) Log-Gabor filter is adopted to capture local and global characteristics of the iris. The phase of the filtered iris is recorded as features. The proposed method is implemented and tested on two iris database sets, i. e CASIA and SJTU-IDB, with different contrast quality. The experimental results show that the performance of the proposed method is encouraging.
{fenge}
35348852616	Efficient iris recognition system based on iris anatomical structure	The global rising security concerns propel growth of biometrics recognition techniques. Iris recognition is widely regarded as one of the most promising biometrics methods because of its high accuracy. Among the whole iris recognition process, how to capture the significant features in the iris pattern and to encode them efficiently is a hard task. In this paper, an innovative method is proposed to extract iris features according to iris anatomical structure characteristics. The proposed method can represent the iris pattern with less redundancy and moreover less computational demanding than traditional methods. © IEICE 2007.
{fenge}
37549026880	Efficient greedy algorithm for schema matching	Schema matching is the task of finding semantic correspondences between elements of two schemas, which plays a key role in many database applications, such as data integration, electronic commerce, data warehouse, semantic query processing, and XML message exchange, etc. Especially, it is a basic research issue in metadata management. Unfortunately, it still remains largely a manual, labor-intensive, and expensive process. In this paper, the schema matching problem is treated as a combinatorial problem. Firstly, schemas are transformed into multi-labeled graphs, which are the internal schema model for schema matching. Therefore, the schema matching problem is reduced to the labeled graph matching problem. Secondly, a generic graph similarity measure is discussed, which uses the labels of nodes and the edges to compute the similarity between the two schemas. Then, an objective function based on the multi-labeled graph similarity is proposed. Based on the objective function, a greedy matching algorithm is designed to find the desired matching state for schema matching. A prominent characteristic of this method is that the algorithm combines the feasible matching information to obtain optimal matching. Finally, some schema samples are used to test the greedy matching algorithm. The test results confirm that the algorithm is effective, which can obtain mapping results with high quality.
{fenge}
0033704698	Fuzzy space based segmentation algorithm on periosteum medical image processing	Object description in medical image often has the property of fuzziness, and with the development of computing, fuzzy logical theories are progressively used in medical image processing. Color medical images differ in spatial presentation and fuzzy description from grey-scale images and must be analyzed by special methods. In this paper, a new method of bone cell segmentation based on fuzzy logical theories is presented. With the utilization of fuzzy set theories in the steps of color enhancing, feature extraction and automatical segmentation, bone cells are detected from the background. The method has the advantages of high accuracy and flexibility to many situations. Experiments of bone cell images have proved that it is a fast and effective method.
{fenge}
0034186316	Recognition of handwritten numerals based on compression of sub-structural features	A set of sub-structural features was proposed for handwritten numeral recognition by analysing numeral structure. Some features which are changeable for different person were substituted for others who only relied on relative location among the strokes. The features given in this paper are less changeable in contrast with others by stressing on the numeral topology information. To avoid matching the troublesome rule, every numeral was described as a matrix which every row stands for a sub-structural feature vector. As the pattern described by sub-structural feature is of strong classification, the feature can be compressed by the matrix operation. There exists the same dimension in all patterns. It allows an easy pattern matching by structure-changeable neural network, The experiments show that the correct recognition rate is about 97.58%.
{fenge}
0034866027	Mosaic and warping for forward moving images	This paper researches mosaic and warping for forward motion-forward moving images (FMI). In FMI, the field of view of front frame is wider than that of latter one, however the resolution of the latter frame is higher than that of front one. The algorithms of warp functions based respectively on mesh warp and triangle grid are presented. And a multiresolution mosaic based on wavelet transform is given. In-between images could be warped form the single mosaic image. The experiment of real scene shows that the algorithm of mesh warp is time consuming than that of triangle grid, beet the image quality of the latter is better than that of the former. It also shows that the multiresolution mosaic image is smooth and nature, eliminating the impact of seam.
{fenge}
0034920159	Software research of vision system in robot soccer system	Because the size of the robot is small and its response is fast in the small league robot-soccer system, the vision software system needs fast and exactly processing of the image data and provides the result to the decision system. The functions of detection, recognition, tracking and prediction of the robots and the ball in the vision software system are realized by using the technique of image processing together with statistical signal processing. The details about the design of software system are presented. Experimental results show that the system runs stably, its velocity can reach 40 frames/s and the delay time is 0.025 s.
{fenge}
0034934942	Detection and removal of base lines from document images	Fast Hough transform is utilized to detect base lines from document images. Feature points taken from the image are divided into two subsets, from which two feature points are selected respectively to compute parameters in Hough space. A threshold is set such that any bin exceeding the threshold means the evidence of the reference line and the detection will stop. The proposed Hough transform can be implemented at fast speed with practical value. The base line is removed by using mathematical morphology operation, while the structural element is decided according to the width of the base line and the intersectional stroke. Character strokes are protected while the base line is removed. Experimental results with envelope images show that the present method can detect and remove base lines effectively.
{fenge}
84897902098	A dam crack image enhancement algorithm based on underwater biological vision	In view of the characteristics such as non-uniform brightness, low signal to noise ratio as well as the low contrast of the underwater dam crack image, this paper brings up a novel dam crack image enhancement algorithm, which adopts the simulation of underwater biological vision. With reference to the brightness adjustment characteristics of the biological vision, this algorithm also improves the non-uniform brightness of underwater dam crack image. Furthermore, in order to improve the low signal-to-noise ratio and solve the problem of low contrast of dam crack image, on the basis of lateral inhibition enhancement mechanism of the "horseshoe crab fish", we introduce the adaptive asymmetric narrow strip guidance models, which can help to enhance the linear characteristics of the crack image. The theoretical and the experimental results got from this paper show that the proposed algorithm can significantly eliminate the noises of the underwater image, and also better improve the definition of the image from the physical standpoint. And at the same time, by strengthening the edges of crack image and enhancing the subtle liner structures of interest in the crack image, this algorithm improves the contrast of the interesting areas, which is of great significance for the subsequent crack feature extraction.
{fenge}
4544234213	Face detection based on Kernel Fisher Discriminant analysis	This paper presents a face detection method based on Kernel Fisher Discriminant analysis (KFD). Kernel based methods have been extensively investigated both in theories and applications, such as SVM and Kernel PCA. Using the kernel trick, Linear Fisher Discriminant can be extended to non-linear case. Since the distribution of face patterns is very complex and highly nonlinear, using non-linear classification tools can hopefully tackle the problem of face detection. We explore the application of KFD in the task of frontal face detection. The experimental results prove the effectiveness of KFD in the face detection problem.
{fenge}
5044252974	New approach for lossless image compression based on fuzzy adaptive prediction	This paper proposes a novel approach for image lossless compression based on fuzzy logic and adaptive prediction. By a flexible strategy, the method can acquire a set of original predictors describing the more detail characteristic. Using a neural network, the proposed method can more efficiently organize the training of original predictors and implement adaptive prediction in fuzzy style. In entropy coding phase, the context-based conditional adaptive arithmetic encoding is adopted. The experiments demonstrate the characteristics make the approach achieve good tradeoff between computational complexity and efficiency of prediction and good performance for lossless compression.
{fenge}
5144225099	Robust watermarking scheme with side information and template matching mechanism	Digital watermarking has been proposed for the copyright protections of multimedia products. In this paper, a robust and blind watermarking scheme is presented. The concept of communication with side information is applied at the encoder to improve the probability of detection within acceptable fidelity, while the template matching technique is employed to estimate the undergone attacks in attacking channel. This scheme is optimized by the optimal design of the encoder to match with the media content and the decoder to adapt to the attack channel state. Experiments show that our method is robust against some common attacks such as filtering, compression, rotation, scaling, cropping and translation. It can be applied to both color and gray images.
{fenge}
5144225283	Three-dimensions volume reconstruction of grayscale serial slice images	This paper focuses on basic geometric and topological access methods, and computational operations implemented by various data objects. It covers such methods as inter-slices point matching, stream slices, sorting of octree blocks, cell operations and experimental results. At first, this paper discusses in detail the feature points matching of inter-slices. Then it introduces stream slices eigenfields and octree data structures theories. Next, it discusses cell operations and its data structure. Finally, it shows an experimental result. The innovations in the paper is the data structure of slices feature and cell feature, and the feature matching methods owns the properties both quickly and exactly.
{fenge}
5144230330	Natural color image segmentation based on phase congruency and region growing	A new method for meaningful regions segmentation in natural color image is proposed in this study. After edge detecting in term of phase congruency, long edge lines are clustered using K-means algorithm based on the joint distribution of their color in image space and in color space to get meaningful seeds, while short ones are merged to eliminate the negative affection causing trivial features in images. Region growing technique is employed in color space to achieve the final segmentation results with the properly selected seeds. The proposed method overcomes the disadvantage of traditional region growing method, and applies it to color images. The meaningful segmentation results are consistent with those executed by people and have shown feasibility and effectiveness to various natural color images.
{fenge}
51449085302	A novel classifier for handwritten numeral recognition	This paper presents a novel pattern classification approach - a kernel and Bhattacharyya distance based classifier which utilizes the distribution characteristics of the samples in each class. Bhattacharyya distance in the subspace spanned by the eigenvectors which are associated with the smaller eigenvalues in each class is adopted as the classification criterion. The smaller eigenvalues are substituted by a small value threshold in such a way that the classification error in a given database is minimized. Application of the proposed classifier to the issue of handwritten numeral recognition demonstrates that it is promising in practical applications. ©2008 IEEE.
{fenge}
52449126241	An algebraic framework for schema matching	It is well known that a formal framework for the schema matching problem (SMP) is important because it facilitates the building of algorithm model and the evaluation of algorithms. An algebraic framework for schema matching is developed in this paper. First, based on universal algebra, we propose a meta-meta structure for schema, which is named multi-labeled schema. This definition has a distinctive feature: it is able to formally describe any particular style of schemas, and transforms a schema and other available information into a finite structure over specific signature. Later, we introduce a formal definition of schema matching that is called multivalent matching. Then, we formulize SMP as a schema homomorphism problem, and prove that SMP is equivalent to finding a semantic homomorphism from one schema to another. These results lead to the main contribution of this paper: an algebraic framework for SMP. This framework builds the algorithm model for SMP. Thirdly, we show a classification of schema matching based on the algebraic framework. Finally, we discuss the relations between matching cardinality and subclasses of schema homomorphism. © 2008 Institute of Mathematics and Informatics.
{fenge}
54249109922	Computerized matching of shoeprints based on sole pattern	Shoeprints are common clues left at crime scenes that provide valuable evidence in detecting criminals. Traditional shoeprints matching algorithm is based on manual coding with limited recognition ability, and the results are strongly dependent on the operator. In this paper, a shoeprint matching method based on PSD (power spectral density) and Zernike moment have been investigated. The PSD method aims at pressing images and the legible shoeprints. The correlation coefficients of the PSD value of each image are used as the measurements of similarity. In addition, the Zernike method has been developed for blurred crime scene shoeprint images and shoeprints with complex backgrounds. A series of irregular shapes are employed to identify the shoeprints. Features are then selected according to the Zernike moments of these shapes. More than 400 real shoeprint images have been tested, experimental results support that the method is effective in shoeprint matching. © 2008 Springer-Verlag Berlin Heidelberg.
{fenge}
67649583326	Fusion of multiple facial regions for expression-invariant gender classification	A novel gender classification method is presented which fuses information acquired from multiple facial regions for improving overall performance. It is able to compensate for facial expression even when training samples contain only neutral expression. We perform experimental investigation to evaluate the significance of different facial regions in the task of gender classification. Three most significant regions are used in our fusion-based method. The classification is performed by using support vector machines based on the features extracted using two-dimension principal component analysis. Experiments show that our fusion-based method is able to compensate for facial expressions and obtained the highest correct classification rate of 95.33%. © IEICE 2009.
{fenge}
70349205671	A novel fusion-based method for expression-invariant gender classification	In this paper, we propose a novel fusion-based gender classification method that is able to compensate for facial expression even when training samples contain only neutral expression. We perform experimental investigation to evaluate the significance of different facial regions in the task of gender classification. Three most significant regions are used in our fusion-based method. The classification is performed by using support vector machines based on the features extracted using two-dimension principal component analysis. Experiments show that our fusion-based method is able to compensate for facial expressions and obtained the highest correct classification rate of 95.33%. ©2009 IEEE.
{fenge}
70449357004	Discriminative canonical correlation analysis with missing samples	Multimodal recognition emerges when the nonrobustness of unimodal recognition is noticed in real applications. Canonical correlation analysis (CCA) is a powerful tool of feature fusion for multimodal recognition. However, in CCA, the samples must be pairwise, and this requirement may not easily be met due to various unexpected reasons. Additionally, the class information of the samples is not fully exploited in CCA. These disadvantages restrain CCA from extracting more discriminative features for recognition. To tackle these problems, in this paper, the class information is incorporated into the framework of CCA for recognition, and a novel method for multimodal recognition, called discriminative canonical correlation analysis with missing samples (DCCAM), is proposed. DCCAM can tolerate the missing of samples and need not artificially make up the missing samples so that its computation is timesaving and space-saving. The experimental results show that 1) DCCAM outperforms the related multimodal recognition methods; and 2) the recognition accuracy of DCCAM is relatively insensitive to the number of missing samples. © 2008 IEEE.
{fenge}
70449387284	Gender classification of facial images based on multiple facial regions	In this paper, we describe an experimental investigation to evaluate the significance of different facial regions of a person in the task of gender classification. For this purpose we use a Support Vector Machine (SVM) classifier on face images for gender classification. We perform experiments using different facial regions of varying resolution so that the significance of facial regions in this application can be assessed. According to the results obtained, the upper region of the face proved to be the most significant for the task of gender classification. Moreover, the changes in the resolution of the facial region images do not produce significant changes in the result. Based on the significance of different facial regions, we propose a gender classification method based on fusion of multiple facial regions and show that this method is able to compensate for facial expressions and lead to better overall performance. © 2008 IEEE.
{fenge}
0035169281	Constrained quantization algorithm for color images	In this paper, we discuss two kinds of VQ algorithms. One is based on minimizing the total variance and the other is based on minimizing the maximum deviation. The algorithms of the first kind better reflect overall fit, but may discount large, but highly localized deviations. Those of the second kind provide absolute distance bounds that are a useful error guarantee, but may be overly sensitive to any noise that might be present in the original models. A new algorithm, combining the two criteria, is presented in this paper. It not only improves the total variance, but also provides a useful maximum error guarantee. The experiments indicate the new quantizer is a better choice in some practical operations.
{fenge}
0035261690	Improved partial differential equations smoothing method	As a cornen in an image is rounded when using degenerate diffusion equation to smooth the image, the paper proposed a way to use both the gradient and the second order directional derivative in the direction orthogonal to the gradient to control the diffusion velocity. This diffusion velocity is about zero at the corner position. At the position of the edge it is dominated by the gradient, and the smoothing is executed on the direction orthogonal to the gradient. In the area where the intensity of the image is changed little, the image is smoothed by the heat equation whose conduction coefficient is constant. A method was given to construct the diffusion velocity in theory. Experiment shows that this method is valid on the image smoothing while preserving the features.
{fenge}
0035261704	Selection of suitable matching area by fractal based approach for high precision location	In the scene matching based robot or flight vehicle navigation system, the pre-loaded reference images are compared with the real-time acquisition images by correlation method for position locating. And it is important to choose most distinguishable scenes as the suitable-matching area (SMA) for high precision location. This paper addressed the close relation between the fractal dimension (FD) and the correlate coefficient of the matched image, that is, the greater the FD is, the less relative the image data. Thus, it suggested a method based on FD of the image to select SMA from the reference image, which is critical for navigation. The experiments prove that the proposed method has the advantages of accurate and reliable extraction of the SMA from the reference images, and high computational efficiency.
{fenge}
0035261795	Restricted Rough lattice-based implication rules discovery	An efficient algorithm was found to discover the implication rules in a data set. As an important data mining technique, the implication rules can help to explore the dependencies among values of attributes of a database. The algorithm extends the concept lattice theory by building a simplified lattice structure according to the data set with the restricted attributes to improve human interaction and mining efficiency. The constrained concept lattice, together with the rough set theory, is then incorporated into the method to implement a new restricted rough lattice-based implication rules discovery (RRLIRD) approach to interactively acquire the rules with specific rough upper and lower approximation. The algorithm is different from the classical rule extraction methods without computing the frequent item sets. For the application to the transaction data set of large-scale supermarkets, a simulation was implemented to demonstrate that the approach can reduce the computational time greatly comparing with that of Apriori algorithm. The algorithm can also be extended to other areas such as stock analysis and agricultural application.
{fenge}
0035322197	Efficient dynamic conceptual clustering algorithm for data mining	A new criterion function based on semantic distance is proposed, and a novel domain-based dynamic conceptual clustering algorithm (DDCA) is also presented. With the discretization of the continuous attribute values, it works well on the datasets that are described by mixed numerical attributes and categorical attributes. The algorithm automatically determines the number of clusters, modifies the demoid according to the frequency of the attribute values within each cluster and gives out the interpretations of the clustering with the conceptual complex expression. The experiments demonstrate that the semantic-based criterion function and the domain based dynamic conceptual clustering algorithm are effective and efficient.
{fenge}
74549181144	Receptive field of visual cortex works follow multi-resolution statistics?	How does man's vision system work? In some cross research fields like neurobiology, psychology and robotics researchers have been work hard to answer the question for long time. Now on visual cortex neuroscience has accumulate much experimental data and some theories like information redundancy reduction, sparse coding have given their interpretation of experiments, but understanding information processing as a whole, especially to make a representation of image with basic conceptions of receptive field and direction column, is still a difficult task. In our work, together with consideration of psychology and sparse coding a multi-resolution statistics scheme is given, signal grads statistics is carried out according to resolution level, strength and direction in space respectively. By comparing the distribution of nerve cell on visual cortex with one of neural network which works follow multi-resolution statistics, the similarity of both tell the arithmetic meanings of receptive field and direction column. With modern neuroscience experimental means the validation of the point of view in this article may be done in principle. ©2009 IEEE.
{fenge}
77950913048	Scaffold modeling application in the repair of skull defects: Thoughts and progress	The repair of large segmental bone defects caused by trauma, inflammation, and surgery on tumors pose a major clinical challenge. Tissue-engineered bone is emerging as a good choice for prefabricating cellular scaffold, and computer-aided technologies and medical imaging have created new possibilities in biomedical engineering. An accurate and efficient construction of anatomic models is critical to the application of these computational methods. Such models must be validated prior to application. In this article, we explore the potential of combining these techniques to scaffold and repair a pediatric skull. Working under the hypothesis that the autogenously cultivated osteoblasts can be grown on individualized scaffolds to improve bone regeneration in skull defects, we focus our study on potential problems concerning the segmentation, reconstruction, and mesh simplification for a pediatric skull. We also propose a new framework to improve the accuracy of the model entity from image segmentation to mesh simplification. © 2010, International Center for Artificial Organs and Transplantation and Wiley Periodicals, Inc.
{fenge}
77952612928	A fusion-based method for 3D facial gender classification	In this paper, we propose a novel fusion-based gender classification method for 3D frontal neutral expression facial shape. Face landmarks, extracted from 3D face shape based on profiles and curvature, are separated as four regions. Experimental investigation to evaluate the significance of different facial regions in the task of gender classification is performed. The classification is performed by using Support Vector Machines (SVMs) based on the feature of regions. Classification results show that the upper region of face contains the highest amount of gender information. Matcher weighting fusion method is also applied to fusion the classification result of four regions. Experimental results demonstrate that fusing multiple facial features can achieve highest correct classification rate to 94.3%. ©2010 IEEE.
{fenge}
77955787264	Wearable accelerometer based extendable activity recognition system	Recognizing the human activities of daily living (ADL) is an important research issue in the pervasive environment. Activity recognition is treated as a classification problem and the multi-class classifier is often used. Though the multi-class classifier can obtain high classification accuracy, it can not detect the noise activities and unknown activities, and the system has no extendable recognition capability. In this paper, we proposed a recognition system which can recognize known activities and detect unknown activities simultaneously. For each known activity, one one-class classification model is built up and the combined one-class classification models are used to judge whether a test sample belongs to known activities. For the known samples, the multi-class classifier is used to recognize their types. For the continuous unknown samples, based on segmentation algorithm, training samples of new activities are extracted and added into the recognition system to extend the system's recognition capability. ©2010 IEEE.
{fenge}
77955498380	Segmentation, surface rendering, and surface simplification of 3-D skull images for the repair of a large skull defect	Given the potential demonstrated by research into bone-tissue engineering, the use of medical image data for the rapid prototyping (RP) of scaffolds is a subject worthy of research. Computer-aided design and manufacture and medical imaging have created new possibilities for RP. Accurate and efficient design and fabrication of anatomic models is critical to these applications. We explore the application of RP computational methods to the repair of a pediatric skull defect. The focus of this study is the segmentation of the defect region seen in computerized tomography (CT) slice images of this patient's skull and the three-dimensional (3-D) surface rendering of the patient's CT-scan data. We see if our segmentation and surface rendering software can improve the generation of an implant model to fill a skull defect. © 2009 SPIE and IS&T.
{fenge}
77956493517	Facial expression recognition on multiple manifolds	Manifold learning has been successfully applied to facial expression recognition by modeling different expressions as a smooth manifold embedded in a high dimensional space. However, the assumption of single manifold is still arguable and therefore does not necessarily guarantee the best classification accuracy. In this paper, a generalized framework for modeling and recognizing facial expressions on multiple manifolds is presented which assumes that different expressions may reside on different manifolds of possibly different dimensionalities. The intrinsic features of each expression are firstly learned separately and the genetic algorithm (GA) is then employed to obtain the nearly optimal dimensionality of each expression manifold from the classification viewpoint. Classification is performed under a newly defined criterion that is based on the minimum reconstruction error on manifolds. Extensive experiments on both the CohnKanade and Feedtum databases show the effectiveness of the proposed multiple manifold based approach. © 2010 Elsevier Ltd. All rights reserved.
{fenge}
77956802925	Sexual dimorphism analysis and gender classification in 3D human face	In this paper, we present the sexual dimoiphism analysis in 3D human face and perform gender classification based on the result of sexual dimorphism analysis. Four types of features are extracted from a 3D human-face image. By using statistical methods, the existence uf sexual dimorphism is demonstrated in 3D human face based on these features. The contributions of each feature to se.xual dimorphism are quantified according to a novel criterion. The best gender classification rate is 94% by using SVMs and Matcher Weighting fusion method.This research adds to the knowledge of 3D faces in sexual dimorphism and affords a foundation that could be used to distinguish between male and female in 3D faces. Copyright © 2010 The Institute of Electronics, Information and Communication Engineers.
{fenge}
78650199326	Gender recognition based on face features	A novel gender classification method based on frontal face images is presented. In the method, the global features are extracted by using an AdaBoost algorithm. The active appearance model (AAM) locates 83 landmarks, from which the local features are characterized. After the fusion of the local and global features, the mixed features are used to train support vector machine (SVM) classifiers. The method is evaluated by the recognition rates over a mixed face database containing over 14700 images from 4 sources (AR, FERET, WWW and a database collected by the lab). Experimental results show that the hybrid method outperforms the unmixed appearance-or geometry-feature based methods and achieves a classification rate over 90%.
{fenge}
78651568454	Recursive error-compensated dynamic eigenbackground learning and adaptive background subtraction in video	We address the problem of foreground object detection through background subtraction. Although eigenbackground models are successful in many computer vision applications, background subtraction methods based on a conventional eigenbackground method may suffer from high false-alarm rates in the foreground detection due to possible absorption of foreground changes into the eigenbackground model. This paper introduces an improved eigenbackground modeling method for videos by recursively applying an error compensation process to reduce the influence of foreground moving objects on the eigenbackground model. An adaptive threshold method is also introduced for background subtraction, where the threshold is determined by combining a fixed global threshold and a variable local threshold. A fast algorithm is then given as an approximation to the proposed method by imposing and exploiting a constraint on motion consistency, leading to about 50% reduction in computations. Experiments have been performed on a range of videos with satisfactory results. Performance is evaluated using an objective criterion. Comparisons are made with two existing methods. © 2008 Society of Photo-Optical Instrumentation Engineers.
{fenge}
79952123925	3D face landmarking method under pose and expression variations	A robust method is presented for 3D face landmarking with facial pose and expression variations. This method is based on Multilevel Partition of Unity (MPU) Implicits without relying on texture, pose, orientation and expression information. The MPU Implicits reconstruct 3D face surface in a hierarchical way. From lower to higher reconstruction levels, the local shapes can be reconstructed gradually according to their significance. For 3D faces, three landmarks, nose, left eyehole and right eyehole, can be detected uniquely with the analysis of curvature features at lower levels. Experimental results on GavabDB database show that this method is invariant to pose, holes, noise and expression. The overall performance of 98.59% is achieved under pose and expression variations.©2011 The Institute of Electronics, Information and Communication Engineers.
{fenge}
79955610899	Segmentation of connected handwritten Chinese characters based on stroke analysis and background thinning	Segmentation of connected handwritten Chinese characters is a very difficult task in document image analysis. In this paper, a novel algorithm based on stroke analysis and background thinning is proposed to segment connected handwritten Chinese characters. The feature points, viz. end points, fork points and corner points are detected in the thinned image. The segments between feature points are considered as substrokes and are extracted. Lengths of substrokes and the topological relations between them are employed to locate connected point. A new method based on background thinning is developed to decide a proper segmentation path. The experimental results show that satisfactory performance is achieved by the presented method for segmentation of connected handwritten Chinese characters. © Springer-Verlag Berlin Heidelberg 2000.
{fenge}
0035764153	Region based representations of image and motion estimation	In this paper, an image representation method based on arbitrary shaped regions, and motion estimation of the image sequence according to this representation of the image is proposed. In order to avoid over-segmentation, the initial frame in the image sequence is smoothed while edge of the image is preserved. The smoothing algorithm is the modification version of Alvarez's method. Then, the smoothed frame is segmented by the watershed method. According to the label image, the image is stored in the form of region adjacency graph. To further solve the problem of the over-segmentation, the merging criterions based on average region intensity and edge strength and region size are given. The affine transformation is used as motion model for each region, and the nonlinear least square method is used for the optimization. Compared with the method based on pixel, the result shows that the motion vectors produced by our algorithm are more consistent and the PSNR is improved.
{fenge}
0035766221	Wavelets for multiresolution image matching	This paper discussed the approaches of wavelets for multiresulition in image matching. Using the hierarchical structure of wavelet transform, the match process is from the coarsest level to the finest one, refining and condensing the field of matching. Two types of special wavelet transform are explored and compared respectively. For vector-valued wavelets, an improved model of multiresolution matching is constituted to match the successive images in the case of exiting only rotation and translation between images. For complex-valued wavelets, a modified algorithm is presented to match image which has project transform between adjacent frames. Experiments for two groups of image sequences show that vector-valued wavelets and complex-valued wavelets used for image matching are available.
{fenge}
0035766465	The algorithm of sub-pixels image matching with high accuracy	The algorithms to obtain sub-pixel accuracy in image matching was discussed. The resampling and surface fitting methods characteristics was analyzed. The following improvement was made to alleviate the computation burden: At first, only the model is needed to be resampled n-times; Next, (2*n-1) sub-models are generated; Again, the NCs among each sub-model and the image are calculated; At last, the maximum among the sub-model is chosen and the shifts corresponding to this sub-model are the sub-pixel displacement required. Then a new algorithm was proposed to combine the resampling and surface fitting methods. The effectiveness of the proposed algorithm was validated by the experiment.
{fenge}
0035768183	Robust initialization of level set method	Level set method is a numerical analysis tool for the computation of propagating interfaces. In order to accelerate and strengthen numerical implementations of level set method, this paper proposed a set of auxiliary algorithms, i.e., simplified scanning based distance function construction, curve inside and outside labeling algorithm, and scanning based extension of velocity. With the former two algorithms, the signed distance function used as level set function can be constructed faster and more accurate. And the last algorithm makes the curve evolution by level set method more robust. The numerical tests showed efficiencies of the proposed algorithms.
{fenge}
0035768186	A new technique for number plate recognition	This paper presents an alternative algorithm for number plate recognition. The algorithm consists of three modules. They are number plate location module, character segmentation module and character recognition module, respectively. Number plate location module extracts the number plate from the detected car image by analyzing the color and the texture properties. Different from most number plate location methods, the algorithm has fewer limits to the car size, the car position in the image and the image background. Character segmentation module applies connected region algorithm both to eliminate noise points and to segment characters. Touching characters and broken characters can be processed correctly. Character recognition module recognizes characters with HHIC (Hierarchical Hybrid Integrated Classifier). The system has been tested with 100 images obtained from crossroad and parking lot, etc, where the cars have different size, position, background and illumination. Successful recognition rate is about 92%. The average processing time is 1.2 second.
{fenge}
0035770704	A framework for distributed medical image collaborative processing based on web	During the last few years, the development of the modern medicine has permitted the accurate diagnosis on more symptom of illness. But it is the imbalance of the medical treatment on different areas and decentralization of the medical resources that limited the widely applying on more people. However, as the important evidence on medical diagnosis, medical images need to be collaborative processed because of their large sizes, modality and processing complexity. Therefore one of the main aims on medical treatment now is to establish the distributed computer to support collaboration working environment based on web. The establishing of the environment is help to dissolve the problem about medical collaborative working on different areas, computer systems and network structures and to permit more people to receive the high quality medical care. In this paper, a distributed medical image collaborative framework was presented using the JAVA (a network computing language) and CORBA (Common Object Broker Request Architecture, a distributed computing standard). From the experimental result with the framework, it was clear that the framework made possible collaborative processing of the medical image by using many collaborative tools.
{fenge}
0036622465	Segmentation based on Mumford-Shah model combined with narrow band	A segmentation model that combines the Mumford-Shah (M-S) model and narrow band scheme of level set was presented. The disadvantage of Mumford-Shah model is computationally time-consuming. In each step of its iteration, the data of whole image have to be renewed, which is unbearable for segmentation of large image or 3D image. Therefore, a fast segmentation model was introduce, which combines the M-S model and narrow band scheme by a new initialization method. The new initialization method is based on fast marching method, is based on fast marching method, and the computing time decreases to O(N). In each step of iteration, the new segmentation model only deals with the data in a narrow band instead of the whole image. The experiments show that the two models can obtain almost the same segmentation result, but the computing time of new narrow band M-S model is much less than that of M-S model.
{fenge}
0036474599	Segmentation of handwritten Chinese characters from destination addresses of mail pieces	In this paper, we illustrate a method to segment handwritten Chinese characters from destination addresses of mail pieces. Fast Hough transform is utilized to detect the reference lines preprinted on the mail piece. In the segmentation, subassemblies of Chinese characters are merged based on the structural features of Chinese characters and the subassemblies' topological relations, viz. upper-lower, inside-outside and left-right relations. The width of subassemblies and the spacing between neighboring subassemblies in the whole image of the destination address are analyzed to guide the merging of the left-right subassemblies. Experimental results with real mail piece images show that the proposed approach has achieved a promising performance for segmenting handwritten Chinese characters.
{fenge}
81555213150	Face recognition using difference vector plus KPCA	In this paper, a novel approach for face recognition based on the difference vector plus kernel PCA is proposed. Difference vector is the difference between the original image and the common vector which is obtained by the images processed by the Gram-Schmidt orthogonalization and represents the common invariant properties of the class. The optimal feature vectors are obtained by KPCA procedure for the difference vectors. Recognition result is derived from finding the minimum distance between the test difference feature vectors and the training difference feature vectors. To test and evaluate the proposed approach performance, a series of experiments are performed on four face databases: ORL, Yale, FERET and AR face databases and the experimental results show that the proposed method is encouraging. © 2011 Elsevier Inc. All Rights Reserved.
{fenge}
84863734551	Optimal wavelength band clustering for multispectral iris recognition	This work explores the possibility of clustering spectral wavelengths based on the maximumdissimilarity of iris textures. The eventual goal is to determine how many bands of spectral wavelengths will be enough for iris multispectral fusion and to find these bands that will provide higher performance of iris multispectral recognition. A multispectral acquisition system was first designed for imaging the iris at narrow spectral bands in the range of 420 to 940 nm. Next, a set of 60 human iris images that correspond to the right and left eyes of 30 different subjects were acquired for an analysis. Finally, we determined that 3 clusters were enough to represent the 10 feature bands of spectral wavelengths using the agglomerative clustering based on two-dimensional principal component analysis. The experimental results suggest (1) the number, center, and composition of clusters of spectral wavelengths and (2) the higher performance of iris multispectral recognition based on a three wavelengths-bands fusion. © 2012 Optical Society of America.
{fenge}
0036999607	Interactive model for segmentation of medical image	In the medical image processing, the desired segmentation object is often very complicated. It is difficult to acquire a satisfied result using a fully automatic image segmentation method. The segmentation guided by experienced doctors is the only possible solution to have reasonable results. In the paper, an interactive model is presented based on the level set method, and combine it with geodesic active region segmentation method. The model inherits the ability of topology adaptability of the level set method. Furthermore, doctors are only needed to put few mark points on the suitable image positions, and then able to monitor the segmentation results. Experiments show that the model is not only practical, but also reliable.
{fenge}
0038488775	Robust watermarking scheme with side information	Digital watermarks have been proposed for the copyright protections of multimedia products. Most schemes were performed primarily for fidelity considerations, and not specifically to improve the detector performance. In this paper, a robust and blind watermarking scheme is presented. The concept of communication with side information was applied at the encoder to improve the probability of detection within acceptable fidelity, and the template matching technique was employed to estimate the undergone attacks in attacking channel. This scheme is optimized by the optimal design of the encoder to match with the media content and the decoder to adapt to the attack channel state. Experiments show that our method is robust against some common attacks such as filtering, compression, rotation, scale, and translation. It can be applied to both color and gray image.
{fenge}
0037910220	Fast level set approach to image segmentation based on Mumford-Shah model	A new level set PDE based on the simplified Mumford-Shah model for image segmentation was proposed by Chan and Vese, which shows less insensibility of initialization and noise affect, and has the ability of detecting both inner and outer edges of targets with inner hole just by one enclosed active contour. However, the edges far way from the active contours would be seriously suppressed by the Dirac function in the proposed PDE. To solve it, this paper improved the C-V's PDE. Besides, to further stabilize and fasten the level set evolution procedures, the paper addresses an improved approach to construction of the signed distance function using Voronoi source scanning method, which extends the Voronoi source of the grids nearest to active contours to the far grids along with characteristic lines, only needs simple comparison and few multiplication operations with computational complication O(N), faster than the traditional approaches. At last, a new sign map labeling method is proposed to distinguish the inside and outside of the 2D closed active contour by fast marching method. These three improvements dramatically give more efficiency and performance than the C-V approach. The segmentation tests for synthesized and biomedical images prove the proposed segmenting method is very fast and robust.
{fenge}
84867922078	Encoding methods of spectral vector in hyperspectral romote sensing image	Taking into account the demands of hyperspectral remote sensing (RS) image retrieval and processing, some encoding methods of spectral vector including direct encoding, feature-based encoding and tree-based encoding methods are proposed and compared. In direct encoding, based on the analysis of binary encoding and quad-value encoding, decimal encoding is proposed. It is proved that quad-value encoding and decimal encoding are suitable to fast processing and retrieval. In absorption feature-based encoding method, five common metrics are compared. Because locations of reflection/absorption features are sensitive to noise, this method is not very effective in retrieval. In tree-based encoding methods, bitree, quadtree, octree and hextree are proposed and discussed. It is proved that 2-level octree and 2-level hextree are more effective than bitree and quadtree. Finally, quad-value encoding, decimal encoding, 2-level octree and 2-level hextree are proposed in spectral vectors encoding, similarity measure and hyperspectral RS image retrieval. © 2005 Shanghai University.
{fenge}
84867948484	Bidirectional automated branch and bound algorithm for feature selection	Feature selection is a process where a minimal feature subset is selected from an original feature set according to a certain measure. In this paper, feature relevancy is defined by an inconsistency rate. A bidirectional automated branch and bound algorithm is presented. It is a new complete search algorithm for feature selection, which performs feature deletion and feature addition in parallel. Its bound is determined by inconsistency rate of the original feature set, hence termed as 'automated'. Experimental study shows that it is fit for feature selection. © 2005 Shanghai University.
{fenge}
84867969200	Diversity sampling based kernel density estimation for background modeling	A novel diversity-sampling based nonparametric multi-modal background model is proposed. Using the samples having more popular and various intensity values in the training sequence, a nonparametric model is built for background subtraction. According to the related intensities, different weights are given to the distinct samples in kernel density estimation. This avoids repeated computation using all samples, and makes computation more efficient in the evaluation phase. Experimental results show the validity of the diversity-sampling scheme and robustness of the proposed model in moving objects segmentation. The proposed algorithm can be used in outdoor surveillance systems. © 2005 Shanghai University.
{fenge}
84872046136	An optimized wavelength band selection for heavily pigmented iris recognition	Commercial iris recognition systems usually acquire images of the eye in 850-nm band of the electromagnetic spectrum. In this work, the heavily pigmented iris images are captured at 12 wavelengths, from 420 to 940 nm. The purpose is to find the most suitable wavelength band for the heavily pigmented iris recognition. A multispectral acquisition system is first designed for imaging the iris at narrow spectral bands in the range of 420-940 nm. Next, a set of 200 human black irises which correspond to the right and left eyes of 100 different subjects are acquired for an analysis. Finally, the most suitable wavelength for heavily pigmented iris recognition is found based on two approaches: 1) the quality assurance of texture; 2) matching performance-equal error rate (EER) and false rejection rate (FRR). This result is supported by visual observations of magnified detailed local iris texture information. The experimental results suggest that there exists a most suitable wavelength band for heavily pigmented iris recognition when using a single band of wavelength as illumination. © 2005-2012 IEEE.
{fenge}
84880073952	Urban water consumption in a rapidly developing flagship megacity of South China: Prospective scenarios and implications	With a booming expansion of urbanization, urban water consumption (WC) attracts increasing concerns in developing countries worldwide, particularly for megacities. In this study, an urban WC model for Shenzhen, a rapidly developing flagship megacity in South China from a small agrarian fishery village since 1979, was built up to simulate the WC changes (1994-2009) with aim to formulate local water resources management strategies. Basically, the model was constructed using a variety of methods including a back-propagation artificial neuron network (BP-ANN), a quadratic polynomial model, a regression and auto-regressive moving average combination model, and a Grey Verhulst model. Simulation of the WC was conducted using a multiple regression forecasting model and a BP-ANN model. The results from these two models showed that the BP-ANN model is outperformed. Subsequently, a series of social-economic and demographic scenarios were formulated to project WC (2011-2020) with uncertainty analysis. The results suggest that the total WC will increase slower and slower over the decade. It might approach a saturated threshold soon after 2020. Scenarios of WC incorporating uncertainty analysis aiming to provide reliable prediction results constitute the highlight of this study. This study will be beneficial to formulate appropriate sustainable development strategies of water resources for similar megacities in South China. © 2012 Springer-Verlag Berlin Heidelberg.
{fenge}
0141508940	Wireless location determination for mobile objects based on GSM in intelligent transportation systems	The mobile object (MO) location determination technologies which can be used in intelligent transportation system (ITS) are studied. The principles and characteristics of wireless location determination technologies are introduced and the characteristics of GSM useful for location determination are also summarized. An experimental positioning system based on GSM is proposed, and the architecture is described. TOA method based on GSM signals and TDOA method are used in the experimental system. Moreover, the methods are simulated. The performance of the positioning methods is assessed in the simulation environment, and the accuracy for 67% mobile stations (MS) is 70 m in urban areas.
{fenge}
0141564808	An algorithm for segmenting moving vehicles	An algorithm for region-based moving object segmentation is presented in this paper. The gray-scale image segmentation based on the Mean Shift Algorithm (MSA) is performed first to segment each frame of a sequence into connective homogeneous regions. A method applying spatio-temporal continuity constrains of the motion vector image is then carried out to detect moving pixels robustly. Finally, each homogeneous region is labeled as either a moving-object region or a non-moving-object region according to the number of moving pixels it contains. Experimental results show that our algorithm is effective and robust in segmenting moving vehicle from noisy scenes.
{fenge}
0041328307	Similarity measures on intuitionistic fuzzy sets	Intuitionistic fuzzy sets (IFSs), proposed by Atanassov, have gained attention from researchers for their applications in various fields. Then similarity measures between IFSs were developed. In this paper, firstly, some existing measures of similarity are reviewed. Then some examples are applied to show that some existing similarity measures are not always effective in some cases. At the same time, several new similarity measures are proposed and the relationships between some similarity measures are proved. Finally a comparison is made to show the proposed similarity measures are more reasonable than some existing similarity measures in general cases. Therefore, the proposed similarity measures can provide a useful way for measuring IFSs more effectively. © 2003 Elsevier B.V. All rights reserved.
{fenge}
84892181731	A background-thinning based algorithm for separating connected handwritten digit strings	Most algorithms for segmenting connected handwritten digit strings are based on the analysis of the foreground pixel distributions and the features on the upper/lower contours of the image. A new approach is presented to segment connected handwritten two-digit strings based on the thinning of background regions. The algorithm first locates several feature points on the background skeleton of the digit image. Possible segmentation paths are then constructed by matching these feature points. With geometric property measures, these segmentation paths are ranked using fuzzy rules generated from a decision-tree approach. Finally, the top ranked segmentation paths are tested one by one by an optimized nearest neighbor classifier until one of these candidates is accepted based on an acceptance criterion. Experimental results on NIST special database 3 show that our approach can achieve a correct classification rate of 92.4% with only 4.7% of digit strings rejected, which compares favorably with the other techniques tested. © 1998 IEEE.
{fenge}
84897798958	An illumination balance algorithm based on improved affine shadow formation model for underwater image	The uneven illumination distribution in underwater visual inspection will lead to the difficulty of extracting texture features. The underwater image illumination balance while keeping the texture details has been one of the key issues in underwater visual inspection. Aimed at this problem, a novel illumination balance algorithm based on improved affine shadow formation model is proposed in this study. In the proposed approach, the linear spatial filter is used to obtain the light intensity distribution of an image, and the original image is divided into a series of small strips of pixels based on the light intensity distribution. Then the illumination balance of the image is carried out based on an improved affine shadow formation model. The experimental results show that the proposed approach can deal with the uneven illumination problem in underwater image, and keep the texture details effectively, which is very important for the subsequent processing and analysis for underwater images. © 2013 IEEE.
{fenge}
84904575769	An evidence fusion approach for characterization of heterogeneous images under complex environment	Characterization, recognition under complex environment is a challenging task. The measured signal will be submerged by noise in complex environment, which makes it difficult to characterize targets, especially when the targets share the similar characteristics. Multi-sensor information fusion will improve characterization significantly and DS evidence theory is an effective approach in heterogeneous information fusion. However, evidence from multi-sensor information is always affected by subjective factors in the process of evidence fusion. In this paper, a new evidence fusion approach for improving characterization under complex environment is proposed. To characterize the heterogeneous images better, a concept of comprehensive credibility is introduced into the proposed approach and a new update rule of evidence is designed. Some experimental results show the efficiency and effectiveness of the proposed approach. © 2014 IEEE.
{fenge}
84919877521	Defining the range of ecological shelter zones in the shore zone of Three Gorges Reservoir, China	To maintaining a health ecological environment in Three Gorges Reservoir (TGR) area, ecological shelter zones (ESZ) need to be built in the TGR shore zone urgently. Based on the implication and function of ESZ, this study first analyzed the relationships amongst three subsystems of the TGR area, including the upstream production-living land, the downstream reservoir water body, and the ESZ. Then a simple and practical hydrological environment model for controlling the eutrophication of the TGR water body was constructed to determine ESZ range of TGR. Additionally, based on the pollutant degradation efficiency of ESZ and the assimilative capacity of reservoir water body, a raster reverse tracking method was proposed to determine the range of ESZ. Thirdly, take Yangdu town in Zhongxian county as a typical region, the ESZ range under three scenarios of different rainfall intensity, degradation efficiency and inflow water quality that corresponding to the three decisive factors of defining ESZ range were discussed. Finally, the statistical laws of the ESZ’s width at each boundary points were discussed to facilitate the ESZ construction projects, and selected standardized rate at 70, 90, and 99 % were labelled as “General”, “Good” and “Excellent” level to represent the performance of the width of the ESZ range. In conclusion, it suggest “Good” level width as basic width of ESZ, and additionally a special protection zone should be put on upstream environment for the extreme large width at the boundary points.
{fenge}
0742284229	Medical image dynamic collaborative processing on the distributed environment	An architecture of medical image dynamic collaborative processing on the distributed environment by combining the JAVA, CORBA (Common Object Request and Broker Architecture) and the MAS (Multi-Agents System) collaborative mechanism is presented. The architecture allows medical specialists or applications to share records and communicate with each other on the web by overcoming the shortcut of traditional approach using Common Gateway Interface (CGI) and client/server architecture, and can support the remote heterogeneous systems collaboration. The approach improves the collaborative processing of medical data and applications and is able to enhance the interoperation among heterogeneous system.
{fenge}
10244235217	An efficient and effective method to solve kernel Fisher discriminant analysis	In this paper, an efficient and effective method to solve kernel Fisher discriminant analysis is proposed. Since the QR decomposition on the small-size matrix is adopted, the superiority of the proposed method is its computational efficiency. Moreover, the proposed method can avoid the singularity problem. Most importantly, the proposed method shows that the maximal number of kernel discriminant vectors is the same as that of linear discriminant vectors. Experimental results on handwritten numeral characters show that the proposed method is effective and feasible. © 2004 Elsevier B.V. All rights reserved.
{fenge}
12844262468	Kernel density estimation for dynamic scene modeling	A kernel density estimation (KDE) based on a multimode model is presented for dynamic scene reference frame maintenance and update problems. A diversity-sampling scheme is proposed to choose a new sample set from the image sequence including moving objects. Using more popular and diversiform intensity samples, a Gaussian KDE is built to estimate the background model and to detect moving objects by background subtraction. The diversity-sampling samples describe the key information of the original whole sample set and avoid the repetition computation in the evaluation phase. Compared with the whole samples based on algorithm, the proposed approach is proved to be efficient in traffic surveillance systems.
{fenge}
13644284537	Compression of hyper-spectral images based on coded quantization	An approach for compression of hyper-spectral images based on wavelet trellis-coded quantization is proposed. Processing of spectral and spatial redundancy make up the main ingredients of compression of hyper-spectral image. Firstly, the proposed algorithm takes advantage of spectral difference pulse code modulation (DPCM) to remove the spectral redundancy, then the discrete wavelet transform is carried out over the error images resulted from DPCM and trellis-coded quantization with uniform threshold value is adopted to quantize the sub-band images. At last, entropy encoding of quantized code-words is performed by adaptive arithmetic encoding. To compute optimal quantization thresholds in rate-distortion sense for each sub-band of all spectral bands, an algorithm for bit allocation based on sub-band statistic characteristic and R-D characteristic of trellis-coded quantization is also designed. In the experiments, excellent performance of the proposed algorithm is demonstrated. For the hyper-spectral image of experiment, the PSNR of the algorithm is 37.1 dB at the compression ratio of 32. This shows that the approach can efficiently compress hyper-spectral image and be suitable for the applications of hyper-spectral images compression.
