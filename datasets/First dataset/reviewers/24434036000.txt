{fenge}
8744315940	Evidence of the coexistence of upstream and downstream solitary wavetrains in the real atmosphere	From a true colour image of the Sea-viewing Wide Field-of-view Sensor (SeaWiFS) onboard the Orbview-2 satellite, we observed two packets of orderly wave clouds on two sides of Hainan Island in the South China Sea. A packet of 23 wave clouds stretches southward from the island. A second packet of more than 20 wave clouds stretches north-eastward off the north-east coast of the island. The concave orientation of the wave cloud lines implies that both packets are propagating away from the island. A chart of geopotential height and velocity at 850 mbar shows a south-westerly air flow over the island; hence the two wave cloud packets propagate upstream and downstream, simultaneously. Thus, we have found new evidence of the coexistence of both upstream and downstream solitary wavetrains generated in the real atmosphere by land topographic disturbances. Comparison with theoretical results supports this conclusion. © 2004 Taylor & Francis Ltd.
{fenge}
8744238370	Observation of the Kuroshio intrusion region in the South China Sea from AVHRR data	The variability of sea surface temperature in the region of the Kuroshio intrusion into the South China Sea (SCS) through the Luzon Strait was studied using sea surface temperature (SST) derived from Advanced Very High Resolution Radiometer (AVHRR) from 1985 to 2002. The covariance empirical orthogonal function (CEOF) method was applied for analysing the temporal and spatial variability in the study area. The results show that the Kuroshio intrusion during El Niño periods is weaker than that in La Niña periods. The calculation of surface layer heat of the Kuroshio intrusion region also shows response to the El Niño-La Niña events. The variation is attributed to the changes in wind fields during those events. © 2004 Taylor & Francis Ltd.
{fenge}
1542357546	A confidence limit for the empirical mode decomposition and Hilbert spectral analysis	The confidence limit is a standard measure of the accuracy of the result in any statistical analysis. Most of the confidence limits are derived as follows. The data are first divided into subsections and then, under the ergodic assumption, the temporal mean is substituted for the ensemble mean. Next, the confidence limit is defined as a range of standard deviations from this mean. However, such a confidence limit is valid only for linear and stationary processes. Furthermore, in order for the ergodic assumption to be valid, the subsections have to be statistically independent. For non-stationary and nonlinear processes, such an analysis is no longer valid. The confidence limit of the method here termed EMD/HSA (for empirical mode decomposition/ Hilbert spectral analysis) is introduced by using various adjustable stopping criteria in the sifting processes of the EMD step to generate a sample set of intrinsic mode functions (IMFs). The EMD technique acts as a pre-processor for HSA on the original data, producing a set of components (IMFs) from the original data that equal the original data when added back together. Each IMF represents a scale in the data, from smallest to largest. The ensemble mean and standard deviation of the IMF sample sets obtained with different stopping criteria are calculated, and these form a simple random sample set. The confidence limit for EMD/HSA is then defined as a range of standard deviations from the ensemble mean. Without evoking the ergodic assumption, subdivision of the data stream into short sections is unnecessary; hence, the results and the confidence limit retain the full-frequency resolution of the full dataset. This new confidence limit can be applied to the analysis of nonlinear and non-stationary processes by these new techniques. Data from length-of-day measurements and a particularly violent recent earthquake are used to demonstrate how the confidence limit is obtained and applied. By providing a confidence limit for this new approach, a stable range of stopping criteria for the decomposition or sifting phase (EMD) has been established, making the results of the final processing with HSA, and the entire EMD/HSA method, more definitive.
{fenge}
0031462927	The effects of water temperature on radar scattering from the water surface: An X-band laboratory study	The surface tension is a restoring force, the viscosity is a dissipative resistance for microwave scattering gravity-capillary waves on the ocean surface. Both the surface tension and viscosity are water temperature dependent; therefore, it is reasonable to expect the surface wave spectral density in the centimeter range to be temperature dependent. Bragg scatter is wave intensity dependent; therefore, the radar cross section of the ocean surface should also be temperature dependent. In order to verify this inference, a laboratory experiment for X-band backscattering from a rough water surface with varied water temperature was conducted in the absence of wind. Our data show a monotonic increase of the radar cross section with the water temperature. Based on our data, a semi-analytic model is proposed to relate the water surface temperature and the Normalized Radar Cross Section (NRCS) of the water surface as follows: Δσ
{fenge}
33645773008	A B-spline approach for empirical mode decompositions	We propose an alternative B-spline approach for empirical mode decompositions for nonlinear and nonstationary signals. Motivated by this new approach, we derive recursive formulas of the Hilbert transform of B-splines and discuss Euler splines as spline intrinsic mode functions in the decomposition. We also develop the Bedrosian identity for signals having vanishing moments. We present numerical implementations of the B-spline algorithm for an earthquake signal and compare the numerical performance of this approach with that given by the standard empirical mode decomposition. Finally, we discuss several open mathematical problems related to the empirical mode decomposition. © Springer 2006.
{fenge}
35448991660	On the trend, detrending, and variability of nonlinear and nonstationary time series	Determining trend and implementing detrending operations are important steps in data analysis. Yet there is no precise definition of "trend" nor any logical algorithm for extracting it. As a result, various ad hoc extrinsic methods have been used to determine trend and to facilitate a detrending operation. In this article, a simple and logical definition of trend is given for any nonlinear and nonstationary time series as an intrinsically determined monotonic function within a certain temporal span (most often that of the data span), or a function in which there can be at most one extremum within that temporal span. Being intrinsic, the method to derive the trend has to be adaptive. This definition of trend also presumes the existence of a natural time scale. All these requirements suggest the Empirical Mode Decomposition (EMD) method as the logical choice of algorithm for extracting various trends from a data set. Once the trend is determined, the corresponding detrending operation can be implemented. With this definition of trend, the variability of the data on various time scales also can be derived naturally. Climate data are used to illustrate the determination of the intrinsic trend and natural variability. © 2007 by The National Academy of Sciences of the USA.
{fenge}
39149105273	Altered phase interactions between spontaneous blood pressure and flow fluctuations in type 2 diabetes mellitus: Nonlinear assessment of cerebral autoregulation	Cerebral autoregulation is an important mechanism that involves dilatation and constriction in arterioles to maintain relatively stable cerebral blood flow in response to changes of systemic blood pressure. Traditional assessments of autoregulation focus on the changes of cerebral blood flow velocity in response to large blood pressure fluctuations induced by interventions. This approach is not feasible for patients with impaired autoregulation or cardiovascular regulation. Here we propose a newly developed technique-the multimodal pressure-flow (MMPF) analysis, which assesses autoregulation by quantifying nonlinear phase interactions between spontaneous oscillations in blood pressure and flow velocity during resting conditions. We show that cerebral autoregulation in healthy subjects can be characterized by specific phase shifts between spontaneous blood pressure and flow velocity oscillations, and the phase shifts are significantly reduced in diabetic subjects. Smaller phase shifts between oscillations in the two variables indicate more passive dependence of blood flow velocity on blood pressure, thus suggesting impaired cerebral autoregulation. Moreover, the reduction of the phase shifts in diabetes is observed not only in previously-recognized effective region of cerebral autoregulation (<0.1 Hz), but also over the higher frequency range from ∼0.1 to 0.4 Hz. These findings indicate that type 2 diabetes mellitus alters cerebral blood flow regulation over a wide frequency range and that this alteration can be reliably assessed from spontaneous oscillations in blood pressure and blood flow velocity during resting conditions. We also show that the MMPF method has better performance than traditional approaches based on Fourier transform, and is more suitable for the quantification of nonlinear phase interactions between nonstationary biological signals such as blood pressure and blood flow. © 2007 Elsevier Ltd. All rights reserved.
{fenge}
40549134941	Investigating complex patterns of blocked intestinal artery blood pressure signals by empirical mode decomposition and linguistic analysis	In this investigation, surgical operations of blocked intestinal artery have been conducted on pigs to simulate the condition of acute mesenteric arterial occlusion. The empirical mode decomposition method and the algorithm of linguistic analysis were applied to verify the blood pressure signals in simulated situation. We assumed that there was some information hidden in the high-frequency part of the blood pressure signal when an intestinal artery is blocked. The empirical mode decomposition method (EMD) has been applied to decompose the intrinsic mode functions (IMF) from a complex time series. But, the end effects and phenomenon of intermittence damage the consistence of each IMF. Thus, we proposed the complementary ensemble empirical mode decomposition method (CEEMD) to solve the problems of end effects and the phenomenon of intermittence. The main wave of blood pressure signals can be reconstructed by the main components, identified by Monte Carlo verification, and removed from the original signal to derive a riding wave. Furthermore, the concept of linguistic analysis was applied to design the blocking index to verify the pattern of riding wave of blood pressure using the measurements of dissimilarity. Blocking index works well to identify the situation in which the sampled time series of blood pressure signal was recorded. Here, these two totally different algorithms are successfully integrated and the existence of the existence of information hidden in high-frequency part of blood pressure signal has been proven. © 2008 IOP Publishing Ltd.
{fenge}
80052612013	Some considerations on physical analysis of data	In this paper, we present some general considerations about data analysis from the perspective of a physical scientist and advocate the physical, instead of mathematical, analysis of data. These considerations have been accompanying our development of novel adaptive, local analysis methods, especially the empirical mode decomposition and its major variation, the ensemble empirical mode decomposition, and its preliminary mathematical explanations. A particular emphasis will be on the advantages and disadvantages of mathematical and physical constraints associated with various analysis methods. We argue that, using data analysis in a given temporal domain of observation as an example, the mathematical constraints imposed on data may lead to difficulties in understanding the physics behind the data. With such difficulties in mind, we promote adaptive, local analysis method, which satisfies fundamental physical principle of consequent evolution of a system being not able to change the past evolution of the system. We also argue, using the ensemble empirical mode decomposition as an example, that noise can be helpful to extract physically meaningful signals hidden in noisy data. © 2011 World Scientific Publishing Company.
{fenge}
80052637482	On hilbert spectral representation: A true time-frequency representation for nonlinear and nonstationary data	As the original definition on Hilbert spectrum was given in terms of total energy and amplitude, there is a mismatch between the Hilbert spectrum and the traditional Fourier spectrum, which is defined in terms of energy density. Rigorous definitions of Hilbert energy and amplitude spectra are given in terms of energy and amplitude density in the time-frequency space. Unlike Fourier spectral analysis, where the resolution is fixed once the data length and sampling rate is given, the time-frequency resolution could be arbitrarily assigned in Hilbert spectral analysis (HSA). Furthermore, HSA could also provide zooming ability for detailed examination of the data in a specific frequency range with all the resolution power. These complications have made the conversion between Hilbert and Fourier spectral results difficult and the conversion formula is elusive until now. We have derived a simple relationship between them in this paper. The conversion factor turns out to be simply the sampling rate for the full resolution cases. In case of zooming, there is another additional multiplicative factor. The conversion factors have been tested in various cases including white noise, delta function, and signals from natural phenomena. With the introduction of this conversion, we can compare HSA and Fourier spectral analysis results quantitatively. © 2011 World Scientific Publishing Company.
{fenge}
84877337770	Detecting signals from data with noise: Theory and applications	Signal detection from noisy data by rejecting a noise null hypothesis depends critically on a priori assumptions regarding the background noise and the associated statistical methods. Rejecting one kind of noise null hypothesis cannot rule out the possibility that the detected oscillations are generated from the stochastic processes of another kind. This calls for an adaptive null hypothesis based on general characteristics of the noise that is present. In this paper, a new method is developed for identifying signals from data based on the finding that true physical signals in a well-sampled time series cannot be destroyed or eliminated by resampling the time series with fractional sampling rates through linear interpolation. Therefore, the significance of signals could be tested by checking whether the signals persist in the true time-frequency spectral representation during resampling. This hypothesis is based on the general characteristics of noise as revealed by empirical mode decomposition, an adaptive data analysis method without linear or stationary assumptions, and without any predefinition of the background noise. Applications of this method to synthetic time series, solar spot number, and sea surface temperature time series illustrate its power in identifying characteristics of background noise without any a priori knowledge. © 2013 American Meteorological Society.
{fenge}
84887503935	Derivative-optimized empirical mode decomposition for the Hilbert-Huang transform	In the empirical mode decomposition (EMD) for the Hilbert-Huang transform (HHT), a nonlinear and non-stationary signal is adaptively decomposed by an HHT into a series of intrinsic mode functions (IMFs) with the lowest one as the trend. At each step of the EMD, the low-frequency component is mainly determined by the average of the upper envelope (consisting of local maxima) and the lower envelope (consisting of local minima). The high-frequency component is the deviation of the signal relative to the low-frequency component. The fact that no local maximum and minimum can be determined at the two end-points leads to detrend uncertainty, and in turn causes uncertainty in the HHT. To reduce such uncertainty, Hermitian polynomials are used to obtain the upper and lower envelopes with the first derivatives at the two end-points (
{fenge}
84897986365	The use of signal analyses of ventricular tachycardia electrograms to predict the response of antitachycardia pacing in patients with implantable cardioverter-defibrillators	ICDs and Signal Analyses Introduction Antitachycardia pacing (ATP), a quick, painless, and effective therapy available in implantable cardioverter-defibrillators (ICDs), can terminate most, but not all, sustained ventricular tachycardias (VTs). This study investigated the possible ventricular electrogram (EGM) factors for predicting the effectiveness of ATP therapy from ICD recordings. Methods and Results In this study, we analyzed 113 EGMs of VT episodes acquired from 20 patients who received ATP or shock to terminate tachyarrhythmias during follow-up after ICD implantations. The relationship between the outcome of ATP and VT EGM features (such as voltage, width, cycle length, and beat-to-beat morphologic variation) was investigated. The divergence (beat-to-beat morphologic variation) of the VT EGMs was determined by calculating the total deviation of all EGMs away from the average template after all VT EMGs were aligned. In total, 72 (63.7%) successful (Group I) and 41 (36.3%) unsuccessful (Group II) ATP therapy episodes were analyzed. The mean amplitude, cycle length, and EGM width were similar between these 2 groups (P > 0.05). A multivariate analysis demonstrated that the only predictor of successful ATP was the divergence among the VT EGMs (0.56 ± 0.32 vs 1.07 ± 0.64, P < 0.001, for Groups 1 and 2, respectively). The optimal cutoff value for determining a successful ATP therapy was 0.73 (with an area under the curve of 0.769, sensitivity of 81.9% [95% CI = 71.1-90.0], and specificity of 65.9% [95% CI = 49.4-79.9], P < 0.0001). Conclusion Signal analyses from stored EGMs of VT can predict the response of ATP therapy in patients with ICD implantations. A lesser ventricular beat-to-beat morphologic variation in the intracardiac recordings from ICDs correlated with a higher probability of a successful ATP. © 2013 Wiley Periodicals, Inc.
{fenge}
54949137679	The modulated annual cycle: An alternative reference frame for climate anomalies	In climate science, an anomaly is the deviation of a quantity from its annual cycle. There are many ways to define annual cycle. Traditionally, this annual cycle is taken to be an exact repeat of itself year after year. This stationary annual cycle may not reflect well the intrinsic nonlinearity of the climate system, especially under external forcing. In this paper, we re-examine the reference frame for anomalies by re-examining the annual cycle. We propose an alternative reference frame for climate anomalies, the modulated annual cycle (MAC) that allows the annual cycle to change from year to year, for defining anomalies. In order for this alternative reference frame to be useful, we need to be able to define the instantaneous annual cycle: we therefore also introduce a new method to extract the MAC from climatic data. In the presence of a MAC, modulated in both amplitude and frequency, we can then define an alternative version of an anomaly, this time with respect to the instantaneous MAC rather than a permanent and unchanging AC. Based on this alternative definition of anomalies, we re-examine some familiar physical processes: in particular SST re-emergence and ENSO phase locking to the annual cycle. We find that the re-emergence mechanism may be alternatively interpreted as an explanation of the change of the annual cycle instead of an explanation of the interannual to interdecadal persistence of SST anomalies. We also find that the ENSO phase locking can largely be attributed to the residual annual cycle (the difference of the MAC and the corresponding traditional annual cycle) contained in the traditional anomaly, and, therefore, can be alternatively interpreted as a part of the annual cycle phase locked to the annual cycle itself. In addition to the examples of reinterpretation of physics of well known climate phenomena, we also present an example of the implications of using a MAC against which to define anomalies. We show that using MAC as a reference framework for anomaly can bypass the difficulty brought by concepts such as "decadal variability of summer (or winter) climate" for understanding the low-frequency variability of the climate system. The concept of an amplitude and frequency modulated annual cycle, a method to extract it, and its implications for the interpretation of physical processes, all may contribute potentially to a more consistent and fruitful way of examining past and future climate variability and change. © The Author(s) 2008.
{fenge}
54949146599	A review on Hilbert-Huang transform: Method and its applications to geophysical studies	Data analysis has been one of the core activities in scientific research, but limited by the availability of analysis methods in the past, data analysis was often relegated to data processing. To accommodate the variety of data generated by nonlinear and nonstationary processes in nature, the analysis method would have to be adaptive. Hilbert-Huang transform, consisting of empirical mode decomposition and Hilbert spectral analysis, is a newly developed adaptive data analysis method, which has been used extensively in geophysical research. In this review, we will briefly introduce the method, list some recent developments, demonstrate the usefulness of the method, summarize some applications in various geophysical research areas, and finally, discuss the outstanding open problems. We hope this review will serve as an introduction of the method for those new to the concepts, as well as a summary of the present frontiers of its applications for experienced research scientists. Copyright 2008 by the American Geophysical Union.
{fenge}
64049107903	An analysis of moisture fluxes into the gulf of California	This study examines the nature of episodes of enhanced warm-season moisture flux into the Gulf of California. Both spatial structure and primary time scales of the fluxes are examined using the 40-yr ECMWF Re-Analysis data for the period 1980-2001. The analysis approach consists of a compositing technique that is keyed on the low-level moisture fluxes into the Gulf of California. The results show that the fluxes have a rich spectrum of temporal variability, with periods of enhanced transport over the gulf linked to African easterly waves on subweekly (3-8 day) time scales, the Madden-Julian oscillation (MJO) at intraseasonal time scales (20-90 day), and intermediate (10-15 day) time-scale disturbances that appear to originate primarily in the Caribbean Sea-western Atlantic Ocean. In the case of the MJO, enhanced low-level westerlies and large-scale rising motion provide an environment that favors large-scale cyclonic development near the west coast of Central America that, over the course of about 2 weeks, expands northward along the coast eventually reaching the mouth of the Gulf of California where it acts to enhance the southerly moisture flux in that region. On a larger scale, the development includes a northward shift in the eastern Pacific ITCZ, enhanced precipitation over much of Mexico and the southwestern United States, and enhanced southerly/southeasterly fluxes from the Gulf of Mexico into Mexico and the southwestern and central United States. In the case of the easterly waves, the systems that reach Mexico appear to redevelop/reorganize on the Pacific coast and then move rapidly to the northwest to contribute to the moisture flux into the Gulf of California. The most intense fluxes into the gulf on these time scales appear to be synchronized with a midlatitude short-wave trough over the U.S. West Coast and enhanced low-level southerly fluxes over the U.S. Great Plains. The intermediate (10-15 day) time-scale systems have zonal wavelengths roughly twice that of the easterly waves, and their initiation appears to be linked to an extratropical U.S. East Coast ridge and associated northeasterly winds that extend well into the Caribbean Sea during their development phase. The short (3-8 day) and, to a lesser extent, the intermediate (10-15 day) time-scale fluxes tend to be enhanced when the convectively active phase of the MJO is situated over the Americas. © 2009 American Meteorological Society.
{fenge}
64249109961	An adaptive threshold filter for ultrasound signal rejection	The threshold filter is a frequently used technique in ultrasound B-scan to reject the small echoes contributed from backscattering that blur the tissue interface and reduce the image contrast. Note that using the threshold based on one value would simultaneously destroy local waveform features of the reflection echoes with amplitudes larger than threshold value. To resolve this problem, we developed an adaptive threshold filter based on the noise-assisted empirical mode decomposition (EMD). Computer simulations at 7.5 MHz using a single-element transducer with a bandwidth of 60% and a pulselength of 0.5 μs were carried out to explore the feasibility of the algorithm. Image measurements on the carotid artery using a 7.5 MHz, 128 elements, 1D linear array transducer with the same characteristics as those in simulations were used to verify the performance of the algorithm in practice. Compared to the result from the conventional threshold technique, the adaptive threshold filter is able to successfully suppress the smaller backscattering signals without changing the local waveform features of the preserved significant echoes due to refection. © 2008 Elsevier B.V. All rights reserved.
{fenge}
0035484673	A new spectral representation of earthquake data: Hilbert spectral analysis of station TCU129, Chi-Chi, Taiwan, 21 September 1999	A new method of spectral analysis, using an approach we call the empirical mode decomposition (EMD) and the Hilbert spectrum analysis (HSA), is presented. The EMD method decomposes any data into a finite number of intrinsic mode function (IMF) components with time-variable amplitudes and frequencies. This decomposition is nearly orthogonal and totally adaptive. With the decomposition, a Hilbert, rather than Fourier, transform is applied to each IMF component, which gives each component instantaneous frequency and energy density. This approach is totally new, and it is different from any of the existing methods: It uses differentiation to define the frequency rather than the traditional convolution computation; thus, it gives the instantaneous frequency and energy density. The greatest advantage of the new approach is that it is the only spectral analysis method applicable to nonstationary and nonlinear data. To illustrate the capability of his new method, we have applied it to the earthquake record from station TCU129, at Chi-Chi, Taiwan, collected during the 21 September 1999 earthquake. The same record is also analyzed with Fourier analysis, wavelet transform, and response spectrum analysis. Comparisons among the different analysis methods indicate that the Hilbert spectral analysis gives the most detailed information in a time-frequency-energy presentation. It also emphasizes the potentially damage-causing low-frequency energy in the earthquake signal missed by all the other methods.
{fenge}
0035485202	Application of the empirical mode decomposition-Hilbert spectrum method to identify near-fault ground-motion characteristics and structural responses	In this article, the empirical mode decomposition method combined with the Hilbert spectrum method (EMD + HHT) is used to analyze the free-field ground motion and to estimate the global structural property of building and bridge structure through the measurement of seismic response data. The EMD + HHT method provides a powerful tool for signal processing to identify nonlinear and nonstationary data. Based on the decomposed ground-motion signal, the absolute input energy of each decomposed wave was studied (the fling step [pulselike wave] can be separated from the recorded near-fault ground motion). Through application of the EMD + HHT method to building and bridge seismic response data, the time-varying system natural frequency and damping ratio can also be estimated. Damage identification from seismic response data of buildings and bridges, particularly from the Chi-Chi earthquake data, is also described.
{fenge}
71749117291	Use of Nakagami Statistics and Empirical Mode Decomposition for Ultrasound Tissue Characterization by a Nonfocused Transducer	The Nakagami parameter associated with the Nakagami distribution estimated from ultrasonic backscattered signals reflects the scatterer concentration in a tissue. A nonfocused transducer does not allow tissue characterization based on the Nakagami parameter. This paper proposes a new method called the noise-assisted Nakagami parameter based on empirical mode decomposition of noisy backscattered echoes to allow quantification of the scatterer concentration based on data obtained using a nonfocused transducer. To explore the practical feasibility of the proposed method, the current study performed experiments on phantoms and measurements on rat livers in vitro with and without fibrosis induction. The results show that using a nonfocused transducer makes it possible to use the noise-assisted Nakagami parameter to classify phantoms with different scatterer concentrations and different stages of liver fibrosis in rats more accurately than when using techniques based on the echo intensity and the conventional Nakagami parameter. However, the conventional Nakagami parameter and the noise-assisted Nakagami parameter have different meanings: the former represents the statistics of signals backscattered from unresolvable scatterers, whereas the latter is associated with stronger resolvable scatterers or local inhomogeneity caused by scatterer aggregation. (E-mail: mechang@gate.sinica.edu.tw; mcho1215@ntu.edu.tw). © 2009 World Federation for Ultrasound in Medicine & Biology.
{fenge}
77951668826	On instantaneous frequency	Instantaneous frequency (IF) is necessary for understanding the detailed mechanisms for nonlinear and nonstationary processes. Historically, IF was computed from analytic signal (AS) through the Hilbert transform. This paper offers an overview of the difficulties involved in using AS, and two new methods to overcome the difficulties for computing IF. The first approach is to compute the quadrature (defined here as a simple 90° shift of phase angle) directly. The second approach is designated as the normalized Hilbert transform (NHT), which consists of applying the Hilbert transform to the empirically determined FM signals. Additionally, we have also introduced alternative methods to compute local frequency, the generalized zero-crossing (GZC), and the teager energy operator (TEO) methods. Through careful comparisons, we found that the NHT and direct quadrature gave the best overall performance. While the TEO method is the most localized, it is limited to data from linear processes, the GZC method is the most robust and accurate although limited to the mean frequency over a quarter wavelength of temporal resolution. With these results, we believe most of the problems associated with the IF determination are resolved, and a true timefrequency analysis is thus taking another step toward maturity. © 2009 World Scientific Publishing Company.
{fenge}
77952009637	Intrinsic mode analysis of human heartbeat time series	The human heartbeat interval is determined by complex nerve control and environmental inputs. As a result, the heartbeat interval for a human is a complex time series, as shown by previous studies. Most of the analysis algorithms proposed for characterizing the profile of heartbeat time series, such as detrended fluctuation analysis and multi-scale entropy, are based on various characteristics of dynamics. In this study, we present an empirical mode decomposition-based intrinsic mode analysis, which uses the appearance energy index (AEI) to quantify the property of long-term correlation, and structure index (SI) to characterize the internal modulation of data. This presented algorithm was used to investigate the human heartbeat time series downloaded from PhysioBank. We found the profiles of human heartbeat time series of subjects with congestive heart failure (CHF) or atrial fibrillation (AF) are significantly different from those of healthy subjects in internal modulation as shown by SI. Moreover, AEI is the critical characteristics for verifying subjects with CHF from subjects with AF in a degree of long-term correlation. Both AEI and SI contribute to presenting the characteristic profiles of a human heartbeat time series. © 2010 Biomedical Engineering Society.
{fenge}
77952877369	Investigating fractal property and respiratory modulation of human heartbeat time series using empirical mode decomposition	The human heartbeat interval reflects a complicated composition with different underlying modulations and the reactions against environmental inputs. As a result, the human heartbeat interval is a complex time series and its complexity can be scaled using various physical quantifications, such as the property of long-term correlation in detrended fluctuation analysis (DFA). Recently, empirical mode decomposition (EMD) has been shown to be a dyadic filter bank resembling those involved in wavelet decomposition. Moreover, the hierarchy of the extracted modes may be exploited for getting access to the Hurst exponent, which also reflects the property of long-term correlation for a stochastic time series. In this paper, we present significant findings for the dynamic properties of human heartbeat time series by EMD. According to our results, EMD provides a more accurate access to long-term correlation than Hurst exponent does. Moreover, the first intrinsic mode function (IMF 1) is an indicator of orderliness, which reflects the modulation of respiratory sinus arrhythmia (RSA) for healthy subjects or performs a characteristic component similar to that decomposed from a stochastic time series for subjects with congestive heart failure (CHF) and atrial fibrillation (AF). In addition, the averaged amplitude of IMF 1 acts as a parameter of RSA modulation, which reflects significantly negative correlation with aging. These findings lead us to a better understanding of the cardiac system. © 2010 IPEM.
{fenge}
77957951339	A novel preprocessing method using hilbert huang transform for MALDI-TOF and SELDI-TOF mass spectrometry data	Motivation: Mass spectrometry is a high throughput, fast, and accurate method of protein analysis. Using the peaks detected in spectra, we can compare a normal group with a disease group. However, the spectrum is complicated by scale shifting and is also full of noise. Such shifting makes the spectra non-stationary and need to align before comparison. Consequently, the preprocessing of the mass data plays an important role during the analysis process. Noises in mass spectrometry data come in lots of different aspects and frequencies. A powerful data preprocessing method is needed for removing large amount of noises in mass spectrometry data. Results: Hilbert-Huang Transformation is a non-stationary transformation used in signal processing. We provide a novel algorithm for preprocessing that can deal with MALDI and SELDI spectra. We use the Hilbert-Huang Transformation to decompose the spectrum and filter-out the very high frequencies and very low frequencies signal. We think the noise in mass spectrometry comes from many sources and some of the noises can be removed by analysis of signal frequence domain. Since the protein in the spectrum is expected to be a unique peak, its frequence domain should be in the middle part of frequence domain and will not be removed. The results show that HHT, when used for preprocessing, is generally better than other preprocessing methods. The approach not only is able to detect peaks successfully, but HHT has the advantage of denoising spectra efficiently, especially when the data is complex. The drawback of HHT is that this approach takes much longer for the processing than the wavlet and traditional methods. However, the processing time is still manageable and is worth the wait to obtain high quality data. ©\ 2010 Wu et al.
{fenge}
77957598733	The multi-dimensional ensemble empirical mode decomposition method	A multi-dimensional ensemble empirical mode decomposition (MEEMD) for multi-dimensional data (such as images or solid with variable density) is proposed here. The decomposition is based on the applications of ensemble empirical mode decomposition (EEMD) to slices of data in each and every dimension involved. The final reconstruction of the corresponding intrinsic mode function (IMF) is based on a comparable minimal scale combination principle. For two-dimensional spatial data or images, f(x,y), we consider the data (or image) as a collection of one-dimensional series in both x-direction and y-direction. Each of the one-dimensional slices is decomposed through EEMD with the slice of the similar scale reconstructed in resulting two-dimensional pseudo-IMF-like components. This new two-dimensional data is further decomposed, but the data is considered as a collection of one-dimensional series in y-direction along locations in x-direction. In this way, we obtain a collection of two-dimensional components. These directly resulted components are further combined into a reduced set of final components based on a minimal-scale combination strategy. The approach for two-dimensional spatial data can be extended to multi-dimensional data. EEMD is applied in the first dimension, then in the second direction, and then in the third direction, etc., using the almost identical procedure as for the two-dimensional spatial data. A similar comparable minimal-scale combination strategy can be applied to combine all the directly resulted components into a small set of multi-dimensional final components. For multi-dimensional temporal-spatial data, EEMD is applied to time series of each spatial location to obtain IMF-like components of different time scales. All the ith IMF-like components of all the time series of all spatial locations are arranged to obtain ith temporal-spatial multi-dimensional IMF-like component. The same approach to the one used in temporal-spatial data decomposition is used to obtain the resulting two-dimensional IMF-like components. This approach could be extended to any higher dimensional temporal-spatial data. © 2009 World Scientific Publishing Company.
{fenge}
78149422204	Decomposing the association of completed suicide with air pollution, weather, and unemployment data at different time scales	Background: Research has implicated environmental risk factors, such as meteorological variables, in suicide. However, studies have not investigated air pollution, known to induce acute medical conditions and increase mortality, in suicide. This study comprehensively assesses the temporal relationship between suicide and air pollution, weather, and unemployment variables in Taipei City from January 1 1991 to December 31 2008. Methods: This research used the empirical mode decomposition (EMD) method to de-trend the suicide data into a set of intrinsic oscillations, called intrinsic mode functions (IMFs). Multiple linear regression analysis with forward stepwise method was used to identify significant predictors of suicide from a pool of air pollution, weather, and unemployment data, and to quantify the temporal association between decomposed suicide IMFs with these predictors at different time scales. Results: Findings of this study predicted a classic seasonal pattern of increased suicide occurring in early summer by increased air particulates and decreased barometric pressure, in which the latter was in accordance with increased temperature during the corresponding time. Gaseous air pollutants, such as sulfur dioxide and ozone, were found to increase the risk of suicide at longer time scales. Decreased sunshine duration and sunspot activity predicted the increased suicide. After controlling for the unemployment factor, environmental risks predicted 33.7% of variance in the suicide data. Conclusions: Using EMD analysis, this study found time-scale dependent associations between suicide and air pollution, weather and unemployment data. Contributing environmental risks may vary in different geographic regions and in different populations. © 2010 Elsevier B.V. All rights reserved.
{fenge}
78149463984	Do seasons have an influence on the incidence of depression? the use of an internet search engine query data as a proxy of human affect	Background: Seasonal depression has generated considerable clinical interest in recent years. Despite a common belief that people in higher latitudes are more vulnerable to low mood during the winter, it has never been demonstrated that human's moods are subject to seasonal change on a global scale. The aim of this study was to investigate large-scale seasonal patterns of depression using Internet search query data as a signature and proxy of human affect. Methodology/Principal Findings: Our study was based on a publicly available search engine database, Google Insights for Search, which provides time series data of weekly search trends from January 1, 2004 to June 30, 2009. We applied an empirical mode decomposition method to isolate seasonal components of health-related search trends of depression in 54 geographic areas worldwide. We identified a seasonal trend of depression that was opposite between the northern and southern hemispheres; this trend was significantly correlated with seasonal oscillations of temperature (USA: r =20.872, p,0.001; Australia: r =20.656, p,0.001). Based on analyses of search trends over 54 geological locations worldwide, we found that the degree of correlation between searching for depression and temperature was latitude-dependent (northern hemisphere: r =20.686; p,0.001; southern hemisphere: r = 0.871; p,0.0001). Conclusions/Significance: Our findings indicate that Internet searches for depression from people in higher latitudes are more vulnerable to seasonal change, whereas this phenomenon is obscured in tropical areas. This phenomenon exists universally across countries, regardless of language. This study provides novel, Internet-based evidence for the epidemiology of seasonal depression. © 2010 Yang et al.
{fenge}
79551635671	Temporal associations between weather and headache: Analysis by empirical mode decomposition	Background: Patients frequently report that weather changes trigger headache or worsen existing headache symptoms. Recently, the method of empirical mode decomposition (EMD) has been used to delineate temporal relationships in certain diseases, and we applied this technique to identify intrinsic weather components associated with headache incidence data derived from a large-scale epidemiological survey of headache in the Greater Taipei area. Methodology/Principal Findings: The study sample consisted of 52 randomly selected headache patients. The weather time-series parameters were detrended by the EMD method into a set of embedded oscillatory components, i.e. intrinsic mode functions (IMFs). Multiple linear regression models with forward stepwise methods were used to analyze the temporal associations between weather and headaches. We found no associations between the raw time series of weather variables and headache incidence. For decomposed intrinsic weather IMFs, temperature, sunshine duration, humidity, pressure, and maximal wind speed were associated with headache incidence during the cold period, whereas only maximal wind speed was associated during the warm period. In analyses examining all significant weather variables, IMFs derived from temperature and sunshine duration data accounted for up to 33.3% of the variance in headache incidence during the cold period. The association of headache incidence and weather IMFs in the cold period coincided with the cold fronts. Conclusions/Significance: Using EMD analysis, we found a significant association between headache and intrinsic weather components, which was not detected by direct comparisons of raw weather data. Contributing weather parameters may vary in different geographic regions and different seasons. © 2011 Yang et al.
{fenge}
79051470764	Noise and poise: Enhancement of postural complexity in the elderly with a stochastic-resonance-based therapy	Pathologic states are associated with a loss of dynamical complexity. Therefore, therapeutic interventions that increase physiologic complexity may enhance health status. Using multiscale entropy analysis, we show that the postural sway dynamics of healthy young and healthy elderly subjects are more complex than that of elderly subjects with a history of falls. Application of subsensory noise to the feet has been demonstrated to improve postural stability in the elderly. We next show that this therapy significantly increases the multiscale complexity of sway fluctuations in healthy elderly subjects. Quantification of changes in dynamical complexity of biologic variability may be the basis of a new approach to assessing risk and to predicting the efficacy of clinical interventions, including noise-based therapies. © Europhysics Letters Association, 2007.
{fenge}
0035880467	Anatomy of plasmas structures in an Equatorial Spread F Event	This paper investigates the small scale plasma structures observed by ROCSAT-1 in the equatorial F region through the newly developed Hilbert-Huang transform (HHT) method in the time (space) domain under the frozen-in approximation. The new method allows us to decompose the non-stationary, nonlinear data into a finite number of intrinsic scale modes. In this report the structures of vertical ion velocity and horizontal density gradient inside a plasma bubble are analyzed mode by mode anatomically without making the usual linearization assumption. We found that the intrinsic modes for velocity and density gradient of the selected event have identical wave form for structures with scales between 300 m and 50 m. This implies that the vertical velocity fluctuations induced from the electric field follows the exact Boltzmann relation in the limited regime of scale length between 300 m and 50 m. A spectral break at 50 m is clearly seen in the velocity HHT spectrum. The spectral form of velocity differs greatly from that of density gradient at scale lengths shorter than 50 m.
{fenge}
79956357196	The time-dependent intrinsic correlation based on the empirical mode decomposition	A Time-Dependent Intrinsic Correlation (TDIC) method is introduced. This new approach includes both auto- and cross-correlation analysis designed especially to analyze, capture and track the local correlations between nonlinear and nonstationary time series pairs. The approach is based on Empirical Mode Decomposition (EMD) to decompose the nonlinear and nonstationary data into their intrinsic mode functions (IMFs) and uses the instantaneous periods of the IMFs to determine a set of the sliding window sizes for the computation of the running correlation coefficients for multi-scale data. This new method treats the selection of the sliding window sizes as an adaptive process determined by the data itself, not a "tuning" process. Therefore, it gives an intrinsic correlation analysis of the data. Furthermore, the multi-window approach makes the new method applicable to complicated data from multi-scale phenomena. The synthetic and time series from real world are used to demonstrate conclusively that the new approach is far more superior over the traditional method in its ability to reveal detailed and subtle correlations unavailable through any other methods in existence. Thus, the TDIC represents a major advance in statistical analysis of data from nonlinear and nonstationary processes. © 2010 World Scientific Publishing Company.
{fenge}
79958723166	Biomedical data processing using HHT: A review	Living organisms adapt and function in an ever changing environment. Even under basal conditions they are constantly perturbed by external stimuli. Therefore, biological processes are all non-stationary and highly nonlinear. Thus the study of biomedical processes, which are heavily depending on observations, is crucially dependent on the data analysis. The newly developed method, the Hilbert-Huang Transform (HHT), is ideally suited for nonlinear and non-stationary data analysis such as appeared in the biomedical processes. Different from all other data analysis existing methods, this method is totally adaptive: It derives the basis from the data and based on the data. As a result, it is highly efficient in expanding any time series in their intrinsic modes, which reveal their full physical meaning. In this article, we review biomedical data processing by using HHT. We introduce two exemplary studies: cardiorespiratory synchronization and human ventricular fibrillation. The power and advantages of HHT are apparent from the achievements of these studies. © 2009 Springer Berlin Heidelberg.
{fenge}
79956369785	Complementary ensemble empirical mode decomposition: A novel noise enhanced data analysis method	The phenomenon of mode-mixing caused by intermittence signals is an annoying problem in Empirical Mode Decomposition (EMD) method. The noise assisted method of Ensemble EMD (EEMD) has not only effectively resolved this problem but also generated a new one, which tolerates the residue noise in the signal reconstruction. Of course, the relative magnitude of the residue noise could be reduced with large enough ensemble, it would be too time consuming to implement. An improved algorithm of noise enhanced data analysis method is suggested in this paper. In this approach, the residue of added white noises can be extracted from the mixtures of data and white noises via pairs of complementary ensemble IMFs with positive and negative added white noises. Though this new approach yields IMF with the similar RMS noise as EEMD, it effectively eliminated residue noise in the IMFs. Numerical experiments were conducted to demonstrate the new approach and also illustrate the problems of mode splitting and translation. © 2010 World Scientific Publishing Company.
{fenge}
79958102365	Association of Internet search trends with suicide death in Taipei City, Taiwan, 2004-2009	Background: Although Internet has become an important source for affected people seeking suicide information, the connection between Internet searches for suicide information and suicidal death remains largely unknown. This study aims to evaluate the association between suicide and Internet searches trends for 37 suicide-related terms representing major known risks of suicide. Methods: This study analyzes suicide death data in Taipei City, Taiwan and corresponding local Internet search trend data provided by Google Insights for Search during the period from January 2004 to December 2009. The investigation uses cross correlation analysis to estimate the temporal relationship between suicide and Internet search trends and multiple linear regression analysis to identify significant factors associated with suicide from a pool of search trend data that either coincides or precedes the suicide death. Results: Results show that a set of suicide-related search terms, the trends of which either temporally coincided or preceded trends of suicide data, were associated with suicide death. These search factors varied among different suicide samples. Searches for "major depression" and "divorce" accounted for, at most, 30.2% of the variance in suicide data. When considering only leading suicide trends, searches for "divorce" and the pro-suicide term "complete guide of suicide," accounted for 22.7% of variance in suicide data. Conclusions: Appropriate filtering and detection of potentially harmful source in keyword-driven search results by search engine providers may be a reasonable strategy to reduce suicide deaths. © 2011 Elsevier B.V. All rights reserved.
{fenge}
79960973968	On the time-varying trend in global-mean surface temperature	The Earth has warmed at an unprecedented pace in the decades of the 1980s and 1990s (IPCC in Climate change 2007: the scientific basis, Cambridge University Press, Cambridge, 2007). In Wu et al. (Proc Natl Acad Sci USA 104:14889-14894, 2007) we showed that the rapidity of the warming in the late twentieth century was a result of concurrence of a secular warming trend and the warming phase of a multidecadal (~65-year period) oscillatory variation and we estimated the contribution of the former to be about 0. 08°C per decade since ~1980. Here we demonstrate the robustness of those results and discuss their physical links, considering in particular the shape of the secular trend and the spatial patterns associated with the secular trend and the multidecadal variability. The shape of the secular trend and rather globally-uniform spatial pattern associated with it are both suggestive of a response to the buildup of well-mixed greenhouse gases. In contrast, the multidecadal variability tends to be concentrated over the extratropical Northern Hemisphere and particularly over the North Atlantic, suggestive of a possible link to low frequency variations in the strength of the thermohaline circulation. Depending upon the assumed importance of the contributions of ocean dynamics and the time-varying aerosol emissions to the observed trends in global-mean surface temperature, we estimate that up to one third of the late twentieth century warming could have been a consequence of natural variability. © 2011 Springer-Verlag.
{fenge}
80052078099	Ensemble empirical mode decomposition: A noise-assisted data analysis method	A new Ensemble Empirical Mode Decomposition (EEMD) is presented. This new approach consists of sifting an ensemble of white noise-added signal (data) and treats the mean as the final true result. Finite, not infinitesimal, amplitude white noise is necessary to force the ensemble to exhaust all possible solutions in the sifting process, thus making the different scale signals to collate in the proper intrinsic mode functions (IMF) dictated by the dyadic filter banks. As EEMD is a timespace analysis method, the added white noise is averaged out with sufficient number of trials; the only persistent part that survives the averaging process is the component of the signal (original data), which is then treated as the true and more physical meaningful answer. The effect of the added white noise is to provide a uniform reference frame in the timefrequency space; therefore, the added noise collates the portion of the signal of comparable scale in one IMF. With this ensemble mean, one can separate scales naturally without any a priori subjective criterion selection as in the intermittence test for the original EMD algorithm. This new approach utilizes the full advantage of the statistical characteristics of white noise to perturb the signal in its true solution neighborhood, and to cancel itself out after serving its purpose; therefore, it represents a substantial improvement over the original EMD and is a truly noise-assisted data analysis (NADA) method. © 2009 World Scientific Publishing Company.
{fenge}
80052082163	An anatomy of economic growth in Taiwan	This paper revises Sedgley's model of innovation-driven endogenous growth and applies it to the case of Taiwan. The methods of empirical mode decomposition (EMD) and constrained vector error correction (VEC model or VECM) are used in the process. The EMD is used to filter out very short term fluctuations in growth, while the VECM is used to detect the various factors that affect economic growth, including human capital, public and private capital, knowledge capital and public institutions (the index of protection of property rights). It is the first attempt to include such a rich set of factors affecting economic growth at least for the studies of Taiwan. © 2010 World Scientific Publishing Company.
{fenge}
80052082724	On the filtering properties of the empirical mode decomposition	The empirical mode decomposition (EMD) based time-frequency analysis has been used in many scientific and engineering fields. The mathematical expression of EMD in the time-frequency-energy domain appears to be a generalization of the Fourier transform (FT), which leads to the speculation that the latter may be a special case of the former. On the other hand, the EMD is also known to behave like a dyadic filter bank when used to decompose white noise. These two observations seem to contradict each other. In this paper, we study the filtering properties of EMD, as its sifting number changes. Based on numerical results of the decompositions using EMD of a delta function and white noise, we conjecture that, as the (pre-assigned and fixed) sifting number is changed from a small number to infinity, the EMD corresponds to filter banks with a filtering ratio that changes accordingly from 2 (dyadic) to 1; the filter window does not narrow accordingly, as the sifting number increases. It is also demonstrated that the components of a delta function resulted from EMD with any prescribed sifting number can be rescaled to a single shape, a result similar to that from wavelet decomposition, although the shape changes, as the sifting number changes. These results will lead to further understandings of the relations of EMD to wavelet decomposition and FT. © 2010 World Scientific Publishing Company.
{fenge}
80052083690	On intrinsic mode function	Empirical Mode Decomposition (EMD) has been widely used to analyze non-stationary and nonlinear signal by decomposing data into a series of intrinsic mode functions (IMFs) and a trend function through sifting processes. For lack of a firm mathematical foundation, the implementation of EMD is still empirical and ad hoc. In this paper, we prove mathematically that EMD, as practiced now, only gives an approximation to the true envelope. As a result, there is a potential conflict between the strict definition of IMF and its empirical implementation through natural cubic spline. It is found that the amplitude of IMF is closely connected with the interpolation function defining the upper and lower envelopes: adopting the cubic spline function, the upper (lower) envelope of the resulting IMF is proved to be a unitary cubic spline line as long as the extrema are sparsely distributed compared with the sampling data. Furthermore, when natural spline boundary condition is adopted, the unitary cubic spline line degenerates into a straight line. Unless the amplitude of the IMF is a strictly monotonic function, the slope of the straight line will be zero. It explains why the amplitude of IMF tends to be a constant with the number of sifting increasing ad infinitum. Therefore, to get physically meaningful IMFs the sifting times for each IMF should be kept low as in the practice of EMD. Strictly speaking, the resolution of these difficulties should be either to change the EMD implementation method and eschew the spline, or to define the stoppage criterion more objectively and leniently. Short of the full resolution of the conflict, we should realize that the EMD as implemented now yields an approximation with respect to cubic spline basis. We further concluded that a fixed low number of iterations would be the best option at this time, for it delivers the best approximation. © 2010 World Scientific Publishing Company.
{fenge}
80052084814	Model validation based on ensemble empirical mode decomposition	We proposed a new model validation method through ensemble empirical mode decomposition (EEMD) and scale separate correlation. EEMD is used to analyze the nonlinear and nonstationary ozone concentration data and the data simulated from the Taiwan Air Quality Model (TAQM). Our approach consists of shifting an ensemble of white noise-added signal and treats the mean as the final true intrinsic mode functions (IMFs). It provides detailed comparisons of observed and simulated data in various temporal scales. The ozone concentration of Wan-Li station in Taiwan is used to illustrate the power of this new approach. Our results show that, at an urban station, the ozone concentration fluctuation has various cycles that include semi-diurnal, diurnal, and weekly time scales. These results serve to demonstrate the anthropogenic origin of the local pollutant and long-range transport effects were all important. The validation tests indicate that the model used here performs well to simulate phenomena of all temporal scales. © 2010 World Scientific Publishing Company.
{fenge}
80052089430	North Atlantic Ocean Basin tropical cyclone activity as related to climate factors for the 2010 hurricane season	Atmospheric and oceanic climate factors and conditions play a crucial role in modulating seasonal/annual tropical cyclone activity in the North Atlantic Ocean Basin. In the following, correlations between North Atlantic tropical cyclone activity including frequency of occurrence and pathways are explored, with special emphasis on hurricanes. The value of two-dimensional and three-dimensional data sets representing climate patterns is investigated. Finally, the diagnostic study of historical tropical cyclone and hurricane temporal and spatial variability and relationships to climate factors lead to a statistical prognostic forecast, made in April, 2010, of the 2010 tropical cyclone and hurricane season. This forecast is tested both retrospectively and presently and is shown to be quite accurate. Knowing the probability of the frequency of occurrence, i.e. the numbers of named storms to form in general and the number of hurricanes (NHs) that are likely to form, is important for many societal sectors. However, the reliable forecasts of probable pathways of predicted events, specifically the likely NH land falls along the coastlines of the United States, should have great potential value to emergency planners, the insurance industry, and the public. The forecast provided in this study makes such a prognostication. As the 2010 hurricane season has progressed, an update of the goodness of the forecast is shown to be quite accurate in numbers of named events, hurricanes, major hurricanes (MHs), and landfalls. The mathematical and statistical methodology used in this study, which could be coupled to next generation "empirical modal decomposition," suggests that this may signal a new era in the future of tropical cyclone forecasting, including the reliable prognostication of numbers of events, intensities of events, and the pathways of those events. The ability to reliably predict the probability and location of land falls of these destructive events would be very powerful indeed. © 2010 World Scientific Publishing Company.
{fenge}
80052090213	Noise-modulated empirical mode decomposition	The empirical mode decomposition (EMD) is the core of the Hilbert-Huang transform (HHT). In HHT, the EMD is responsible for decomposing a signal into intrinsic mode functions (IMFs) for calculating the instantaneous frequency and eventually the Hilbert spectrum. The EMD method as originally proposed, however, has an annoying mode mixing problem caused by the signal intermittency, making the physical interpretation of each IMF component unclear. To resolve this problem, the ensemble EMD (EEMD) was subsequently developed. Unlike the conventional EMD, the EEMD defines the true IMF components as the mean of an ensemble of trials, each consisting of the signal with added white noise of finite, not infinitesimal, amplitude. In this study, we further proposed an extension and alternative to EEMD designated as the noise-modulated EMD (NEMD). NEMD does not eliminate mode but intensify and amplify mixing by suppressing the small amplitude signal but the larger signals would be preserved without waveform deformation. Thus, NEMD may serve as a new adaptive threshold amplitude filtering. The principle, algorithm, simulations, and applications are presented in this paper. Some limitations and additional considerations of using the NEMD are also discussed. © 2010 World Scientific Publishing Company.
{fenge}
80052098088	Smoothing empirical mode decomposition: A patch to improve the decomposed accuracy	Hilbert-Huang Transformation (HHT) is designed especially for analyzing data from nonlinear and nonstationary processes. It consists of the Empirical Mode Decomposition (EMD) to generate Intrinsic Mode Function (IMF) components, from which the instantaneous frequency can be computed for the time-frequency Hilbert spectral Analysis. Currently, EMD, based on the cubic spline, is the most efficient and popular algorithm to implement HHT. However, EMD as implemented now suffers from dependence on the cubic spline function chosen as the basis. Furthermore, due to the various stoppage criteria, it is difficult to establish the uniqueness of the decomposition. Consequently, the interpretation of the EMD result is subject to certain degree of ambiguity. As the IMF components from the classic EMD are all approximations from the combinations of piece-wise cubic spline functions, there could also be artificial frequency modulation in addition to amplitude modulation. A novel Smoothing Empirical Mode Decomposition (SEMD) is proposed. Although SEMD is also an approximation, extensive tests on nonlinear and nonstationary data indicate that the smoothing procedure is a robust and accurate approach to eliminate the dependence of chosen spline functional forms. Thus, we have proved the uniqueness of the decomposition under the weak limitation of spline fittings. The natural signal length-of-day 19651985 was tested for the performance in nonstationary and nonlinear decomposition. The resulting spectrum by SEMD is quite stable and quantitatively similar to the optimization of EMD. © 2010 World Scientific Publishing Company.
{fenge}
84555191266	Communication security using a combination of steganographic system and empirical mode decomposition	Information security has become a major issue in recent years, as new ways of information exchange arise due to the rapid development of computing, communication and internet technologies. We propose the image communication systems to secure the information by using a steganographic system and empirical mode decomposition method. The concealed message between the sender and receiver is important in the steganographic system. The encrypted message is further decomposed by using the empirical mode decomposition. The information is transmitted via the public channel and secure channel. At the receiver side the weak message can be retrieved back effectively. The retrieved message carries the same characteristics as the original message. Simulation results have confirmed that this combination model is highly robust against various signal processing operations and geometric attacks. The system increases the security of information data given a variety of constraints and conditions. Our methods have been proven effective for application in various fields which require secure communication, such as mobile telephone, internet and others. By means of this method, researchers can better understand the characteristics of the secure communication.
{fenge}
84863143628	Measurement of the irregular geometric shapes	Image presents the basic physical features of an object. Geometry, on the other hand, provides us a powerful way to quantify the information reflected by images or their shapes. Traditional geometry however finds limitation in describing the differences between highly irregular objects, which requires us to find new approaches to measure an object and quantify its difference from another. In this paper, we define some scalars in two dimensions to meet this demand. These approaches, grounded on circularity, convexity and cavity, describe the geometry of shapes in statistic sense, and they can also be applied to qualify the differences of shapes. © (2012) Trans Tech Publications.
{fenge}
84864837921	A reappraisal of ocean wave studies	A reappraisal of wave theory from the beginning to the present day is made here. On the surface, the great progress in both theory and applications seems to be so successful that there would be no great challenge in wave studies anymore. On deeper examination, we found problems in many aspects of wave studies starting from the definition of frequency, the governing equations, the various source functions of wave models, the directional development of wind wavefield, the wave spectral form and finally the role of waves as they affect coastal and global ocean dynamics. This is a call for action for the wave research community. For future research, we have to consider these problems seriously and also to examine the basic physics of wave motion to determine their effects on other ocean dynamic processes quantitatively, rather than relying on parameterization in oceanic and geophysical applications. © 2012. American Geophysical Union. All Rights Reserved.
{fenge}
84865332562	Empirical mode decomposition based detrended sample entropy in electroencephalography for Alzheimer's disease	Quantitative electroencephalographs (qEEG) provide a potential method to objectively quantify the cortical activations in Alzheimer's disease (AD), but they are too insensitive to probe the alteration of EEG in the early AD. The sample entropy (SaEn) attempts to quantify the complex information embedded in EEG non-linearly, which fits in that EEG originates from non-linear interactions. However, a technical issue which has been ignored by most researchers is that the signal should be stationary. In order to resolve the non-stationarity of SaEn in EEG to improve the sensitivity, an empirical mode decomposition (EMD) was applied for detrending in this study. Twenty-seven AD patients (9M/18F; mean age 74.0 ± 1.5 years) were included. Their initial Minimal Mental Status Examination was 19.3 ± 0.7. They received the first resting-awake 30-mine EEG before the therapy. Five of them received a follow-up examination within 6 months after the therapy. The 30-s EEG data without artifacts were selected and analyzed with a new proposed method, "EMD-based detrended-SaEn" to attenuate the influence of intrinsic non-stationarity. The correlation factors in 27 AD patients showed a moderate correlation (0.361-0.523, p<0.05) between MMSE and EMD-based detrended SaEn in Fp1, Fp2, F4 and T3. There was a high correlation (Correlation coefficient=0.975, p<0.05) between the changes of MMSE and the changes of EMD-based detrended-SaEn in F7 in 5 follow-up patients. The dynamic complexity of EEG fluctuations is degraded by pathological degeneration, and EMD-based detrended SaEn provides an objective, non-invasive and non-expensive tool for evaluating and following AD patients. © 2012.
{fenge}
84869080097	Complexity of spontaneous BOLD activity in default mode network is correlated with cognitive function in normal male elderly: A multiscale entropy analysis	The nonlinear properties of spontaneous fluctuations in blood oxygen level-dependent (BOLD) signals remain unexplored. We test the hypothesis that complexity of BOLD activity is reduced with aging and is correlated with cognitive performance in the elderly. A total of 99 normal older and 56 younger male subjects were included. Cognitive function was assessed using Cognitive Abilities Screening Instrument and Wechsler Digit Span Task. We employed a complexity measure, multiscale entropy (MSE) analysis, and investigated appropriate parameters for MSE calculation from relatively short BOLD signals. We then compared the complexity of BOLD signals between the younger and older groups, and examined the correlation between cognitive test scores and complexity of BOLD signals in various brain regions. Compared with the younger group, older subjects had the most significant reductions in MSE of BOLD signals in posterior cingulate gyrus and hippocampal cortex. For older subjects, MSE of BOLD signals from default mode network areas, including hippocampal cortex, cingulate cortex, superior and middle frontal gyrus, and middle temporal gyrus, were found to be positively correlated with major cognitive functions, such as attention, orientation, short-term memory, mental manipulation, and language. MSE from subcortical regions, such as amygdala and putamen, were found to be positively correlated with abstract thinking and list-generating fluency, respectively. Our findings confirmed the hypothesis that complexity of BOLD activity was correlated with aging and cognitive performance based on MSE analysis, and may provide insights on how dynamics of spontaneous brain activity relates to aging and cognitive function in specific brain regions. © 2013 Elsevier Inc.
{fenge}
84871026598	Structural health monitoring based on HHT	Based on this adaptive data analysis a new method for nondestructive instrument method to monitor the health of a bridge has been developed. This new method is based on a transient test load and simple data collection. The nuclear of the method is the data analysis based on the HHT method for nonstationary and nonlinear time series analysis which consisted of the Empirical Mode Decomposition and Hilbert Spectral Analysis. The final decision on the health of the bridge structure is based on the nonlinear characteristic of the bridge responding frequency under different loading conditions and on the comparison between the free and the forced vibration frequencies all analyzed with HHT. Thus this alternative method enjoys many advantages: no a priori data required simple data collection minimum traffic disruption.
{fenge}
84872049930	Novel assessment of temporal variation in fractionated electrograms using histogram analysis of local fractionation interval in patients with persistent atrial fibrillation	Background - The characteristics of atrial electrograms associated with atrial fibrillation (AF) termination are controversial. We investigated the electrogram characteristics that indicate procedural AF termination during continuous complex fractionated electrogram ablation. Methods and Results - Fifty-two consecutive patients with persistent AF (47 men; aged 54±9 years), who underwent electrogram-based catheter ablation in the left atrium and coronary sinus after pulmonary vein isolation, were enrolled. The intracardiac bipolar atrial electrogram recordings were characterized by (1) fractionation interval (FI) analysis (>6 seconds), (2) kurtosis (shape of the FI histogram), and (3) skewness (asymmetry of the FI histogram). Sites showing complex, fractionated electrograms (mean FI ≤60 ms) were targeted, and AF was terminated in 20 patients (38%) after the pulmonary vein isolation. The conventional complex fractionated electrogram sites (mean ≤120 ms) in patients with AF termination exhibited higher median kurtosis (2.69 [interquartile range, 2.03-3.46] versus 2.35 [interquartile range, 1.79-2.48]; P=0.024) and higher complex fractionated electrogram-mean interval (102.7±19.8 versus 87.7±15.0; P=0.008) than patients without AF termination. Furthermore, AF termination sites had higher median kurtosis than targeted sites without AF termination (5.13 [interquartile range, 3.51-6.47] versus 4.18 [interquartile range, 2.91-5.34]; P<0.01) in patients with procedural termination. In addition, patients with AF termination had a higher sinus rhythm maintenance rate after a single procedure than patients without AF termination (log-rank test, P=0.007). Conclusions - A kurtosis analysis using the FI histogram may be a useful tool in identifying the critical substrate for persistent AF and potential responders to catheter ablation. © 2012 American Heart Association, Inc.
{fenge}
84874745158	Nonlinear analysis of fibrillatory electrogram similarity to optimize the detection of complex fractionated electrograms during persistent atrial fibrillation	Introduction: Currently, the identification of complex fractionated atrial electrograms (CFEs) in the substrate modification is mostly based on cycle length-derived algorithms. The characteristics of the fibrillation electrogram morphology and their consistency over time are not clear. The aim of this study was to optimize the detection algorithm of crucial CFEs by using nonlinear measure electrogram similarity. Methods and Results: One hundred persistent atrial fibrillation patients that underwent catheter ablation were included. In patients who required CFE ablation (79%), the time-domain fibrillation signals (6 seconds) were acquired for a linear analysis (mean fractionation interval and dominant frequency [DF]) and nonlinear-based waveform similarity analysis of the local electrograms, termed the similarity index (SI). Continuous CFEs were targeted with an endpoint of termination. Predictors of the various signal characteristics on the termination and clinical outcome were investigated. Procedural termination was observed in 39% and long-term sinus rhythm maintenance in 67% of the patients. The targeted CFEs didn't differ based on the linear analysis modalities between the patients who responded and did not respond to CFE ablation. In contrast, the average SI of the targeted CFEs was higher in termination patients, and they had a better outcome. Multivariate regression analysis showed that a higher SI independently predicted sites of termination (≥0.57; OR = 4.9; 95% CI = 1.33-18.0; P = 0.017). Conclusions: In persistent AF patients, a cycle length-based linear analysis could not differentiate culprit CFEs from bystanders. This study suggested that sites with a high level of fibrillation electrogram similarity at the CFE sites were important for AF maintenance. (J Cardiovasc Electrophysiol, Vol. 24, pp. 280-289, March 2013) © 2012 Wiley Periodicals, Inc.
{fenge}
84876054176	Effects of age, sex, index admission, and predominant polarity on the seasonality of acute admissions for bipolar disorder: A population-based study	Bipolar disorder seasonality has been documented previously, though information on the effect of demographic and clinical variables on seasonal patterns is scant. This study examined effects of age, sex, index admission, and predominant polarity on bipolar disorder seasonality in a nationwide population. An inpatient cohort admitted to hospital exclusively for mental illness was derived from the Taiwan National Health Insurance Research Database for 2002-2007. The authors identified 9619 inpatients with bipolar disorder, who had generated 15 078 acute admission records. An empirical mode decomposition method was used to identify seasonal oscillations in bipolar admission data, and regression and cross-correlation analyses were used to quantify the degree and timing of bipolar admission seasonality. Results for seasonality timing found that manic or mixed episodes peak in spring or summer, and depressive episodes peak in winter. Analysis for degree of seasonality revealed that (1) the polarity of patients' index admission predicted the seasonality of relapse admissions; (2) seasonality was significant in female admissions for depressive episodes and in male admissions for manic episodes; (3) young adults displayed a higher degree of seasonality for acute admissions than middle-aged adults; and (4) patients with predominantly depressive admissions displayed a higher degree of seasonality than patients with predominantly manic admissions. Demographic and clinical variables were found to affect the seasonality of acute admissions for bipolar disorders. These findings highlight the need for research on identification and management of seasonal features in bipolar patients.© Informa Healthcare USA, Inc.
{fenge}
84878212054	A study on the dynamic characteristics and ultimate capacity of steel transmission towers	The safety of steel towers strongly influences the reliability of power supply in transmission lines. The dynamic characteristics, non-linear behavior, and ultimate capacity of 345kV steel transmission towers are mainly studied in this article. The approach in this article is based on the ensemble empirical mode decomposition method, the down-sampling process, and the Hilbert-Huang transform. This study intends to identify vibration characteristics and detect damage from the measured ambient vibration data. Two different types of tower used by Taiwan Power Company (TPC), suspension towers (Type B) and strain towers (Type E), are discussed in this study. According to the specifications of the TPC Standard Code, the applied loads on a tower in the transverse, longitudinal, and vertical directions are determined, and the applied forces are increased gradually until the tower fails. Finally, the ultimate capacity for the tower are found by using the stiffness matrix operation approach dealing with non-linear behavior. The results of this study will be a valuable reference for advanced studies and for improving the design of steel transmission towers in Taiwan. © 2013 The Chinese Institute of Engineers.
{fenge}
84878345183	Suicide and media reporting: A longitudinal and spatial analysis	Purpose: The impact of media reporting on copycat suicides has been well established in various cases of celebrity suicide. However, knowledge is limited about the spatial and temporal relationship between suicide death and media reporting over a long period of time. This study investigated the association of suicide deaths with suicide news in longitudinal and spatial dimensions. Methods: All suicides during 2003-2010 (n = 31,364) were included. Suicide news in the study period was retrieved from Google News, and included all available news media in Taiwan. Empirical mode decomposition was used to identify the main intrinsic oscillation, reflecting both major and minor suicide events, and time-dependent intrinsic correlation was used to quantify the temporal correlation between suicide deaths and suicide news. Results: The media reporting of suicide was synchronized with increased suicide deaths during major suicide events such as celebrity death, and slightly lagged behind the suicide deaths for 1 month in other periods without notable celebrity deaths. The means of suicide reported in the media diversely affected the suicide models. Reports of charcoal burning suicide exhibited an exclusive copycat effect on actual charcoal burning deaths, whereas media reports of jumping had a wide association with various suicide models. Media reports of suicide had a higher association with suicide deaths in urban than in rural areas. Conclusions: This report suggested that a delayed effect of copycat suicide may exist in media reports of minor suicide events. The competitive reporting of minor suicide events must be avoided and addressed by media professionals. © 2012 Springer-Verlag.
{fenge}
84883408794	Cognitive and neuropsychiatric correlates of EEG dynamic complexity in patients with Alzheimer's disease	This study assessed the utility of multiscale entropy (MSE), a complexity analysis of biological signals, to identify changes in dynamics of surface electroencephalogram (EEG) in patients with Alzheimer's disease (AD) that was correlated to cognitive and behavioral dysfunction. A total of 108 AD patients were recruited and their digital EEG recordings were analyzed using MSE methods. We investigate the appropriate parameters and time scale factors for MSE calculation from EEG signals. We then assessed the within-subject consistency of MSE measures in different EEG epochs and correlations of MSE measures to cognitive and neuropsychiatric symptoms of AD patients. Increased severity of AD was associated with decreased MSE complexity as measured by short-time scales, and with increased MSE complexity as measured by long-time scales. MSE complexity in EEGs of the temporal and occipitoparietal electrodes correlated significantly with cognitive function. MSE complexity of EEGs in various brain areas was also correlated to subdomains of neuropsychiatric symptoms. MSE analysis revealed abnormal EEG complexity across short- and long-time scales that were correlated to cognitive and neuropsychiatric assessments. The MSE-based EEG complexity analysis may provide a simple and cost-effective method to quantify the severity of cognitive and neuropsychiatric symptoms in AD patients. © 2013 Elsevier Inc.
{fenge}
84886544583	Empirical mode decomposition-based time-frequency analysis of multivariate signals: The power of adaptive data analysis	This article addresses data-driven time-frequency (T-F) analysis of multivariate signals, which is achieved through the empirical mode decomposition (EMD) algorithm and its noise assisted and multivariate extensions, the ensemble EMD (EEMD) and multivariate EMD (MEMD). Unlike standard approaches that project data onto predefined basis functions (harmonic, wavelet) thus coloring the representation and blurring the interpretation, the bases for EMD are derived from the data and can be nonlinear and nonstationary. For multivariate data, we show how the MEMD aligns intrinsic joint rotational modes across the intermittent, drifting, and noisy data channels, facilitating advanced synchrony and data fusion analyses. Simulations using real-world case studies illuminate several practical aspects, such as the role of noise in T-F localization, dealing with unbalanced multichannel data, and nonuniform sampling for computational efficiency. © 1991-2012 IEEE.
{fenge}
84888070885	Intercomparison between observed and simulated variability in global ocean heat content using empirical mode decomposition, part I: Modulated annual cycle	This study proposes a new more precise and detailed method to examine the performance of IPCC AR4 models in simulation of nonlinear variability of global ocean heat content (OHC) on the annual time scale during 1950-1999. The method is based on the intercomparison of modulated annual cycle (MAC) of OHC and its instantaneous frequency (IF), derived by Empirical Mode Decomposition and Hilbert-Huang Transformation. In addition to indicate the general agreement in gross features globally between models and observation, our results point out the problems both in observation and in modeling. In the well observed Northern Hemisphere, models exhibit extremely good skills to capture nonlinear annual variability of OHC. The simulated MACs are highly correlated with observations (>0.95) and the IF of MACs varies coherently with each other. However, in sparsely observed Southern Hemisphere (SH), even though the simulated MACs highly correlate with observations, the IF shows significant difference. This comparisons show that the models exhibit coherent variability of IF of MACs in SH with each other, but not with observations, revealing the problems in the objective analyzed dataset using sparse observations. In the well observed tropic region, the models lack the coherence with the observations, indicating inadequate physics of the models in the tropical area. These results illustrate that the proposed method can be used routinely to identify problems in both models and in observation of the global ocean as a critical component of global climate change. © 2012 Springer-Verlag Berlin Heidelberg.
{fenge}
84888271200	Global sea level trend during 1993-2012	Projection of future sea level change relies on the understanding of present sea-level trend and how it has varied in the past. Here we investigate the global-mean sea level (GMSL) change during 1993-2012 using Empirical Mode Decomposition, in an attempt to distinguish the trend over this period from the interannual variability. It is found that the GMSL rises with the rate of 3.2 ± 0.4. mm/yr during 1993-2003 and started decelerating since 2004 to a rate of 1.8 ± 0.9. mm/yr in 2012. This deceleration is mainly due to the slowdown of ocean thermal expansion in the Pacific during the last decade, as a part of the Pacific decadal-scale variability, while the land-ice melting is accelerating the rise of the global ocean mass-equivalent sea level. Recent rapid recovery of the rising GMSL from its dramatic drop during the 2011 La Niña introduced a large uncertainty in the estimation of the sea level trend, but the decelerated rise of the GMSL appears to be intact. © 2013 Elsevier B.V.
{fenge}
84890719332	A new method for bridge structure health monitoring	This paper describes a field assessment and evaluation of a concrete highway bridge with health monitoring instrumentation on the bridge structural elements and with a nonstationary and nonlinear time series evaluation method consisting of empirical mode decomposition and Hilbert Spectral analysis. The final decision on the health diagnostics of the bridge system depends on the nonlinear characteristics of the data, the free and the forced vibration frequencies, and the bridge response to the light load and/or the heavy load. The advantages of this method are (1) simple data collection required, (2) minimum traffic disruption, (3) precise and nuance quantitative answers. A case study was included by using this new method of analysis for structural diagnostics from health monitoring on an old damage concrete bridge. © 2006 Taylor & Francis Group.
{fenge}
84891500111	Prevalence, characteristics, mapping, and catheter ablation of potential rotors in nonparoxysmal atrial fibrillation	Background: Identification of critical atrial substrates in patients with nonparoxysmal atrial fibrillation (AF) failing to respond to pulmonary vein isolation is important. This study investigated the signal characteristics, substrate nature, and ablation results of rotors during AF. Methods and Results: In total, 53 patients (age=55±8), 31 with persistent AF and 22 with long-lasting AF, underwent pulmonary vein isolation and substrate modification of complex fractionated atrial electrograms. Small-radius-reentrant rotors were identified from signal analyses of the dominant frequency and fractionation interval and nonlinear analyses (newly developed, beat-to-beat nonlinear measurement of the repetitiveness of the electrogram morphology >6 seconds). In 15% of the patients, activation maps demonstrated occurrences of rotor-like small-radius reentrant circuits (n=9;1.1 per patient; cycle length=110±21 ms; diameter=11±6 mm) with fibrillation occurring outside these areas. Rotors were identified by conventional point-by-point mapping and signal analyses and were subsequently eradicated by catheter ablation in these patients. Persistent AF for <1 year, a smaller left atrial size, substrates with higher mean voltages and shorter total activation durations predicted a higher incidence of rotors (all P<0.05). In the multivariable model, areas of reentrant circuits exhibited a higher dominant frequency, kurtosis, and higher degree of a beat-to-beat electrogram similarity than areas without or outside the rotors (all P<0.05). Conclusions: Rotor-like re-entry with fibrillatory conduction was found in a limited number of patients with nonparoxysmal AF after pulmonary vein isolation. Those areas were characterized by rapid repetitive activity with a high degree of electrogram similarity. © 2013 American Heart Association, Inc.
{fenge}
84892157869	Application of steganography and empirical mode decomposition in communications security	Information security has become a major issue in recent years, as new ways of information exchange arise due to the rapid development of computing, communication and internet technologies. The steganography concealed the information between the sender and receiver without causing any attention by third party. The encrypted algorithm transformed and substituted the hidden information. The encrypted message with secret key is transmitted via the communication channel. At the receiver side the weak encrypted message can be retrieved back effectively. Thus, we propose the image communication systems to secure the information by using a steganographic system and empirical mode decomposition method. Simulation results have confirmed that this combination model is highly robust against various signal processing operations and geometric attacks. By giving a variety of constraints and conditions, the proposed system increases the security in communication system. Our methods have been proven effective for applications in various fields which require secure communication, such as mobile telephone, internet and others. © 2013 International Information Institute.
{fenge}
84901407726	A new dynamic building health monitoring method based on the Hilbert-Huang Transform	The theoretical solution for a Multiple-Degree-Of-Freedom (MDOF) structure is composed of a combination of several individual modes. When we demonstrate the actual response directly on the time-frequency spectrum, the energy distribution is usually concentrated at some range of frequencies, with the temporal variations of each band clearly shown. Those variations in the frequencies are the actual structure performances even though those "modal behaviors" are not coming from the theoretical solutions. Using the Hilbert-Huang Transform (HHT) the modal behaviors can be obtained easily by directly reading the time-frequency spectrum. To find Structural-Health- Monitoring (SHM) information, some numerical steps are found helpful. Including the signal enhancement skills, the time-frequency domain amplification function (T.F.AF), the modal temporal variation curve (MTVC) and the instantaneous frequency application. We develop a new method called the HHT SHM method; both experiment measurement and building observation are used to show the performance and method-validation. The procedures are described as follows. The original signal is first transferred into the wave-propagating properties, the T.F.AF. The T.F.AF can give dynamic parameter results through all phases in an earthquake event. After adopting useful modal information from the T.F.AF, which is called the MTVC. The MTVC contains detailed SHM information that enables observers to read the modal behavior. This is a new way to explore SHM information from actual records. These MTVCs can be used to explore the vivid differences in structure healthy conditions that might be ignored by other observers.
{fenge}
84902160538	The APOE e{open}4 allele affects complexity and functional connectivity of resting brain activity in healthy adults	The apolipoprotein E (APOE) gene is associated with structural and functional brain changes. We have used multiscale entropy (MSE) analysis to detect changes in the complexity of resting blood oxygen level-dependent (BOLD) signals associated with aging and cognitive function. In this study, we further hypothesized that the APOE genotype may affect the complexity of spontaneous BOLD activity in younger and older adults, and such altered complexity may be associated with certain changes in functional connectivity. We conducted a resting-state functional magnetic resonance imaging experiment in a cohort of 100 younger adults (aged 20-39 years; mean 27.2±4.3 years; male/female: 53/47) and 112 older adults (aged 60-79 years; mean 68.4±6.5 years; male/female: 54/58), and applied voxelwise MSE analysis to assess the main effect of APOE genotype on resting-state BOLD complexity and connectivity. Although the main effect of APOE genotype on BOLD complexity was not observed in younger group, we observed that older APOE e{open}4 allele carriers had significant reductions in BOLD complexity in precuneus and posterior cingulate regions, relative to noncarriers. We also observed that reduced BOLD complexity in precuneus and posterior cingulate regions was associated with increased functional connectivity to the superior and inferior frontal gyrus in the older group. These results support the compensatory recruitment hypothesis in older APOE e{open}4 carriers, and confer the impact of the APOE genotype on the temporal dynamics of brain activity in older adults. © 2013 Wiley Periodicals, Inc.
