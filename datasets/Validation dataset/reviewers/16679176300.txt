{fenge}
1542376001	Reduce the number of support vectors by using culstering techniques	A serious problem of Support Vector Machine (SVM) is its low classifying speed. The speed depends on the number of support vectors. The Clustering Svm, proposed in this paper, is a new method to reduce the number of support vectors. The method uses a k-means clustering technique to assign the data of each class to k groups, then we train the Svm based on a new dataset consist of the central vectors of each group. The value of k is the upper bound of the number of support vector in the class. Experiment results demonstrate that our method can control the tradeoff between the classifying speed and the performance of SVM.
{fenge}
1642423650	A Scalable High Performance Network Monitoring Agent for CERNET	In a cost-effective way, collecting and analyzing data from such a nationwide operational network as China Education and Research Network (CERNET) is an increasingly challenging task. This paper presents experience gained in designing and implementing a passive monitoring agent applicable to CERNET, which helps to cooperate not only with network intrusion detection system (IDS), network management system (NMS) for detecting and identifying signs of malicious activities, non-malicious failures and other exceptional events in real-time, but provides anomaly information to accounting and billing system (ABS) so as to make it healthy. This agent is characterized by a high performance data collecting facility and a methodology of real-time data correlation and analysis. A customized agent can be deployed on a particular link of CERNET for monitoring network dynamically. The paper will discuss how to conflate, correlate, associate and refine measurement data to discriminate anomalies such as DoS from normal traffic, and how to respond to the anomalies for the purpose of operational network's health. It concludes with experiences learned from the development and deployment of the agent and ongoing research work.
{fenge}
1642635127	Attack Recall Control in Anomaly Detection	This paper presents an approach to controlling the attack recall in an anomaly detection system using Support Vector Machine (SVM). The recall and precision of SVM are controlled by the selection of the training model. The training model is selected by optimization method using Genetic Algorithm. A SVM training model optimization problem is presented and an expected attack recall is controlled by a tradeoff parameter ρ in the objective function. Experiment results demonstrate that as ρ increases from 0 to 1, the recall increases from 0 to 1. If we use the value of ρ to estimate the recall, the mean square error of this estimation is decreased during the evolution of the training model. Our approach allows a user to design a system with an expected recall while the precision is high.
{fenge}
19544371376	On the correspondency between TCP acknowledgment packet and data packet	At the TCP sender side, the arrival of an ack packet always triggers the sender to send data packets, which establishes a correspondency between the arrived ack packet and the sent data packets. In a TCP connection, the correspondency between every ack packet and its corresponding data packets forms a sequence. This sequence characterizes the sender's behavior. In this paper, we propose a method to estimate this correspondency sequence from the dump trace measured at the receiver side. Because many possible correspondency sequences can be constructed based on the trace, the problem here is an estimation problem, which is to select a most possible one from those candidate sequences. The method proposed first eliminates some candidates that violate basic TCP congestion behavior. Then, it chooses the most possible one among the remaining sequences using the statistical characteristics of delays between the acks and their corresponding data packets under maximum-likelihood criterion. The method can work in the condition when the TCP connection experiences various network delay and loss, and it applies to TCP senders of different versions. Simulations and Internet experiments have been performed to validate the method. Copyright 2003 ACM.
{fenge}
2442621091	Optical network: CERNET's experiences and prospective	China Education and Research Network (CERNET) is the largest academic Internet backbone in China and one of the largest in the world. This paper will introduce the current CERNET infrastructure as well as the CERNET's next generation plan. CERNET has more than 20.000KM dark fibers and operates its own DWDM transport network. Currently it is a 40Gbps system, providing 2.5Gbps router-to-router connectivity for the 8 CERNET GigaPops and reaches all the provincial capitals via a 155Mbps-2.5Gbps backbone. It connects more than 1200 universities and research institutions. Most connected university campus networks are IGbps based. The number of end users is about 12 Million. The traffic statistics will be analyzed in this paper and the future bandwidth demand will be estimated. CERNET is also evolving to the next generation Internet. It connects to Internet2 and other next generation academic experimental Internet backbones worldwide. The goals of next generation CERNET are to provide a high-speed backbone network and to offer services to meet the demands of advanced research applications. The challenges are to provide scalable, high speed, high quality network services to all the universities and schools in China and their total 320M students and pupils. The current and future plans of CERNET will also be discussed in this paper, including the nationwide DWDM system, the CWDM MAN and campus network, the unified network management system, the lambda on demand service, the IPv6 service, the multicast service and large scale video service.
{fenge}
2342518879	Hybrid optimization of feature selection and SVM training model	A method was developed for hybrid optimization of feature selection and support vector machine (SVM) training models, using the interdependent relationship between the feature selection and the training model to improve the SVM performance. The method includes three important techniques: (1) The objective function is the SVM performance which is calculated using the ξα-estimate method; (2) The feature selection is described by a binary vector and the training model is described by a mixed kernel and tradeoff control parameters; (3) The hybrid optimization problem is solved using evolutionary algorithms. A standard data set for intrusion detection was used to compare the hybrid optimization method with single optimization and separate optimization methods and to compare the performances using genetic algorithms (GA) and particle swarm optimization (PSO). The experimental results show that the hybrid optimization method guarantees better SVM performance and that the optimization process using this approach has a higher rate of convergence than other optimization methods.
{fenge}
24944518771	Anomaly internet network traffic detection by kernel principle component classifier	As a crucial issue in computer network security, anomaly detection is receiving more and more attention from both application and theoretical point of view. In this paper, a novel anomaly detection scheme is proposed. It can detect anomaly network traffic which has extreme large value on some original feature by the major component, or does not follow the correlation structure of normal traffic by the minor component. By introducing kernel trick, the non-linearity of network traffic can be well addressed. To save the processing time, a simplified version is also proposed, where only major component is adopted. Experimental results validate the effectiveness of the proposed scheme. © Springer-Verlag Berlin Heidelberg 2005.
{fenge}
26444523414	An article language model for BBS search	Bulletin Board Systems (BBS), similar to blogs, newsgroups, online forums, etc., are online broadcasting spaces where people can exchange ideas and make announcements. As BBS are becoming valuable repositories of knowledge and information, effective BBS search engines are required to make the information universally accessible and useful. However, the techniques that have been proven successful for web search are not suitable for searching BBS articles due to the nature of BBS. In this paper, we propose a novel article language model (LM) to build an effective BBS search engine. We investigate the differences between BBS articles and web pages, then extend the traditional LM to author LM and category LM. The article LM is powerful in the sense that it can combine the three LMs into a single framework. Experimental results shows that our article LM substantially outperforms both INQUERY algorithm and the traditional LM. © Springer-Verlag Berlin Heidelberg 2005.
{fenge}
28444479158	A novel boosting-based anomaly detection scheme	As a crucial issue in computer network security, anomaly detection is receiving more and more attention from both application and theoretical point of view. In this paper, by introducing boosting technique, a novel anomaly detection scheme is proposed. On the whole, the proposed scheme is based on Ada-Boost and can be viewed as an extension of Ada-Boost in terms of both probability density estimation (PDE) and confidence area estimation (CAE). Different kinds of base learners are adopted and investigated in the proposed scheme. Systematic experimental results on DARPA 1999 dataset validate the effectiveness of the proposed scheme. © 2005 IEEE.
{fenge}
2942633541	Optical network: CERNET's experiences and prospective	China Education and Research Network (CERNET) is the largest academic Internet backbone in China and one of the largest in the world. This paper will introduce the current CERNET infrastructure as well as the CERNET's next generation plan. CERNET has more than 20.000KM dark fibers and operates its own DWDM transport network. Currently it is a 40Gbps system, providing 2.5Gbps router-to-router connectivity for the 8 CERNET GigaPops and reaches all the provincial capitals via a 155Mbps-2.5Gbps backbone. It connects more than 1200 universities and research institutions. Most connected university campus networks are 1Gbps based. The number of end users is about 12 Million. The traffic statistics will be analyzed in this paper and the future bandwidth demand will be estimated. CERNET is also evolving to the next generation Internet. It connects to Internet2 and other next generation academic experimental Internet backbones worldwide. The goals of next generation CERNET are to provide a high-speed backbone network and to offer services to meet the demands of advanced research applications. The challenges are to provide scalable, high speed, high quality network services to all the universities and schools in China and their total 320M students and pupils. The current and future plans of CERNET will also be discussed in this paper, including the nationwide DWDM system, the CWDM MAN and campus network, the unified network management system, the lambda on demand service, the IPv6 service, the multicast service and large scale video service.
{fenge}
2942662198	Optical network: CERNET's experiences and prospective	China Education and Research Network (CERNET) is the largest academic Internet backbone in China and one of the largest in the world. This paper will introduce the current CERNET infrastructure as well as the CERNET's next generation plan. CERNET has more than 20,000KM dark fibers and operates its own DWDM transport network. Currently it is a 40Gbps system, providing 2.5Gbps router-to-router connectivity for the 8 CERNET GigaPops and reaches all the provincial capitals via a 155Mbps-2.5Gbps backbone. It connects more than 1200 universities and research institutions. Most connected university campus networks are 1Gbps based. The number of end users is about 12 Million. The traffic statistics will be analyzed in this paper and the future bandwidth demand will be estimated. CERNET is also evolving to the next generation Internet. It connects to Internet2 and other next generation academic experimental Internet backbones worldwide. The goals of next generation CERNET are to provide a high-speed backbone network and to offer services to meet the demands of advanced research applications. The challenges are to provide scalable, high speed, high quality network services to all the universities and schools in China and their total 320M students and pupils. The current and future plans of CERNET will also be discussed in this paper, including the nationwide DWDM system, the CWDM MAN and campus network, the unified network management system, the lambda on demand service, the IPv6 service, the multicast service and large scale video service.
{fenge}
2942675345	Design and implementation of CERNET multicast network	China Education and Research Network (CERNET) is the first Native Multicast backbone in China. It now provides multicast service on all 10 GigaPops and is enlarging service to its 28 Pops. PIM-SM/MBGP/MSDP routing protocols with Anycast RPs are adopted to build multicast distribution tree and exchange SAs (source active) in ultra-domain and inter-domains. Several security polices are taken for multicast routing. CERNET multicast network has national multicast ISP peer with NSFCNET and international multicast ISP peers with APAN in JAPAN and STARTAP in U.S.A. This Paper addresses the key technologies for design and implementation of CERNET multicast network. IP/Multicast based Videoconference services developed on CERNET are also introduced in this paper.
{fenge}
30944433663	Analysis of honeypot deployment	Using honeypots to detect and monitor malware behaviors for network security trend analysis and early warning has become a new research direction. Honeypot deployment is the basic and all-important problem facing effectively collecting information of attackers. Research layers of honeypot deployment are firstly given and then some factors such as the interactive grade, the position, the number and the deploying model, which are related to honeypot deployment, are described. Especially under the condition of uniform distribution, the proper ratio of the number of honeypots to network total resources is deferred from theory and limited numbers of honeypots in IPv4 and IPv6 networks are given according to the ratio. Practical low interactive honeypots data statistical analysis is performed at last to give practical evidence for honeypot deployment research.
{fenge}
3042599906	Optical network: CERNET's experiences and prospective	China Education and Research Network (CERNET) is the largest academic Internet backbone in China and one of the largest in the world. This paper will introduce the current CERNET infrastructure as well as the CERNET's next generation plan. CERNET has more than 20,000KM dark fibers and operates its own DWDM transport network. Currently it is a 40Gbps system, providing 2.5Gbps router-to-router connectivity for the 8 CERNET GigaPops and reaches all the provincial capitals via a 155Mbps-2.5Gbps backbone. It connects more than 1200 universities and research institutions. Most connected university campus networks are IGbps based. The number of end users is about 12 Million. The traffic statistics will be analyzed in this paper and the future bandwidth demand will be estimated. CERNET is also evolving to the next generation Internet. It connects to Internet2 and other next generation academic experimental Internet backbones worldwide. The goals of next generation CERNET are to provide a high-speed backbone network and to offer services to meet the demands of advanced research applications. The challenges are to provide scalable, high speed, high quality network services to all the universities and schools in China and their total 320M students and pupils. The current and future plans of CERNET will also be discussed in this paper, including the nationwide DWDM system, the CWDM MAN and campus network, the unified network management system, the lambda on demand service, the IPv6 service, the multicast service and large scale video service.
{fenge}
30944442901	Experimental study on network coordinate-based node clustering	In the application of large-scale distributed network, node clustering is a useful way to construct an effective network infrastructure. Network coordinate can reflect node's position in Internet and can be used to predict the network distance. After getting every node's network coordinate, the triangulated heuristic method is used to predict the network distance between nodes. A distributed clustering algorithm using network distance is presented, having done the experiments on 156 nodes of PlanetLab testbed all over the world. The experimental results show that this algorithm can work well on large-scale node clustering in distributed way, and it has high reliability and scalability.
{fenge}
30944449705	Application of rank aggregation to campus network search engine	Relevance ranking is one of the key technologies for web pages search engine. Campus network search engine (CNSE) focuses on web information within a certain campus network, which has its own characteristics compared with Internet and Intranets. The influence of heuristic evidence in web page ranking and the performance of rank aggregation to CNSE were analyzed. The impact of each heuristic evidence differs in different data sets, and the recall of each combination of subsets of heuristics varies from 2% to 48%. The combination whose recall is over 35% includes at least four heuristics, that is, a few heuristics should be considered according to dataset in ranking system. The experimental results show that rank aggregation technology is necessary for producing robust results in CNSE. The rank aggregation algorithm has been deployed in Tsinghua University campus network search engine.
{fenge}
30944455531	Implementation and evaluation of Chinese spam filtering system	Spam has been a serious problem to e-mail users for a long time. Anti-spam technique can be used to block not only spam but also unsolicited commercial mobile messages and VoIP phones. A Chinese spam filtering system using Bayes filtering method is introduced and the evaluation is performed. It is shown that there are certain optimized values for the size of the training aggregate and the token numbers which are calculated to the final probability. If the size of the training aggregate exceeds the optimum value, the filtering effect will decrease a little and go to a constant as the aggregate size increases.
{fenge}
3042683479	Optical network: CERNET's experiences and prospective	China Education and Research Network (CERNET) is the largest academic Internet backbone in China and one of the largest in the world. This paper will introduce the current CERNET infrastructure as well as the CERNET's next generation plan. CERNET has more than 20,000KM dark fibers and operates its own DWDM transport network. Currently it is a 40Gbps system, providing 2.5Gbps router-to-router connectivity for the 8 CERNET GigaPops and reaches all the provincial capitals via a 155Mbps-2.5Gbps backbone. It connects more than 1200 universities and research institutions. Most connected university campus networks are IGbps based. The number of end users is about 12 Million. The traffic statistics will be analyzed in this paper and the future bandwidth demand will be estimated. CERNET is also evolving to the next generation Internet. It connects to Internet2 and other next generation academic experimental Internet backbones worldwide. The goals of next generation CERNET are to provide a high-speed backbone network and to offer services to meet the demands of advanced research applications. The challenges are to provide scalable, high speed, high quality network services to all the universities and schools in China and their total 320M students and pupils. The current and future plans of CERNET will also be discussed in this paper, including the nationwide DWDM system, the CWDM MAN and campus network, the unified network management system, the lambda on demand service, the IPv6 service, the multicast service and large scale video service.
{fenge}
3042686098	Optical network: CERNET's experiences and prospective	China Education and Research Network (CERNET) is the largest academic Internet backbone in China and one of the largest in the world. This paper will introduce the current CERNET infrastructure as well as the CERNET's next generation plan. CERNET has more than 20,000KM dark fibers and operates its own DWDM transport network. Currently it is a 40Gbps system, providing 2.5Gbps router-to-router connectivity for the 8 CERNET GigaPops and reaches all the provincial capitals via a 155Mbps-2.5Gbps backbone. It connects more than 1200 universities and research institutions. Most connected university campus networks are 1Gbps based. The number of end users is about 12 Million. The traffic statistics will be analyzed in this paper and the future bandwidth demand will be estimated. CERNET is also evolving to the next generation Internet. It connects to Internet2 and other next generation academic experimental Internet backbones worldwide. The goals of next generation CERNET are to provide a high-speed backbone network and to offer services to meet the demands of advanced research applications. The challenges are to provide scalable, high speed, high quality network services to all the universities and schools in China and their total 320M students and pupils. The current and future plans of CERNET will also be discussed in this paper, including the nationwide DWDM system, the CWDM MAN and campus network, the unified network management system, the lambda on demand service, the IPv6 service, the multicast service and large scale video service.
{fenge}
3142670350	HAG-based application layer multicast system for streaming media	A fault-tolerant system, the hierarchical arrangement graph (HAG), was developed for application layer multicast to support streaming media service. In HAG, the hosts are grouped into many arrangement graphs, with these arrangement graphs assembled into a tree structure. Independent multicast trees can be embedded into HAG to deliver different descriptions of the MDC media streaming. With HAG, a single host failure disrupts only one multicast tree, without affecting the data delivery in the other multicast trees which improves media delivery fault-tolerance. Simulation results show that HAG achieves up to 20% improvement of the average received bitrate compared with the traditional multicast strategy with a 5% host failure probability. In addition, HAG can cluster adjacent hosts into the same arrangement graph to improve the data delivery efficiency.
{fenge}
33646410079	Exploring statistical correlations for image retrieval	Bridging the cognitive gap in image retrieval has been an active research direction in recent years, of which a key challenge is to get enough training data to learn the mapping functions from low-level feature spaces to high-level semantics. In this paper, image regions are classified into two types: key regions representing the main semantic contents and environmental regions representing the contexts. We attempt to leverage the correlations between types of regions to improve the performance of image retrieval. A Context Expansion approach is explored to take advantages of such correlations by expanding the key regions of the queries using highly correlated environmental regions according to an image thesaurus. The thesaurus serves as both a mapping function between image low-level features and concepts and a store of the statistical correlations between different concepts. It is constructed through a data-driven approach which uses Web data (images, their surrounding textual annotations) as training data source to learn the region concepts and to explore the statistical correlations. Experimental results on a database of 10,000 general-purpose images show the effectiveness of our proposed approach in both improving search precision (i.e. filter irrelevant images) and recall (i.e. retrieval relevant images whose context may be varied). Several major factors which have impact on the performance of our approach are also studied.
{fenge}
33744734369	4over6: IPv4 network interconnection over IPv6 backbone without explicit tunneling	As IPv6 networks rapidly deployed, native IPv6 backbones (such as CNGI) are emerging. However, vast applications and services still stay in IPv4 network. Thus, interconnection of IPv4 networks over IPv6 backbones is required. Unfortunately, there are no suitable transition mechanisms available to satisfy this requirement. We propose a 4over6 framework for IPv4 network interconnection over IPv6 backbone without explicit tunneling. The 4over6 mechanism is discussed and analyzed. Prototype implementation verifies the theory of the framework. ISP independent deployment scheme then is proposed which reduces the routing overhead and increases the practicability of 4over6 deployment. Being transparent to IPv4 and IPv6 networks, the light weight scalable 4over6 framework is fit for large-scale complexity network interconnection with automatic discovery and control.
{fenge}
33646525176	Steganography based on baseline sequential JPEG compression	Information hiding in Joint Photographic Experts Group (JPEG) compressed images are investigated in this paper. Quantization is the source of information loss in JPEG compression process. Therefore, information hidden in images is probably destroyed by JPEG compression. This paper presents an algorithm to reliably embed information into the JPEG bit streams in the process of JPEG encoding. Information extraction is performed in the process of JPEG decoding. The basic idea of our algorithm is to modify the quantized direct current (DC) coefficients and non-zero alternating current (AC) coefficients to represent one bit information (0 or 1). Experimental results on gray images using baseline sequential JPEG encoding show that the cover images (images without secret information) and the stego-images (images with secret information) are perceptually indiscernible.
{fenge}
33646738466	Port scan behavior diagnosis by clustering	Detecting and identifying port scans is important for tracking malicious activities at early stage. The previous work mainly focuses on detecting individual scanners, while cares little about their common scan patterns that may imply important security threats against network. In this paper we propose a scan vector model, in which a scanner is represented by a vector that combines different scan features online, such as target ports and scan rate. A center-based clustering algorithm is then used to partition the scan vectors into groups, and provide a condense view of the major scan patterns by a succinct summary of the groups. The experiment on traffic data gathered from two subnets in our campus network shows that our method can accurately identify the major scan patterns without being biased by heavy hitters, meanwhile, possessing simplicity and low computation cost. © Springer-Verlag Berlin Heidelberg 2005.
{fenge}
33745790134	Distributed PageRank computation based on iterative aggregation- disaggregation methods	PageRank has been widely used as a major factor in search engine ranking systems. However, global link graph information is required when computing PageRank, which causes prohibitive communication cost to achieve accurate results in distributed solution, In this paper, we propose a distributed PageRank computation algorithm based on iterative aggregation-disaggregation (IAD) method with Block Jacobi smoothing. The basic idea is divide-and-conquer. We treat each web site as a node to explore the block structure of hyperlinks. Local PageRank is computed by each node itself and then updated with a low communication cost with a coordinator. We prove the global convergence of the Block Jacobi method and then analyze the communication overhead and major advantages of our algorithm. Experiments on three real web graphs show that our method converges 5-7 times faster than the traditional Power method. We believe our work provides an efficient and practical distributed solution for PageRank on large scale Web graphs. Copyright 2005 ACM.
{fenge}
33749166761	The transition to IPv6, Part II: The softwire mesh framework solution	Part I of this series described a prototype solution that provides dynamic IPv4 routing and forwarding across the IPv6-based China Education and Research Network (CERNET2). This work spawned an effort in the IETF to develop a generalized method for routing and tunneling different address families across uniform IPv4 or IPv6 backbone networks. Inspired by the CERNET2 effort, the IETF Softwires working group has introduced a framework for a solution that offers a generalized, network-based capability for routing and tunneling multiple address families across native IPv4 or IPv6 backbone networks. © 2006 IEEE.
{fenge}
33845535502	Time-driven vs packet-driven: A deep study on traffic sampling	Traffic sampling technology has been widely deployed in front of many high-speed network applications to alleviate the great pressure on packet capturing. Packet-driven sampling mechanism is believed better than time-driven one and no in-depth comparison is given to these two kinds of mechanisms. In this paper, a systematic comparison is conducted on three sampling methods, 1/N packet-driven, 1/T time-driven and t/T time-driven samplings, with a result showing that t/T sampling achieves similar accuracy as 1/N sampling in most aspects, and surpasses 1/N sampling in estimating the interval time distribution. Then we try to optimize performance of t/T sampling by tuning its parameters, and verify putative conclusions with both real and simulation traffic. The experiment in a real measurement application also indicates that these two kinds of sampling mechanisms achieve similar online estimation performance. © Springer-Verlag Berlin Heidelberg 2006.
{fenge}
33845353521	Hybrid prefix preserving IP address anonymization algorithm	Prefix preserving anonymization schemes are either slow or inconsistent. This paper describes a random bit string-based consistent prefix-preserving IP address anonymization scheme, which uses a pre-computed random bit string to reduce the computational overhead and accelerate the process. The hybrid algorithm with crypto-pan further reduces the large memory requirement. Experiments indicate that the time required for the bit string-based algorithm to process a set of addresses is only 1/10 that of the Crypto-pan algorithm. The time required for the hybrid algorithm is only 1/4 that of the Crypto-pan algorithm with far less memory than the bit string based approach. Therefore, the hybrid algorithm provides a better memory time compromise.
{fenge}
33947243579	A honeypot-based degree statistics method for scans detection	One of difficulties network scan detection system must face is how to identify a scan source from normal and abnormal hybrid traffics. In this paper, firstly we use modified low interaction honeypots to get pure abnormal scan traffics for avoiding scan sources identification procedure. Secondly, we try to consider scans detection problem through the eye of a network on the basis of above dataset. A 3 layers scan detection network is constructed where the node of every layer is Source-IP, Destination-IP and Resource (the couple {destination port, protocol}), the link is the scan access connection between nodes. The scan detection network owns good features of layer and single-direction. A degree statistics method is put forward to grade the importance of nodes of the scan detection network and give proper warnings. By using a degree statistics method on honeypot dataset we can focus on the research of scan sources' behaviors and stand out what's really worthy of noticing and warning instead of staying at the procedure of identifying whether a source is a scanner or not. Our method enriches the statistic information of scan detection and can effectively reduce warning false positives comparing to previous works. © 2006 IEEE.
{fenge}
34250760796	Forwarding IPv4 traffics in pure IPv6 backbone with stateless address mapping	As the IPv6 networks rapidly deployed, the transition problem has been changed. Because the transition of applications is a steady process with a far longer duration in comparison to the transition of infrastructure, providers cannot give up the duty of serving IPv4 traffics for the time being. On the other hand, operating a dual-stack backbone is highly costing for large-scale deployment of new networks. In this paper, a new technique of forwarding IPv4 traffics in IPv6-only backbone is developed. Rather than the ever-existing tunneling approaches, the proposed one is automatic and stateless for end nodes, without explicit tunneling. The route entries for delivering IPv4 traffics are well aggregated on the borders of IPv6 autonomous systems. This makes the technique suitable for large-scale deployment in an inter-domain networking environment. © 2006 IEEE.
{fenge}
35048844149	Learning image manifold using Web data	Manifold learning has become a hot research topic in recent years and is widely used in the area of dimension reduction, information retrieval and ranking, etc. However, how to reconstruct the intrinsic manifold from the observed data points, i.e. what is the proper data point distance measure, is still an open problem. In this paper, we propose to take advantages of the information provided by web-pages and the image-related website link structure to learn the Web image manifold, which better approaches to the intrinsic manifold than those learned by previous methods which use Euclidean alike distances to construct the initial affinity matrix. Experimental results prove the effectiveness of our learned Web image manifold. © Springer-Verlag Berlin Heidelberg 2004.
{fenge}
35048845672	Query based chinese phrase extraction for site search	Word segmentation(WS) is one of the major issues of information processing in character-based languages, for there are no explicit word boundaries in these languages. Moreover, a combination of multiple continuous words, a phrase, is usually a minimum meaningful unit. Although much work has been done on WS, in site web search, little has been explored to mine site-specific knowledge from user query log for both more accurate WS and better retrieval performance. This paper proposes a novel, statistics-based method to extract phrases based on user query log. The extracted phrases, combined with a general, static dictionary, construct a dynamic, site-specific dictionary. According to the dictionary, web documents are segmented into phrases and words, which are kept as separate index terms to build phrase enhanced index for site search. The experiment result shows that our approach greatly improves the retrieval performance. It also helps to detect many out-of-vocabulary words, such as site-specific phrases, newly created words and names of people and locations, which are difficult to process with a general, static dictionary. © Springer-Verlag 2004.
{fenge}
35048874291	A study of Internet packet reordering	Packet reordering is a well-known phenomenon that the order of packets is inverted in the Internet. Previous studies indicates reordering can affect the performance of both the network and the packets receiver. Nevertheless, they get different results about the prevalence of reordering in the Internet. In this paper, we firstly present a methodology for single-point reordering measurement at a TCP receiver, including the algorithm and its implementation. Then we show the results of our three-week observation of reordering from a set of 10,647 Internet Web sites in China. In addition, we discuss a method to distinguish reordering and loss by making use of the distribution of their time lag and packet lag. Finally, we study the pertinence of sites experiencing reordering according to the network topology and propose a novel and relatively reliable approach to infer reorder-generating spots in the Internet. © Springer-Verlag Berlin Heidelberg 2004.
{fenge}
36448957566	Estimating collection size with logistic regression	Collection size is an important feature to represent the content summaries of a collection, and plays a vital role in collection selection for distributed search. In uncooperative environments, collection size estimation algorithms are adopted to estimate the sizes of collections with their search interfaces. This paper proposes heterogeneous capture (HC) algorithm, in which the capture probabilities of documents are modeled with logistic regression. With heterogeneous capture probabilities, HC algorithm estimates collection size through conditional maximum likelihood. Experimental results on real web data show that our HC algorithm outperforms both multiple capture-recapture and capture history algorithms.
{fenge}
37349030697	NTS6: IPv6 based network topology service system of CERNET2	In this paper, we propose NTS6, an IPv6 based Network Topology Service system, which provides a Query and Response Service of Network Topology Information between any pair of hosts accessing IPv6 Internet via CERNET2. The NTS6 system periodically collects the latest OSPF, BGP and SNMP information of CERNET2. Based on these information, NTS6 provides Network Topology Information such as Net Distance, Available Bandwidth and Path Packet Loss in response to users' query. The real-world experiment on CERNET2 confirms the accuracy of our system. Also, NTS6 now performs well on large deployed Maze P2P File-Sharing System. We believe NTS6 will be a powerful middleware for other applications. © 2007 IEEE.
{fenge}
38049097552	Controllable multi-party audio/video collaboration based on multicast over CERNET	Multicast based multi-party audio/video collaboration system is one important application for collaboration in internet. Adopting multicast could save bandwidth for group communication. But native multicast is not ubiquitously available which hurdles the application, on the other hand, the current multicast based A/V collaboration system lacks effective control and service. This paper introduces the controllable multiparty audio/video collaboration systems based on multicast over China Education and Research Network (CERNET). The native multicast environment and performance monitoring, control and management on audio/video collaboration, session management and congestion controls are presented. The controllable multiparty collaboration system has been implemented and applied on CERNET successfully. © Springer-Verlag Berlin Heidelberg 2007.
{fenge}
38649140698	Network distance prediction based on network coordinate system	Network coordinates provide a practical and efficient way to estimate latencies among hosts in the network. In this paper, we study the problem of designing and implementing a Network Coordinate System (NCS). To combine advantages from both Vivaldi and GNP algorithms, we propose our Network Coordinate System. We implement such a system on PlanetLab test-bed all over the world. Network distances can be predicted based on our Network Coordinate System. By performing experiments on PlanetLab, we show that NCS can predict network distances quickly and accurately. We believe that our system is a viable step to provide a network service of distance prediction in the Internet. © 2006 IEEE.
{fenge}
33644833772	Design and implementation of a scalable distributed information retrieval	To overcome the difficulties that the centralized information retrieval system has in coverage, freshness, access control, specialty, and network load, a scalable distributed information retrieval system was designed and implemented. The statistical information and search engine log was used to describe resource, the log-based CORI algorithm proposed in this paper is used to select resource. The distributed system is scalable as only 1% storage space, time, and network load of that of a centralized system is needed to build the system. The performance of log-based CORI algorithm is 9.8% better than that of CORI in recall-precision, and 8.1% better than that of CORI in Kendall's τ distance. The results show that log-based CORI is an efficient resource selection algorithm and is benefit to improve the performance of distributed information retrieval.
{fenge}
4143097145	Dynamic optimization of IEEE 802.11 CSMA/CA based on the number of competing stations	The number of competing stations has great influence on the performance of IEEE 802.11 MAC protocol based on the distributed coordination function (DCF), which utilizes Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA). Some researchers try to use performance modeling to analyze and optimize the protocol, but the strict assumptions of the modeling often lead to research results that could not be adaptive to the dynamic change of competing station number, which is extremely prevalent in today's IEEE 802.11 networks. Some other researchers try to use filters, based on accurate measurement, to estimate the number of competing stations, and improve system performance by dynamically tuning the protocol parameters. However, such mechanisms are too complex to apply in real environment Base on our discovery, we propose a simple adaptive optimization mechanism, DOOR (Dynamic Optimization on Range), for the IEEE 802.11 DCF, which is based on the subrange of competing station number. The reason, principle and method for partitioning subranges are introduced. Moreover, the detailed system model and performance evaluation for the new mechanism are given. The elaborate numerical results show that this mechanism could achieve much higher throughput and shorter delay than the standard IEEE 802.11 DCF in almost all the different competing stations numbers.
{fenge}
58049112274	Inter-domain access volume model: Ranking autonomous systems	Exploring topological structure at Autonomous System (AS) level is indispensable for understanding most issues in Internet services. Previous models of AS graph involve address or connectivity information separately, and neither of these information can serve as a comprehensive metric for evaluating an AS's contribution to the global routing. In this paper, we propose a new model for AS ranking named IDAV (Inter-Domain Access Volume). IDAV introduces the quantity of routed addresses into AS graph, and enriches the methodology of Internet marco structure inference. In IDAV, the magnitude of AS is measured with the primary eigenvector of the access volume matrix (Carriage Matrix) for AS graph. We construct the AS graph by parsing the forwarding information bases in border gateways. The computation, compared with previous approaches, demonstrate that IDAV model results in more accurate AS rankings. We believe the IDAV model is promisingly useful for studying inter-domain routing and Internet service behavior. © 2008 Springer Berlin Heidelberg.
{fenge}
80052895304	Transition from IPv4 to IPv6: A translation approach	IPv4 addresses are already depleted in IANA and will be soon exhausted in RIR while more clients are pouring into the Internet. IPv6, as the only available next generation Internet protocol, is still not commercially successful because a scheme that could solve the migration of IPv4 resources to IPv6 network, as well as mutual communication between the two incompatible protocols, has not been fully developed and deployed. Translation solution provides a proper approach to address this problem. In this article, we propose IVI, an IPv4/IPv6 translation scheme, in order to facilitate resource migration and protocol transition. We explain how it works to translate between IPv4 and IPv6, and how combinations of IVI flavours and various translation scenarios are used in each phase of transition. The evaluation of scalability and robustness, which is important to a widely deployed translation scheme, is also discussed. © 2011 IEEE.
{fenge}
84861878721	Make best use of social networks via more valuable friend recommendations	The human factors behind how a user gets in touch with the others are complex especially in twitter-like social networks, which unlike Facebook-like social networks, are gradually showing great power in information propagation. In an effective friend recommendation, the identification of factors that influence links creation between users is essential. This paper makes a full study of the human factors in social networks and takes into account both the users' need of similar friends and diversified friends. This paper, focusing on Twitter-like social networks, enumerates several of those intuitive and connotative criteria in establishing friendship on-line and then designs a recommendation system that fit Twitter-like social networks to help improve the user experience and help user benefit from the architecture and resources from social networks. The recommendation mechanism is developed based on the incorporation of heterophily value and homophily value in establishing friendship into hybrid content and collaborative filtering recommendation algorithm. © 2012 IEEE.
{fenge}
84877724243	The establishment and application of cantonese/mandarin semantic relevant database for search engine	In the existing commercial search engines, the retrieval precision of Cantonese keyword is very low, which cannot meet users' demand. This paper improves machine translation techniques in Cross-Language Information Retrieval. It introduces Cantonese/Mandarin Semantic Relevant Database that's characteristic of Self-learning Artificial Intelligence and then puts forward a search engine model based on this database. Experimental results show that the search engine model based on Cantonese / Mandarin semantic relevant database is much more superior to the traditional search techniques in the Cantonese search. The search engine model greatly improves the retrieval precision of Cantonese while not affecting the performance of existing search engines.
{fenge}
46449136945	Telemeter: Network distance prediction base on network topology	Coordinates-based distance prediction algorithms can improve the performance of many Internet applications, especially in the peer-to-peer architecture and overlay construction. But some recent researches indicate that the performance gain via distance prediction based on coordinates, rather disappointed, can be significantly worse than the improvement obtained by direct measurement algorithm, and the inaccuracy of coordinates-based distance prediction would degrade the performance of applications evidently. In this paper, we propose a novel distance prediction algorithm base on network topology information, Telemeter, which uses the topology and routing information from CERNET2's ISP, instead of coordinates mechanism. Telemeter can predict the distance accurately between any pair of nodes from CERNET2 without any end-to-end measurement overhead. We evaluate the performance of Telemeter from P2P-related application's perspective systematically, and compare it with three representative coordinates-based distance prediction algorithms (Triangulated Heuristic, GNP, and IDES). We demonstrate that Telemeter overcomes some drawback shared among coordinates-based distance prediction algorithms, and bridge the significant performance gap between measurement-based algorithm and these algorithms. ©2007 IEEE.
{fenge}
4544375302	Range estimation and performance optimization for IEEE 802.11 based on filter	The dynamic character of complex and variable network environment, the key problem, puzzles the corresponding protocols design for Wireless LANs. However, the distributed coordination function (DCF) of IEEE 802.11 MAC protocol, which is Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA) using constant parameters, could not perform well when network environment changes. Thus many researchers try to optimize IEEE 802.11 DCF. However early dynamic optimization mechanisms for the protocol mostly depend on measuring the number of "competing" stations accurately. The problem of them is that the algorithms are too complex to apply in reality. In our research, we find that system performance approaches optimization with the same protocol parameters, when the number of competing stations changes within a certain range dynamically. Therefore, we propose a self-adaptive optimization mechanism, DOOR (Dynamic Optimization on Range), for the IEEE 802.11 DCF. DOOR uses filter to estimate the range of competing station number and adjusts the protocol parameters to optimize system performance effectively. The detailed analytical model and performance evaluation for the new mechanism are given. Moreover, the measurement method and parameters of filter are introduced. At last, the elaborate numerical results show that our mechanism could not only achieve much higher throughput and lower delay than the standard IEEE 802.11 DCF along with the change of competing stations, but also improve the stability of system performance based on reasonably partitioned ranges.
{fenge}
46449115885	Modeling of scale-free network with tunable clustering based on neighbor coefficients	Clustering coefficients do not indicate the connectivity of indirect neighbors and have limited to represent high-degree node clustering. This paper presents a clustering measurement, the neighbor coefficient, with a neighbor coefficient network model based on the statistical definition of the neighbor coefficient. The neighbor coefficient describes the neighbor evolution and quantifies the likelihood that indirect neighbors are also direct neighbors. The analysis indicates that the neighbor coefficient represents the clustering of all kinds of nodes. The neighbor coefficient network model extends the Barabási-Albert (BA) scale-free network model by introducing a local-link which is the neighbor evolution mechanism. Simulations indicate that the model has both tunable clustering and a power-law distribution of the node degrees.
{fenge}
47749101236	A peer-to-peer traffic identification method using machine learning	The use of peer-to-peer (P2P) applications is growing dramatically, which results in several serious problems such as the network congestion and traffic hindrance. In this paper, a method is proposed to identify the P2P traffic based on the machine learning. The novelty of the proposed method is that it utilizes only the size of packets exchanged between IPs within seconds. By investigating the ratio between the upload and download traffic volume of several P2P applications, a characteristic library is constructed. Then the unknown network traffic can be recognized online using this library. The distinguished features of the proposed method lie in that fast computation, high identification accuracy, and resource-saving capability. Finally, experiment results show the satisfactory performance of the proposed method. © 2007 IEEE.
{fenge}
48149084974	Building a robust and economical Internet testbed: 6PlanetLab	Building a robust and economical Internet testbed will contribute a lot to the study, the use, and the deployment of new Internet technologies. In this paper, we present our experience on building such a testbed in China, named 6PlanetLab. To achieve better robustness, we design and implement a mechanism for semi automatical fail-over and a slice-integrated interface for fault-tolerance. To increase cost-efficiency, we adopt greedy sharing mechanism to leverage all available resources and develop simple but strong tools to save management cost. The six-month running data of 6PlanetLab demonstrate the success of our design. We believe 6PlanetLab is a good paradigm for other communities. © 2007 IEEE.
{fenge}
48349112377	Source address validation: Architecture and protocol design	The current Internet addressing architecture does not verify the source address of a packet received and forwarded. This causes serious security and accounting problems. Based on the drastically increased IPv6 address space, a "Source Address Validation Architecture" (SAVA) is proposed in this paper, which can guarantee that every packet received and forwarded holds an authenticated source IP address. The design goals of the architecture are lightweight, loose coupling, "multi-fence support" and incremental deployment. This paper discusses the details of design and implementation for the architecture, including inter-AS, intra-AS and local subnet. This architecture is deployed into the CNGI-CERNET2 infrastructure -a large-scale native IPv6 backbone network of the China Next Generation Internet project. We believe that the Source Address Validation Architecture will help the transition to a new, more secure and sustainable Internet. ©2007 IEEE.
{fenge}
50249184741	Construct intra-cluster load-balancing overlay	In application layer multicast, peers' local service capacities are heterogeneous and span a large range, how to arrange the number of the node's connections is one load-balancing issue. The other important aspect of constructing efficient overlay network is to exploit network locality in the underlying network to decrease delivery latency for media streaming. In this paper, we propose one hierarchical structure overlay, in which peers are divided into clusters according peers' network distances. The intra-cluster nodes are self-organized to unstructured load-balancing overlay via fitness based preferential random walk. Simulation shows intra-cluster load-balancing could be gained via short walk. © 2007 IEEE.
{fenge}
49749116766	Web site recommendation using HTTP traffic	Collaborative Filtering (CF) is widely used in web rec-ommender systems, while most existing CF applications focus on transactions or page views within a single site. In this paper, we build a recommender system prototype, which suggests web sites to users, by collecting browsing events at routers without neither user nor website effort. 100 million HTTP flows, involving 11, 327 websites, are converted to user-site ratings using access frequency as the implicit rating metric. With this rating dataset, we evaluate six CF algorithms including one proposed algorithm based on IP address locality. Our experiments show that the recommendation from K nearest neighbors (R
{fenge}
50049103169	Swing - A novel mechanism inspired by Shim6 address-switch conception to limit the effectiveness of DoS attacks	Denial-of-Service (DoS) attacks play a significant role among all the network security issues today. In this paper, we present a mechanism (called Swing) to limit the effectiveness of DoS attacks. Inspired by the address-switch conception of the newly proposed shim6 protocol, Swing tries to protect servers from attacks by using a new strategy. In the mechanism, when a DoS attack is detected, the server will automatically change its address to get rid of the attack. Meanwhile, existing connections from normal clients will be kept using an address-switch protocol like shim6. A p2p network is included in the mechanism to help clients establish new connections to the server under attack situations, and side equipments are deployed near the server to monitor and reshape the network flow. This mechanism suggests a new kind of strategy to defend DoS attacks, and provides a resilient and effective solution. © 2008 IEEE.
{fenge}
50249091026	DV-based extensible video transport terminal for standard-definition video conference	Video conferencing systems have been widely used all over the word and bring much convenience to our daily life. With the increase of network capability, users of video conference desire upgrade of video quality more and more intensively. However, the extensibility for large-scale standard-definition video conference is seriously restricted by the ability of decoding multi-path standard-definition video flows simultaneously in conference clients. To solve this crucial problem, we design and implement a DV-based extensible video transport terminal with a combination of standard-definition and low-definition video flows both from a single input DV camcorder. The low-definition video is sampled from the original DV stream and its size and sample rate can be adjusted to accommodate different application conditions. Using this method, our video tool can solve the extensible problem in standard-definition video conference and shows much flexibility in many conference scenes. Based on this video tool, we propose an extensible and flexible architecture for standard-definition video conference which can also be used in high-definition video conferencing systems. © 2007 IEEE.
{fenge}
50249106346	A tunnels-between-hosts based method for IPv4 application over native IPv6 network	Along with the development of IPv6, native IPv6 networks will begin to appear. It would be helpful if we can provide an effective mechanism for existing IPv4-only applications to work in those native IPv6 networks. In this paper, we analyze the problems of some current transition methods, and present a new mechanism based on Tunnels-Between-Hosts. Our strategy is to provide the IPv4-only application with a temporary IPv4 "virtual address", which is negotiated directly between two communicating hosts using IPv6. We give a detailed description of our mechanism and compare it with some other mechanisms. © 2007 IEEE.
{fenge}
57849134606	End-to-end tomography and congestion control on multicast based videoconferencing	Congestions in many-to-many videoconferencing are usually caused by multiple senders, the congestion information feedback, bottleneck link judge and sending rate adjust are much different from one-tomany multicasting. In this paper, we propose one multicast congestion control scheme based on end-toend tomography (ET-MCC) for many-to-many videoconferencing. The end-to-end packet loss rates are measured and aggregated for judging bottleneck links through tomography approach. One performance server is adopted to aggregate the packet loss rate and do tomography with low overhead. The rates of senders that generate traffic on bottleneck links are equally adjusted to their acceptable value to realize congestion control with sender-fairness. By Simidations and applying the protocol to live videoconferencing of CERNET-MVC, ET-MCC is proved to be valid and effective. © 2008 IEEE.
{fenge}
62349122414	Multicast congestion control on many-to-many videoconferencing	Congestions in many-to-many videoconferencing are usually caused by multiple senders. Judging the congestion links and determining the adjusting bit rate of senders which caused the congestions are the two issues in congestion control. In this paper, we propose one multicast congestion control scheme based on packets transmission model of shared multicast tree. The end-to-end packet loss rates are measured to get PLR matrix for judging congestion links via tomography method. The bit rates of senders which cause congestions are adjusted to implement congestion control according to the packet loss rate of congestion links with sender-fairness. Simulations and experiments show the scheme is valid and effective. © 2008 IEEE.
{fenge}
65349109706	On modeling and deploying an effective scan monitoring system	Constructing an effective scan monitoring system is a necessary step for early detection and warning of unknown threats. Scan monitoring systems constructed by routable unused IP addresses will be more effective than those deployed in active networks for their special advantages in identifying threats precisely which results in low false alarm rate. Nowadays systematic researches on how to deploy such an effective monitoring system are still missing. This paper presents a novel scan monitoring model based on BGP route distribution to answer two practical deployment questions. One is how to design and deploy an ideal target-specified scan monitoring system and the other is how to evaluate the detecting effectiveness of actual limited deploying resources. On the basis of the model, this paper puts forward a new concept of deployment threshold which describes the most economical matching value between the monitoring system's scale and the scanner's scanning width on the same detection probability demand. According to the model and the deployment threshold, an effective monitoring system can be designed and appropriate detecting targets can be proposed which match the practical deploying resources to avoid blind deployment as before. Simulation results are coincident with the theretical analyses. © by Institute of Software, the Chinese Academy of Sciences.
{fenge}
64849092307	Receiver-based diagnosis of TCP bulk transfer rate limiting factors	This paper presents a receiver-based diagnostics method to identify the factors limiting the data transfer during transmission control protocol (TCP) downloads. The TCP timestamp option is used to determine the correspondency between the TCP packets. Then, the inflight bytes are calculated based on the correspondency. Finally, the dynamics of the inflight bytes are used to identify three limiting factors and their durations during data transfers. Testbed experiments indicate that the average estimation errors are less than 0.02. Internet experiments showing the usefulness of this tool identified the rate limiting factor as the receiver buffer with the TCP throughput doubled when the receiver buffer was doubled.
{fenge}
67249116906	Stateless Mapping and Multiplexing of IPv4 Addresses in Migration to IPv6 Internet	IPv4 addresses will be soon exhausted while more and more users are pouring into the Internet. It is commonly understood that IPv6 is definitely necessary for connecting new users, but lack of resources in current IPv6 world discourages providers from developing their IPv6 market. Address and packet translations are considered necessary for Internet content resources migrating from IPv4 world to IPv6, but up to now there is no one translation approach scalable enough. We understand the scalability is essentially restricted by the states in routing and those in translation, and accordingly we propose a novel architecture, called IVI, where IPv6 subscriber addresses are mapped from IPv4 with a certain rule that keeps IPv6 routing table well aggregated and makes translation stateless at all. Moreover, we introduce multiplex into the mapping to accommodate the trend of IPv4 addresses being more and more precious. Analysis based on real traffic data proves that the proposed approach is feasible to be deployed by an ISP for its customer networks and the potential degradation in end-to-end performance is acceptable. © 2008 IEEE.
{fenge}
68249097958	DTSM: Dynamic tunneling based scalable multicasting routing protocol	Multicasting states often exceed the router's capability due to wide deployment and extensive usage of IP layer multicasting. A dynamic tunneling based scalable multicasting routing protocol (DTSM) was developed to reduce the number of multicasting states connected to the router. The protocol eliminates non-branching node states by tunneling with sufficient state capacity, and achieves comparable efficiency to traditional multicasting. When the state capacity is exhausted, the protocol adjusts by adaptively tunneling the topology to further reduce the multicasting states at the expense of bandwidth and delay. Simulations show that the protocol reduces the maximum multicasting states by an order of magnitude without incurring significant bandwidth or delay overhead, which effectively alleviates multicasting state limitations.
{fenge}
70350439494	A binary-tree based algorithm for online duplicate documents detection	The redundancy of web information is growing rapidly with the development of Internet. The research on duplicate detection is ongoing and new methods are strongly needed. In this paper, we propose a novel algorithm for online duplicate documents detection which has four main features. First, it largely reduces the computational complexity especially for a huge amount of documents. Second, it has a high precision according to our practical experiments. Third, it is a kind of dynamic detection which can work continuously while increasing new documents. Last, it is self-adaptive and has little parameters. This approach is suitable for information retrieval as well as other applications dealt with document processing. 1548-7741/ Copyright © 2009 Binary Information Press.
{fenge}
71249097317	Address switching: Reforming the architecture and traffic of Internet	The success of the Internet is largely ascribable to the packet-switching scheme, which, however, also presents major challenges. Having identified three missing links in the current Internet architecture based on our long-term experiences of designing and operating large-scale backbones, we put forward a new, but incrementally deployable, network scheme-address switching. The address switching has both the advantages of packet switching and circuit switching; it supplies the missing links in the current Internet architecture and can reform the Internet traffic. Our analysis, protocol design and experiments indicate that the address switching can greatly improve the quality of service (QoS), security and routing scalability of today's Internet. So it can provide flexible, high-performance and "per-service" networking for the scientific research communities. Moreover, it can provide a fairer and more sustainable business model for the commodity Internet. © 2009 Science in China Press and Springer-Verlag GmbH.
{fenge}
71749109794	AoS: A scalable architecture for inter-domain IP multicast	IP multicast originally works in Any Source Multicast (ASM) that comes with great burden and dynamics on the backbone routers and weakness in inter-domain scalability. It also brought serious security and management problems. In contrast, Source-Specific Multicast (SSM) has been recognized as a simple, scalable and secure method, especially in inter-domain multicast. However, its applicability to many-to-many applications and other issues lead to stagnation in deployment. In this paper, a novel ASM-over-SSM (AoS) architecture is proposed as a solution for scalable inter-domain multicast. Evaluations demonstrate that AoS mitigates the dynamics and complexity in core routers, and reduces states in inter-domain multicast, without modification on current routing infrastructure and multicast applications.
{fenge}
72049118893	An ISP-friendly multiple IPv6 addresses configuration scheme	Internet is becoming an indispensible infrastructure of essential media, which makes a great burden for ISP's security and traffic management. Especially the situation will be much more serious in NGI (the Next-Generation Internet) because of its innumerable users, mobile device, information appliances (IA) and networked sensors etc with 128-bit IPv6 address. For the reason of lacking scalability, ISP's current security and traffic management scheme will be unavailable in NGI environment unless novel architecture and protocol proposed. In this paper, we studied the problem ISP faced and introduced an IPv6-based multiple addresses configuration scheme to ease ISP's traffic management in NGI environment. In the scheme, each type of service has its own source IPv6 address so that ISP can easily deploy security and traffic management policy with scalability. At the same time, QoS is improved and bandwidth is saved. In addition, some key technologies of the scheme are proposed in detail for future research activities focus on. ©2009 IEEE.
{fenge}
77955634132	Study on partial-transit inter-domain routing over the TEIN2 backbone	Based on the transit behavior, we categorize the Internet backbones into two types, global-transit backbone and partial-transit backbone. Partial-transit backbone represents the majority of R&E (Research & Education) backbones, which is liable to a number of inter-domain routing problems due to its particular characteristics. Through two routing cases in TEIN2 backbone, a typical R&E partial-transit backbone, we point out the main problems in partial-transit inter-domain routing, most of which are all relevant to inter-domain routing policy. After studying the related work on inter-domain routing policy, we propose a Distributed BGP Policy Simulation and Evaluation System, BGP-Grid. This solution is mainly out of consideration for operation and network engineering of TEIN2 backbone, which is proved to be practicable and effective during the three years' TEIN2 operation. ©2010 IEEE.
{fenge}
78149317279	Unbiased sampling in directed social graph	Microblogging services, such as Twitter, are among the most important online social networks(OSNs). Different from OSNs such as Facebook, the topology of microblogging service is a directed graph instead of an undirected graph. Recently, due to the explosive increase of population size, graph sampling has started to play a critical role in measurement and characterization studies of such OSNs. However, previous studies have only focused on the unbiased sampling of undirected social graphs. In this paper, we study the unbiased sampling algorithm for directed social graphs. Based on the traditional Metropolis-Hasting Random Walk (MHRW) algorithm, we propose an unbiased sampling method for directed social graphs(USDSG). Using this method, we get the first, to the best of our knowledge, unbiased sample of directed social graphs. Through extensive experiments comparing with the "ground truth" (UNI, obtained through uniform sampling of directed graph nodes), we show that our method can achieve excellent performance in directed graph sampling and the error to UNI is less than 10%.
{fenge}
79551639095	PET: Prefixing, encapsulation and translation for IPv4-IPv6 coexistence	IPv6 transition problem has become one of the key factors which are holding up the development of the next generation Internet. Aiming to solve IPv6 transition problem, several translation and tunneling techniques have been proposed, satisfying the demand of IPv4-IPv6 interconnection and traversing respectively. However, translation techniques can't convert the semantic between IPv4 and IPv6 protocol perfectly, and they have serious limitations in operation complexity and scalability. Researchers tried to decompose, simplify these problems and improve translation techniques accordingly, but they've come to little achievement since these problems result from the very nature of translation. We propose a novel approach of choosing appropriate translation spot to solve these problems in a different angle, and hence make effective use of translation technique. Then we propose a framework for IPv4-IPv6 coexistence called PET, which integrates tunneling and translation to support both traversing and IPv4-IPv6 interconnection, and uses them properly to constitute communication models in different scenarios. Moreover, we put forward PET signaling method to achieve automatic translation spot election and translation context advertisement, as a complement to the framework. ©2010 IEEE.
{fenge}
79951752598	Multi-party videoconferencing based on hybrid multicast with peer-forwarding	Multi-party videoconferencing is one many-to-many group communication application in which multicast could be utilized to save bandwidth. For native multicast is still not available everywhere, we need provide scalable and efficient way for unicast users to communicate with multicast-capable users in videoconferencing. This paper proposes one scalable hybrid multicast scheme with peer-forwarding for multi-party videoconferencing. The multicast-capable users are designed as peers to forward data as reflectors do. The group communication mechanisms of hybrid multicast with reflector-based and peer-based data forwarding are introduced. Session management, connection building between peers and unicast users, and terminal functions are introduced. We implement the videoconferencing system based on hybrid multicast and applied it on CERNET backbone. The applications and experiments show that the scheme is feasible and valid. © 2010 IEEE.
{fenge}
80053159413	Pomelo: Accurate and decentralized shortest-path distance estimation in social graphs	Computing the shortest-path distances between nodes is a key problem in analyzing social graphs. Traditional methods like breadth-first search (BFS) do not scale well with graph size. Recently, a Graph Coordinate System, called Orion, has been proposed to estimate shortest-path distances in a scalable way. Orion uses a landmark-based approach, which does not take account of the shortest-path distances between non-landmark nodes in coordinate calculation. Such biased input for the coordinate system cannot characterize the graph structure well. In this paper, we propose Pomelo, which calculates the graph coordinates in a decentralized manner. Every node in Pomelo computes its shortest-path distances to both nearby neighbors and some random distant neighbors. By introducing the novel partial BFS, the com- putational overhead of Pomelo is tunable. Our experimental results from different representative social graphs show that Pomelo greatly outperforms Orion in estimation accuracy while maintaining the same computational overhead.
{fenge}
80054825530	VDT: A data integration model for web applications	This paper proposes a three-layer model for web applications named VDT (View, Data Processor and Transceiver) and analyzes its performance. It standardizes the design of a web application when fetching data from different sources on both a browser by AJAX (Asynchronous JavaScript and XML) and an agent server. It has the benefits of general hierarchical models such as loosely coupled structure which can fit the varied data sources. Using the VDT model, we implement two web maps applications integrating data obtained from three sources. One gets the data from original sources directly by AJAX API while the other does through an agent server. They are vertical search engines of course. We compare these two applications and conclude that each has its own advantages in the response time, resource consumption and quality of results. © 2011 IEEE.
{fenge}
84863023786	Construct optimized overlay multicast via preferential random walk	Tree depth and load balancing are two main metrics in overlay multicast network. Optimizing the two metrics with lightweight overhead is important for live media streaming. This paper proposes one scheme to construct optimized overlay multicast with short tree depth and load balancing via short random walk. The key idea is the preferential random walk based on fitness function in which the tree depth and load balancing metrics are defined as parameters with weighted coefficients. Simulations and experiments show that the fitness function is valid and optimized overlay network could be constructed via preferential random walk. We also find the local and global optimized results occur at some middle value of coefficient between 0 and 1, which is not consist with our intuitions that optimized result with single metric should occur at the boundary of coefficient(0 or 1.0).
{fenge}
84863069505	Data selection for user topic model in twitter-like service	Twitter-like services are now a popular kind of online social networking services, in which user can express themselves, share contents, and follow others they are interested in. User modeling, building a model for user's interests, is a key problem in many social networking applications, such as recommendation, advertisement, etc. This paper focuses on data selection for user modeling in Twitter-like services. That is, we study the problem of how to select useful data to model a user's interests. Using different data, three user modeling methods are proposed and experiments on a real Twitter-like service are conducted to verify the effectiveness of proposed approaches. Experimental results shows that modeling user's interests with what he/she wrote and selectively what he read performs the best among the three methods we proposed. © 2011 IEEE.
{fenge}
84865620107	AUS: A scalable IPv6 multicast solution	While the deployment of IPv4 network-layer multicast has been mostly limited to LAN level networks due to scalability and management issues, the application of a large-scale, secure and controllable IPv6 multicast is of great interest in the current high-bandwidth transmission networks. In this paper we (1) define multicast application requirements, (2) propose a scalable IPv6 multicast framework solution (AUS) and (3) provide the evaluation and deployment of the AUS framework in CERNET2. Given the deployment of this scalable multicast framework, we believe that our solution offer the advantages of both a bandwidth-saving delivery network and strong controllability. © 2012 Springer-Verlag.
{fenge}
0036970757	An approach to accelerate convergence for path vector protocol	BGP, a path vector protocol, is the de facto interdomain routing protocol. However, slow convergence problem, the bigotry of path vector protocol, has demonstrated a significant impact on the performance of BGP. In this paper, we propose an enhancement to path vector protocol to alleviate the impact of slow convergence process. We compare the convergence time of the legacy path vector protocol and the improved one for complete AS graph, meanwhile the upper and lower bound of convergence time for any AS graph are given for the improved protocol. Simulation results reveal that the improved path vector protocol has a much better performance than the original one.
{fenge}
0036989620	Chinese keyword extraction based on max-duplicated strings of the documents	The corpus analysis methods in Chinese keyword extraction look on the corpus as a single sample of language stochastic process. But the distributions of keywords in the whole corpus and in each document are very different from each other. The extraction based on global statistical information only can get significant keywords in the whole corpus. Max-duplicated strings contain the local significant keywords in each document. In this paper, we designed an efficient algorithm to extract the max-duplicated strings by building PAT-tree for the document, so that the keywords can be picked out from the max-duplicated strings by their SIG values in the corpus.
{fenge}
84868092241	IVI-based locator/ID separation architecture for IPv4/IPv6 transition	The current Internet is challenged by the IPv4 address depletion. The stateless IPv4/IPv6 translation technology (IVI) is proposed to facilitate IPv4/IPv6 coexistence and transition. The IVI protocol translation involves the address mapping between IPv4 and IPv6, but the address mapping rules still rely on static configuration. In this paper, we propose an IVI-based locator/id separation architecture for IPv4/IPv6 transition. The new architecture provides a scalable address mapping mechanism and extends IVI to support inter-domain networking and host mobility. Through the deployment of this architecture, the Internet would eventually evolve into a pure IPv6 backbone while the IPv4 layer would be separated from the IPv6 network via protocol translation. © 2012 IEEE.
{fenge}
84871136547	Scalable distributed standard definition video conferencing system: architecture and forwarding model	Videoconferencing systems are widely used on the Internet with standard/high definition videoconferencing a key research topic. However, various videoconferencing systems (e.g. Access Grid, DVTS, VLC, and Ultra Grid) face the problem of scalability. Bandwidth is the primary factor that limits the system capacity. This paper presents the architecture of a scalable, distributed standard definition videoconferencing system and its forwarding model. Several data stream transmitters are used to cooperatively forward video streams. The system architecture, component behavior, and forwarding models were designed on both the control and data planes, with reasonable load allocation and balancing. The idea was implemented based on DVTS as a multi-point standard-definition distributed DVTS Plus and tested on the China Education and Research Network (CERNET). Tests on CERNET show that the distributed DVTS Plus provides higher system capacity, easier deployment and better scalability.
{fenge}
84872792917	Study on BGP security	BGP is a core Internet routing protocol. The Internet inter-domain routing relies on the exchange of BGP routing information. BGP has significant vulnerabilities, which have been found to cause problems such as prefix hijacking, route leak and Internet-targeted denial of service attack. First, by analyzing BGP route propagation and BGP routing policies, the fundamental flaw in the design of the protocol is revealed. The paper then discusses possible threats to BGP and presents a route leak model, which contributes to the description of its characteristics. Second, the existing defense mechanisms for BGP security are generalized, and their shortcomings are exposed. The paper then classifies various BGP security-enhancing technologies and studies them in detail to explore their advantages and disadvantages. Finally, the research trends of BGP security are discussed in this paper. © 2013 ISCAS.
{fenge}
84874738477	Unbiased sampling in directed social graph	Microblogging services, such as Twitter, are among the most important online social networks(OSNs). Different from OSNs such as Facebook, the topology of microblogging service is a directed graph instead of an undirected graph. Recently, due to the explosive increase of population size, graph sampling has started to play a critical role in measurement and characterization studies of such OSNs. However, previous studies have only focused on the unbiased sampling of undirected social graphs. In this paper, we study the unbiased sampling algorithm for directed social graphs. Based on the traditional Metropolis-Hasting Random Walk (MHRW) algorithm, we propose an unbiased sampling method for directed social graphs(USDSG). Using this method, we get the first, to the best of our knowledge, unbiased sample of directed social graphs. Through extensive experiments comparing with the "ground truth" (UNI, obtained through uniform sampling of directed graph nodes), we show that our method can achieve excellent performance in directed graph sampling and the error to UNI is less than 10%.
{fenge}
84875096069	Additive order preserving encryption based encrypted documents ranking in secure cloud storage	Ranking the encrypted documents stored on cloud storage servers is important in encrypted information retrieval. Order preserving encryption (OPE) could be used to help ranking the encrypted documents. However, order preserving encryption schemes don't support additions over cipher texts. A new additive order preserving encryption is proposed. Both the cipher text and the sum of the cipher texts preserve orders. By summing up the encryptions of term weights, the relevance between encrypted documents and queries are obtained. According to the relevance the documents are ranked. Experimental results show that the proposed encryption scheme based ranking could achieve very good retrieval performance. © 2012 Springer-Verlag.
{fenge}
0242469243	Evolving training model method for one-class SVM	This paper proposes and analyzes an evolving training model method for selecting the best training parameters of one-class Support Vector machines (SVM). The method: 1) presents and computes effectively the generalization performance of one-class SVM, including using fraction of support vectors and ξαρ-estimate of recall to evaluate the size of region and the generalization fraction of data points in the region, respectively; and 2) Uses Genetic Algorithms to evolve the training model, the evolution is supervised by the generalization performance of one-class SVM. Experiments on an artificial data illustrate the adaptation of the region to the distribution. Experiments on a standard intrusion detection dataset demonstrate that our method not only improves the false positive rate and detection rate, but also is able to control the tradeoff between these measures.
{fenge}
11244335585	Data-driven approach for bridging the cognitive gap in image retrieval	Bridging the cognitive gap in image retrieval has been an active research direction in recent years. Existing solutions typically require a large volume of training data that could be difficult to obtain in practice. In this paper, we propose a data-driven approach that uses Web images and their surrounding textual annotations as the source of training data to bridge the cognitive gap. We construct an image thesaurus that contains a set of codewords, each representing a semantically related subspace in the feature space. We also explore the use of query expansion based on the constructed image thesaurus for improving image retrieval performance.
{fenge}
13444282390	Multi-model similarity propagation and its application for Web image retrieval	In this paper, we propose an iterative similarity propagation approach to explore the inter-relationships between Web images and their textual annotations for image retrieval. By considering Web images as one type of objects, their surrounding texts as another type, and constructing the links structure between them via webpage analysis, we can iteratively reinforce the similarities between images. The basic idea is that if two objects of the same type are both related to one object of another type, these two objects are similar; likewise, if two objects of the same type are related to two different, but similar objects of another type, then to some extent, these two objects are also similar. The goal of our method is to fully exploit the mutual reinforcement between images and their textual annotations. Our experiments based on 10,628 images crawled from the Web show that our proposed approach can significantly improve Web image retrieval performance.
{fenge}
13444287777	Grouping web image search result	In this paper, we propose a Web image search result organizing method to facilitate user browsing. We formalize this problem as a salient image region pattern extraction problem. Given the images returned by Web search engine, we first segment the images into homogeneous regions and quantize the environmental regions into image codewords. The salient codeword "phrases" are then extracted and ranked based on a regression model learned from human labeled training data. According to the salient "phrases", images are assigned to different clusters, with the one nearest to the centroid as the entry for the corresponding cluster. Satisfying experimental results show the effectiveness of our proposed method.
