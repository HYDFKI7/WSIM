{fenge}
1542285057	Replay boundary detection in MPEG compressed video	With the large amounts of digital sports video increasing day-by-day, effectively analyzing sports video content has become more and more important. In sports video, replay scene often represents the highlight or interesting event of the video. The detection of replay boundary in the sports video is an important step in analyzing sports video content. In this paper, we present a model of replay boundary dectection, and we address a new technique of identifying the replay boundary directly from MPEG compressed domain. It uses MPEG feature including macroblock and motion vector that is easy extract from MPEG video, then applies the rule of macroblock and motion vector to the detection of replay boundary. For working on features directly from the MPEG compressed domain, it performs faster than real time decoding. The experiment results show our model-free method is effective and low complex.
{fenge}
23944503561	Automatic segmentation of moving objects in video sequences based on dynamic background construction	In this paper, an automatic segmentation algorithm for moving objects in video sequences based on dynamic background construction is proposed. First, based on a coarse separation of foreground from images, the dynamic background construction technique, an accurate background for current frame with information in temporally adjacent frames is constructed. Then, the intact moving objects' areas are obtained by subtracting the constructed background from the current frame and merging the static foreground areas (namely, parts of objects stopping moving between adjacent frames) detected using the temporal information. Finally, the accurate objects' contours are extracted by active contour (snake) using color gradient as its external energy. Experiments demonstrate that the proposed method is robust to the influence of uncovered background and objects' irregular motion, and able to extract moving objects successfully from video sequences with dynamic background.
{fenge}
27144481545	High throughput and low memory access sub-pixel interpolation architecture for H.264/AVC HDTV decoder	In this paper, we proposed a parallel and pipeline architecture for the sub-pixel interpolation filter in H.264/AVC conformed HDTV decoder. To efficiently use the bus bandwidth, we bring forward three memory access optimization strategies to avoid redundant data transfer and improve data bus utilization. To improve the processing throughput, we use parallel and multi-stage pipeline architecture for conducting data transmission and interpolation filtering in parallel. Moreover, To balance the tradeoff between memory accessing scheme and sub-pixel interpolation processing granularity we devise a dedicated buffer organization to convert tree-structured block size reading to fixable and sequential processing. As compared to the traditional designs, our scheme offers 60% reduced memory data transfer. While clocking at 66MHz, our design can support 1280x7200Hz processing throughput. The proposed design is suitable for low cost and real-time applications, Moreover, it can easily be applied in system-on-chip design. © 2005 IEEE.
{fenge}
28244461499	A panorama composition technique of sports video	A technique of composing mosaics from sports videos is proposed. First we select means of the temporal median for background composition, then we propose a foreground mix technique based on foreground region extraction and α-composition. To estimate the global motion, Konrad algorithm investigated in the framework of MPEG-4 and an outlier filter based on Fisher discriminant are used. The foreground mask is extracted from margin image by median filter and morphological filter. We add foreground region to background with a-composition. The final panoramas clearly show the full background and vivid actions of athletes.
{fenge}
30544438321	Sub-pixel motion compensation interpolation method and its high performance VLSI design	Transform and motion compensation hybrid coding structure is commonly adopted in modern video coding standards, which transforms the residues and codes motion vectors. The accuracy of motion compensation is the key technique in this coding scheme. As real motion has arbitrary precision, allowing motion vectors to have sub-pixel resolution can greatly improve the prediction accuracy. In order to estimate and compensate sub-pixel displacements, the image signal on sub-pixel position has to be generated by interpolation. This paper proposes a quarter-pixel interpolation method named as Two Steps Four Taps interpolation (TSFT), compared with interpolation method in H.264, 11% spatial complexity is reduced, computation complexity and average SNR is about the same. It has been adopted by the coding standard AVS1.0. In addition, sub-pixel interpolation is the computing and memory access bottleneck of video decoder. This paper proposes a VLSI architecture based on multiple stages pipeline, which reduces the bandwidth while accelerates interpolation operation and satisfies real-time decoding of HDTV sequences.
{fenge}
3142679492	Motion vector composition for frame-skipping transcoder	Video server should afford video frame-skipping transcoding for users because of clients' and network's heterogeneity. However, the video frame-skipping algorithm that directly reuses the motion vector from the incoming bit stream results in degraded video quality. Based on a forward dominant vector selection (FDVS) algorithm, discussed is the impact of different processing methods for motion vector out-of-range and forward intra dominant macroblock after the motion vector composition. An intra-refresh FDVS video transcoding algorithm is proposed. Experimental results show that the algorithm can stop the error propagation efficiently, decrease the bit rate of video stream, and increase the video quality.
{fenge}
33746937081	Motion adaptive deinterlacing with accurate motion detection and anti-aliasing interpolation filter	Both the motion-detection and intra-field interpolation filter are important factors affect the efficiency of motion adaptive de-interlacing. New accurate motion detection (AMD) algorithm is proposed to improve the accuracy of motion detection, which reduces the possibility of error motion detection with a median filter. To improve the efficiency of intra-field interpolation deinterlacing in moving regions, an anti-aliasing interpolation filter (AAIF) is proposed, which is better than the typical windowed sinc function. The simulation results show that peak signal noise ratio(PSNR) of our proposed deinterlacing method is 0.5-7.5 dB higher than that of previous studies and attains the best quality of subjective view. © 2006 IEEE.
{fenge}
33748469004	Complexity scalable algorithm for DCT in H.264	An improved fast DCT algorithm is set up to reduce the complexity of H.264 integer 4 × 4 DCT. Since the 4 × 4 DCT distribution does not fit Laplacian model well, three simplified blocks are defined and accordingly three coefficient distribution models are created based on a statistical analysis. Furthermore, a fast DCT algorithm based on new models is proposed. Three butterfly algorithms are designed for those 3 simplified blocks respectively, and the complexities of the proposed algorithms are analyzed and compared. Then, a complexity scalable algorithm based on the latter is presented to adjust the 4 × 4 DCT complexity on different platforms with limited computation resource. Simulation results show that the algorithm can control H. 264 4 × 4 DCT complexity within the target with negligible loss of encoding performance.
{fenge}
33749603962	Efficient quantization step selection scheme for I-frame in rate-constrained video coding	Quantization step (QS) selection for I-frame has an obvious impact on rate-distortion performance in rate-constrained video coding. An efficient QS selection scheme for I-frame is presented which is based on a balanced bits allocation scheme between I and P frames and a new experimental rate-quantization step (R-Q) model. In the balanced bits allocation scheme, firstly a model on the ratio of bits allocation between I and P frame is derived under the constraint of certain target bit rate; then based on the model, a feasible bits allocation algorithm is proposed by experimental analysis among different target bit rates. The analysis and final simulation results show that compared to the existing methods, the proposed algorithm improves PSNR performance significantly (up to 1.2dB). © 2005 IEEE.
{fenge}
33750915251	Low complexity mode decision for H.264 inter frame encoding	The new video coding standard, H.264 gives a better encoding performance than previous video standards at the cost of expensive computation since it allows motion estimation performing on tri-tree structured macroblock partitioning and multiple reference frames. In this paper, a fast algorithm FIMDA is proposed to accelerate mode decision of inter macroblock. FIMDA makes full use of valuable cues provided by the previous searching reference frames, such as mode, rate distortion cost etc., to eliminate unnecessary modes and reference frames in the following searching. FIMDA can effectively reduce encoding complexity and the quality degradation compared with full search can be ignored. Simulation results show that average complexity reduction exceeds 85% and average quality degradation is only about 0.07dB.
{fenge}
34147193304	Partial retransmission based on minimal bandwidth-distortion cost in error prone video delivery	There are two critical factors in error prone video transmission: the total usage of bandwidth and the distortion of reconstructed images at receiver side. Therefore, the concept of bandwidth-distortion (B-D) cost is proposed intuitively so as to evaluate a video transmission system more effectively. Further, B-D relationship is provided as a theorem, by which B-D cost function could be definitely made out. With these tools, a partial retransmission scheme based on minimal B-D cost is proposed based on the temporal and spatial correlation in video sequence. From the analytical analysis, it can be seen that B-D cost is more effective than bandwidth or distortion only when evaluating the performance of an error prone video transmission system. Besides, the proposed partial retransmission scheme can reduce the bandwidth usage effectively by the use of the temporal and spatial correlation in video sequence. Simulation results and discussions show that, compared to best effort ARQ scheme (BEARQ), the proposed scheme has the following features: (1) It can reduce the usage of bandwidth (maximally more than 20% on average) while keeping the quality of reconstructed images to be nearly unchanged; (2) It is preferable to be used in low bit rate since its B-D performance is better in low bit rate than in high bit rate; (3) Similarly, it is preferable for the sequence in which motion and texture is relatively slow and smooth since in the case, its B-D performance is better.
{fenge}
34047150352	Local MAP decoding of arithmetic codes in joint souce-channel coding	Arithmetic codes (AC) with forbidden symbol are often used to provide error detection/correction capability. An improved soft decoding algorithm of AC with forbidden symbol was proposed to provide good error correction capability while keeping low computational complexity. In the scheme, on one hand, the first branch of decoding tree is generated by choosing the modulated signal of minimal amplitude; on the other hand, the decoding tree is pruned according to local MAP (LMAP) metric and forbidden symbol detection. The simulation results show that, compared to the existing methods, the proposed scheme can achieve good error correction capability while keeping low computational complexity.
{fenge}
34249326956	Transcoing-based data transmission of sphere panoramic videos	Omnidirectional video is a kind of new emerging media. The filed of view of an omnidirectional video can be 360 degrees in vertical and horizontal. The users can navigate interactively through the scene and change their view angel. The scene of an omnidirectional video is often projected on the surface of a sphere or a cylinder to store, which is a panoramic video. Panoramic videos are often high-resolution and consume a significant amount of bandwidth for transmission. To resolve the problem, tiles-based data transmission is applied in some systems but it is not efficient for sphere panoramic video and transmits a mass of redundant bits to the users. In this paper, we proposed an efficient transcoding-based data transmission technique for panoramic videos, which reduced the amount of data transmission at most. © 2006 IEEE.
{fenge}
34248207574	Efficient relevance feedback scheme based on SVM in image retrieval	An approach called constrained random selection for relevance feedback is proposed in this paper. At first, all the images are sorted by similar measure, and then a threshold is selected to restrict the space of random selection. At last, the restricted space is divided into some sub-spaces, and random selection is applied to these sub-spaces to enlarge the training sets and resolve the small sample problem preferably. In addition, we compute the weights of multiple SVM classifiers dynamically and fuse the single results to resolve the users' preference problems in relevance feedback preferably. Experimental results demonstrate the effectiveness of the method.
{fenge}
34547654441	Format-independent motion content description based on spatiotemporal visual sensitivity	With the extensive application of digital video technology, developing format-independent motion describing method is of great significance for retrieving and searching video content in different formats. In this paper, a format-independent motion describing method for video content is proposed. The features based on visual sensitivity are extracted from spatiotemporal slice. Since the same video content gives the same visual stimuli to visual perception, the method based on this kind of visual sensitivity related feature is format-independent. The experiments show the feature proposed is sensitive to the variation of video content and robust to the variation of video format. The motion describing method proposed is format-independent. © 2007 IEEE.
{fenge}
36049047998	Selection of the most efficient tile size in tile-based cylinder panoramic video coding and transmission	Panoramic videos are a 360 degree representation of a certain scene. The users can navigate interactively through the scene and change their view angles. Panoramic videos are often high-resolution and consume a significant amount of bandwidth for transmission. To resolve the problem, tile-based panoramic video coding and transmission is applied in some systems. With tile-based panoramic video coding and transmission, only the tiles involved with the perspective view are transmitted and decoded. Different tile sizes will bring different transmission bit rates for same video quality. In this paper, a two path coding method with H.264/AVC for cylinder panoramic video based on a hyperbolic model is proposed. With this method, the most efficient tile size can be selected and users can build the same quality perspective view with the smallest transmission bit rate. © 2007 Springer-Verlag.
{fenge}
34247383205	Interactive key video object selection model	Summarization of video can well represent the content of video. In the MPEG-1/2 standard key frame is used for representing the content of a video sequence. Similarly, in an object-based framework of the suggested MPEG-4 standard, key video object can summarize the content of video objects. In this paper, an interactive key video objects selection model (IKVOS) is presented as the result of improving the model of key video objects selection (KVOS). The model of KVOS is proved to satisfy the criterion of induction. Also, the course of IKVOS is formalized and the model of IKVOS is proved to satisfy the criterion of conduction. It can dynamically generate key video objects with user's preference. The experimental results are given, as well as the evaluation of the performance of the proposed method whose distortion rate is lower than the current methods.
{fenge}
34247579266	Improvements on rate-distortion performance of H.264 rate control in low bit rate video coding	This paper points out some defects in the techniques used in H.264 rate control and presents two new techniques to improve them. The improved scheme has the following main features: 1) the bits allocated to each P-frame is proportional to the local motion in it, i.e, more bits are allocated to a frame if the local motion in it is stronger; 2) the quantization paramter (QP) calculation is based on a simple encoding complexity prediction scheme, which is more robust and simple than the quadratic model used by H.264 in low bit rate video coding. Simulation results show that compared to rate control scheme in H.264, the improved scheme has significantly improved R-D performance (up to 1.29dB). © 2006 IEEE.
{fenge}
40949128634	Efficient rate control schemes for H.264/AVC	In this work, a novel coding characteristics prediction scheme is presented to improve R-D modeling, by exploiting spatio-temporal correlations. Two different approaches to the problem of optimum bit allocation at a macroblock-by-macroblock basis are achieved, one of which is developed on a modified MPEG-4 Q2 rate model and the other on a linear rate model. Extensive experiments show that the linear scheme is a bit more accurate than the quadratic one while they achieve similar coding performance. It's also shown that both the two schemes significantly exceed JVT G012, the current standardized RC scheme.
{fenge}
77954124161	Video copy detection based on trajectory behavior pattern	In order to effectively extract temporal motion information of videos for robust and precise video copy detection, this paper proposes a novel video feature based on behavior patterns of keypoint trajectories. By the algorithm, first the keypoint trajectories are generated and modeled into behavior patterns. Then patterns are learned using bag-of-visual-word method as video features. Finally, similarity between features is used for video copy detection. Comparison experiments on benchmark video dataset (TRECVID) show that proposed algorithm achieves high detection precision. And this work demonstrates that the trajectory based feature has better robustness for various visual changes.
{fenge}
42549113016	Fast global motion estimation using threshold method	In this paper, a fast global motion estimation method is proposed for video coding. This method can accommodate not only a translational motion model but also a polynomial motion model. It speeds up the procedure of the global motion estimation (GME) by pre-analyzing the characteristics of the block. At the first stage, the smooth region blocks which contribute less to the GME are filtered by using a threshold method based on image intensity. Next, a threshold method based on the discrepancy of the motion vectors is used to exclude the foreground blocks from the GME. From the experimental results, we can conclude that the proposed fast global motion estimation method manages to speed up the processing of estimating the motion vector field while maintaining the coding performance.
{fenge}
46449113347	Adaptive selection of motion models for panoramic video coding	A panoramic video is an image-based rendering (IBR) technique which provides users with a large field of view (e.g. 360 degree) on surrounding dynamic scenes. It includes not only the translational motions but also the nontranslational motions, such as zooming, rotation and uneven stretching etc. This paper presents a motion compensated prediction scheme based on adaptive selection of motion models to predict the complex changes between successive frames efficiently in panoramic video coding. By performing the initial motion estimation phrase and the refined motion estimation phrase in the proposed scheme, simulated results show that the coding performance of the proposed scheme is much higher than the traditional motion compensated prediction scheme in panoramic video coding. ©2007 IEEE.
{fenge}
48149084746	A novel anchorperson detection algorithm based on spatio-temporal slice	For conveniently navigating and editing the news programs, it is very important to segment the video into meaningful units. The effective indexing of news videos can be fulfilled by the anchorperson shot because it is an indicator which denotes the occurrence of upcoming news stories. The paper presents a novel anchorperson detection algorithm based on spatio-temporal slice (STS). With STS pattern analysis, clustering and decision fusion, anchorperson shots can be detected for browsing news video. The large-scale experimental results demonstrate that the algorithm is accurate, robust and effective. © 2007 IEEE.
{fenge}
49249084017	An innovative tempo model for movie content analysis	The paper presents a novel tempo model for movie content analysis. We originally propose that tempo indicates the rhythm of both movie scenarios and human perception and focus on the low level features extraction to represent both aspects. By thoroughly analyzing them, we classify the factors of tempo into two sorts. The first is based on the film grammar and we use the low level features of Shot Length and Camera Motion to describe filmmaking by directors. The second is based on the human perception and the low level features of Motion Intensity, Motion Complexity, Audio Energy and Audio Pace are integrated for the formulation of information to describe the viewers' emotional changes to continuously developing storyline. With both factors, tempo is defined and tempo flow plot is derived as the clue of storyline. Then we implement the tempo model for Action scene detection and build a system, SmartMovirPlayer, for hierarchical browse and edit with Action concept annotation. The large-scale experiments demonstrate the effectiveness of the tempo model for movie content analysis.
{fenge}
50849142280	An innovative model of tempo and its application in action scene detection for movie analysis	In this paper, we present an innovative model of tempo and its application in action scene detection for movie analysis. For the first time, we clearly propose that tempo indicates the rhythm of both movie scenarios and human perception. By thoroughly analyzing both aspects, we classify the factors of tempo into two sorts. The first is based on the film grammar and we use the low level features of Shot Length and Camera Motion to describe filmmaking by directors. The second is based on the human perception and we originally propose the information measure for perception depending on the cognitive informatics, a newly emerging and significative subject. With the information in both visual and auditory modalities, the low level features of Motion Intensity, Motion Complexity, Audio Energy and Audio Pace are integrated for the formulation of information to describe the viewers' emotional changes to continuously developing storyline. With both aspects, tempo is defined and tempo flow plot is derived as the clue of storyline. On the basis of video structuralization and movie tempo analysis, we build a system for hierarchical browse and edit with action scene annotation. The large-scale experiments demonstrate the effectiveness and generality of tempo for action movie analysis.
{fenge}
51649118140	Event analysis in soccer video by dynamic programming based fusion of multiple modalities	To better satisfy audience' demand on browsing and retrieving soccer video, a framework for event analysis in soccer video is proposed that fuses text knowledge and video information. Event information is extracted from text and video, respectively, and then they are globally matched based on dynamic programming (DP) algorithm. For unmatched event information extracted from text, their corresponding event boundaries in video stream are estimated using a global probability model. This approach searches the best global matching for event information extracted from text and video, which avoids missing and mistaking errors caused by other methods using local matching. Experimental results show that the proposed method detects events accurately and efficiently and gets detailed event content information, achieving better performance than other work using local matching methods.
{fenge}
54049150513	Human attention model for semantic scene analysis in movies	In this paper, we specifically propose the Weber-Fechner Law-based human attention model for semantic scene analysis in movies. Different from traditional video processing techniques, we pay more attention on bringing in the related subjects, such as psychology, physiology and cognitive informatics, for content-based video analysis. The innovation of our work has two aspects. Firstly, we originally construct the human attention model with temporal information instructed by the Weber-Fechner Law. Secondly, motivated by cognitive informatics, we formulate the computational methodology of features in visual, audio and textual modalities in the uniform metric of information quantity. With human attention analysis and semantic scene detection, we build a system for hierarchical browse and edit with semantics annotation. Large-scale experiments demonstrate the effectiveness and generality of the proposed human attention model for movie analysis. © 2008 IEEE.
{fenge}
55649097052	Method of adaptively selecting best LDA model based on density	Topic models have been successfully used to information classification and retrieval. These models can capture word correlations in a collection of textual documents with a low-dimensional set of multinomial distribution, called "topics". It is important but difficult to select an appropriate number of topics for a specific dataset. This paper proposes a theorem that the model reaches optimum as the average similarity among topics reaches minimum, and based on this theorem, proposes a method of adaptively selecting the best LDA model based on density. Experiments show that the proposed method can achieve performance matching the best of LDA without manually tuning the number of topics.
{fenge}
57549108528	Adaptive multiple feedback strategies for interactive video search	In this paper, we propose adaptive multiple feedback strategies for interactive video retrieval. We first segregate interactive feedback into 3 distinct types (recall-driven relevance feedback, precision-driven active learning and locality-driven relevance feedback) so that a generic interaction mechanism with more flexibility can be performed to cover different search queries and different video corpuses. Our system facilitates expert searchers to flexibly decide on the types of feedback they want to employ under different situations. To cater to the large number of novice users (non-expert users), an adaptive option is built-in to learn the expert user behavior so as to provide recommendations on the next feedback strategy, leading to a more precise and personalized search for the novice users. Experimental results on TRECVID news video corpus demonstrate that our proposed adaptive multiple feedback strategies are effective. Copyright 2008 ACM.
{fenge}
61349201610	Spatiotemporal video copy detection based on visual perception analyses	A novel spatiotemporal video copy detection method based on visual perception features is proposed in this paper. The method differs from the conventional video copy detection algorithms in that it does not using key frame based features any more. By extracting visual perception based spatiotemporal correlation of slice in frequency domain using DCT, the proposed method possesses both robustness and discriminability for video copy detection. It copes well with not only the format, resolution variation of video but also the aspect ratio change. Even more, the method is robust to display format conversion such as adding pillar-box. The experiment results show the proposed method is effective and robust.
{fenge}
61849154516	A density-based method for adaptive LDA model selection	Topic models have been successfully used in information classification and retrieval. These models can capture word correlations in a collection of textual documents with a low-dimensional set of multinomial distribution, called "topics". However, it is important but difficult to select the appropriate number of topics for a specific dataset. In this paper, we study the inherent connection between the best topic structure and the distances among topics in Latent Dirichlet allocation (LDA), and propose a method of adaptively selecting the best LDA model based on density. Experiments show that the proposed method can achieve performance matching the best of LDA without manually tuning the number of topics. © 2008 Elsevier B.V. All rights reserved.
{fenge}
77749310224	Automatic detection and analysis of player action in moving background sports video sequences	This paper presents a system for automatically detecting and analyzing complex player actions in moving background sports video sequences, aiming at action-based sports videos indexing and providing kinematic measurements for coach assistance and performance improvement. The system works in a coarse-to-fine fashion. For an input video, in the coarse granularity level, we automatically segment the highlights, that is, the video clips containing the desired action as summaries for general user viewing purposes; in the middle granularity level, we recognize the action types to support action-based video indexing and retrieval; and finally in the fine granularity level, the critical kinematic parameters of player action are obtained for sports professionals' training purposes. However, the complex and dynamic background of sports videos and the complexity of player actions bring considerable difficulty to the automatic analysis. To fulfill such a challenging task, robust algorithms including global motion estimation with adaptive outliers filtering, object segmentation based on adaptive background construction, and automatic human body tracking are proposed in this paper. Two visual analyzing tools: motion panorama and overlay composition, are also introduced. Real diving and jump game videos are used to test the proposed system and algorithms, and the extensive and encouraging experimental results show their effectiveness. © 2006 IEEE.
{fenge}
77952505283	Fast spatial verification with affine transformations	A fast spatial verification scheme using affine transformations is proposed to improve the retrieval precision by exploiting proper spatial constraints among visual key words. Firstly, affine covariant neighborhoods of visual words are used to verify the spatial consistency. Secondly, a set of affine transformation matrices between the corresponding covariant regions is calculated, and the matrix with the most inliers is chosen as the best matching affine transformation matrix (BMATM). In this step, only a single pair of corresponding affine covariant regions is used to calculate the 6 degree of freedom (DOF) affine transformation for acceleration. In the last step, the spatial consistency is verified by the BMATM. Experimental results show that this scheme is more robust, more accurate and faster in compare with the state-of-the-art approaches.
{fenge}
77953742838	An effective video retrieval approach based on multi-modality concept correlation graph	A novel multi-modality concept correlation graph approach is proposed to promote the performance of concept-based video retrieval. Firstly, a net-style concept correlation graph is constructed using the original similarities among the concepts. Then, query is added into the graph based on a multi-modality mapping strategy between query and concept. Thirdly, ranking on manifolds algorithm is used to dynamically diffuse the concept correlations in this graph until a global stable state is achieved. Finally, the selected concepts are orthogonally fused to implement the video retrieval. In the experiments of automatic video retrieval, our approach has achieved great improvement from 14.6% to 86.2% over the state-of-art methods. Moreover, we also apply it to our interactive retrieval system and gains excellent performance and user experience.
{fenge}
77958098199	GPU-based fast image copy detection	To speed up image copy detection by exploring the powerful computing capability of GPU, a novel GPU-based image copy detection scheme is proposed. Firstly, a new scale-invariant interest point detector-Harris-Hessian (H-H) is designed according to the architecture of GPU. The H-H extracts interest points in low scale and refines their location and scale in a series of scale-space with the determinant of Hessian matrix, which significantly reduces the pixel-level computation complexity and has better parallelism. Then, an image copy detection system based on the H-H is presented, the detection speed is significantly improved. The experimental results show that, compared to the existing CPU-based methods, the H-H achieves up to a speedup factor of 10~20 times and maintains a high detection accuracy. It only takes 19.8 ms for the system to detect a 640 × 480 image in a dataset of 11250 images with 95% accuracy rate, which meets the demand of real-time applications under large scale data.
{fenge}
78049380781	Fast and robust spatial matching for object retrieval	Spatial matching for visual words based object retrieval often involves generating affine transformation hypotheses and then choosing the best hypothesis to measure the spatial consistency. In existing methods, generating an affine transformation hypothesis either requires three correspondences or assumes images are taken in restricted range of viewpoints in using a single correspondence. In this paper, we propose a novel spatial matching method, in which the transformation hypothesis can be estimated from only a single correspondence without the assumption of the viewpoints from which the images are taken. Firstly, affine covariant neighborhoods(ACNs) of features are used to eliminate possible false matches. Secondly, we decompose the affine transformation into three sub-transforms and conquer each sub-transform by exploiting the shape information and the ACNs of a single pair of corresponding features. Experiment results demonstrate that this method improves the average retrieval precision evidently with less computation in comparison with the previous methods. ©2010 IEEE.
{fenge}
78049395305	GPU-based fast scale invariant interest point detector	To take full advantage of the powerful computing capability of graphics processing units (GPU) to speed up local feature detection, we present a novel GPU-based scale invariant interest point detector, coined Harris-Hessian(H-H). H-H detects Harris points in low scale and refines their location and scale in higher scale-space with the determinant of Hessian matrix. Compared to the existing methods, H-H significantly reduces the pixel-level computation complexity and has better parallelism. The experiment results show that with the assistance of GPU, H-H achieves up to a 10-20x speedup than CPU-based method. It only takes 6.3ms to detect a 640 x 480 image with high detection accuracy, meeting the need of real-time detection. ©2010 IEEE.
{fenge}
78649325413	On defining affinity graph for spectral clustering through ranking on manifolds	Spectral clustering consists of two distinct stages: (a) construct an affinity graph from the dataset and (b) cluster the data points through finding an optimal partition of the affinity graph. The focus of the paper is the first step. Existing spectral clustering algorithms adopt Gaussian function to define the affinity graph since it is easy to implement. However, Gaussian function is hard to depict the intrinsic structure of the data, and it has to specify a scaling parameter whose selection is still an open issue in spectral clustering. Therefore, we propose a new definition of affinity graph for spectral clustering from the graph partition perspective. In particular, we propose two consistencies: smooth consistency and constraint consistency, for affinity graph to hold, and then define the affinity graph respecting these consistencies in a regularization framework of ranking on manifolds. Meanwhile the proposed definition of affinity graph is applicable to both unsupervised and semi-supervised spectral clustering. Encouraging experimental results on synthetic and real world data demonstrate the effectiveness of the proposed approach. © 2009 Elsevier B.V.
{fenge}
78349276086	Parallel spatial matching for object retrieval implemented on GPU	Spatial matching for object retrieval is often timeconsuming and susceptible to viewpoint changes. To address this problem, we propose a novel spatial matching method and implement it on modern GPU in parallel. Unlike previous spatial matching methods, in which the affine transformation estimation is based on the gravity vector assumption, our method abandons this strong assumption by matching the ACNs(affine covariant neighbors) of corresponding local regions and estimating affine transformation from a single pair of corresponding local regions. To speed up the process, we implement the method on modern GPU in parallel. Computations are distributed evenly to threads with load balancing, and the memory accesses are optimized and bitmap based parallel scan is exploited. Experimental results demonstrate that our method is more robust and more efficient than previous methods especially when the viewpoints are changed, and the parallel implementation on GPU obtains ten times speedup. © 2010 IEEE.
{fenge}
78650029091	Video copy detection based on multiple visual feature matching	Video copy detection is an important technique for filtering out unnecessary video content which is copyright invaded or redundant for large video databases. The difficulties of detecting video copies lie in the dissimilarities between video and its copies. Various visual transformations make the existing methods invalid where a single feature is used for video matching. This paper proposes a novel method which uses multiple visual features for content matching and searching. The proposed method adopts the cascade detection approach which first retrieves the query video using global features, then videos is matched by more accurate local features. To achieve satisfactory efficiency for large scale applications, the kd-tree indexing structure is adopted. Experiments on benchmark dataset show that the proposed method manifests a good balance of robustness to common copy transformations and high detection efficiency.
{fenge}
78751661289	Perceptual motivated coding strategy for quality consistency	In this paper, we propose a novel quality control scheme which aims to keep quality consistency within a frame. Quality consistency is an important requirement in video coding. However, many existing schemes usually consider the quality consistency as the quantization parameter (QP) consistency. Moreover, the most frequently used metric to evaluate the quality consistency is PSNR, which has been well known that it is not good for subjective quality evaluation. These flaws of the existing methods are pointed out and proved to be unreasonable. For optimization, we take the effect of texture complexity on subjective evaluation into consideration to build a new D-Q model. We use the new model to adjust the quantization parameters of different regions to keep quality consistency. The simulation result shows that the new scheme gets better subjective quality and higher coding efficiency compared to traditional way. © 2011 Springer-Verlag Berlin Heidelberg.
{fenge}
79951793036	Compressive video sensing based on user attention model	We propose a compressive video sensing scheme based on user attention model (UAM) for real video sequences acquisition. In this work, for every group of consecutive video frames, we set the first frame as reference frame and build a UAM with visual rhythm analysis (VRA) to automatically determine region-of-interest (ROI) for non-reference frames. The determined ROI usually has significant movement and attracts more attention. Each frame of the video sequence is divided into non-overlapping blocks of 16×16 pixel size. Compressive video sampling is conducted in a block-by-block manner on each frame through a single operator and in a whole region manner on the ROIs through a different operator. Our video reconstruction algorithm involves alternating direction l
{fenge}
84861148079	Efficient parallel framework for H.264/AVC deblocking filter on many-core platform	The H.264/AVC deblocking filter is becoming the performance bottleneck of H.264/AVC parallelization on many-core platform. Efficient parallelization of the deblocking filter on a many-core platform is challenging, because the deblocking filter has complicated data dependencies, which provide insufficient parallelism for so many cores. Furthermore, parallelization may have significant synchronization and load imbalance overhead. At present, research on the parallelizing deblocking filter on a many-core platform is rare and focuses on data-level parallelization. In this paper, we propose a three-step framework considering task-level segmentation and data-level parallelization to efficiently parallelize the deblocking filter. First, we review the entire deblocking filter process in 4×4 block edge-level and divide it into two parts: 1) boundary strength computation (BSC) and 2) edge discrimination and filtering (EDF), which increases the parallelism. Then, we apply the Markov empirical transition probability matrix and Huffman tree (METPMHT) to the BSC, which alleviate the load imbalance problem. Finally, we use an independent pixel connected area parallelization (IPCAP) for the EDF, which increases the parallelism and reduces the synchronization. In experiments, we apply our parallel method to the deblocking filter of the H.264/AVC reference software JM15.1 on the Tile64 platform without any Tile64 platform-based optimizations. Compared to the well-known 2D-wavefront method, the proposed method achieves on average 14.85, 17.83, and 10.60 times speed-up for QCIF, CIF, and HD videos using 62 cores, respectively. © 2012 IEEE.
{fenge}
84862662713	Pose-invariant clothing segmentation based on saliency detection and graph cuts	A novel algorithm of clothing segmentation, which can handle variable human poses, is proposed in this paper. The segmentation performance is significantly improved by combining saliency detection and graph cuts methods. Firstly, we propose a sliding window based visual saliency detection method to locate initial foreground/background seed regions, which are invariant to poses. Secondly, the seed regions are further adjusted by a graph based segmentation method. Finally, the segmentation results of clothing regions are acquired by an iterated graph cuts method called GrabCut, with the seed regions as the input. The experimental results demonstrate that our proposed algorithm can achieve promising results and is feasible in practical applications.
{fenge}
84862290827	Improved total variation minimization method for compressive sensing by intra-prediction	Total variation (TV) minimization algorithms are often used to recover sparse signals or images in the compressive sensing (CS). But the use of TV solvers often suffers from undesirable staircase effect. To reduce this effect, this paper presents an improved TV minimization method for block-based CS by intra-prediction. The new method conducts intra-prediction block by block in the CS reconstruction process and generates a residual for the image block being decoded in the CS measurement domain. The gradient of the residual is sparser than that of the image itself, which can lead to better reconstruction quality in CS by TV regularization. The staircase effect can also be eliminated due to effective reconstruction of the residual. Furthermore, to suppress blocking artifacts caused by intra-prediction, an efficient adaptive in-loop deblocking filter was designed for post-processing during the CS reconstruction process. Experiments show competitive performances of the proposed hybrid method in comparison with state-of-the-art TV models for CS with respect to peak signal-to-noise ratio and the subjective visual quality. © 2012 Elsevier B.V. All rights reserved.
{fenge}
84863026792	Local geometric consistency constraint for image retrieval	In state-of-the-art image retrieval systems, an image is represented by bag-of-features (BOF). As BOF representation discards geometric relationships among local features, exploiting geometric constraints as post-processing procedure has been shown to greatly improve retrieval precision. However, full geometric constraints are computationally expensive and weak geometric constraints have limited range of applications. To efficiently handle common transformations and deformations, we present a novel local geometric consistency constraint (LGC) method. It utilizes the local similarity characteristic of deformations, and measures the pairwise geometric similarity of matches between two sets of local features. Besides, we propose a new method to accurately calculate the transformation matrix between two matched features, with the information provided by their local neighbors. Experiments performed on famous datasets show the excellent performance of our method. © 2011 IEEE.
{fenge}
84863032019	Human skin detection in images by MSER analysis	Human skin detection in images is desirable in many practical applications, e.g., adult-content filtering. However, existing methods are mainly pixel-based and ignore that human skin is region-based. In this paper, we introduce a successful region detector, i.e., MSER, into the skin detection by regarding the skin region as the maximally stable extremal region (MSER). We extend the original MSER to both color and texture analysis to reduce the skinlike regions. Furthermore, to be adaptive to the dynamic illumination and chrominance, face detection is used to customize the skin color model to each image. The proposed method has achieved promising performance over our dataset, which is a challenging set with a great part of hard images. Our True Positive Rate is 81.2% under False Positive Rate 8.2%, which outperforms all of eight state-of-the-art algorithms. © 2011 IEEE.
{fenge}
84863040444	Hollow TV logo detection	Most existing TV logo detection methods regard the logo's region as a whole and depend on the global features derived from it, these methods fit to solid TV logos. However, we find one special kind of TV logo which has large hollow areas within the logo's region and we name it "hollow TV logo." In this case, the global features are dramatically varying due to the changing content in the hollow areas, and traditional global feature based methods fail to detect such TV logos. In this paper, we propose a local feature based approach for hollow TV logo detection. It successfully suppresses the noises from hollow areas, and can complete detection in single-frame scenario. Compared to the traditional edge-based method, our method achieves 40.5% and 29.3% improvements on false alarm rate and false reject rate separately for hollow TV logos. © 2011 IEEE.
{fenge}
84863289406	A two-stage scheme based on block search for low-quality Chinese character	Due to the complex character strokes, the quality of video-extracted Chinese character images is often poor, for which traditional optical character recognition (OCR) could not get desired results. To address this problem, this paper presents a two-stage scheme for low-quality Chinese character recognition based on block search. The block structure of the Chinese character image is built, along with a training set, imitating low-quality Chinese characters. And an index is generated after extracting the features from each block of the training set by applying principle component analysis. This scheme retrieves candidate character set from the index by block search and voting (1st stage), and then recognizes the character according to the salience of voting result assisted with global structural feature match (2nd stage). The experimental results have demonstrated that this scheme has better recognition rate for low-quality Chinese character images compared with traditional OCR method.
{fenge}
84863230559	Mining concise and distinctive affine-stable features for object detection in large corpus	Invariant features extraction is important for object detection. Affine-SIFT (ASIFT) [J.M. Morel and G. Yu, ASIFT: A new framework for fully affine invariant image comparison, SIAM J. Imaging Sci. 2(2) (2009)] has been proved to be fully affine-invariant. However, the high cost of memory and query time hampers its application in large-scale object detection tasks. In this paper, we present a novel algorithm for mining concise and distinctive invariant features called affine-stable characteristics (ASC). Two new notions, global stability and local stability, are introduced to calculate the robustness of each feature from two mutually complementary aspects. Furthermore, to make these stable characteristics more distinctive, spatial information taken from several representative scales is encoded in a concise method. Experiments show that the robustness of our ASC is comparable with ASIFT, while the cost of memory can be reduced significantly to only 5%. Moreover, compared with the traditional SIFT method [D. Lowe, Distinctive image features from scale invariant keypoints, Int. J. Comput. Vis. 60(2) (2004), pp. 91-110], the accuracy of object detection can be improved 38.6% by our ASC using similar amount of features. © 2011 Copyright Taylor and Francis Group, LLC.
{fenge}
84868583240	Query range sensitive probability guided multi-probe locality sensitive hashing	Locality Sensitive Hashing (LSH) is proposed to construct indexes for high-dimensional approximate similarity search. Multi-Probe LSH (MPLSH) is a variation of LSH which can reduce the number of hash tables. Based on the idea of MPLSH, this paper proposes a novel probability model and a query-adaptive algorithm to generate the optimal multi-probe sequence for range queries. Our probability model takes the query range into account to generate the probe sequence which is optimal for range queries. Furthermore, our algorithm does not use a fixed number of probe steps but a query-adaptive threshold to control the search quality. We do the experiments on an open dataset to evaluate our method. The experimental results show that our method can probe fewer points than MPLSH for getting the same recall. As a result, our method can get an average acceleration of 10% compared to MPLSH. © 2012 IEEE.
{fenge}
84870437460	Data independent method of constructing distributed LSH for large-scale dynamic high-dimensional indexing	Constructing effective and efficient indexes for explosive growing multimedia data is a very challenging problem. To solve the problem, Haghani et al. provide a distributed similarity search method in high dimensions using Locality Sensitive Hashing. However, their method needs to estimate a global parameter on the whole dataset beforehand. It is impractical for a large-scale dynamical dataset. This paper proposes a novel constructing method of distributed LSH which does not need any priori knowledge about the dataset. Through generating the hash function with consistent output distribution, we get a data independent predicting model in theory which can guarantee a well load balance even if the dataset dynamically changes. Furthermore, we modify the query algorithm of the basic LSH to make the proposed model more practical. The experimental results on two open large-scale high-dimensional datasets show that the proposed method is more robust, scalable and practical than state-of-the-art. © 2012 IEEE.
{fenge}
84883813628	Graph-based multi-space semantic correlation propagation for video retrieval	By introducing the concept detection results to the retrieval process, concept-based video retrieval (CBVR) has been successfully used for semantic content-based video retrieval application. However, how to select and fuse the appropriate concepts for a specific query is still an important but difficult issue. In this paper, we propose a novel and effective concept selection method, named graph-based multispace semantic correlation propagation (GMSSCP), to explore the relationship between the user query and concepts for video retrieval application. Compared with traditional methods, GMSSCP makes use of a manifold-ranking algorithm to collectively explore the multi-layered relationships between the query and concepts, and the expansion result is more robust to noises. Parallel to this, GMSSCP has a query-adapting property, which can enhance the process of concept correlation propagation and selection with strong pertinence of query cues. Furthermore, it can dynamically update the unified propagation graph by flexibly introducing the multi-modal query cues as additional nodes, and is not only effective for automatic retrieval but also appropriate for the interactive case. Encouraging experimental results on TRECVID datasets demonstrate the effectiveness ofGMSSCP over the state-of-the-art concept selection methods. Moreover, we also apply it to the interactive retrieval system-VideoMap and gain an excellent performance and user experience. © Springer-Verlag 2010.
{fenge}
84889258941	High efficiency video coding	In recent years, with the development of video coding technology and the increasing popularity of high definition (HD) video content, the ISO/IEC Moving Picture Experts Group (MPEG) and the ITU-T Video Coding Experts Group (VCEG) formed the joint collaborative team on video coding (JCV-VC) in 2010 which aims to develop the next-generation video coding standard for HD video application, called High Efficiency Video Coding (HEVC). So far the test model HM has been used for performance evaluation and algorithm test. The final international standard of HEVC has been completed and published in the end of 2012 based on the working plan of JCV-VC. In this paper, the key technologies about HEVC will be surveyed, specifically including the quad-tree structure of coding unit, prediction unit and transform unit, the advanced motion vector prediction and merging technology, angular intra prediction, DCT-based fractional pixel interpolation filter and context adaptive arithmetic coding etc. Finally the coding performance of some coding tools and complexity of HEVC are analyzed in detail.
{fenge}
84890521413	A video copy detection algorithm combining local feature's robustness and global feature's speed	This paper presents a novel algorithm for fast and robust video copy detection. The idea is to use local features to estimate the copy transformation parameters first and then use the estimated parameters to guide the global-feature-based matching at a later stage. It is based on the fact that the copy transformations generally remain unchanged in a continuous video clip even in the whole video. Local-feature-based matching can find the candidates which are difficult to be detected only using global features. Furthermore, the matched local feature points can provide enough information to estimate the copy transformations. After the copy transformations are estimated, the subsequent detection can be accelerated by doing global-feature-based matching. The experimental results show that the proposed algorithm can get the same good robustness as the local-feature-based method but the faster detection speed. © 2013 IEEE.
{fenge}
84897788646	Data driven multi-index hashing	Binary representation for large scale nearest neighbor search received more and more concern recently. Although binary codes can be directly used as indices of the hash tables, correlations between the bits may lead to non-uniform codes distribution and reduce the performance of the hash table. In this paper, we propose a data driven multi-index hashing method for exact nearest neighbor search in Hamming space. By exploring the statistics properties of the dataset, we can separate the correlated bits into different segments during the process of building multiple hash tables, and thus make binary codes distributed as uniformly as possible in each hash table. Experiments conducted on a huge amount of binary codes extracted from the UK Bench dataset show that our method can achieve significant acceleration in searching speed for large scale dataset. © 2013 IEEE.
