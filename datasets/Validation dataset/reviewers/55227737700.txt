{fenge}
84930512085	Energy-efficient design techniques	While the relentless scaling of CMOS technology has brought digital IC designs with enhanced functionality and improved performance in every new generation, at the same time, the associated ever-increasing on-chip power and temperature densities make them suffer from more severe reliability threats [6, 93]. For example, as demonstrated in [94], the average mean-time-to-failure (MTTF) of a contemporary superscalar processor drops by about 4 ×from 180 to 65 nm technology node. In fact, the failure rates for today's electrical systems can be quite high, e.g., as high as 16.4 % for the Microsoft Xbox 360 within 10 months [90].
{fenge}
29144453227	Modular SOC testing with reduced wrapper count	Motivated by the increasing design for test (DFT) area overhead and potential performance degradation caused by wrapping all the embedded cores for modular system-on-a-chip (SOC) testing, this paper proposes a solution for reducing the number of wrapper boundary register (WBR) cells. By utilizing the functional interconnect topology and the WBRs of the surrounding cores to transfer test stimuli and responses, the WBRs of some cores can be removed without affecting the testability of the SOC. We denote the cores without WBRs as light-wrapped cores and present a new modular SOC test architecture for concurrently testing both the wrapped and the light-wrapped logic cores. Since the WBRs of cores that transfer test stimuli and test responses for light-wrapped cores become shared resources during test, conflicts arise during test scheduling that will negatively impact the test application time. As a consequence, to alleviate this problem, we present a novel test access mechanism (TAM) design algorithm for the proposed SOC test architecture. We conduct experiments on several SOC benchmark circuits and demonstrate that, with an acceptable increase in test application time, the number of WBRs can be significantly decreased. This will ultimately lessen the necessary DFT area for modular SOC testing and reduce the propagation delays between cores. © 2005 IEEE.
{fenge}
31344462692	Multifrequency TAM design for hierarchical SOCs	The emergence of megacores in hierarchical system-on-a-chip (SOC) presents new challenges to electronic test automation. This paper describes a new framework for designing test access mechanisms (TAMs) for modular testing of hierarchical SOCs. We first explore the concept that TAMs on the same level of design hierarchy employ multiple frequencies for test data transportation. Then we extend this concept to hierarchical SOCs and, by introducing frequency converters at the inputs and outputs of the megacores, the proposed solution not only removes the constraint that the system level TAM width must be wider than the internal TAM width of the megacores, but also facilitates rapid exploration of the tradeoffs between the test application time and the required test area. Experimental results for the ITC'02 SOC Test Benchmarks show that the proposed TAM design algorithms increase the size of the solution space that is explored, which, in turn, will lower the test application time when compared to the existing solutions.
{fenge}
33645239835	DFT infrastructure for broadside two-pattern test of core-based SOCs	Existing approaches for modular manufacturing test of core-based system-on-a-chip (SOC) devices do not provide any explicit mechanism for delivering two-pattern tests in the broadside mode, which is necessary to achieve reliable coverage of delay and stuck-open faults. Although wrapper input cells can be enhanced with two memory elements to address this problem, this will incur a large test area overhead. This paper proposes a novel architecture for broadside two-pattern test of core-based SOCs without any loss in fault coverage and without increasing the size of the wrapper input cells. The proposed solution combines the dedicated bus-based test access mechanism and functional interconnects for test data transfer in order to provide full controllability of the wrapper input cells in the two consecutive clock cycles required by two-pattern testing. New algorithms for test access mechanism design and test scheduling are proposed and design trade-offs between test area and testing time are discussed using experimental results. © 2006 IEEE.
{fenge}
33845440422	Retention-aware test scheduling for BISTed embedded SRAMs	In this paper we address the test scheduling problem for Built-in Self-tested (BISTed) embedded SRAMs (e-SRAMs) when Data Retention Faults (DRFs) are considered. The proposed test scheduling algorithm utilizes the "retention-aware" test power model [1] to minimize the total testing time of e-SRAMs while not violating given power constraints. Without losing generality, we consider both cases where the pause time for data retention faults is fixed and cases where it can be varied. Experimental results show that the "retention-aware" test scheduling algorithm can reduce the testing time of e-SRAMs up to more than 98 percent at the computational time within a second. © 2006 IEEE.
{fenge}
33947144187	Modular and rapid testing of SOCs with unwrapped logic blocks	Extensive research has been carried out for test planning of core-based system-on-a-chip devices. Most of the prior work assumes that all of the embedded cores are wrapped for test purpose. However, some designs may contain user-defined logic or cores that cannot be wrapped due to area constraints or timing violations. This paper discusses how these unwrapped logic blocks can be tested rapidly by adapting the TestRail architecture, which uses only the test control mechanism and the test instructions available through the IEEE 1500 standard for embedded core test. A new test scheduling algorithm, which facilitates a concurrent test of both unwrapped logic blocks and IEEE 1500-wrapped cores, is proposed, and experiments show that it outperforms a previous approach when the available number of tester channels and/or the number of unwrapped logic blocks are small. © 2005 IEEE.
{fenge}
33947705725	Test/repair area overhead reduction for small embedded SRAMs	For current highly-integrated and memory-dominant System-on-a-Chips (SoCs), especially for graphics and networking SoCs, the test/repair area overhead of embedded SRAMs (e-SRAMs) is a big concern. This paper presents various approaches to tackle this problem from a practical point of view. Without sacrificing at-speed testability, diagnosis capability and repairability, the proposed approaches consider partly sharing wrapper for identical memories, sharing memory BIST controllers for e-SRAMs embedded in different functional blocks, test responses compression for wide memories, and various repair strategies for e-SRAMs with different configurations. By combining the above approaches, the test/repair area overhead for e-SRAMs can be significantly reduced. For example, for one benchmark SoC used in our experiments, it can be reduced as much as 10% of the entire memory array. © 2006 IEEE.
{fenge}
34248226226	Test scheduling for built-in self-tested embedded SRAMs with data retention faults	The test scheduling problem for built-in self-tested embedded SRAMs (e-SRAMs) when data retention faults (DRFs) are considered is addressed here. We proposed a 'retention-aware' test power model by taking advantage of the fact that there is near-zero test power during the pause time for testing DRFs. The proposed test scheduling algorithm then utilises this new test power model to minimise the total testing time of e-SRAMs while not violating given power constraints, by scheduling some e-SRAM tests during the pause time of DRF tests. Without losing generality, we consider both cases where the pause time for DRFs is fixed and cases where it can be varied. Experimental results show that the proposed 'retention-aware' test power model and the corresponding test scheduling algorithm can reduce the testing time of e-SRAMs significantly with negligible computational time. © The Institution of Engineering and Technology 2007.
{fenge}
34547217327	Test wrapper design and optimization under power constraints for embedded cores with multiple clock domains	Even though many embedded cores contain several clock domains, most published methods for wrapper design have been limited to single-frequency cores. Cumbersome and invasive design techniques, such as insertion of test points, are needed to make these methods applicable to current-generation embedded cores. This paper presents a new method for designing test wrappers for embedded cores with multiple clock domains. The proposed 1500-compliant wrapper prevents clock skew and allows scan chains in different clock domains to shift test data at distinct clock frequencies, which enables a better control of power dissipation during test. We present an integer linear programming (ILP) model that can be used to minimize the core testing time under power constraints for small problem instances, and which can be combined with LP-relaxation to obtain lower bounds on the testing time for larger instances. We also present an efficient heuristic method that is applicable to large problem instances, and which yields the same (optimal) testing time as ILP for small problem instances. © 2007 IEEE.
{fenge}
34547320390	SOC test architecture optimization for signal integrity faults on core-external interconnects	The test time for core-external interconnect shorts/opens is typically much less than that for core-internal logic. Therefore, prior work on test infrastructure design for core-based system-on-a-chip (SOC) has mainly focused on minimizing the test time for core-internal logic. However, as feature sizes shrink for newer process technologies, the test time for interconnect signal integrity (SI) faults cannot be neglected. We investigate the impact of interconnect SI tests on SOC test architecture design and optimization. We present a compaction method for SI faults and algorithms for test architecture optimization. Experimental results for the ITC'02 benchmarks show that the proposed approach can significantly reduce the overall testing time for core-internal logic and core-external interconnects. Copyright 2007 ACM.
{fenge}
34548361505	A multi-core debug platform for NoC-based systems	Network-on-Chip (NoC) is generally regarded as the most promising solution for the future on-chip communication scheme in gigascale integrated circuits. As traditional debug architecture for busbased systems is not readily applicable to identify bugs in NoC-based systems, in this paper, we present a novel debug platform that supports concurrent debug access to the cores under debug (CUDs) and the NoC in a unified architecture. By introducing core-level debug probes in between the CUDs and their network interfaces and a system-level debug agent controlled by an off-chip multi-core debug controller, the proposed debug platform provides in-depth analysis features for NoC-based systems, such as NoC transaction analysis, multi-core cross-triggering and global synchronized timestamping. Therefore, the proposed solution is expected to facilitate the designers to identify bugs in NoC-based systems more effectively and efficiently. Experimental results show that the design-for-debug cost for the proposed technique in terms of area and traffic requirements is moderate. © 2007 EDAA.
{fenge}
39749128537	Pattern-directed circuit virtual partitioning for test power reduction	For a large circuit under test (CUT), it is likely that some test patterns result in excessive power dissipations that exceed the CUT's power rating. Designers may resort to lowpower automatic test pattern generation (ATPG) tools to solve this problem, which, however, usually leads to larger test data volume and requires extra computational effort, even if such tools are available. Another method is to partition the circuit into multiple subcircuits and test them separately. Unfortunately, this usually involves rerunning the time-consuming ATPG for each partitioned subcircuit and solving the problem of how to achieve an acceptable fault coverage for the glue logic between subcircuits. In this paper, we propose a novel low-power virtual test partitioning technique without the above-mentioned shortcomings. The basic idea is to partition the circuit in such way that the faults in the glue logic between subcircuits can be detected by patterns with low power dissipation that are applied at the entire circuit level, while the patterns with high power dissipation can be applied within a partitioned subcircuit without loss of fault coverage. Scan chain routing cost has also been considered during the partitioning process. Experimental results show that the proposed technique is very effective in reducing test power. © 2007 IEEE.
{fenge}
39749202968	Test-wrapper designs for the detection of signal-integrity faults on core-external interconnects of SoCs	As feature sizes continue to shrink for newer process technologies, signal integrity (SI) is emerging as a major concern for core-based system-on-a-chip (SoC) integrated circuits. To effectively test SI faults on core-external interconnects, core test wrappers need to be able to generate appropriate transitions at a wrapper output cell (WOC) on the driving side and detect the signal integrity loss at a wrapper input cell on the receiving side. In current wrapper designs, the WOCs for a victim interconnect and its aggressors make transitions at the same time with a common test clock signal in test mode, which is different from the functional mode. This is not adequate for SI test because the time elapsed between the transition of the victim and the transitions of its aggressors significantly affects the behavior of SI-related errors. To address this problem, we propose new IEEE Std. 1500-compliant wrapper designs that are able to apply SI test at functional mode or make transitions with various pre-defined skews between a victim line and its aggressors. We also introduce a novel overshoot detector inside the proposed wrapper. Experimental results show that the proposed wrapper designs are more effective for detecting Si-related errors when compared to existing techniques, with a moderate amount of DFT overhead. © 2007 IEEE.
{fenge}
58049086140	A hybrid model for production planning under demand uncertainty in refineries	A hybrid model for production planning under uncertain demands in refineries, which incorporates the deterministic planning and stochastic planning models by weight factors, is presented. Normal and uniform distribution assumptions for uncertain demand are used to test the robust of the normal stochastic model and the hybrid model. To solve these models, piecewise linear approximate functions are employed, which bears enough accuracy and fast solution speed. The optimal results obtained by only deterministic planning model are more aggressive, while the results by only stochastic model are more conservative. However, using the hybrid model with appropriate weight factors will result in better economic performance than both deterministic and stochastic models. This is an abstract of a paper presented at the AIChE Annual Meeting (Salt Lake City, UT 11/4-9/2007).
{fenge}
58049101871	Process cost modeling and production planning for petrochemical industries under uncertainties	A discussion covers the incorporation of data mining techniques into modeling and planning procedures; a data preprocess method to keep the data integrality, reduce data noise, and decrease the number of input variables; a modeling methodology correlating variable costs and processing amount for various processing units; a graph-assisted production-planning modeling system for a general petrochemical plant; systematic uncertainties; solving the nonlinear problem induced by the proposed production-planning model; and planning results. This is an abstract of a paper presented at the 2006 AIChE Annual Meeting (San Francisco, CA 11/12-17/2006).
{fenge}
58049124958	Optimal integration of production planning and process operation in petrochemical industry	For a petrochemical industry which has a large number of units, a variety of products and diversiform processes, there are many production plans for option, so optimal one is essential to insure it running safely and bring maximal economic benefits. A discussion on production planning and process operation optimized and integrated as two hierarchies to find a feasible production plan and corresponding process operation condition; modeling and solutions; solution procedure of determination, examination, revision, and determination; and preflash products. This is an abstract of a paper presented at the 2006 AIChE Annual Meeting (San Francisco, CA 11/12-17/2006).
{fenge}
77954089034	X-filling for simultaneous shift- and capture-power reduction in at-speed scan-based testing	Power consumption during at-speed scan-based testing can be significantly higher than that during normal functional mode in both shift and capture phases, which can cause circuits' reliability concerns during manufacturing test. This paper proposes a novel X-filling technique, namely iFill, to address the above issue, by analyzing the impact of X-bits on switching activities of the circuit nodes in the two different phases. In addition, different from prior $X$ -filling methods for shift-power reduction that can only reduce shift-in power, our method is able to cut down power consumptions in both shift-in and shift-out processes. Experimental results on benchmark circuits show that the proposed technique can guarantee the power safety in both shift and capture phases during at-speed scan-based testing. © 2006 IEEE.
{fenge}
79951587791	On signal tracing for debugging speedpath-related electrical errors in post-silicon validation	One of the most challenging problems in post-silicon validation is to identify those errors that cause prohibitive extra delay on speed-paths in the circuit under debug (CUD) and only expose themselves in a certain electrical environment. To address this problem, we propose a trace-based silicon debug solution, which provides real-time visibility to the speedpaths in the CUD during normal operation. Since tracing all speedpath-related signals can cause prohibited design for debug (DfD) overhead, we present an automated trace signal selection methodology that maximizes error detection probability under a given constraint. In addition, we develop a novel trace qualification technique that reduces the storage requirement in trace buffers. The effectiveness of the proposed methodology is verified with large benchmark circuits. © 2010 IEEE.
{fenge}
80052648336	Re-synthesis for cost-efficient circuit-level timing speculation	As the transistor feature size is continuously scaled down, integrated circuits are more vulnerable to process, voltage and temperature (PVT) variations, causing infrequent timing errors. Various techniques have been proposed to tackle this problem and circuit-level timing speculation is one of the most promising solutions. However, directly applying such technique can be quite costly in terms of area overhead and energy consumption. In this paper, we propose cost-efficient re-synthesis solutions to tackle this problem. We try to reduce the number of suspicious flip-flops (FFs) that might have timing errors by retiming techniques, which relocate some suspicious FFs without increasing critical path delay. An efficient and effective algorithm is then utilized to pad those short paths linking the remaining suspicious FFs to ensure the functional correctness of timing speculators. Experimental results show that the proposed solution can achieve significant area reduction for timing speculation. © 2011 ACM.
{fenge}
80052659381	Customer-aware task allocation and scheduling for multi-mode MPSoCs	Today's multiprocessor system-on-a-chip (MPSoC) products typically have multiple execution modes, and for each mode, all the products utilize the same task allocation and schedule strategy determined at design stage. As these products experience different usages by customers, such unified solution can at best be optimized for a hypothetical common case. It is hence likely that the product is not reliable or energy-efficient from particular customers' point of view. To tackle this problem, we propose a novel customer-aware task allocation and scheduling technique, wherein we generate an initial task schedule for each execution mode at design stage and then perform online adjustment at regular intervals for lifetime reliability improvement and/or energy reduction according to the specific usage strategy of individual products. Experimental results on several hypothetical MPSoCs with various task graphs demonstrate the effectiveness of the proposed personalized solution. © 2011 ACM.
{fenge}
84876775635	On multiplexed signal tracing for post-silicon validation	Trace-based debug techniques have widely been utilized in the industry to eliminate design errors escaped from pre-silicon verification. Existing solutions typically trace the same set of signals throughout each debug run, which is not quite effective for catching design errors. In this paper, we propose a multiplexed signal tracing strategy that is able to significantly increase debuggability of the circuit. That is, we divide the tracing procedure in each debug run into a few periods and trace different sets of signals in each period. We present a trace signal grouping algorithm to maximize the probability of catching the propagated evidences from design errors, considering the trace interconnection fabric design constraints. Moreover, we propose a trace signal selection solution to enhance the error detection capability. Experimental results on benchmark circuits demonstrate the effectiveness of the proposed solution. © 1982-2012 IEEE.
{fenge}
84897025501	Shutdown strategy for flare minimization at an olefin plant	Shutdown operations in olefin plants generate extensive flare emissions, which cause adverse environmental and societal impacts as well as large amounts of raw material and energy losses that could supposedly be unitized to generate much more needed products. Consequently, shutdown optimization for flare minimization is crucially important to all stake holders. However, the current practice for shutdown flare minimization almost exclusively depends on experienced operators, engineers, and plant administration. There is still a lack of systematic studies on how to cost-effectively identify and examine shutdown flare minimization strategies through plant-wide modeling and simulations. A novel process retrofit and shutdown operation strategy for flare minimization in an olefin plant is introduced. Plant-wide dynamic simulations are employed to examine the operational feasibility and critical information during the plant shutdown operation. The proposed shutdown strategy could virtually reduce the flare emission significantly compared to historical records. Flare minimization during olefin plant shutdowns is a challenging issue for olefin industry sustainability. An innovative process retrofit and shutdown strategy for flare minimization with plant-wide dynamic simulation models is introduced. The suggested shutdown strategy allows a substantial reduction of the flare emission compared to historical records. © 2014 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim.
{fenge}
43049122098	A Hybrid Programming Model for Optimal Production Planning under Demand Uncertainty in Refinery*	Production planning under uncertainty is considered as one of the most important problems in plant-wide optimization. In this article, first, a stochastic programming model with uniform distribution assumption is developed for refinery production planning under demand uncertainty, and then a hybrid programming model incorporating the linear programming model with the stochastic programming one by a weight factor is proposed. Subsequently, piecewise linear approximation functions are derived and applied to solve the hybrid programming model under uniform distribution assumption. Case studies show that the linear approximation algorithm is effective to solve the hybrid programming model, along with an error ≤0.5% when the deviation/mean ≤20%. The simulation results indicate that the hybrid programming model with an appropriate weight factor (0.1-0.2) can effectively improve the optimal operational strategies under demand uncertainty, achieving higher profit than the linear programming model and the stochastic programming one with about 1.5% and 0.4% enhancement, respectively. © 2008 Chemical Industry and Engineering Society of China (CIESC) and Chemical Industry Press (CIP).
{fenge}
49549101975	A debug probe for concurrently debugging multiple embedded cores and inter-core transactions in NoC-based systems	Existing SoC debug techniques mainly target bus-based systems. They are not readily applicable to the emerging system that use Network-on-Chip (NoC) as on-chip communication scheme. In this paper, we present the detailed design of a novel debug probe (DP) inserted between the core under debug (CUD) and the NoC. With embedded configurable triggers, delay control and timestamping mechanism, the proposed DP is very effective for inter-core transaction analysis as well as controlling embedded cores' debug processes. Experimental results show the functionalities of the proposed DP and its area overhead. ©2008 IEEE.
{fenge}
49549103060	On reducing both shift and capture power for sean-based testing	Power consumption in scan-based testing is a major concern nowadays. In this paper, we present a new X-filling technique to reduce both shift power and capture power during scan tests, namely LSC-filling. The basic idea is to use as few as possible X-bits to keep the capture power under the peak power limit of the circuit under test (CUT), while using the remaining X-bits to reduce the shift power to cut down the CUT's average power consumption during scan tests as much as possible. In addition, by carefully selecting the X-filling order, our X-filling technique is able to achieve lower capture power when compared to existing methods. Experimental results on ISCAS'89 benchmark circuits show the effectiveness of the proposed methodology. ©2008 IEEE.
{fenge}
50649093119	Channel width utilization improvement in testing NoC-based systems for test time reduction	Testing NoC-based systems mainly relies on reusing the Network-on-Chip architecture as the test access mechanism (TAM). This, however, implies that the core's test wrapper is supplied with full NoC channel width even if there is a mismatch between the two. How to effectively and efficiently make better utilization of the NoC channels for test data transferring is therefore an interesting and challenging problem. In this paper, we propose to combine a new wrapper design with interleaved test scheduling. Compared to[8], the proposed method can achieve better NoC channel utilization for test without manipulating test frequencies, which not only reduces test power, but also saves design effort for the test engineers. Consequently, the testing time of the NoC-based system is considerably reduced with the proposed technique (especially under stringent power constraints), as shown in the experimental results on circuits crafted from ITC02 benchmarks. © 2008 IEEE.
{fenge}
51549102248	On reliable modular testing with vulnerable test access mechanisms	In modular testing of system-on-a-chip (SoC), test access mechanisms (TAMs) are used to transport test data between the input/output pins of the SoC and the cores under test. Prior work assumes TAMs to be error-free during test data transfer. The validity of this assumption, however, is questionable with the ever-decreasing feature size of today's VLSI technology and the ever-increasing circuit operational frequency. In particular, when functional interconnects such as network-on-chip (NoC) are reused as TAMs, even if they have passed manufacturing test beforehand, failures caused by electrical noise such as crosstalk and transient errors may happen during test data transfer and make good chips appear to be defective, thus leading to undesired test yield loss. To address the above problem, in this paper, we propose novel solutions that are able to achieve reliable modular testing even if test data may sometimes get corrupted during transmission with vulnerable TAMs, by designing a new "jitter-aware" test wrapper and a new "jitter-transparent" ATE interface. Experimental results on an industrial circuit demonstrate the effectiveness of the proposed technique. Copyright 2008 ACM.
{fenge}
49749120586	Re-examining the use of Network-on-Chip as test access mechanism	Existing work on testing NoC-based systems advocates to reuse the on-chip network itself as test access mechanism (TAM) to transport test data to/from embedded cores. While this methodology obviously reduces the routing cost when compared to the case that dedicated test buses are introduced as TAMs, it is not clear whether it is beneficial in terms of other important factors that significantly affect test cost, e.g., testing time, test control complexity and test reliability. As a result, in this paper, we re-examine the issue of using NoC as TAM in order to facilitate designers to construct a cost-effective system test architecture based on their requirements. © 2008 EDAA.
{fenge}
49749144400	In-band cross-trigger event transmission for transaction-based debug	Cross-trigger, the mechanism to trigger activities in one debug entity from debug events happened in another debug entity, is a very useful technique for debugging applications involving multiple embedded cores. Existing solutions rely on dedicated interconnects (i.e., different from functional interconnects) to transfer debug events and cannot guarantee the arrival time of the debug events coincides with the arrival time of the data messages between multiple cores. This results in mismatches between the observed system internal operations and the ones that designers expect to watch. To tackle the above problem, in this paper, we propose to package the cross-trigger events and the actual data together into transaction messages and transfer them along the same functional interconnects (namely in-band debug event transmission), with the help of novel design-for-debug circuits. Simulation results on a hypothetical NoC-based systems show the effectiveness of the proposed technique. © 2008 EDAA.
{fenge}
49749144734	iFill: An impact-oriented X-filling method for shift- and capture-power reduction in at-speed scan-based testing	In scan-based tests, power consumptions in both shift and capture phases may be significantly higher than that in normal mode, which threatens circuits' reliability during manufacturing test. In this paper, by analyzing the impact of X-bits on circuit switching activities, we present an X-filling technique that can decrease both shift- and capture-power to guarantees the reliability of scan tests, called iFill. Moreover, different from prior work on X-filling for shift-power reduction which can only reduce shift-in power, iFill is able to decrease power consumptions during both shift-in and shift-out. Experimental results on ISCAS'89 benchmark circuits show the effectiveness of the proposed technique. © 2008 EDAA.
{fenge}
49749146713	Defect tolerance in homogeneous manycore processors using core-level redundancy with unified topology	Homogeneous manycore processors are emerging for terascale computation. Effective defect tolerance techniques are essential to improve the yield of such complex integrated circuits. In this paper, we propose to achieve fault tolerance by employing redundancy at the core-level instead of at the microarchitecture-level. When faulty cores existing on-chip in this architecture, how to reconfigure the processor with the most effective topology is a relevant research problem. We present novel solutions for this problem, which not only maximize the performance of the manycore processor, but also provide a unified topology to operating system and application software running on the processor. Experimental results show the effectiveness of the proposed techniques. © 2008 EDAA.
{fenge}
58249114359	On reusing test access mechanisms for debug data transfer in SoC post-silicon validation	One of the main difficulties in post-silicon validation is the limited debug access bandwidth to internal signals. At the same time, SoC devices often contain dedicated bus-based test access mechanisms (TAMs) that are used to transfer test data between external testers and embedded cores. In this paper, we propose to reuse these precious TAM resources for real-time debug data transfer in post-silicon validation. This strategy significantly increases debug bandwidth with negligible routing overhead. To support different TAM architectures and debug scenarios, design for debug (DfD) structures are introduced at both core test wrapper level and system level. Simulation results demonstrate the effectiveness of the proposed approach at low DfD cost. © 2008 IEEE.
{fenge}
57849131734	On capture power-aware test data compression for scan-based testing	Large test data volume and high test power are two of the major concerns for the industry when testing large integrated circuits. With given test cubes in scan-based testing, the "don't-care" bits can be exploited for test data compression and/or test power reduction. Prior work either targets only one of these two issues or considers to reduce test data volume and scan shift power together. In this paper, we propose a novel capture power-aware test compression scheme that is able to keep scan capture power under a safe limit with little loss in test compression ratio. Experimental results on benchmark circuits demonstrate the efficacy of the proposed approach.
{fenge}
60349113440	SOC test-architecture optimization for the testing of embedded cores and signal-integrity faults on core-external interconnects	The test time for core-external interconnect shorts and opens is typically much less than that for core-internal logic. Therefore, prior work on test-infrastructure design for core-based system-on-a-chip (SOC) has mainly focused on minimizing the test time for core-internal logic. However, as feature sizes shrink for newer process technologies, the test time for signal integrity (SI) faults on interconnects cannot be neglected. The test time for SI faults can be comparable to, or even larger than, the test time for the embedded cores. We investigate the impact of interconnect SI tests on SOC test-architecture design and optimization. A compaction method for SI faults and algorithms for test-architecture optimization are also presented. Experimental results for the ITC'02 benchmarks show that the proposed approach can significantly reduce the overall testing time for core-internal logic and core-external interconnects. © 2009 ACM.
{fenge}
67249105720	SoC test architecture design and optimization considering power supply noise effects	Excessive power supply noise (PSN) during testing can erroneously cause good chips to fail the manufacturing test, thus leading to unnecessary yield loss. While there are some emerging methodologies such as PSN-aware test generation technique to tackle this problem, they are not readily applicable in modular system-on-a-chip (SoC) testing. This is because: (i). embedded core tests are usually prepared by core providers who are not knowledgeable about the SoC power distribution network; (ii) embedded cores are usually tested in parallel to reduce testing time, but the associated intercore PSN effects are not considered in existing SoC test architecture design and optimization process. In this paper, we present a fast inter-core PSN estimation method and use it to guide the test scheduling process to solve the PSN-induced SoC test yield loss problem. In addition, upon observing that the PSN effects usually manifest themselves only during the capture phase for scan-tested cores, we introduce novel design for test (DfT) structures into SoC test controller to avoid PSN effects with negligible testing time penalty. Experimental results demonstrate the effectiveness of the proposed solution. © 2008 IEEE.
{fenge}
69649093856	On topology reconfiguration for defect-tolerant NoC-Based homogeneous manycore systems	Homogeneous manycore systems are emerging for tera-scale computation and typically utilize Network-on-Chip (NoC) as the communication scheme between embedded cores. Effective defect tolerance techniques are essential to improve the yield of such complex integrated circuits. We propose to achieve fault tolerance by employing redundancy at the core-level instead of at the microarchitecture level. When faulty cores exist on-chip in this architecture, however, the physical topologies of various manufactured chips can be significantly different. How to reconfigure the system with the most effective NoC topology is a relevant research problem. In this paper, we first show that this problem is an instance of a well known NP-complete problem. We then present novel solutions for the above problem, which not only maximize the performance of the on-chip communication scheme, but also provide a unified topology to Operating System and application software running on the processor. Experimental results show the effectiveness of the proposed techniques. © 2006 IEEE.
{fenge}
70350707907	Interconnection fabric design for tracing signals in post-silicon validation	Post-silicon validation has become an essential step in the design flow of today's complex integrated circuits. One effective technique that provides real-time visibility to the circuit under debug (CUD) is to monitor and trace internal signals during its normal operation. Typically, a large number of signals are tapped and a subset of them are selected to be observed in each debug process. These trace signals need to be transferred to on-chip buffers and/or off-chip trace ports for analysis. Existing solutions use multiplexer trees or specific access networks to conduct the above duty, which, however, either provide less visibility to the CUD or result in high hardware cost. In this paper, we propose a novel trace signal interconnection fabric design to tackle the above problem. Experimental results on benchmark circuits show the efficacy of the proposed solution. Copyright 2009 ACM.
{fenge}
76349088251	Layout-driven test-architecture design and optimization for 3D SoCs under pre-bond test-pin-count constraint	We propose a layout-driven test-architecture design and optimization technique for core-based system-on-chips (SoCs) that are fabricated using three-dimensional (3D) integration. In contrast to prior work, we consider the pre-bond test-pin-count constraint during optimization since these pins occupy large silicon area that cannot be used in functional mode. In addition, the proposed test-architecture design takes the SoC layout into consideration and facilitates the sharing of test wires between pre-bond tests and post-bond test, which significantly reduces the routing cost for a test-access mechanism in 3D technology. Experimental results for the ITC'02 SoC benchmarks circuits demonstrate the effectiveness of the proposed solution. Copyright 2009 ACM.
{fenge}
76549101516	Compression-aware pseudo-functional testing	With technology scaling, the discrepancy between integrated circuits' activities in normal functional mode and that in structural test mode has an increasing adverse impact on the effectiveness of manufacturing test. By identifying functionally unreachable states in the circuit and avoiding them during the test generation process, pseudo-functional testing is an effective technique to address this problem. Pseudo-functional patterns, however, feature much less don't-care bits when compared to conventional structural patterns, making them less friendly to test compression techniques. In this paper, we propose novel solutions to address the above problem, which facilitate to apply pseudo-functional testing in linear decompressor-based test compression environment. Experimental results on ISCAS'89 benchmark circuits demonstrate the effectiveness of the proposed methodology. © 2009 IEEE.
{fenge}
76549111150	On simultaneous shift- and capture-power reduction in linear decompressor-based test compression environment	Growing test data volume and excessive test power consumption in scan-based testing are both serious concerns for the semiconductor industry. Various test data compression (TDC) schemes and low-power X-filling techniques were proposed to address the above problems. These methods, however, exploit the very same "don't-care" bits in the test cubes to achieve different objectives and hence may contradict to each other. In this work, we propose a generic framework for test power reduction in linear decompressor-based test compression environment, which is able to effectively reduce shiftand capture-power simultaneously. Experimental results on benchmark circuits demonstrate that our proposed techniques significantly outperform existing solutions. © 2009 IEEE.
{fenge}
76549124286	Test economics for Homogeneous manycore systems	Homogeneous manycore systems that contain a large number of structurally identical cores are emerging for tera-scale computation. To ensure the required quality and reliability of such complex integrated circuits before supplying them to final users, extensive manufacturing tests need to be conducted and the associated test cost can account for a great share of the total production cost. By introducing spare cores on-chip, the burn-in test time can be shortened and the defect coverage requirements for core tests can be also relaxed, without sacrificing quality of the shipped products. The above test cost reduction is likely to exceed/compensate the manufacturing cost of the extra cores, thus reducing the total production cost of manycore systems. We develop novel analytical models that capture the above tradeoff in this paper and we verify the effectiveness of the proposed test economics model for hypothetical manycore systems with various configurations. © 2009 IEEE.
{fenge}
77951156678	Test pattern selection for potentially harmful open defects in power distribution networks	Power distribution network (PDN) designs for today's high performance integrated circuits (ICs) typically occupy a significant share of metal resources in the circuit, and hence defects may be introduced on PDNs during the manufacturing process. Since we cannot afford to over-design the PDNs to tolerate all possible defects, it is necessary to conduct manufacturing test for them. In this paper, we propose novel methodologies to identify those potentially harmful open defects in PDNs and we show how to select a set of patterns that initially target transition faults to achieve high fault coverage for the PDN defects. Experimental results on benchmark circuits demonstrate the effectiveness of the proposed technique. © 2009 IEEE.
{fenge}
77951219422	On signal tracing in post-silicon validation	It is increasingly difficult to guarantee the first silicon success for complex integrated circuit (IC) designs. Post-silicon validation has thus become an essential step in the IC design flow. Tracing internal signals during circuit's normal operation, being able to provide real-time visibility to the circuit under debug (CUD), is one of the most effective silicon debug techniques and has gained wide acceptance in industrial designs. Trace-based debug solution, however, involves non-trivial design for debug overhead. How to conduct signal tracing effectively for bug elimination is therefore a challenging task for IC designers. In this paper, we provide in-depth discussion for trace-based debug strategy and review recent advancements in this important area.
{fenge}
77951698984	Dynamic simulation and optimization for the start-up operation of an ethylene oxide plant	Ethylene oxide (EO) is an important chemical intermediate for the production of various chemical products. The manufacturing of EO involves critical exothermic reactions at high temperature and high pressure, whose failure may cause catastrophic personal injury, severe air pollution, and tremendous economic loss. Thus, an EO plant must be well controlled under various situations, especially during its start-up operations. In this paper, a general methodology for improving chemical plant start-up operations through plant-wide dynamic simulation has been developed. It undergoes modeling and validations for steady-state, dynamic, and historian start-up operations. On the basis of the validated dynamic simulation model, the original plant start-up strategy is further examined and optimized to speed-up the plant start-up operation with enhanced safety considerations. A case study on an EO plant start-up has demonstrated the significant operational and economic benefits of the proposed methodology. © 2010 American Chemical Society.
{fenge}
77953101561	Layout-aware pseudo-functional testing for critical paths considering power supply noise effects	When testing delay faults on critical paths, conventional structural test patterns may be applied in functionally-unreachable states, leading to over-testing or under-testing of the circuits. In this paper, we propose novel layout-aware pseudo-functional testing techniques to tackle the above problem. Firstly, by taking the circuit layout information into account, functional constraints related to delay faults on critical paths are extracted. Then, we generate functionally-reachable test cubes for every true critical path in the circuit. Finally, we fill the don't-care bits in the test cubes to maximize power supply noises on critical paths under the consideration of functional constraints. The effectiveness of the proposed methodology is verified with large ISCAS'89 benchmark circuits. © 2010 EDAA.
{fenge}
77953104730	Energy-efficient task allocation and scheduling for multi-mode MPSoCs under lifetime reliability constraint	In this paper, we consider energy minimization for multiprocessor system-on-a-chip (MPSoC) under lifetime reliability constraint of the system, which has become a serious concern for the industry with technology scaling. As today's complex embedded systems typically have multiple execution modes, we first identify a set of "good" task allocation and schedules for each execution mode in terms of lifetime reliability and/or energy consumption, and then we introduce novel techniques to obtain an optimal combination of these single-mode solutions, which is able to minimize the energy consumption of the entire multi-mode system while satisfying given lifetime reliability constraint. Experimental results on several hypothetical MPSoC platforms with various task graphs demonstrate the effectiveness of the proposed approach. © 2010 EDAA.
{fenge}
77953114464	AgeSim: A simulation framework for evaluating the lifetime reliability of processor-based SoCs	Aggressive technology scaling has an ever-increasing adverse impact on the lifetime reliability of microprocessors. This paper proposes a novel simulation framework for evaluating the lifetime reliability of processor-based system-on-a-chips (SoCs), namely AgeSim, which facilitates designers to make design decisions that affect SoCs' mean time to failure. Unlike existing work, AgeSim can simulate failure mechanisms with arbitrary lifetime distributions and do not require to trace the system's reliability-related factors over its entire lifetime, and hence is more efficient and accurate. Two case studies are conducted to show the flexibility and effectiveness of the proposed methodology. © 2010 EDAA.
{fenge}
77953122741	Lifetime reliability for load-sharing redundant systems with arbitrary failure distributions	In this work, a general closed-form expression is presented for the lifetime reliability of load-sharing k -out-of-n:G hybrid redundant systems. In such systems, m components are initially configured as active units. Depending on whether it is performing tasks, an active component can be in either a processing, or a wait state. Each state corresponds to an arbitrary failure distribution. The remaining (n-m) are spares to provide fault tolerance. Each time an active component fails, a spare one converts into active mode, until there are no more spares in the system. Then, the system works in a gracefully degrading manner such that less than m components share the workload, until the number of good components is less than k. The task allocation, and service are modeled as queueing systems, wherein the utilization ratio essentially affects the aging effect of components. We integrate the various failure distributions for components in different operational states into an analytical model according to the statistical properties of the task allocation mechanisms, and the components' processing capacity, and analyse the lifetime reliability of the entire system. Finally, three special cases, and a series of numerical experiments are discussed in detail to show the practical applicability of the proposed approach. © 2006 IEEE.
{fenge}
77954872445	Economic analysis of testing homogeneous manycore chips	The employment of a large number of structurally identical cores on a single silicon die is generally regarded as a promising solution for tera-scale computation, known as manycore chips. To ensure the product quality of such complex integrated circuits before shipping them to final users, extensive manufacturing tests are necessary and the associated test cost can account for a large share of the total production cost. By introducing spare cores on-chip, the burn-in test time can be shortened and the defect coverage requirements for core tests can be also relaxed, without sacrificing quality of the shipped products. If the above test cost reduction exceeds the manufacturing cost of the extra cores, the total production cost of manycore chips can be reduced. In this paper, we develop novel analytical models to study the above tradeoff and we verify the effectiveness of the proposed test economics model for hypothetical manycore chips with various configurations. © 2010 IEEE.
{fenge}
77956201399	Performance yield-driven task allocation and scheduling for MPSoCs under process variation	With the ever-increasing transistor variability in CMOS technology, it is essential to integrate variation-aware performance analysis into the task allocation and scheduling process to improve its performance yield when building today's multiprocessor system-ona- chip (MPSoC). Existing solutions assume that the execution times of tasks performed on different processors are statistically independent, which ignores the spatial correlation characteristics for systematic variation. In addition, a unified task schedule is constructed at design stage and applied to all products with various variation effects, which restricts the maximum performance yield that can be achieved for MPSoC products. To tackle the above problems, in this paper, we present a novel quasi-static scheduling algorithm. Based on a more accurate performance yield estimation method, a set of variation-aware schedules is synthesized off-line and, at run time, the scheduler will select the right one based on the actual variation for each chip, such that the timing constraint can be satisfied whenever possible. Experimental results demonstrate the effectiveness. Copyright 2010 ACM.
{fenge}
78650868305	On timing-independent false path identification	This paper is concerned with finding timing-independent false paths that cannot be sensitized under any signal arrival time condition in integrated circuits. Existing techniques regard a path as a true path as long as a vector pair can be found to sensitize it. This is rather pessimistic since such a path might be activated only with illegal states in the circuit and hence it is actually functionally-unsensitizable. In this paper, we develop novel techniques to take the above issue into consideration when identifying false paths, which facilitates us to find much more false paths than conventional techniques. Experimental results on benchmark circuits demonstrate the effectiveness of the proposed methodology. ©2010 IEEE.
{fenge}
78650885114	Characterizing the lifetime reliability of manycore processors with core-level redundancy	With aggressive technology scaling, integrated circuits suffer from everincreasing wearout effects and their lifetime reliability has become a serious concern for the industry. For manycore processors that integrate a large number of processor cores on a single silicon die, introducing core-level redundancy is an effective way to alleviate this problem. There are, however, many strategies to make use of the redundant cores, which have different implications on the aging effects of embedded processors. How to characterize the lifetime reliability of manycore processors with different usages is therefore an important and relevant problem. In this paper, we propose a novel analytical method to tackle the above problem, which captures the impact of workloads and the associated temperature variations. We then use the proposed model to analyze the lifetime reliability for manycore processors with various redundancy configurations. Finally, the effectiveness of the proposed method is demonstrated with extensive experiments. © 2010 IEEE.
{fenge}
78650920477	Yield enhancement for 3D-stacked memory by redundancy sharing across dies	Three-dimensional (3D) memory products are emerging to fulfill the ever-increasing demands of storage capacity. In 3D-stacked memory, redundancy sharing between neighboring vertical memory blocks using short through-silicon vias (TSVs) is a promising solution for yield enhancement. Since different memory dies are with distinct fault bitmaps, how to selectively matching them together to maximize the yield for the bonded 3D-stacked memory is an interesting and relevant problem. In this paper, we present novel solutions to tackle the above problem. Experimental results show that the proposed methodology can significantly increase memory yield when compared to the case that we only bond self-reparable dies together. © 2010 IEEE.
{fenge}
79551551465	Fine-grained characterization of process variation in FPGAs	As semiconductor manufacturing continues towards reduced feature sizes, yield loss due to process variation becomes increasingly important. To address this issue on FPGA platforms, several variation aware design (VAD) methodologies have been proposed. In this work we present a practical method of process variation characterization (PVC) to facilitate VAD using only intrinsic FPGA resources. The scheme is based on measuring the difference between ring oscillator (RO) delay at different locations within a die, and can be used to perform process variation characterization for LE delays and interconnect delays including direct connection, double wire and hex wires. The difference in loop delays can also be estimated from equations using parameters extracted from primitives and compared with direct measurements. On a Xilinx Spartan-3e device, it was found that the error between the estimated and measured values was on average less than 10%. © 2010 IEEE.
{fenge}
79955555190	Capture-power-aware test data compression using selective encoding	Ever-increasing test data volume and excessive test power are two of the main concerns of VLSI testing. The don't-care bits (also known as X-bits) in given test cube can be exploited for test data compression and/or test power reduction, and these techniques may contradict to each other because the very same X-bits are likely to be used for different optimization objectives. This paper proposes a capture-power-aware test compression scheme that is able to keep capture-power under a safe limit with low test compression ratio loss. Experimental results on benchmark circuits validate the effectiveness of the proposed solution. © 2011 Elsevier B.V. All rights reserved.
{fenge}
79957552925	On multiplexed signal tracing for post-silicon debug	Trace-based debug solutions facilitate to eliminate design errors escaped from pre-silicon verification and have gained wide acceptance in the industry. Existing techniques typically trace the same set of signals throughout each debug run, which is not quite effective for catching design errors. In this work, we propose a multiplexed signal tracing strategy that is able to significantly increase debuggability of the circuit. That is, we divide the tracing procedure in each debug run into a few periods and trace different sets of signals in each period. A novel trace signal grouping algorithm is presented to maximize the probability of catching the propagated evidences from design errors, considering the trace interconnection fabric design constraints. Experimental results on benchmark circuits demonstrate the effectiveness of proposed solution. © 2011 EDAA.
{fenge}
80055052389	On task allocation and scheduling for lifetime extension of platform-based MPSoC designs	With the relentless scaling of semiconductor technology, the lifetime reliability of today's multiprocessor system-on-a-chip (MPSoC) designs has become one of the major concerns for the industry. Without explicitly taking this issue into consideration during the task allocation and scheduling process, existing works may lead to imbalanced aging rates among processors, thus reducing the system's service life. To tackle this problem, in this paper, we propose an analytical model to estimate the lifetime reliability of multiprocessor platforms when executing periodical tasks, and we present a novel task allocation and scheduling algorithm that is able to take the aging effects of processors into account, based on the simulated annealing technique. In addition, to speed up the annealing process, several techniques are proposed to simplify the design space exploration process with satisfactory solution quality. Experimental results on various hypothetical multiprocessors and task graphs show that significant system lifetime extension can be achieved by using the proposed approach, especially for heterogeneous platforms with large task graphs. © 2006 IEEE.
{fenge}
84855790452	Online clock skew tuning for timing speculation	The timing performance and yield of integrated circuits can be improved by carefully assigning intentional clock skews to flip-flops. Due to the ever-increasing process, voltage, and temperature variations with technology scaling, however, traditional clock skew optimization solutions that work in a conservative manner to guarantee always correct computation cannot perform as well as expected. By allowing infrequent timing errors and recovering from them with minor performance impact, the concept of timing speculation has attracted lots of research attention since it enables better than worst-case design. In this work, we propose a novel online clock skew tuning technique for circuits equipped with timing speculation capability. By observing the occurrence of timing errors at runtime and tuning clock skews accordingly, the proposed technique is able to achieve much better timing performance when compared to existing clock skew optimization solutions. Experimental results on various benchmark circuits demonstrate the effectiveness of the proposed methodology. © 2011 IEEE.
{fenge}
84859959086	Yield enhancement for 3D-stacked ICs: Recent advances and challenges	Three-dimensional (3D) integrated circuits (ICs) that stack multiple dies vertically using through-silicon vias (TSVs) have gained wide interests of the semiconductor industry. The shift towards volume production of 3D-stacked ICs, however, requires their manufacturing yield to be commercially viable. Various techniques have been presented in the literature to address this important problem, including pre-bond testing techniques to tackle the "known good die" problem, TSV redundancy designs to provide defect-tolerance, and wafter/die matching solutions to improve the overall stack yield. In this paper, we survey recent advances in this filed and point out challenges to be resolved in the future. © 2012 IEEE.
{fenge}
84859966945	CODA: A concurrent online delay measurement architecture for critical paths	With technology scaling, integrated circuits behave more unpredictably due to process variation, environmental changes and aging effects. Various variation-aware and adaptive design methodologies have been proposed to tackle this problem. Clearly, more effective solutions can be obtained if we are able to collect real-time information such as the actual propagation delay of critical paths when the circuit is running in normal function mode. Motivated by the above, in this paper, we propose a novel concurrent online delay measurement architecture for critical paths, namely CODA, to facilitate this task. Experimental results demonstrate high accuracy and practicality of the proposed technique. © 2012 IEEE.
{fenge}
84859970126	Learning-based power management for multi-core processors via idle period manipulation	Learning-based dynamic power management (DPM) techniques, being able to adapt to varying system conditions and workloads, have attracted lots of research attention recently. To the best of our knowledge, however, none of the existing learning-based DPM solutions are dedicated to power reduction in multi-core processors, although they can be utilized by treating each processor core as a standalone entity and conducting DPM for them separately. In this work, by including task allocation into our learning-based DPM framework for multi-core processors, we are able to manipulate idle periods on processor cores to achieve a better tradeoff between power consumption and system performance. Experimental results show that the proposed solution significantly outperforms existing DPM techniques. © 2012 IEEE.
{fenge}
84862069800	Clock skew scheduling for timing speculation	By assigning intentional clock arrival times to the sequential elements in a circuit, clock skew scheduling (CSS) techniques can be utilized to improve IC performance. Existing CSS solutions work in a conservative manner that guarantees "always correct" computation, and hence their effectiveness is greatly challenged by the ever-increasing process variation effects. By allowing infrequent timing errors and recovering from them with minor performance impact, timing speculation techniques such as Razor have gained wide interests from both academia and industry. In this work, we formulate the clock skew scheduling problem for circuits equipped with timing speculation capability and propose a novel CSS algorithm based on gradient-descent method. Experimental results on various benchmark circuits demonstrate the effectiveness of our proposed methodology. © 2012 EDAA.
{fenge}
84862106154	On effective TSV repair for 3D-stacked ICs	3D-stacked ICs that employ through-silicon vias (TSVs) to connect multiple dies vertically have gained wide-spread interest in the semiconductor industry. In order to be commercially viable, the assembly yield for 3D-stacked ICs must be as high as possible, requiring TSVs to be reparable. Existing techniques typically assume TSV faults to be uniformly distributed and use neighboring TSVs to repair faulty ones, if any. In practice, however, clustered TSV faults are quite common due to the fact that the TSV bonding quality depends on surface roughness and cleaness of silicon dies, rendering prior TSV redundancy solutions less effective. To resolve this problem, we present a novel TSV repair framework, including a hardware architecture that enables faulty TSVs to be repaired by redundant TSVs that are farther apart, and the corresponding repair algorithm. By doing so, the manufacturing yield for 3D-stacked ICs can be dramatically improved, as demonstrated in our experimental results. © 2012 EDAA.
{fenge}
84862911075	Pseudo-functional testing for small delay defects considering power supply noise effects	Detecting small delay defects (SDDs) has become increasingly important to address the quality and reliability concerns of integrated circuits. Without considering functional constraints in the circuits under test, however, existing techniques may generate test patterns that are functionally-unreachable. Such SDD patterns may incur excessive (or limited) power supply noise (PSN) on sensitized paths in test mode, thus leading to over-testing or under-testing of the circuits. In this paper, we propose novel pseudo-functional testing techniques to tackle the above problem. Firstly, by taking the circuit layout information into account, functional constraints related to critical paths are extracted. Then, we generate functionally-reachable test cubes for SDD faults in the circuit. Finally, we use ATPG-like algorithm to justify transitions that pose the maximized PSN effects on sensitized critical paths under the consideration of functional constraints. The effectiveness of the proposed methodology is verified with large ISCAS'89 and ILWS'05 benchmark circuits. © 2011 IEEE.
{fenge}
84863544270	X-tracer: A reconfigurable X-tolerant trace compressor for silicon debug	The effectiveness of at-speed silicon debug is constrained by the limited trace buffer size and/or trace port bandwidth, requiring highly-efficient trace data compression solutions. As it is usually inevitable to have unknown 'X' values during silicon debug, trace compressor should be equipped with X-tolerance feature in order not to significantly degrade error detection capability. To tackle this problem, this paper presents a novel reconfigurable X-tolerant trace compressor, namely X-Tracer, which is able to tolerate as many X-bits as possible in the trace streams while guaranteeing high compression ratio, at the cost of little extra design-for-debug hardware. Experimental results on benchmark circuits demonstrate the effectiveness of the proposed technique. © 2012 ACM.
{fenge}
84863988760	Integrated test-architecture optimization and thermal-aware test scheduling for 3-D SoCs under pre-bond test-pin-count constraint	We propose a layout-driven test-architecture design and optimization technique for core-based system-on-chips (SoCs) that are fabricated with three-dimensional (3-D) integration technology. In contrast to prior work, we consider the pre-bond test-pin-count constraint during optimization since these pins occupy large silicon area that cannot be used in functional mode. In addition, the proposed test-architecture design takes the SoC layout into consideration and facilitates the sharing of test wires between pre-bond tests and post-bond test, which significantly reduces the routing cost for test-access mechanisms. In addition, a thermal-aware test scheduling algorithm is proposed to eliminate hot spots during manufacturing test. Experimental results for the ITC'02 SoC benchmarks circuits demonstrate the effectiveness of the proposed solution. © 2012 IEEE.
{fenge}
84864115288	HTOutlier: Hardware Trojan detection with side-channel signature outlier identification	Hardware Trojan (HT) is a growing concern for the semiconductor industry. As a non-invasive and inexpensive approach, side-channel analysis methods based on signatures such as power, current, or circuit delay are widely used for HT detection. However, the effectiveness of these methods is greatly challenged by the ever-increasing process variation (PV) effects with technology scaling. In this work, considering the inherent relationship among side-channel signatures in a chip, we formulate the HT detection problem as a signature outlier identification problem, and solve it by comparing each signature with an estimated value from other signatures. Experimental results on benchmark circuits show that the proposed technique is much more effective than existing solutions. © 2012 IEEE.
{fenge}
84864149975	On signal selection for visibility enhancement in trace-based post-silicon validation	Today's complex integrated circuit designs increasingly rely on post-silicon validation to eliminate bugs that escape from pre-silicon verification. One effective silicon debug technique is to monitor and trace the behaviors of the circuit during its normal operation. However, due to the associated overhead, designers can only afford to trace a small number of signals in the design. Selecting which signals to trace is therefore a crucial issue for the effectiveness of this technique. This paper proposes an automated trace signal selection strategy with a new probability-based evaluation metric, which is able to dramatically enhance the visibility in post-silicon validation. Experimental results on benchmark circuits show that the proposed technique is more effective than existing solutions. © 1982-2012 IEEE.
{fenge}
84864939222	An FPGA chip identification generator using configurable ring oscillators	Physically unclonable functions (PUF) are commonly used in applications such as hardware security and intellectual property protection. Various PUF implementation techniques have been proposed to translate chip-specific variations into a unique binary string. It is difficult to maintain repeatability of chip ID generation, especially over a wide range of operating conditions. To address this problem, we propose utilizing configurable ring oscillators and an orthogonal re-initialization scheme to improve repeatability. An implementation on a Xilinx Spartan-3e field-programmable gate array was tested on nine different chips. Experimental results show that the bit flip rate is reduced from 1.5% to approximately 0 at a fixed supply voltage and room temperature. Over a 20 °C-80 °C temperature range and 25% variation in supply voltage, the bit flip rate is reduced from 1.56% to 3.125 × 10
{fenge}
84867803893	On X-variable filling and flipping for capture-power reduction in linear decompressor-based test compression environment	Excessive test power consumption and growing test data volume are both serious concerns for the semiconductor industry. Various low-power X-filling techniques and test data compression schemes were developed accordingly to address the above problems. These methods, however, often exploit the very same don't-care bits in the test cubes to achieve different objectives and hence may contradict each other. In this paper, we propose novel techniques to reduce scan capture power in linear decompressor-based test compression environment, by employing algorithmic solutions to fill and flip X-variables supplied to the linear decompressor. Experimental results on benchmark circuits demonstrate that our proposed techniques significantly outperform existing solutions. © 1982-2012 IEEE.
{fenge}
84872343313	On logic synthesis for timing speculation	By allowing the occurrence of infrequent timing errors and correcting them with rollback mechanisms, the so-called timing speculation (TS) technique can significantly improve circuit energy-efficiency and hence has become one of the most promising solutions to mitigate the ever-increasing variation effects in nanometer technologies. As timing error recovery incurs non-trivial performance/energy overhead, it is important to reshape the delay distribution of critical paths in timing-speculated circuits to minimize their timing error rates. Most existing TS optimization techniques achieve this objective with post-synthesis techniques such as gate sizing or body biasing. In this work, we propose to conduct logic synthesis for timing-speculated circuits from the ground up. Being able to manipulate circuit structures during logic optimization, the proposed solution is able to dramatically reduce circuit timing error rates and hence improve its throughput, as demonstrated with experimental results on various benchmark circuits. © 2012 ACM.
{fenge}
84873150863	On modeling faults in FinFET logic circuits	FinFET transistor has much better short-channel characteristics than traditional planar CMOS transistor and will be widely used in next generation technology. Due to its significant structural difference from conventional planar devices, it is essential to revisit whether existing fault models are applicable to detect faults in FinFET logic gates. In this paper, we study some unique defects in FinFET logic circuits and simulate their faulty behavior. Our simulation study shows that most of the defects can be covered with existing fault models, but they vary under different cases and test strategies may need to be augmented to target them. © 2012 IEEE.
{fenge}
84873110096	On efficient silicon debug with flexible trace interconnection fabric	Trace-based debug solutions facilitate to eliminate bugs escaped from pre-silicon verification and have gained wide acceptance in the industry. Generally speaking, a number of 'key' signals in the circuit are tapped, but not all of them can be observed at the same time due to the limited trace bandwidth. Therefore, a trace interconnection fabric is utilized to output either a subset of signals with multiplexor (MUX) network or compressed signatures with XOR network to the trace memory/port in each debug run. However, both kinds of trace interconnection fabrics have limitations. On one hand, with MUX-based fabric, the visibility of the circuit is limited and it requires many debug runs to locate errors. On the other hand, with XOR-based fabric, typically clean 'golden vectors' (i.e, without unknown bits) are required so that signatures are not corrupted. In this paper, we propose a flexible trace interconnection fabric design that is able to overcome the above limitations, at the cost of little extra design-for-debug hardware. Experimental results on benchmark circuits demonstrate the effectiveness of the proposed technique. © 2012 IEEE.
{fenge}
84875188537	On effective through-silicon via repair for 3-D-stacked ICs	3-D-stacked integrated circuits (ICs) that employ through-silicon vias (TSVs) to connect multiple dies vertically have gained wide-spread interest in the semiconductor industry. In order to be commercially viable, the assembly yield for 3-D-stacked ICs must be as high as possible, requiring TSVs to be reparable. Existing techniques typically assume TSV faults to be uniformly distributed and use neighboring TSVs to repair faulty ones, if any. In practice, however, clustered TSV faults are quite common due to the fact that the TSV bonding quality depends on surface roughness and cleanness of silicon dies, rendering prior TSV redundancy solutions less effective. Furthermore, existing techniques consume a lot of redundant TSVs that are still costly in the current TSV process. This inefficient TSV redundancy can limit the amount of TSVs that is allowed to use and may even become the obstacle to commercial production. To resolve this problem, we present a novel TSV repair framework, including a hardware redundancy architecture that enables faulty TSVs to be repaired by redundant TSVs that are farther apart, the corresponding repair algorithm and the redundancy architecture construction. By doing so, the manufacturing yield for 3-D-stacked ICs can be dramatically improved, as demonstrated in our experimental results. © 1982-2012 IEEE.
{fenge}
84879851211	Post-placement voltage island generation for timing-speculative circuits	Region-based multi-supply voltage (MSV) design, by which circuits are partitioned into multiple "voltage islands" and each island operates at a supply voltage that meets its own performance requirement, is an effective technique to tradeoff power and performance. Different from conventional voltage island generation techniques that work in a conservative manner to guarantee "always correct" computation, in this work, we investigate the MSV design problem for timingspeculative circuits, which achieves high energy-efficiency by allowing the occurrence of infrequent timing errors and correcting them online. A novel algorithm based on dynamic programming is developed to tackle this problem. Experimental results on various benchmark circuits demonstrate the effectiveness of the proposed methodology. Copyright © 2013 ACM.
{fenge}
84879856164	VeriTrust: Verification for hardware trust	Hardware Trojans (HTs) implemented by adversaries serve as backdoors to subvert or augment the normal operation of infected devices, which may lead to functionality changes, sensitive information leakages, or Denial of Service attacks. To tackle such threats, this paper proposes a novel verification technique for hardware trust, namely VeriTrust, which facilitates to detect HTs inserted at design stage. Based on the observation that HTs are usually activated by dedicated trigger inputs that are not sensitized with verification test cases, VeriTrust automatically identifies such potential HT trigger inputs by examining verification corners. The key difference between VeriTrust and existing HT detection techniques is that VeriTrust is insensitive to the implementation style of HTs. Experimental results show that VeriTrust is able to detect all HTs evaluated in this paper (constructed based on various HT design methodologies shown in the literature) at the cost of moderate extra verification time, which is not possible with existing solutions. Copyright © 2013 ACM.
{fenge}
84879863354	InTimeFix: A low-cost and scalable technique for in-situ timing error masking in logic circuits	With technology scaling, integrated circuits (ICs) suffer from increasing process, voltage, and temperature (PVT) variations and adverse aging effects. In most cases, these reliability threats manifest themselves as timing errors on critical speed-paths of the circuit, if a large design guard band is not reserved. This work presents a novel insitu timing error masking technique, namely InTimeFix, by introducing fine-grained redundant approximation circuit into the design to provide more timing slack for speed-paths. The synthesis of the redundant circuit relies on simple structural analysis of the original circuit, which is easily scalable to large IC designs. Experimental results show that InTimeFix significantly increases circuit timing slack with low area/power cost. Copyright © 2013 ACM.
{fenge}
84879871852	On effective and efficient in-field TSV repair for stacked 3D ICs	Three-dimensional (3D) integration based on through-silicon-vias (TSVs) is rapidly gaining traction for industry adoption. However, manufacturing processes for TSVs have been shown to introduce new failure mechanisms. In particular, thermo-mechanical stress and electromigration introduce reliability threats for TSVs, e.g., voids and interfacial cracks, which can lead to hard-to-predict timing errors on critical paths with TSVs, thereby resulting in accelerated chip failure in the field. Burn-in for screening latent defects during manufacturing is expensive and its effectiveness for new TSV defect types has yet to be thoroughly characterized. We describe a reconfigurable in-field repair solution that is able to effectively tolerate latent TSV defects through the judicious use of spares. The proposed solution includes a reconfigurable repair architecture that enables spare TSV sharing between TSV grids, and the corresponding in-field repair algorithms. The effectiveness and efficiency of our proposed solution is evaluated using 3D benchmark designs. Copyright © 2013 ACM.
{fenge}
84879585548	On predicting NBTI-induced circuit aging by isolating leakage change	Negative bias temperature instability (NBTI) has become a serious concern for the lifetime reliability of integrated circuits. On-line aging prediction is a promising way to prevent NBTI-induced circuit failure. However, the ever-increasing parameter variations, design complexity and area overhead degrade the effectiveness of such delay detection-based scheme. In this paper, we propose to use the isolated leakage change in critical path from full-chip leakage measurement result to predict NBTI-induced circuit aging. The chip-level leakage changes under a set of measurement vectors are firstly formulated as an equation set. Solving this equation set can obtain leakage changes in the gates along the critical path. Then, we predict delay degradation on arbitrary critical path based on the correlation between leakage change and delay increase. Our scheme is immune to the runtime noise and accommodates process variation by increasing measurement time overhead. Experimental results demonstrate that our scheme can effectively predict NBTI-induced circuit aging with acceptable accuracy loss. © 2013 IEEE.
{fenge}
84883355084	Optimization for timing-speculated circuits by redundancy addition and removal	Integrated circuits suffer from severe variation effects with technology scaling, making their timing behavior increasingly unpre-dictable. Timing speculation is a promising technique to tackle this problem with the help of online timing error detection and correction mechanisms. In this paper, we propose to use redundancy addition and removal (RAR) technique to optimize timing-speculated circuits. By intentionally removing wires on those frequently-exercised critical paths and replacing them with wires on less critical ones (if possible), the proposed technique is able to greatly reduce the timing error rate of the circuit and improve its overall throughput, as shown in our experimental results on various benchmark circuits. © 2013 IEEE.
{fenge}
84883703211	On hardware Trojan design and implementation at register-transfer level	There have been a number of hardware Trojan (HT) designs at register-transfer level (RTL) in the literature, which mainly describe their malicious behaviors and trigger mechanisms. Generally speaking, the stealthiness of the HTs is shown with extremely low sensitization probability of the trigger events. In practice, however, based on the fact that HTs are not sensitized with verification test cases (otherwise their malicious behaviors would have manifested themselves), designers could focus on verification corners for HT detection. Consequently, a stealthy HT not only requires to be hard to trigger, but also needs to be able to evade those hardware trust verification techniques based on 'unused circuit identification (UCI)'. In this paper, we present new HT design and implementation techniques that are able to achieve the above objectives. In addition, attackers would like to be able to control their HTs easily, which is also considered in the proposed HT design methodology. Experimental results demonstrate that HTs constructed with the proposed technique are both hard to be detected and easy to be controlled when compared to existing HTs shown in the literature. © 2013 IEEE.
{fenge}
84891503513	AgentDiag: An agent-assisted diagnostic framework for board-level functional failures	Diagnosing functional failures in complicated electronic boards is a challenging task, wherein debug technicians try to identify defective components by analyzing some syndromes obtained from the application of diagnostic tests. The diagnosis effectiveness and efficiency rely heavily on the quality of the in-house developed diagnostic tests and the debug technicians' knowledge and experience, which, however, have no guarantees nowadays. To tackle this problem, we propose a novel agent-assisted diagnostic framework for board-level functional failures, namely AgentDiag, which facilitates to evaluate the quality of the diagnostic tests and bridge the knowledge gap between the diagnostic programmers who write diagnostic tests and the debug technicians who conduct in-field diagnosis with a lightweight model of the boards and tests. Experimental results on a real industrial board and an OpenRISC design demonstrate the effectiveness of the proposed solution. © 2013 IEEE.
{fenge}
84893344834	ForTER: A forward error correction scheme for timing error resilience	With technology scaling, integrated circuits suffer from increasingly severe static and dynamic variations, which often manifest themselves as infrequent timing errors on circuit speed paths, if a large timing guard-band is not reserved. This paper presents a new forward timing error correction scheme, namely ForTER, which predicts whether the occurrence of timing errors would propagate to the next level of sequential elements and corrects them without necessarily borrowing timing slack. The proposed technique can be combined with other timing error resilient circuit design techniques to further improve circuit performance, as demonstrated in our experimental results with various benchmark circuits. © 2013 IEEE.
{fenge}
84893360544	On reconfiguration-oriented approximate adder design and its application	Approximate circuit designs allow us to tradeoff computation quality (e.g., accuracy) and computational effort (e.g., energy), by exploiting the inherent error-resilience of many applications. As the computation quality requirement of an application generally varies at runtime, it is preferable to be able to reconfigure approximate circuits to satisfy such needs and save unnecessary computational effort. In this paper, we present a reconfiguration-oriented design methodology for approximate circuits, and propose a reconfigurable approximate adder design that degrades computation quality gracefully. The proposed design methodology enables us to achieve better quality-effort tradeoff when compared to existing techniques, as demonstrated in the application of DCT computing. © 2013 IEEE.
{fenge}
84893289527	Flare minimization during start-ups of an integrated cryogenic separation system via dynamic simulation	The integrated cryogenic separation system (ICSS), which includes a chilling train and a demethanization section, is a crucial production system in an ethylene plant. It accounts for up to 50% of the total start-up time and flare emissions of the whole ethylene plant. Traditional start-up scenarios are developed on experience and improved by trial and error, which is inefficient and dangerous. This paper employs rigorous dynamic simulations to examine the potential infeasibilities and operational risks of different start-up scenarios. The best start-up scenario with minimal start-up time and flare emissions is determined. To obtain the initial start-up state with ambient nitrogen filling in the whole system, an initialization algorithm based on parameter modification for the dynamic ICSS model is presented. This novel initialization algorithm greatly saves time and effort of the initialization of the start-up model compared with previous studies. In addition, if time-related variables are important for scenario study or temperature of the dynamic model changes greatly, heat capacity must be added into dynamic start-up model, which was not mentioned in published literatures. They are critical to determine accurate start-up time, control the cooling rate, and verify the feasibility of scenarios during the dynamic start-up process under arbitrary temperature changes. The dynamic simulation provides insight into process dynamic behavior, which is crucial for the plant to evaluate and improve start-up scenarios. A real case study has demonstrated the efficacy of the dynamic simulation with heat capacity added. © 2014 American Chemical Society.
{fenge}
84903123018	Learning-based power management for multicore processors via idle period manipulation	Learning-based dynamic power management (DPM) techniques, being able to adapt to varying system conditions and workloads, have attracted a lot of research attention recently. To the best of our knowledge, however, none of the existing learning-based DPM solutions are dedicated to power reduction in multicore processors, although they can be utilized by treating each processor core as a standalone entity and conducting DPM for them separately. In this paper, by including task allocation into our learning-based DPM framework for multicore processors, we are able to manipulate idle periods on processor cores to achieve a better tradeoff between power consumption and system performance. Experimental results show that the proposed solution significantly outperforms existing DPM techniques. © 2014 IEEE.
{fenge}
84903161612	ApproxIt: An approximate computing framework for iterative methods	Approximate computing, being able to tradeoff computation quality (e.g., accuracy) and computational effort (e.g., energy) for error-tolerant applications such as media processing and the emerging Recognition, Mining, and Synthesis (RMS) applications, has gained significant traction in recent years. Many of these applications employ iterative methods for solutionfinding, wherein a sequence of improving approximate solutions are generated before reaching the final converged solution. In this work, we propose ApproxIt, a novel approximate computing framework for iterative methods with quality guarantees. To be specific, we present a lightweight quality estimator that is able to capture the solution quality of each iteration and use it to guide the selection of approximate computing mode in the next iteration. With the proposed dynamic effort scaling technique, ApproxIt is able to dramatically improve application energy efficiency under quality guarantees, as demonstrated in our experimental results. Copyright 2014 ACM.
{fenge}
84903204765	On the simulation of nbti-induced performance degradation considering arbitrary temperature and voltage variations	With aggressive CMOS technology scaling, Negative Bias Temperature Instability (NBTI) has emerged as one of the major system lifetime reliability threats, which gradually increases PMOS transistor threshold voltage and hence results in increased circuit delay. NBTI-induced performance degradation depends heavily on time-varying parameters such as temperature, duty cycle and supply voltage. Previous analytical models for NBTI effects, however, cannot cover all these parameters, causing overly optimistic or overly pessimistic analysis. In this work, we propose a comprehensive NBTI analytical model that explicitly takes supply voltage, duty cycle and temperature variations into consideration. The accuracy of the proposed model is validated against cycle-accurate simulation for NBTI effects. In addition, based on the proposed model, we present an efficient simulation framework for system lifetime prediction by running representative workloads only. Experimental results demonstrate the efficacy and efficiency of the proposed solution. Copyright 2014 ACM.
{fenge}
84910606828	DeTrust: Defeating hardware trust verification with stealthy implicitly-triggered hardware trojans	Hardware Trojans (HTs) inserted at design time by malicious insiders on the design team or third-party intellectual property (IP) providers pose a serious threat to the security of computing systems. Researchers have proposed several hardware trust verification techniques to mitigate such threats, and some of them are shown to be able to effectively flag all suspicious HTs implemented in the Trust-Hub HT backdoor benchmark suite. No doubt to say, adversaries would adjust their tactics of attacks accordingly and it is hence essential to examine whether new types of HTs can be designed to defeat these hardware trust verification techniques. In this paper, we present a systematic HT design methodology to achieve the above objective, namely DeTrust. Given an HT design, DeTrust keeps its original malicious behavior while making the HT resistant to state-of-the-art hardware trust verification techniques by manipulating its trigger designs. To be specific, DeTrust implements stealthy implicit triggers for HTs by carefully spreading the trigger logic into multiple sequential levels and combinational logic blocks and combining the trigger logic with the normal logic, so that they are not easily differentiable from normal logic. As shown in our experimental results, adversaries can easily employ DeTrust to evade hardware trust verification. We close with a discussion on how to extend existing solutions to alleviate the threat posed by DeTrust. However, they generally suffer from high computational complexity, calling for more advanced techniques to ensure hardware trust. Copyright 2014 ACM.
