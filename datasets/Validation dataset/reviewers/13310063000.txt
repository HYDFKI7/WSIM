{fenge}
84929727055	Randomized incremental least squares for distributed estimation over sensor networks	This paper proposes a randomized incremental algorithm to distributedly compute the least square (LS) estimate of linear systems over sensor networks. By integrating its measurement information, a sensor is randomly activated at every time to incrementally update a diffusion vector, which is also used to recursively estimate the unknown parameters of the system via a temporal average algorithm. Then, the updated diffusion vector is passed to the next activated sensor. The activating process is modeled as an identically and independently distributed process. It is shown that the estimate in each sensor asymptotically converges both in mean and almost surely to the standard LS estimate of the system parameters, which is based on all the sensor information. Simulation is finally included to validate the theoretical results.
{fenge}
84938095020	Non-linear neighborhood component analysis based on constructive neural networks	In this paper, we propose a novel non-linear supervised metric learning algorithm. The algorithm combines the neighborhood component analysis method with constructive neural networks which gradually increase the network size during the training process. The network aims to maximize a stochastic variant of the leave-one-out K-nearest neighbor (KNN) score on the training set. In this way, the proposed algorithm learns a nonlinear metric for KNN classification, overcoming the limitations of traditional metric learning algorithms which are only capable of learning linear transformations. Therefore, the proposed method is more flexible and powerful in transforming data than its linear counterpart. Moreover, it can also learn a low-dimensional non-linear mapping for visualization and fast classification. We validate our method on several benchmark datasets both for metric learning and dimensionality reduction, and the results demonstrate the competitiveness of the proposed approach.
{fenge}
17944361852	Supply chain coordination of loss-averse newsvendor with contract	This paper studies a supply chain model in which a single supplier sells a single product to a single retailer who faces the newsvendor problem. The retailer is loss averse. The results show that the optimal production quantity with decentralized decision making with a wholesale price contract is less than that with centralized decision making. The supply chain can achieve channel coordination with buy back and target rebate contracts. With buy back contracts, the supply chain system profits can be allocated arbitrarily between the supplier and retailer. A new kind of contract, the incremental buy back contract, gives similar results as with the buy back contract. The advantages and drawbacks of these three types of contracts are analyzed with numerical examples.
{fenge}
2942665793	Optimal inventory control policy in fuzzy sense	This paper developed the EOQ model with fuzzy lead time. The lead lime was fuzzified into tripodal fuzzy number and the fuzzy average cost was obtained. To find the optimal order quantity and reorder point, the average cost was defuzzifted using signed distance in fuzzy sense. By analysing the convexity of this defuzzified function, the characterization of the optimal solution was obtained, from which one could compute the optimal solution easily. Furthermore numerical examples were provided, which show that if the uncertainty of lead time is small, the optimal average cost increases with the uncertainty of it very slowly.
{fenge}
3142660147	Risk allocation in a coordinated supply chain system	A quantitative risk measurement method was developed to analyze the influence of the coordination mechanism on risk allocation in the supply chain. The method was used to study risk allocation when the supply chain achieves channel coordination with several commonly used contracts. When a buy back contract is used, the risk of the retailer is equal to that of the manufacture. When a two part tariff contract is used, the risk of one unit is zero and the risk of the supply chain system is taken by the other side. When a target rebate contract is used, the risk of the retailer is larger than that of the supply chain. The characteristics of these contracts were then combined into a new kind of contract where the supply chain achieves channel coordination and the system profit and risk of arbitrarily are allocated between the retailer and the manufacturer.
{fenge}
33745311332	Genetic algorithm based on NDP with application to job shop scheduling	Genetic algorithms (GA) are widely used to solve job shop scheduling problems, but the optimal parameters of genetic algorithms are difficult to determine. A GA based on neuro-dynamic programming (NDP) was formulated using the Markov decision process (MDP) model based on the relationship between the optimal MDP model and the optimal parameters for the GA. Then the neuro-dynamic programming method was used to approximate the optimal parameters which were used to guide the selection of the GA parameters. Computational results show that the method can automatically select the optimal parameters to give good stable solutions for solving job shop problems.
{fenge}
33745875684	Subgradient-based feedback neural networks for non-differentiable convex optimization problems	This paper developed the dynamic feedback neural network model to solve the convex nonlinear programming problem proposed by Leung et al. and introduced subgradient-based dynamic feedback neural networks to solve non-differentiable convex optimization problems. For unconstrained non-differentiable convex optimization problem, on the assumption that the objective function is convex coercive, we proved that with arbitrarily given initial value, the trajectory of the feedback neural network constructed by a projection subgradient converges to an asymptotically stable equilibrium point which is also an optimal solution of the primal unconstrained problem. For constrained non-differentiable convex optimization problem, on the assumption that the objective function is convex coercive and the constraint functions are convex also, the energy functions sequence and corresponding dynamic feedback subneural network models based on a projection subgradient are successively constructed respectively, the convergence theorem is then obtained and the stopping condition is given. Furthermore, the effective algorithms are designed and some simulation experiments are illustrated. © Science in China Press 2006.
{fenge}
33745926171	Differential inclusions-based neural networks for nonsmooth convex optimization on a closed convex subset	Differential inclusions-based dynamic feedback neural network models are introduced to solve in real time nonsmooth convex optimization problems restricted on a closed convex subset of R<sup>n</sup>. First,a differential inclusion-based dynamic feedback neural network model for solving unconstrained optimization problem is established, and its stability and convergence are investigated, then based on the preceding results and the method of successive approximation, differential inclusions-based dynamic feedback neural network models for solving in real time nonsmooth optimization problem on a closed convex subset are successively constructed, and its dynamical behavior and optimization capabilities are analyzed rigorously. © Springer-Verlag Berlin Heidelberg 2006.
{fenge}
33745926792	A neural network model for non-smooth optimization over a compact convex subset	A neural network model is introduced which is aimed to solve non-smooth optimization problem on a nonempty compact convex subset of R<sup>n</sup>. By using the subgradient, this neural network model is shown to obey a gradient system of differential inclusion. It is proved that the compact convex subset is a positive invariant and is a attractive to the neural network system, and that all the network trajectories starting from the inside of the compact convex subset converge to the set of equilibrium points of the neural network. The above every equilibrium point of the neural network is an optimal solution of the primal problem. A numerical simulation example is also given to illustrate the qualitative properties of the proposed neural network model. © Springer-Verlag Berlin Heidelberg 2006.
{fenge}
33845290293	An improved version of the NEH algorithm and its application to large-scale flow-shop scheduling problems	This paper deals with the Flow-shop Scheduling Problem (FSP). The NEH algorithm is regarded as one of the best constructive methods for solving the FSP. However, the running time of the NEH algorithm when used to solve large-scale FSPs is fairly long. The block properties of the FSP are investigated to reduce the running time. Using these block properties it is found that if a partial schedule is evaluated, the lower bounds of other partial makespans can be obtained in a time of 0(1). A pruning procedure based on the block properties of the FSP is introduced into the NEH algorithm to reduce the computational complexity. Experimental results show that the improved NEH algorithm has a greatly reduced running time compared with the classical NEH algorithm. It takes less than 0.2 seconds on average to get a solution for a large-scale FSP (up to 500 jobs and 20 machines).
{fenge}
33846368133	Optimal purchasing strategy based risk utility in two periods inventory systems under stochastic circumstance	Lose averse utility function is adopted to describe retailers' attitude for treating with the risk, the problem concerning with optimal purchasing strategies of retailers in a two-periods inventory systems with wholesale price contract is investigated under the circumstance of stochastic market information and stochastic demand. It is shown that the optimal inventory strategy in the second period is base-stock policy. Then we investigate the dynamic properties of optimal purchasing quantities in the second period, which are determined in term of quantities in the first period. The analytical expression of optimal purchasing quantities with its' tighter lower bound in the first period is then given. The relationship between optimal purchasing quantities and coefficients of risk averse in every period is analyzed. Finally, conclusions of this paper are validated by some simulation experiments.
{fenge}
33947246685	A new beam search algorithm for the large-scale permutation FSP	Beam Search algorithm, as an adaptation of branch and bound method, is regarded as one of the effective approaches in solving combinational optimization problems. In this paper, a new beam search algorithm for the large-scale permutation flow shop problem is proposed. A new branching scheme is addressed and compared with the traditional branching scheme. With the new branching scheme, the number of partial schedules in search tree can be greatly reduced. To balance the computational effort and solution quality, partial schedules are evaluated with a new approximate function based on forecast. Numerical experiments show that good solutions of large-scale FSPs could be found in a short time with the proposed algorithm. © 2006 IEEE.
{fenge}
34047245109	SA algorithm based on block properties of large-scale FSPs	Simulated annealing (SA) algorithm is one of the commonly used approaches in solving flow shop scheduling problems (FSPs). For the large-scale FSPs, the accepting probability of the candidate neighbor decreases greatly as the size of neighborhood and the number of bad neighbors increase, which leads to low performance of SA. A kind of simulated annealing algorithm based on the Block properties of FSP is proposed to solve the problem. In the proposed algorithm, the whole neighborhood is first divided into several small sub-neighborhoods. The best neighbor in the whole sub-neighborhood is selected as the candidate neighbor so as to increase the accepting probability. Moreover, the Block properties of FSP is introduced, with which the size of neighborhood is greatly reduced, and search is then focused on the promising area of the neighborhood, which enhance the performance more. Numerical experiments show that the near-optimal solutions of large-scale FSPs can be found in a short time with the proposed algorithm.
{fenge}
37649013950	Acceleration-based Dopplerlet transform-Part I: Theory	Steady-motion-based Dopplerlet transform has been recently proposed and applied to the estimation of range and speed of moving sound source. In this paper, we develop a new Dopplerlet by introducing acceleration into its definition. Compared with the steady-motion-based Dopplerlet, the acceleration-based Dopplerlet can simultaneously exploit the information of range, speed and acceleration of a moving sound source and can better capture the true time-varying nature of the Doppler-like signals. Part I concerns the fundamentals of the proposed transform, while Part II is devoted to the implementations and applications. © 2007 Elsevier B.V. All rights reserved.
{fenge}
34247379556	Fast TS algorithm based on Block properties of FSP	To the problem that it takes a long time for current available algorithms to solve large-scale flow shop scheduling problems (FSPs), a fast taboo search algorithm based on Block properties of FSP is proposed to reduce the neighborhood size. With the Block properties, most bad solutions in the neighborhood are excluded without losing the optimal solution. The point of search is focused on the most promising area to reduce the size of neighborhood and running time. Numerical experiments show that good solutions of large-scale FSPs are found in a short time with the proposed algorithm.
{fenge}
40649105766	A definition of partial derivative of random functions and its application to RBFNN sensitivity analysis	Considering the inputs of a feed-forward neural network as random variables, this paper proposes a definition of partial derivative of a function with respect to a random variable in the probability measure space. The mathematical expectation of the mean square or absolute value of the partial derivative is regarded as a type of measure of the network's sensitivity, which extends Zurada's sensitivity definition of networks in Zurada et al, [Perturbation method for deleting redundant inputs of perceptron networks, Neurocomputing 14 (1997) 177-193] from the certain environment to the stochastic environment. Furthermore, for the purpose of network's redundant feature deletion or feature selection, the new sensitivity measure is applied to the sensitivity analysis of Radial Basis Function Neural Networks (RBFNNs). The feasibility and the effectiveness of the sensitivity approach to redundant feature deletion are illustrated. © 2007 Elsevier B.V. All rights reserved.
{fenge}
84867402924	Some heuristics for no-wait flowshops with total tardiness criterion	No-wait flowshop scheduling problem is widely investigated because of its practical application and specific properties. However, the total tardiness criterion has not been much considered. In this paper, we propose six heuristic approaches for no-wait flowshops with total tardiness criterion, among which the modified NEH algorithm (MNEH) is verified to be the best. Also, a speed-up technique is introduced to MNEH to reduce the computational time in certain cases. By numeral experiments and analysis, we evaluate the performances of various heuristics. Finally we find out that MNEH is a satisfactory algorithm dealing with this problem. © 2012 Elsevier Ltd. All rights reserved.
{fenge}
84877284549	Dynamic programming and heuristic for stochastic uncapacitated lot-sizing problems with incremental quantity discount	The stochastic uncapacitated lot-sizing problems with incremental quantity discount have been studied in this paper. First, a multistage stochastic mixed integer model is established by the scenario analysis approach and an equivalent reformulation is obtained through proper relaxation under the decreasing unit order price assumption. The proposed reformulation allows us to extend the production-path property to this framework, and furthermore we provide a more accurate characterization of the optimal solution. Then, a backward dynamic programming algorithm is developed to obtain the optimal solution and considering its exponential computation complexity in term of time stages, we design a new rolling horizon heuristic based on the proposed property. Comparisons with the commercial solver CPLEX and other heuristics indicate better performance of our proposed algorithms in both quality of solution and run time. © 2012 Yuli Zhang et al.
{fenge}
84907942271	Second-order consensus for multi-agent systems with limited communication range	This paper studies the second-order consensus problem for multi-agent systems with a limited communication range where two agents can communicate with each other only when they are within a certain distance. Second-order consensus means that the agents asymptotically gather to a point and move in the same velocity. Different form most existing works where the change of network topology is independent of the system evolution, we construct a Cuker-Smale type model to formulate the relation between the network topology and the system state. The main result of this paper provides a sufficient condition on the initial velocities, positions and the communication range which can guarantee the multi-agent system to asymptotically achieve the second-order consensus. We prove it using the Lyapunov functional approach. Finally, simulation examples are given to verify the theorem.
{fenge}
84908565952	Minimizing makespan for a no-wait flowshop using tabu mechanism improved iterated greedy algorithm	This paper proposes a tabu mechanism improved iterated greedy (TMIIG) algorithm to solve the no-wait flow-shop scheduling problem with makespan criterion. The motivation of seeking for further improvement in the iterated greedy (IG) algorithm framework is based on the observation that the construction phase of the original IG algorithm may lead to repeated search when applying the insertion neighborhood search. To overcome the drawback, we modified the IG algorithm by a tabu-based reconstruction strategy to enhance its exploitation ability. A powerful neighborhood search method which involves insert, swap, and double-insert moves is then applied to obtain better soluions from the reconstructed solution in the previous step. Numerical computations verified the advantages of utilizing the new reconstruction scheme. In addition, comparisons with other high-performing algorithms demonstrated the effectiveness and robustness of the proposed algorithm.
{fenge}
84908606644	Affinity Propagation clustering with incomplete data	Incomplete data are often encountered in data sets for clustering problems, and inappropriate treatment of incomplete data will significantly degrade the clustering performances. The Affinity Propagation (AP) algorithm is an effective algorithm for clustering analysis, but it is not directly applicable to the case of incomplete data. In view of the prevalence of missing data and the uncertainty of missing attributes, we put forward improved AP clustering for solving incomplete data problems. Three strategies(WDS, PDS and IPDS) are given, which involve modified versions of the AP algorithm. Clustering performances at different missing rates are discussed, and all approaches are tested on several UCI data sets with randomly missing data.
{fenge}
41949120771	Key theorem and the bounds on the rate of uniform convergence of statistical learning theory on quasi-probability spaces	Some properties of quasi-probability are further discussed. The definitions and properties of quasi-random variable and its distribution function, expected value and variance are then presented. Markov inequality, Chebyshev's inequality and the Khinchine's law of large numbers on quasi-probability spaces are also proved. Then the key theorem of learning theory on quasi-probability spaces is proved, and the bounds on the rate of uniform convergence of learning process on quasi-probability spaces are constructed. The investigations will help lay essential theoretical foundations for the systematic and comprehensive development of the quasi-statistical learning theory.
{fenge}
42549162455	Dyeing machine scheduling problem in dyeing and finishing workshop	Based on actual requirements of the dyeing and finishing workshop in the cloth-making factory, the scheduling model for dyeing machine was constructed. Being different from traditional scheduling models, the proposed model considered not only the merge of small jobs but also the decomposition of large jobs. Aims of the proposed model were to minimize the total tardiness and maximize the average utilization of dyeing machines simultaneously. An existing heuristic algorithm was improved and a new heuristic algorithm was proposed to solve the dyeing scheduling problem. All the proposed algorithms were applied in real-life data from the dyeing and finishing workshop in a typical cloth-making factory in Beijing. Results showed that the proposed algorithm could not only minimize the total tardiness but also enhance the utilization of dyeing machines.
{fenge}
4444376242	Study on EOQ model in the fuzzy environment	To find the optimal reorder point and order quantity which minimize the total average cost, an EOQ model with fuzzy lead time was proposed. By analyzing the convexity of the objective function, the optimal solution was obtained for each α -cut of lead time with Kuhn-Tucher Conditions. So the membership function of the optimal reorder point and order quantity in the fuzzy sense can be got. In order that the results can be operated practically, the fuzzy reorder point and order quantity are defuzzified into real number. Furthermore examples were provided, in which the lead time is charactered as a trapezoidal fuzzy number and the optimal reorder point and order quantity are resolved.
{fenge}
43949126196	A simulated annealing based beam search algorithm for the flow-shop scheduling problem	Beam search algorithm, as an adaptation of branch and bound method, is regarded as one of the effective approaches in solving combinational optimization problems. In this paper, a new beam search algorithm for the large-scale permutation flow shop scheduling problem (FSP) is proposed. A new branching scheme is addressed and compared with the traditional branching scheme. With the new branching scheme, the number of partial schedules in the search tree can be greatly reduced. Based on a simple simulated annealing algorithm, partial schedules are globally evaluated. Numerical experiments show that good solutions of large-scale FSPs could be found with the proposed algorithm in a short time. © 2008 World Scientific Publishing Company.
{fenge}
55849130389	Makespan distribution of permutation flowshop schedules	The makespan distribution of permutation flowshop schedules has been a topic of debate for almost fifty years. Many researchers have confirmed or doubted the famous claim that the makespan distribution of permutation flowshop schedules is asymptotically normal if the number of jobs is sufficiently large. This paper theoretically and empirically investigates the makespan distribution of permutation flowshop schedules and shows that the normality claim is not valid for the job-dominated and machine-dominated flowshops. Errors in the proof of normality of the makespan distribution of permutation flowshop schedules are pointed out. It is shown that the makespan distribution of a permutation flowshop scheduling problem depends on the number of jobs as well as the number of machines. © 2007 Springer Science+Business Media, LLC.
{fenge}
57649166522	A simulated annealing algorithm for single machine scheduling problems with family setups	Motivated by the real-life scheduling problem in a steel-wire factory in China, this paper studies the problem of minimizing the maximum lateness on a single machine with family setups. In view of the NP-hard nature of the problem, neighborhood properties of the problem are investigated. It is found that the traditional move-based neighborhood is inefficient to search. Then a new neighborhood, which is based on batch destruction and construction, is developed. A simulated annealing algorithm with the new neighborhood is proposed. Experiments are carried out on the randomly generated problems and the real-life instances from a factory in China. Computational results show that the proposed algorithm can obtain better near optimal solutions than the existing algorithm. © 2008 Elsevier Ltd. All rights reserved.
{fenge}
57749117282	Exact inventory cost model with random demands and lead time	By using the traditional modeling method to construct the inventory cost model with random demands and lead time, the modeling result was imprecise even wrong. It was difficult to obtain an exact cost model under irregular random demand distribution. To deal with this problem, the infinitesimal dividing method was used to construct the exact (Q, r) inventory cost model with random demands and lead time. In the modeling process, both the discrete demands and the continuous demands were taken into consideration. Then, to deal with the classical case that the demands arrived as a stable Poisson process, the exact cost model was constructed and related properties were analyzed. Finally, it was simulated and analyzed by genetic algorithm.
{fenge}
70350719638	A new algorithm of support vector machine based on weighted feature	For the classification problems based on support vector machine, if the sample contains irrelative or even completely irrelative features to the problem, the difference related to the degree of features to the problem becomes such large that may greatly affect the classification effect by means of support vector machine. To solve this problem, a new classification algorithm using SVM based on weighted features is proposed in this paper. First, the deviation between two random variables is defined, and the weights of every feature are determined by using the principle of maximizing deviations between categories, then the value to same feature for all samples is weighted by the corresponding weights of samples, respectively. Finally the samples are used for SVM training and testing. The experimental results show that the proposed algorithm can improve the classification accuracy of the classifier and decrease the numbers of support vectors. © 2009 IEEE.
{fenge}
70350729091	Adjustable entropy funtion method for misclassification minimization problems	Misclassification minimization problem is a fundamental problem of support vector machines. It can be stated by a way of minimizing the sum of violations of misclassified points, generally, its objective function is non- differentiable. In order\ to solve this problem, commonly, ones either use the Sigmoid functions (or a concave functions) sequence to approximate the step function, while the problem is converted into a constrained linear programming model, or use differentiable functions sequence to approximate non-differential objective function by the successive iterative optimization algorithm. But one of serious deficiency of these known algorithms is that the phenomenon of ill-conditioned matrix and data overflow occurs in the numerical computing. To overcome the drawbacks mentioned above, a new differentiable functions sequence constructed by the adjustable entropy function method proposed in [14], is adopted to approximate the non-differentiable objective function of the primal problem, a new optimization algorithm is designed to solve this problem. Further, the stop criterion of above adjustable entropy function method is improved and another new optimization algorithm is given consequently. The experimental results validate the accuracy and efficiency of the proposed algorithms for solving the problem, the classification accuracy of two new algorithms is almost accordant, but the computational efficiency of the last one is faster than the first one. © 2009 IEEE.
{fenge}
70350733654	Application of lp norm regularization methods for modelling biological systems	In systems biology, molecular interactions are typically modelled using white-box differential equations based on mass action kinetics. Unfortunately, problems with dimensionality can arise when the number of molecular species in the system becomes very large, which make the transparent modelling and behavior simulation extremely difficult or computationally too expensive. As an alternative, data-driven identification of molecular interaction pathways using a black-box approach has recently been investigated. One of the main objectives in building black-box models, which in many cases are linear-in-the-parameters ones, is to produce a sparse model to effectively represent the system behavior. A popular approach is to select model terms one by one from a pool of candidates (basis functions), and an information criterion is then used to stop the selection process. The advantage is the computational efficiency, the disadvantage is that the derived model is not necessarily sparse. Alternative approach is to introduce into the normal loss function a penalty term on the parameters, leading to improved sparseness and generalization performance of the derived model. Moreover, there is a positive probability that the model structure can be accurately picked up among a wide range of possibilities. Generally speaking, there are three l
{fenge}
77951491176	Exact inventory cost modeling in complex inventory environment for iron & steel enterprises	To reduce huge amount of funds used for raw materials inventory, the exact inventory cost modeling with multi-items, multi-suppliers and random lead times was studied. The statistics analysis and calculation method for real-time cost was presented, and the exact mathematical model of inventory cost function with multi-items, multi-suppliers and random lead times was established. Constraints of overseas procurement, which were guaranteeing supply and arriving evenly were formally expressed. The reorder points of multi-items were also analyzed. Finally, the model was optimized and simulated by intelligent optimization algorithm. Model properties were analyzed and the optimization results were provided.
{fenge}
77951933474	Infinitesimal dividing modeling method for dual suppliers inventory model with random lead times	As one of the basic inventory cost models, the (Q, r) inventory cost model of dual suppliers with random procurement lead time is mostly formulated by using the concepts of "effective lead time" and "lead time demand", which may lead to an imprecise inventory cost. Through the real-time statistic of the inventory quantities, this paper considers the precise (Q, r) inventory cost model of dual supplier procurement by using an infinitesimal dividing method. The traditional modeling method of the inventory cost for dual supplier procurement includes complex procedures. To reduce the complexity effectively, the presented method investigates the statistics properties in real-time of the inventory quantities with the application of the infinitesimal dividing method. It is proved that the optimal holding and shortage costs of dual supplier procurement are less than those of single supplier procurement respectively. With the assumption that both suppliers have the same distribution of lead times, the convexity of the cost function per unit time is proved. So the optimal solution can be easily obtained by applying the classical convex optimization methods. The numerical examples are given to verify the main conclusions.
{fenge}
77951934312	Modeling and optimization of exact inventory cost with dynamic pricing policy	A demand rate expression closer to reality is presented considering the influence of both price and the time when the products apart from factory. With dynamic pricing policy, the profit function of an inventory cost model is established. Exact holding cost model is also investigated. Because of the complex form of the function, the properties of the profit function are analyzed by using genetic algorithm. The relationships of the optimal profit and the optimal price and reprising time are given. And the affects of changing holding cost and consumers desire to purchase are also investigated.
{fenge}
77953652730	Single machine scheduling with sequence-dependent family setups to minimize maximum lateness	Motivated by a real-life scheduling problem in a steel wire factory in China, this paper considers the single machine scheduling problem with sequence-dependent family setup times to minimize maximum lateness. In view of the NP-hard nature of the problem, structural (dominance and neighbourhood) properties of the problem are described and used in the tabu search algorithms to find optimal or near-optimal schedules. These proposed structural properties quickly exclude unpromising and/or non-improving neighbours from further search. Empirical results on the randomly generated and real-life problem instances from a factory in China show that the proposed heuristic algorithms utilizing the structural properties can obtain optimal or near optimal solutions with a reasonable computational effort. © 2010 Operational Research Society Ltd.
{fenge}
77953088678	Multi-echelon multi-item dynamic inventory management via decomposition and coordination algorithm	This paper considers a multi-echelon multi-item dynamic inventory problem with deterministic, time-varying demand. Since in some cases in practice it's inappropriate to use (R, Q) policy or (s, S) policy, a mixed 0-1 linear programming model is established. By relaxing the coupled transportation capacity constraints, individual sub-problems for each material are obtained and sub-gradient method is introduced to coordinate these sub-problems. In order to obtain feasible solution, a heuristic repair approach is proposed, then approximate optimal solutions of primary problem are obtained. Numerical experiments have been carried out to validate the effectiveness of this algorithm and show that this method could give tighter upper bound and lower bound than LP relaxation. ©2010 IEEE.
{fenge}
77957561750	Dominance property based tabu search for single machine scheduling problems with family setups	The problem of minimizing the maximum lateness on a single machine with family setups is considered. To solve the problem, dominance property is studied and then introduced into the tabu search (TS) algorithm. With the dominance property, most unpromising neighbors can be excluded from the neighborhood, which makes the search process always focus on the most promising areas of the solution space. The proposed algorithms are tested both on the randomly generated problems and on the real-life problems. Computational results show that the proposed TS algorithm outperforms the best existing algorithm and can solve the real-life problems in about 1.3 on average.
{fenge}
77957867896	An inventory model with stochastic lead-time and stochastic demand	In this paper, the periodic review stochastic inventory control problem is investigated where the logistics cost consists of holding costs, shortage costs and ordering costs. The goal is to coordinate a sequence of orders of a single commodity, aiming to supply stochastic demands over a discrete finite horizon with minimum expected costs. Under some assumptions, the convexity of the cost function is proved and the global optimal solution can be given by explicit form. Finally, the numerical examples are presented to illustrate the validity for solving this model using Simulated Annealing algorithm. © 2010 IEEE.
{fenge}
77957877491	Modeling and optimization of ocean-going unloading problem with stochastic arrival time	One of the important issues which steel enterprises focus on is to reduce the cost occurred in unloading process of ocean-going ship, based on the overseas procurement background of a famous steel enterprise, the unloading problem with random arrival times is investigated in this paper, the cost construction of unloading problem is analyzed and its mathematical models for deterministic and stochastic arrival time are established, respectively. Moreover, Lagrangian relaxation algorithm and genetic algorithm combined with sub-gradient is designed to solve this problem. Finally, some examples are simulated and illustrated to validate the effectiveness and accuracy of the proposed algorithm. © 2010 IEEE.
{fenge}
78049243986	Structural property and meta-heuristic for the flow shop scheduling problem	According to the No Free Lunch Theorem, all algorithms equal to the randomly blind search if no problem information is known. Therefore, it is very important to study the problem properties (especially structural properties) and introduce them into algorithms so as to improve the algorithm performance (both solution quality and computational effort). For the flow shop scheduling problem (FSP) with makespan criterion, structural properties are wildly used in the existing literature, but there is no systematic review on it. This chapter surveys the existing structural properties, which are divided into two types: neighborhood properties (such as the famous block property) and solution space properties (such as the big-valley phenomenon). This chapter also shows how to introduce the structural properties into meta-heuristic algorithms like tabu search (TS). By comparing the performance of structural property based TS with the simple version of TS, it is shown how much the meta-heuristic algorithm can benefit from the structural properties. © 2009 Springer-Verlag Berlin Heidelberg.
{fenge}
78649539338	Identification of chiller model in HVAC system using fuzzy inference rules with Zadeh's implication operator	In the heating, ventilating, and air-conditioning (HVAC) system, chiller is the central part and one of the primary energy consumers. For the purpose of saving energy, the identification of the chiller model is of great significance. In this paper, based on fuzzy inference rules with Zadeh's implication operator, the model of chiller in HVAC is identified. The mean square error (MSE) is employed to evaluate the approximating capability of the fuzzy inference system. The objective of the problem is to minimize MSE. Since the Zadeh's implication operator is adopted in the fuzzy inference, the output of the system becomes a continuous but non-smooth function. In addition, the objective function contains many parameters that need to be optimized, consequently, traditional optimization algorithms based on gradient descent method fail to work. Therefore, an improved genetic algorithm (GA) is applied to minimize the MSE. Actual operational data of a chiller in HVAC are gathered to train the fuzzy inference system. Numerical experiment results validate the accuracy and efficiency of proposed fuzzy model and the improved GA algorithm. © 2010 Springer-Verlag.
{fenge}
78649586231	Stochastic optimization of two-stage multi-item inventory system with hybrid genetic algorithm	This paper considers a two-stage, multi-item inventory system with stochastic demand. First we propose two types of exact stochastic optimization models to minimize the long-run average system cost under installation and echelon (r, nQ) policy. Second we provide an effective hybrid genetic algorithm (HGA) based on the property of the optimization problem. In the proposed HGA, a heuristic search technique, based on the tradeoff between inventory cost and setup cost, is introduced. The long-run average cost of each solution in the model is estimated by Monte Carlo method. At last, computation tests indicate that when variance of stochastic demand increases, echelon policy outperforms installation policy and the proposed heuristic search technique greatly enhances the search capacity of HGA. © 2010 Springer-Verlag.
{fenge}
79955064984	Detecting link spam using temporal information	How to effectively protect against spam on search ranking results is an important issue for contemporary web search engines. This paper addresses the problem of combating one major type of web spam: 'link spam.' Most of the previous work on anti link spam managed to make use of one snapshot of web data to detect spam, and thus it did not take advantage of the fact that link spam tends to result in drastic changes of links in a short time period. To overcome the shortcoming, this paper proposes using temporal information on links in detection of link spam, as well as other information. Specifically, it defines temporal features such as In-link Growth Rate (IGR) and In-link Death Rate (IDR) in a spam classification model (i.e., SVM). Experimental results on web domain graph data show that link spam can be successfully detected with the proposed method. © 2006 IEEE.
{fenge}
79956193213	Stochastic model for total cost optimization in street lamp maintenance and its probabilistic Lagrangian relaxation method	Optimization models and algorithms for the maintenance policy of components with general failure modes in a finite horizon still remain a challenge. This paper provides a multi-stage stochastic model to optimize the joint replacement policy for street lamp components of general failure modes. The major difficulty arises from the stochastic coupling constraints on different component replacement decisions. Instead of relaxing those constraints based on scenarios as in existing methods, we propose the probability Lagrangian relaxation method(PLR) by introducing multipliers associated with the probability distributions of decisions, where the number of multipliers is independent of the exponentially increasing scenarios. A solution method and its sufficient conditions are also provided for a phase-wise policy structure to decouple the correlation among stages due to the time-variant failure rates. In numerical testing with real data, the PLR obtains the lower bound of the optimal solution and a suboptimal solution. The results lead to a significant reduction in the current maintenance cost, and demonstrate the efficiency of the model and PLR in solving practical problems.
{fenge}
79957471330	Truncation error calculation based on Richardson extrapolation for variable-step collaborative simulation	Collaborative simulation is an effective approach to performing simulation analysis for complex systems by integrating models developed for different engineering disciplines. Collaborative simulation issues include the modeling of coupled multidisciplinary systems, and the simulation running time integration of these models that are solved parallelly. Estimation of the local truncation error of coupling models is the key to solve multidisciplinary collaborative simulation problem, which is actually used to restrict the simulation step. This paper presents a variable-step method based on Richardson extrapolation for calculating the local truncation error to solve collaborative simulation problem of multidisciplinary coupling models. Formulas for estimating the local truncation error are derived through theoretical analysis by using integration methods and interpolation technologies, respectively. The simulation experiments are illustrated to validate the accuracy and efficiency of proposed collaborative simulation algorithm in comparison with the usual combinative algorithm. © 2011 Science China Press and Springer-Verlag Berlin Heidelberg.
{fenge}
80855132450	Improved conjugate gradient implementation for least squares support vector machines	As a promising method for pattern recognition and function estimation, least squares support vector machines (LS-SVM) express the training in terms of solving a linear system instead of a quadratic programming problem as for conventional support vector machines (SVM). In this paper, by using the information provided by the equality constraint, we transform the minimization problem with a single equality constraint in LS-SVM into an unconstrained minimization problem, then propose reduced formulations for LS-SVM. By introducing this transformation, the times of using conjugate gradient (CG) method, which is a greatly time-consuming step in obtaining the numerical solution, are reduced to one instead of two as proposed by Suykens et al. (1999). The comparison on computational speed of our method with the CG method proposed by Suykens et al. and the first order and second order SMO methods on several benchmark data sets shows a reduction of training time by up to 44%. © 2011 Elsevier B.V. All rights reserved.
{fenge}
82055194240	LS-SVR method of ore grade estimation in Solwara 1 region with missing data	Seafloor hydrothermal sulphide is a new poly metallic ore resource as well as oceanic poly metallic nodules and rich-Co crust containing huge amounts of metals and rare metals. The appropriate and accurate estimation of ore grade plays an important role for the prediction of total mineral resources and further exploitation. Kriging and neural network methods have already been successfully used for grade estimation problem. However, the performance of these methods is not perfect for the limited borehole data. Therefore, this paper introduces a new nonlinear method to the issue of ore grade estimation based on the least squares support vector regression (LS-SVR). The borehole data obtained from Solwara 1 region are heterogeneous and discontinuities with huge missing values. Data preprocessing methods including weighted K-nearest neighbor (WKNN) imputation and Genetic algorithm (GA) for data segmentation were used before using LS-SVR algorithm. Finally the performance and efficacy of the LS-SVR were compared with BP, RBF neural network and geostatistical techniques such as inverse distance weight (IDW) and ordinary kriging (OK). The outcome indicates that the LS-SVR method outperforms other four methods.
{fenge}
84855930280	A two-stage hybrid particle swarm optimization algorithm for the stochastic job shop scheduling problem	Real-world manufacturing systems are influenced by various random factors, which must be taken into consideration in order to obtain an effective schedule. However, compared with the extensive research on the deterministic model, the stochastic job shop scheduling problem (SJSSP) has not been sufficiently studied. In this paper, we propose a two-stage particle swarm optimization (PSO) algorithm for SJSSP with the objective of minimizing the expected total weighted tardiness. In the first-stage PSO, a performance estimate is used for quick evaluation of the solutions, and a local search procedure is embedded for accelerating the convergence to promising regions in the solution space. The second-stage PSO continues the search process, but applies a more accurate solution evaluation policy, i.e. the Monte Carlo simulation. In order to reduce the computational burden, the optimal computing budget allocation (OCBA) method is used in this stage. Finally, the computational results on different-scale test problems validate the effectiveness of the proposed approach. © 2011 Elsevier B.V. All rights reserved.
{fenge}
84862828315	A three-phase algorithm for flowshop scheduling with blocking to minimize makespan	This paper proposes a three-phase algorithm (TPA) for the flowshop scheduling problem with blocking (BFSP) to minimize makespan. In the first phase, the blocking nature of BFSP is exploited to develop a priority rule that creates a sequence of jobs. Using this as the initial sequence and a variant of the NEH-insert procedure, the second phase generates an approximate solution to the problem. Then, utilizing a modified simulated annealing algorithm incorporated with a local search procedure, the schedule generated in the second phase is improved in the third phase. A pruning procedure that helps evaluate most solutions without calculating their complete makespan values is introduced in the local search to further reduce the computational time needed to solve the problem. Results of the computational experiments with Taillards benchmark problem instances show that the proposed TPA algorithm is relatively more effective and efficient in minimizing makespan for the BFSP than the state-of-the-art procedures. Utilizing these results, 53 out of 60 new tighter upper bounds have been found for large-sized Taillards benchmark problem instances. © 2012 Elsevier Ltd. All rights reserved.
{fenge}
84862942748	Two techniques to improve the NEH algorithm for flow-shop scheduling problems	Flow-shop scheduling problem (FSP) has been widely investigated in the area of manufacturing systems. Up to now, the NEH algorithm is the best heuristic approach to solve FSP. However, in large-scale problems, it takes quite long time for the NEH algorithm to find an approximate optimal solution. In this paper, two new techniques are proposed to improve the NEH algorithm. Firstly, to reduce the running time, block properties are developed and introduced to NEH algorithm. Secondly, to obtain solutions with smaller makespan, tie-break rules are applied. Simulation results show that these two techniques perform well in improving the NEH algorithm. © 2012 Springer-Verlag.
{fenge}
84865652319	A hybrid genetic algorithm for two-stage multi-item inventory system with stochastic demand	We study a two-stage, multi-item inventory system where stochastic demand occurs at stage 1, and nodes at stage 1 replenish their inventory from stage 2. Due to the complexity of stochastic inventory optimization in multi-echelon system, few analytical models and effective algorithms exist. In this paper, we establish exact stochastic optimization models by proposing a well-defined supply-demand process analysis and provide an efficient hybrid genetic algorithm (HGA) by introducing a heuristic search technique based on the tradeoff between the inventory cost and setup cost and improving the initial solution. Monte Carlo method is also introduced to simulate the actual demand and thus to approximate the long-run average cost. By numerical experiments, we compare the widely used installation policy and echelon policy and show that when variance of stochastic demand increase, echelon policy outperforms installation policy and, furthermore, the proposed heuristic search technique greatly enhances the search capacity of HGA. © 2011 Springer-Verlag London Limited.
{fenge}
84867613599	Single-period inventory model with discrete stochastic demand based on prospect theory	This paper studies a single-period inventory (newsvendor) prob- lem with discrete stochastic demand. In general, most of the previous works are based on the expected profit/cost criterion or expected utility criterion. We consider the effect of irrational factor under uncertainty and therefore in- corporate prospect theory into inventory model. Our objective is to maximize the overall value of the prospect, which can be calculated by using the value function and the weighting function. For any given initial inventory level, it can be shown that a state-dependent order-up-to policy is optimal. Further, the optimal policy has a simple structure, and the retailer can easily decide whether to place an order or not. Moreover, the impacts of parameters on the optimal policy are illustrated through numerical experiments.
{fenge}
84869488069	A hybrid artificial bee colony algorithm for the job shop scheduling problem	The job shop scheduling problem (JSSP) has attracted much attention in the field of both information sciences and operations research. In terms of the objective function, most existing research has been focused on the makespan criterion (i.e.; minimizing the overall completion time). However, for contemporary manufacturing firms, the due date related performance is usually more important because it is crucial for maintaining a high service reputation. Therefore, in this study we aim at minimizing the total weighted tardiness in JSSP. Considering the high complexity, a novel artificial bee colony (ABC) algorithm is proposed for solving the problem. A neighborhood property of the problem is discovered, and then a tree search algorithm is devised to enhance the exploitation capability of ABC. According to extensive computational tests, the proposed approach is efficient in solving the job shop scheduling problem with total weighted tardiness criterion. © 2012 Elsevier B.V. All rights reserved.
{fenge}
84869491882	Impact of loss aversion on the newsvendor game with product substitution	This paper studies a newsvendor game in which two substitutable products are sold by two different retailers (newsvendors) with loss-averse preferences. Each loss-averse retailer facing stochastic customer demand and deterministic substitution rate will make an order quantity decision to maximize his expected utility. Since product substitution causes two retailers to make decisions in a competitive environment, game theory is used to find the retailers' optimal order quantities. It is shown that under certain conditions, there exists a unique Nash equilibrium in the newsvendor game. Under a symmetry assumption, each retailer's equilibrium order quantity is decreasing in the loss aversion coefficient and increasing in the substitution rate. Further, if the effect of loss aversion on the order quantity is strong enough to dominate the effect of competition, the total inventory level of a decentralized supply chain will be lower than that of a centralized supply chain. Numerical experiments are conducted to illustrate our results. © 2012 Elsevier B.V. All rights reserved.
{fenge}
84869499003	Orthogonal least squares algorithm for training cascade neural networks	This paper proposes a novel constructive training algorithm for cascade neural networks. By reformulating the cascade neural network as a linear-in-the-parameters model, we use the orthogonal least squares (OLS) method to derive a novel objective function for training new hidden units. With this objective function, the sum of squared errors (SSE) of the network can be maximally reduced after each new hidden unit is added, thus leading to a network with less hidden units and better generalization performance. Furthermore, the proposed algorithm considers both the input weights training and output weights training in an integrated framework, which greatly simplifies the training of output weights. The effectiveness of the proposed algorithm is demonstrated by simulation results. © 2004-2012 IEEE.
{fenge}
84875242772	Inventory policies for a partially observed supply capacity model	This paper considers a multi-period inventory problem with partially observed supply capacity in the lost sales case. Partially observed supply means that exact available supply in a period is observed only when the order quantity is not less than the supply capacity. Then, these observations are used to update the supply capacity distribution from one period to the next. For this inventory problem with partially observed supply information and random demand, we establish the inventory model according to a known Markov decision process(MDP) space. The existence of an optimal policy for this inventory problem is proved. Finally, some numerical examples considering Poisson distributed demand are given to verify the ability to find an optimal order quantity.
{fenge}
84876155975	Impulsive control for existence, uniqueness, and global stability of periodic solutions of recurrent neural networks with discrete and continuously distributed delays	In this paper, a class of recurrent neural networks with discrete and continuously distributed delays is considered. Sufficient conditions for the existence, uniqueness, and global exponential stability of a periodic solution are obtained by using contraction mapping theorem and stability theory on impulsive functional differential equations. The proposed method, which differs from the existing results in the literature, shows that network models may admit a periodic solution which is globally exponentially stable via proper impulsive control strategies even if it is originally unstable or divergent. Two numerical examples and their computer simulations are offered to show the effectiveness of our new results. © 2012 IEEE.
{fenge}
84876925191	Robust support vector regression for uncertain input and output data	In this paper, a robust support vector regression (RSVR) method with uncertain input and output data is studied. First, the data uncertainties are investigated under a stochastic framework and two linear robust formulations are derived. Linear formulations robust to ellipsoidal uncertainties are also considered from a geometric perspective. Second, kernelized RSVR formulations are established for nonlinear regression problems. Both linear and nonlinear formulations are converted to second-order cone programming problems, which can be solved efficiently by the interior point method. Simulation demonstrates that the proposed method outperforms existing RSVRs in the presence of both input and output data uncertainties. © 2012 IEEE.
{fenge}
84877020867	Robust Bayesian Classification with Incomplete Data	In this paper, we address the Bayesian classification with incomplete data. The common approach in the literature is to simply ignore the samples with missing values or impute missing values before classification. However, these methods are not effective when a large portion of the data have missing values and the acquisition of samples is expensive. Motivated by these limitations, the expectation maximization algorithm for learning a multivariate Gaussian mixture model and a multiple kernel density estimator based on the propensity scores are proposed to avoid listwise deletion (LD) or mean imputation (MI) for solving classification tasks with incomplete data. We illustrate the effectiveness of our proposed algorithms on some artificial and benchmark UCI data sets by comparing with LD and MI methods. We also apply these algorithms to solve the practical classification tasks on the lithology identification of hydrothermal minerals and license plate character recognition. The experimental results demonstrate their good performance with high classification accuracies. © 2012 Springer Science+Business Media, LLC.
{fenge}
84878109159	A fast iterative single data approach to training unconstrained least squares support vector machines	Least squares support vector machines (LS-SVMs) express the training in terms of solving a system of linear equations or an equivalent quadratic program (QP) with one linear equality constraint, in contrast to a QP with lower and upper bounds and one linear equality constraint for conventional support vector machines (SVMs). But for large scale problems, the presence of the linear equality constraint impedes the applications of some well developed methods. In this paper, we first eliminate the linear equality constraint of the QP in training LS-SVM and make it an unconstrained one, then propose a fast iterative single data approach with stepsize acceleration to the unconstrained QP. As a result of combining the selection rule of variables with the coordinate descent approach, the proposed approach is superior to the successive over-relaxation (SOR) method. Meanwhile updating only one variable at each iteration makes the proposed approach simpler and more flexible than the sequential minimal optimization (SMO) method. Computational experiment results on several benchmark data sets show that the proposed approach is more efficient than the existing single data approach and the SMO methods. © 2013.
{fenge}
84878984076	A simulation-based differential evolution algorithm for stochastic parallel machine scheduling with operational considerations	We consider a parallel machine scheduling problem with the objective of minimizing two types of costs: the cost related to production operations and the cost related to due date performances. The former could be reduced by reasonable settings of the operational variables (e.g., the number of workers, the frequency of maintenance), while the latter could be reduced by appropriate scheduling of the production process. However, the optimization of both targets is significantly complicated by the influence of human factors that play a dominant role in real-world manufacturing systems. To cope with this issue, a simulation-based optimization framework is adopted in this paper for obtaining high-quality robust solutions to the integrated scheduling problem. Meanwhile, differential evolution, a metaheuristic algorithm based on swarm intelligence, is applied for a systematic search of the huge solution space. Finally, numerical computations are conducted to verify the effectiveness of the proposed approach. Sensitivity analysis and practical implications are also presented. © 2013 International Federation of Operational Research Societies.
{fenge}
84880070750	Asymptotically optimal parameter estimation with scheduled measurements	To reduce the communication cost of a sensor node, this paper is concerned with an estimation framework with scheduled measurements for a linear system. A scheduler is designed to control the transmission of measurements from sensor to estimator, which results in that only a subset of measurements is transmitted to the estimator. We propose an innovation based scheduler and derive an analytical expression for the Cramér-Rao lower bound (CRLB) for the given scheduling strategy. Under a communication constraint, an adaptive scheduler and a corresponding recursive estimator are jointly designed to asymptotically attain the CRLB. The structure of the estimator bears close resemblance to the standard least square estimator (LSE) with the full set of sensor measurements. Moreover, we prove that the estimation performance in terms of mean-square estimation error is comparable to the standard LSE even under a moderate communication cost. The theoretical results are verified by simulations. © 1991-2012 IEEE.
{fenge}
84881670265	A hybrid differential evolution algorithm for job shop scheduling problems with expected total tardiness criterion	In real-world manufacturing systems, the processing of jobs is frequently affected by various unpredictable events. However, compared with the extensive research for the deterministic model, study on the random factors in job shop scheduling has not received sufficient attention. In this paper, we propose a hybrid differential evolution (DE) algorithm for the job shop scheduling problem with random processing times under the objective of minimizing the expected total tardiness (a measure for service quality). First, we propose a performance estimate for roughly comparing the quality of candidate solutions. Then, a parameter perturbation algorithm is applied as a local search module for accelerating the convergence of DE. Finally, the K-armed bandit model is utilized for reducing the computational burden in the exact evaluation of solutions based on simulation. The computational results on different-scale test problems validate the effectiveness and efficiency of the proposed approach. © 2012 Elsevier B.V. All rights reserved.
{fenge}
84882305539	Stability of the Kalman filtering with two periodically switching sensors over lossy networks	This paper considers the stability of Kalman filtering of a discrete-time stochastic system using two periodically switching sensors over a network subject to random packet losses, which is modeled by an independent and identically distributed Bernoulli process. It is proved that this problem can be converted into the stability of Kalman filtering using two sensors at each time instant, where the measurements of each sensor are transmitted via an independent lossy channel. Some necessary and sufficient conditions for stability of the estimation error covariance matrices are respectively established, and the effect of the periodic switching on the stability is revealed. Their implications and relationships with related results in the literature are discussed. © 2013 IEEE.
{fenge}
84881061407	A second order cone programming approach for semi-supervised learning	Semi-supervised learning (SSL) involves the training of a decision rule from both labeled and unlabeled data. In this paper, we propose a novel SSL algorithm based on the multiple clusters per class assumption. The proposed algorithm consists of two stages. In the first stage, we aim to capture the local cluster structure of the training data by using the k-nearest-neighbor (kNN) algorithm to split the data into a number of disjoint subsets. In the second stage, a maximal margin classifier based on the second order cone programming (SOCP) is introduced to learn an inductive decision function from the obtained subsets globally. For linear classification problems, once the kNN algorithm has been performed, the proposed algorithm trains a classifier using only the first and second order moments of the subsets without considering individual data points. Since the number of subsets is usually much smaller than the number of training points, the proposed algorithm is efficient for handling big data sets with a large amount of unlabeled data. Despite its simplicity, the classification performance of the proposed algorithm is guaranteed by the maximal margin classifier. We demonstrate the efficiency and effectiveness of the proposed algorithm on both synthetic and real-world data sets. © 2013 Elsevier Ltd.
{fenge}
84883769228	2-approximation and hybrid genetic algorithm for long chain design problem in process flexibility	Long chain flexibility strategy is an effective way to match the supply with the uncertain demand in manufacturing system. However there are few studies on the long chain design problem with nonhomogeneous link costs. This paper first presents a mixed 0-1 LP model and proves that it belongs to NP-complete. Then an approximation algorithm is proposed which includes three steps: 1) solve a relaxed LP; 2) generate a minimum spanning tree; 3) find the optimal local match. Under the quadrangle inequality assumption, we show that it is a 2-approximation algorithm. At last, based on another equivalent reformulation, we embed the 2-approximation algorithm and a 2-opt exchange local search into a hybrid genetic algorithm. By comparison with CPLEX solver, numerical experiments validate the effectiveness of the proposed algorithms. © Springer-Verlag Berlin Heidelberg 2013.
{fenge}
84883771311	The loss-averse retailer's ordering policy under yield and demand uncertainty	This paper studies a single-period inventory problem with random yield and demand. In general, most of the previous works are based on the assumption of risk neutrality. We incorporate loss-averse preferences into this problem and the retailer's objective is to maximize the expected utility. We obtain the retailer's optimal ordering policy and then investigate the impact of loss aversion on it. Especially, if the shortage cost is small enough, the loss-averse retailer will always order less than the risk-neutral one. Moreover, the impacts of price and cost parameters on the loss-averse retailer's optimal order quantity are analyzed. Then numerical experiments are conducted to illustrate our results. © Springer-Verlag Berlin Heidelberg 2013.
{fenge}
84883814805	Hybrid NSGA-II Algorithm on multi-objective inventory management problem	Inventory management is a key issue in supply chain management. Under the circumstances that there are plenty of risks, it is more usable and appropriate if the risk problem is also taken into consideration when addressing the issue of inventory management. In this paper, we firstly introduces the classifications of inventory model, introduces two parameters, VaR and CVaR to measure risks. Also, we established a bi-objective model considering inventory cost and CVaR at the same time. Heuristic method to solve the problem is addressed then. We examined the application of Genetic Algorithm on multi-objective problems, i.e. the NSGA-II algorithm. We proposed an analytic method to simplify the solution of the problem. Besides, we examined the local search method based on the problem and proposed a Hybrid Genetic Algorithm. Simulation verifies the usability of our model and the efficiency of our algorithm. © Springer-Verlag Berlin Heidelberg 2013.
{fenge}
84885893515	Measurement and statistics of application business in complex internet	Owing to independent topologies and autonomic routing mechanism, the logical networks formed by Internet application business behavior cause the significant influence on the physical networks. In this paper, the backbone traffic of TUNET (Tsinghua University Networks) is measured, further more, the two most important application business: HTTP and P2P are analyzed at IP-packet level. It is shown that uplink HTTP and P2P packets behavior presents spatiotemporal power-law characteristics with exponents 1.25 and 1.53 respectively. Downlink HTTP packets behavior also presents power-law characteristics, but has more little exponents γ = 0.82 which differs from traditional complex networks research result. Moreover, downlink P2P packets distribution presents an approximate power-law which means that flow equilibrium profits little from distributed peer-to peer mechanism actually. © 2009 ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.
{fenge}
84886512889	Asymptotic distribution of makespan in permutation flowshops	In this paper, for permutation flowshops with two machines or more than two machines, as the number of jobs tends to infinity, the properties of asymptotic distribution of makespan are proposed. We introduce several conclusions in queuing theory to the scheduling problem, and convert the distribution of makespan to the distribution of waiting time in the queue. In two-machine conditions, the asymptotic distribution of makespan is proved to be the right half of a normal distribution. In m-machine conditions (m > 2), the asymptotic distribution of waiting time is proved under certain assumptions, and the bounds of probability distribution functions of waiting times are given. © 2013 Springer-Verlag.
{fenge}
0141653924	A DENEB-QUEST based production line simulation system	QUEST is a complete 3D digital factory environment for process flow simulation and analysis, accuracy, and profitability. QUEST provides a complete solution, providing the tools necessary for both efficient process flow analysis and effective presentation of results to customers, managers, and other engineering disciplines. QUEST allows us to quickly build a simulation model to the level of detail required, adding more detail as necessary to improve accuracy throughout the design process. Firstly, this article analyses the principle, framework and the technical implementation of modeling a QUEST based manufacturing system. Gives out three methods to expand the function of QUEST. The BCL method, the SCL method, and the C DLL are introduced here. Then, it introduces the concepts, methods and the architecture of the production line simulation system based on QUEST. Gives out a three-layer architecture of the simulation system, the executive layer, the management-control layer, and the administrator layer. Then, gives out the work flow of it. Finally, gives out a real DENEB-QUEST based production line simulation system. Some pivotal source codes of the system are also given.
{fenge}
84888340360	A dispatching rule-based hybrid genetic algorithm focusing on non-delay schedules for the job shop scheduling problem	Job shop scheduling is an important decision process in contemporary manufacturing systems. In this paper, we aim at the job shop scheduling problem in which the total weighted tardiness must be minimized. This objective function is relevant for the make-to-order production mode with an emphasis on customer satisfaction. In order to save the computational time, we focus on the set of non-delay schedules and use a genetic algorithm to optimize the set of dispatching rules used for schedule construction. Another advantage of this strategy is that it can be readily applied in a dynamic scheduling environment which must be investigated with simulation. Considering that the rules selected for scheduling previous operations have a direct impact on the optimal rules for scheduling subsequent operations, Bayesian networks are utilized to model the distribution of high-quality solutions in the population and to produce the new generation of individuals. In addition, some selected individuals are further improved by a special local search module based on systematic perturbations to the operation processing times. The superiority of the proposed approach is especially remarkable when the size of the scheduling problem is large. © 2013 Springer-Verlag London.
{fenge}
84890466117	Observability of linear systems for Kalman filtering with packet losses	This paper provides a short survey of the state-of-the-art results on the mean square stability of Kalman filtering with packet losses, and discusses several approaches to study the stability of the estimation error covariance matrix of the intermittent Kalman filter. In comparison with the Riccati approach by Sinopoli et al, the observability approach is more suitable to exactly characterize the effect of random packet losses on the stability of the estimation error covariance matrix. Moreover, it is shown that this approach can be used to design the coding or sampling strategies to reduce the effect of packet losses on the stability of the intermittent Kalman filter. © 2013 TCCT, CAA.
{fenge}
84892912068	Robust LS-SVM regression for ore grade estimation in a seafloor hydrothermal sulphide deposit	Due to the geological complexities of ore body formation and limited borehole sampling, this paper proposes a robust weighted least square support vector machine (LS-SVM) regressionmodel to solve the ore grade estimation for a seafloor hydrothermal sulphide deposit in Solwara 1, which consists of a large proportion of incomplete samples without ore types and grade values. The standard LS-SVM classification model is applied to identify the ore type for each incomplete sample. Then, a weighted K-nearest neighbor (WKNN) algorithm is proposed to interpolate the missing values. Prior to modeling, the particle swarm optimization (PSO) algorithm is used to obtain an appropriate splitting for the training and test data sets so as to eliminate the large discrepancies caused by randomdivision. Coupled simulated annealing (CSA) and grid search using 10-fold cross validation techniques are adopted to determine the optimal tuning parameters in the LS-SVM models. The effectiveness of the proposed model by comparing with other well-known techniques such as inverse distance weight (IDW), ordinary kriging (OK), and back propagation (BP) neural network is demonstrated. The experimental results showthat the robust weighted LS-SVMoutperforms the othermethods, and has strong predictive and generalization ability. © The Chinese Society of Oceanography and Springer-Verlag Berlin Heidelberg 2013.
{fenge}
84900343691	The loss-averse newsvendor problem with random yield	This paper studies a single-period inventory problem with random yield and demand, where the loss-averse preferences are adopted to describe the retailer's (newsvendor's) decision-making behavior. When the loss-averse retailer orders, the fraction of good units in a batch is stochastic. He will choose an order quantity to maximize his expected utility. Both shortage cost and no shortage cost are considered, respectively. The retailer's optimal ordering policies are obtained, then the impacts of loss aversion, price and cost on the optimal order quantity are analysed. For the model without shortage cost, the loss-averse retailer's optimal order quantity is always less than the risk-neutral retailer's, and decreasing in the loss aversion level. While for the model with shortage cost, the loss-averse retailer's optimal order quantity may be larger than the risk-neutral retailer's, and increasing in the loss aversion level. Moreover, it may be decreasing in selling price and increasing in purchasing cost, which will never occur in the case of zero shortage cost. The numerical experiments are conducted to demonstrate our theoretical results. © The Author(s) 2013.
{fenge}
84906536577	Likelihood ratio based communication for distributed detection	This paper is concerned with a detection framework under scheduled communication for a binary hypothesis testing problem. A scheduler is designed to smartly select useful sensor measurements for transmission and leave non-useful ones, which results in that only a subset of measurements is sent to the testing agency. To this purpose, a likelihood ratio based scheduler is implemented to decide the transmission of measurements from sensor to the tester. For comparison, a random scheduler which randomly selects measurements for transmission is also included. The Neyman-Pearson tests under the above two schedulers is provided. Given a moderate communication cost constraint, it is shown that the likelihood ratio based scheduler achieves a comparable asymptotic testing performance to the optimal test using the full set of measurements, and is strictly better than the random scheduler. The theoretical results are verified by simulations. © 2014 IEEE.
{fenge}
84907012517	Transductive minimax probability machine	The Minimax Probability Machine (MPM) is an elegant machine learning algorithm for inductive learning. It learns a classifier that minimizes an upper bound on its own generalization error. In this paper, we extend its celebrated inductive formulation to an equally elegant transductive learning algorithm. In the transductive setting, the label assignment of a test set is already optimized during training. This optimization problem is an intractable mixed-integer programming. Thus, we provide an efficient label-switching approach to solve it approximately. The resulting method scales naturally to large data sets and is very efficient to run. In comparison with nine competitive algorithms on eleven data sets, we show that the proposed Transductive MPM (TMPM) almost outperforms all the other algorithms in both accuracy and speed. © 2014 Springer-Verlag.
{fenge}
84911944987	Semi-supervised and unsupervised extreme learning machines	Extreme learning machines (ELMs) have proven to be efficient and effective learning mechanisms for pattern classification and regression. However, ELMs are primarily applied to supervised learning problems. Only a few existing research papers have used ELMs to explore unlabeled data. In this paper, we extend ELMs for both semi-supervised and unsupervised tasks based on the manifold regularization, thus greatly expanding the applicability of ELMs. The key advantages of the proposed algorithms are as follows: 1) both the semi-supervised ELM (SS-ELM) and the unsupervised ELM (US-ELM) exhibit learning capability and computational efficiency of ELMs; 2) both algorithms naturally handle multiclass classification or multi-cluster clustering; and 3) both algorithms are inductive and can handle unseen data at test time directly. Moreover, it is shown in this paper that all the supervised, semi-supervised, and unsupervised ELMs can actually be put into a unified framework. This provides new perspectives for understanding the mechanism of random feature mapping, which is the key concept in ELM theory. Empirical study on a wide range of data sets demonstrates that the proposed algorithms are competitive with the state-of-the-art semi-supervised or unsupervised learning algorithms in terms of accuracy and efficiency.
