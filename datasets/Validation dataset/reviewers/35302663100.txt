{fenge}
21444455875	Research on resource integration framework of logistics resource grid	In accordance with the characteristics of logistics application, the logistics resource grid was proposed for Grid Service Architecture. Furthermore, a resource integration framework of logistics resource grid was constructed based on Globus Toolkit and Open Grid Services Architecture-Data Access and Integration (OGSA-DAI). Through this grid service-oriented architecture, third party logistics companies formed virtual logistics enterprise alliance. The resource integration framework consisted of resource dispatch-enabled services (including resource match service, resource allocation service, and resource monitor service) and some distributed, autonomous resource domains. To manage the logistics information in different third party logistics companies, a resource domain provided grid services, including domain control agent service, resource management service, user management service, etc., or encapsulated the legacy systems as grid services. Based on resource domains, logistics information sharing and dispatching optimization were implemented with resource dispatch-enabled services in virtual logistics enterprise alliance.
{fenge}
24344465367	Statistical method of improving efficiency on sequential patterns	This paper analyzes some features of discovering frequent patterns on large set of transactions. On this basis, it gives an improved algorithm (called AprioriAdjust) with the development of two techniques: (1) applying the compressive processing of the transaction set for mining sequential patterns; (2) presenting a method based on the statistical mechanism to evaluate the sequence's support, in which the convergence of average value of the support in the whole procedure is considered, so as to effectively prune the candidate set of the frequent patterns. Furthermore, it discusses the results of the experiments. Compared to the AprioriTID algorithm, it shows that the AprioriAdjust algorithm is more efficient and scalable over the large sets of transactions.
{fenge}
33646826682	Concept chain based text clustering	Different from familiar clustering objects, text documents have sparse data spaces. A common way of representing a document is as a bag of its component words, but the semantic relations between words are ignored. In this paper, we propose a novel document representation approach to strengthen the discriminative feature of document objects. We replace terms of documents with concepts in WordNet and construct a model named Concept CHain Model(CCHM) for document representation. CCHM is applied in both partitioning and agglomerative clustering analysis. Hierarchical clustering processes in different levels of concept chains. The experimental evaluation on textual data sets demonstrates the validity and efficiency of CCHM. The results of experiments with concept show the superiority of our approach in hierarchical clustering. © Springer-Verlag Berlin Heidelberg 2005.
{fenge}
33745633099	Semantic correlation network based text clustering	Text documents have sparse data spaces, and nearest neighbors may belong to different classes when using current existing proximity measures to describe the correlation of documents. In this paper, we propose an asymmetric similarity measure to strengthen the discriminative feature of document objects. We construct a semantic correlation network by asymmetric similarity between documents and conjecture the power law feature of the connections distributions. Hub points which exist in semantic correlation network are classified by an agglomerative hierarchical clustering approach named SCN. Both objects similarity and neighbors similarity are considered in the definition of hub points proximity. Finally, we assign the rest text objects to their nearest hub points. The experimental evaluation on textual data sets demonstrates the validity and efficiency of SCN. The comparison with other clustering algorithms shows the superiority of our approach. © Springer-Verlag Berlin Heidelberg 2005.
{fenge}
33745671616	Improved ROCK for text clustering using asymmetric proximity	The ROCK algorithm can be applied to text clustering in large databases. The effectiveness of ROCK, however, is limited, because of the high dimensionality of textual data and traditional proximity measure of documents. In this paper, we propose an improved approach to strengthen the discriminative feature of text documents, which uses asymmetric proximity. Instead of the links count in ROCK, we propose a novel concept of link weight overlaps to measure the proximity between two clusters. The IROCK (Improved ROCK) algorithm performs clustering analysis based on the overlap information of asymmetric proximities between text objects. We carry on the clustering process in an agglomerative hierarchical way. To demonstrate the effectiveness of IROCK, we perform an experimental evaluation on real textual data. A comparison with ROCK and classical algorithms indicates the superiority of our approach. © Springer-Verlag Berlin Heidelberg 2006.
{fenge}
33749844813	Text clustering based on asymmetric similarity	Text clustering data sets have sparse data spaces, with existing text clustering methods using distance-based dissimilarity to measure the document similarity. The document discrimination ability can be strengthened by a asymmetric similarity approach for text clustering. The asymmetric similarity is measured by a clustering analysis of the strong components of the sparse matrix. The approach provides a conceptual structure after the hierarchical clustering. Tests on textual data sets show that the asymmetric similarity measure provides higher precision with less run time than the distance-based dissimilarity method. With small numbers of clusters, the accuracy is improved by about 20%.
{fenge}
33847232578	An improved genetic algorithm for cost-delay-Jitter QoS multicast routing	In this paper, an improved genetic algorithm is presented to solve the multicast routing problem, which is known as NP-complete problem. The contribution of this work includes: (1) the adaptive niche technique and new migration rules are designed to improve the performance of genetic algorithm. (2) In order to fulfill the adaptability of the basic operators of genetic algorithm, the artificial immune system is involved to dynamically control the crossover operator and the mutation operator. (3) A tree encoding based on the theory of generating the spanning tree is proposed to map the solution space of the multicast tree of QoS multicast routing problem, which basic definitions and axioms of the topology are described especially the character of spanning tree and the nature of the cut edge and cut set of a tree. Experiment result shows that this improved genetic algorithm has higher accuracy and performance than traditional methods. © 2005 IEEE.
{fenge}
36248986804	Species abundance and zoogeographic affinities of Chinese terrestrial earthworms	Terrestrial earthworm variously reported from China number amounts to 298 species with 84 of these, or 28%, non-natives for which 67% are Asiatic Megascolecidae and 22.6% are Lumbricidae of Holarctic origin. All the 298 species belong to 8 families and 27 genera. Among of them, 59 species are new species or new records after 1992. Using SPSS 12.0 to establish the distributional relationships among genera and species, we could draw a conclusion that the numbers and abundances of species in the South of China were more abundant and richer than that in the North of China. Megascolecidae was dominant in China, amounting to 243 species. The numbers of wide-range species and wide-range genera were 11 and 6, respectively, and about 3.7% of total species and 22.2% of total genera. Most species only are distributed in one or two Provinces, which indicates most genera and species have a bias to limitation of distribution. That Lumbricidae distributes in Oriental region still could not define its origin. It is not clear that the origin of earthworms among the seven Provinces, but the species abundance in Oriental region is much richer than that in Palaearctic region. Molecular (DNA and RNA) methods may solve the problems of identification and origin. © 2007 Elsevier Masson SAS. All rights reserved.
{fenge}
79951637168	A novel evaluation method for defect prediction in software systems	In this paper, we propose a novel evaluation method for defect prediction in object-oriented software systems. For each metric to evaluate, we start by applying it to the dependency graph extracted from the target software system, and obtain a list of classes ordered by their predicted degree of defect under that metric. By utilizing the actual defect data mined from the subversion database, we evaluate the quality of each metric through means of a weighted reciprocal ranking mechanism. Our method can tell not only the overall quality of each evaluated metric, but also the quality of the prediction result for each class, especially those costly ones. Evaluation results and analysis show the efficiency and rationality of our method. ©2010 IEEE.
{fenge}
84866631790	User-Sentiment topic model: Refining user's topics with sentiment information	In large social networks, users feel free to share their feelings about anything they are interested in and many research works have focused on modeling users' interests on social network for product recommendations or personal services. Unfortunately, there are fewer works about finding why users like or dislike something. More specifically, there are many researches about sentiment analysis of users' opinion toward products or topics, but fewer are focused on why they hold this feeling and which aspects or factors of the product (topic) lead to users' different opinions about it. In this paper, we present a hierarchical generative model, called user-sentiment topic model (USTM), which captures users' topics with sentiment information. Our aim is to use USTM to refine users' topics with different sentiment trends including positive, negative and neutral, which can be further used in social network analysis to find influential users on topic level with sentiment information. The experiment results on three datasets show that our proposed USTM can capture user's interests with their sentiment well, making it useful for social network analysis. Copyright © 2010 ACM.
{fenge}
84876759347	GMS: A new graph-based feature selection method for text categorization	Text categorization is an important task that assigns an electronic document to one or more categories based on its contents, and Feature selection is a significant preprocessing process to remove irrelevant data and increase learning accuracy so as to save store space and processing time. Feature selection is especially significant for text categorization since feature (word term) space is usually up to tens of thousands dimension. A lot of feature selection methods have been proposed. Among them, IG (Information Gain) and CHI-square are mostly used in the text domain. In this paper we propose a filtering feature selection method which leverages Markov chain model and techniques. Markov chain model is a widely used model in many areas, such as classification, web search, .etc. It is used in graph analysis to compute distribution probability for each node. Our novel graph-based method computes distribution probability of every feature of each category based on Markov Chain model, and then combines category score to obtain a single score for each feature. Using Multinomial Naive Bayes and SVM (SMO) as classifiers, our method outperforms CHI consistently, and outperforms IG when reduced dimension is reduced to about 30-100 terms.
{fenge}
84887452526	Discovering correlated entities from news archives	Most textual documents contain references to real-word entities such as people, locations and organizations. The understanding of their correlations is behind many applications including social relationship construction platform and major search engines, etc. This paper aims to discover entity correlations from news archives by means of the proposed hierarchical Entity Topic Model (hETM). hETM is a semantic-based analysis model which follows the gist of probabilistic topic models and in which a directed acyclic graph (DAG) is leveraged to capture arbitrary topic correlations. Entity extraction is taken as a preprocessing step of our model and we then employ different generative processes for ordinary words and entities. The discovering of entity correlations is achieved via the analysis of the dependencies between entities and their associated topics as well as topic correlations. We evaluate the approach upon BBC news dataset and results demonstrate the higher quality of discovered entity correlations compared with existing methods. © 2013 Springer-Verlag.
{fenge}
84896986679	Combining lexical and semantic features for short text classification	In this paper, we propose a novel approach to classify short texts by combining both their lexical and semantic features. We present an improved measurement method for lexical feature selection and furthermore obtain the semantic features with the background knowledge repository which covers target category domains. The combination of lexical and semantic features is achieved by mapping words to topics with different weights. In this way, the dimensionality of feature space is reduced to the number of topics. We here use Wikipedia as background knowledge and employ Support Vector Machine (SVM) as classifier. The experiment results show that our approach has better effectiveness compared with existing methods for classifying short texts. © 2013 The Authors.
{fenge}
58349094000	Cross-domain knowledge transfer using semi-supervised classification	Traditional text classification algorithms are based on a basic assumption: the training and test data should hold the same distribution. However, this identical distribution assumption is always violated in real applications. Due to the distribution of test data from target domain and the distribution of training data from auxiliary domain are different, we call this classification problem cross-domain classification. Although most of the training data are drawn from auxiliary domain, we still can obtain a few training data drawn from target domain. To solve the cross-domain classification problem in this situation, we propose a two-stage algorithm which is based on semi-supervised classification. We firstly utilizes labeled data in target domain to filter the support vectors of the auxiliary domain, then uses filtered data and labeled data from target domain to construct a classifier for the target domain. The experimental evaluation on real-world text classification problems demonstrates encouraging results and validates our approach. © 2008 Springer Berlin Heidelberg.
{fenge}
64549086893	Incorporating pageview weight into an association-rule-based web recommendation system	Web recommendation systems based on web usage mining try to mine users' behavior patterns from web access logs, and recommend pages to the online user by matching the user's browsing behavior with the mined historical behavior patterns. Recommendation approaches proposed in previous works, however, do not distinguish the importance of different pageviews, and all the visited pages are treated equally whatever their usefulness to the user. We propose to use pageview duration to judge its usefulness to a user, and try to give more consideration to more useful pageviews, in order to better capture the user's information need and recommend pages more useful to the user. In this paper we try to incorporate pageview weight into the Association Rule (AR) based model and develop a Weighted Association Rule (WAR) model. Comparative experiment of the two shows a significant improvement in the recommendation effectiveness with the proposed WAR model. © Springer-Verlag Berlin Heidelberg 2006.
{fenge}
70350708168	Stock temporal prediction based on time series motifs	Recent researches pay more attention to stock tendency prediction, which various machine learning approaches have been proposed. In this paper, we propose an algorithm to discover self-correlation of stock price in virtue of the notion of time series motifs, by viewing stock price sequences as time series. Generally, time series motif is a pattern appearing frequently in a time sequence, useful to forecast the stock temporal tendencies and prices as a reliable part in time series. In the proposed approach, we firstly search for one part of time series motifs using ordinal comparison and k-NN clustering algorithm, and then attempt to discover the correlation between motifs and subsequences connected behind them. Experimental results demonstrate the positive contribution of time series motifs, the acceptable prediction accuracy, and priority of our algorithm. © 2009 IEEE.
{fenge}
74049097506	Trajectory simplification method for location-based social networking services	The increasing availabilities of GPS-enabled devices have given rise to the location-based social networking services (LBSN), in which users can record their travel experiences with GPS trajectories and share these trajectories among each other on Web communities. Usually, GPS-enabled devices record far denser points than necessary in the scenarios of GPS-trajectory-sharing. Meanwhile, these redundant points will decrease the performance of LBSN systems and even cause the Web browser crashed. Existing line simplification algorithms only focus on maintaining the shape information of a GPS trajectory while ignoring the corresponding semantic meanings a trajectory implies. In the LBSN, people want to obtain reference knowledge from other users' travel routes and try to follow a specific travel route that interests them. Therefore, the places where a user stayed, took photos, or changed moving direction greatly, etc, would be more significant than other points in presenting semantic meanings of a trajectory. In this paper, we propose a trajectory simplification algorithm (TS), which considers both the shape skeleton and the semantic meanings of a GPS trajectory. The heading change degree of a GPS point and the distance between this point and its adjacent neighbors are used to weight the importance of the point. We evaluated our approach using a new metric called normalized perpendicular distance. As a result, our method outperforms the DP (Douglas-Peuker) algorithm, which is regarded as the best one for line simplification so far. © 2009 ACM.
{fenge}
77249153195	Ontology based opinion mining for movie reviews	Ontology itself is an explicitly defined reference model of application domains with the purpose of improving information consistency and knowledge sharing. It describes the semantics of a domain in both human-understandable and computer-processable way. Motivated by its success in the area of Information Extraction (IE), we propose an ontology-based approach for opinion mining. In general, opinion mining is quite context-sensitive, and, at a coarser granularity, quite domain dependent. This paper introduces a fine-grain approach for opinion mining, which uses the ontology structure as an essential part of the feature extraction process, by taking account the relations between concepts. The experiment result shows the benefits of exploiting ontology structure to opinion mining. © 2009 Springer-Verlag Berlin Heidelberg.
{fenge}
78049307994	Accumulative influence weight collaborative filtering recommendation approach	Memory-based collaborative filtering algorithms are widely used in practice. But most existing approaches suffer from a conflict between prediction quality and scalability. In this paper, we try to resolve this conflict by simulating the "word-of-mouth" recommendation in a new way. We introduce a new metric named influence weight to filter neighbors and weight their opinions. The influence weights, which quantify the credibility of each neighbor to the active user, form accumulatively in the process of the active user gradually provides new ratings. Therefore, when recommendations are requested, the recommender systems only need to select the neighbors according to these ready influence weights and synthesize their opinions. Consequently, the scalability will be significantly improved without loss of prediction quality. We design a novel algorithm to implement this method. Empirical results confirm that our algorithm achieves significant progress in both aspects of accuracy and scalability simultaneously. © 2009 Springer-Verlag Berlin Heidelberg.
{fenge}
78049313221	Evaluating importance of websites on news topics	In this paper, we study a novel problem which we refer to as News Website Evaluation (NWE). Given a collection of news articles, NWE is primarily concerned with evaluating the importance of their websites with respect to specific news topics. This general problem subsumes many interesting applications including news tracking and website ranking. To solve this problem, we first propose a Topic-oriented Website Evaluation Model (TWEM) which exploits various forms of information and combines them in a unified computation framework. Then, considering the special characteristics of news articles, we incorporate an article merging operation into TWEM and present the merge-TWEM model. The experimental results show that the proposed models perform significantly better than competitive baseline systems, and can serve as effective solutions to the News Website Evaluation problem. © 2010 Springer-Verlag Berlin Heidelberg.
{fenge}
78049405118	MindDigger: Feature identification and opinion association for Chinese movie reviews	In this paper, we present a prototype system called MindDigger, which can be used to analyze the opinions in Chinese movie reviews. Different from previous research that employed techniques on product reviews, we focus on Chinese movie reviews, in which opinions are expressed in subtle and varied ways. The system designed in this work aims to extract the opinion expressions and assign them to the corresponding features. The core tasks include feature and opinion extraction, and feature-opinion association. To deal with Chinese effectively, several novel approaches based on syntactic analysis are proposed in this paper. Running results show the performance is satisfactory. © 2010 Springer-Verlag Berlin Heidelberg.
{fenge}
78449262151	A novel approach of process mining with event graph	Modern enterprises are increasingly moving towards the workflow paradigm in modeling their business process. One prevailing approach counts on process mining that aims to discover workflow models from log files which contain rich process information. The process models discovered are then used to model and design information systems intended for workflow management. Although workflow logs contain rich information, they have not been made full use in many existing modeling formalisms like Petri nets. In this paper, we propose a novel approach for process mining using event graph to integrate various process related information. Analysis is conducted to show the advantages of event graph based models compared to Petri nets. A case study is also reported to illustrate the entire mining process. Finally, a preliminary evaluation is conducted to show the merits of our method in terms of precision, generalization and robustness. © 2010 Springer-Verlag.
{fenge}
78649858699	Automatically grouping questions in yahoo! answers	In this paper, we define and study a novel problem which is referred to as Community Question Grouping (CQG). Online QA services such as Yahoo! Answers contain large archives of community questions which are posted by users. Community Question Grouping is primarily concerned with grouping a collection of community questions into predefined categories. We first investigate the effectiveness of two basic methods, i.e., K-means and PLSA, in solving this problem. Then, both methods are extended in different ways to include user information. The experimental results with real datasets show that incorporation of user information improves the basic methods significantly. In addition, performance comparison reveals that PLSA with regularization is the most effective solution to the CQG problem. © 2010 IEEE.
{fenge}
78650377751	A core-based community detection algorithm for networks	Community detection is now playing a significant role in the discovery of underlying structures of social networks. This problem has been proved to be very hard and not been satisfactorily solved yet. Most of the algorithms proposed so far tend to maximize the number of intra-cluster edges, but ignore the importance of the core nodes within clusters. In contrast, this paper proposes a core-based algorithm that makes use of these core nodes. It first computes the core values of each vertex, and then gradually chooses the vertex with the maximum core value and performs a cluster expansion based on a structural similarity measurement. Evaluation using both real and synthetic datasets demonstrates that our method is not only efficient but also effective. Community Detection, Network Clustering, Network Underlying Structure, Core Node. © 2010 IEEE.
{fenge}
78650454712	Topic-based computing model for web page popularity and website influence	We propose a novel algorithm called Popularity&InfluenceCalculator (PIC) to get the most popular web pages and influent websites under certain keywords. We assume that the influence of a website is composed of its own significance and the effects of its pages, while the popularity of a web page is related with the websites and all the other pages. After that, we design a novel algorithm which iteratively computes importance of both websites and web pages. The empirical results show that the PIC algorithm can rank the pages in famous websites and pages with descriptive facts higher. We also find out that those pages contain more popular contents, which is accordant with our previous description of popularity. Our system can help users to find the most important news first, under certain keywords. © Springer-Verlag Berlin Heidelberg 2009.
{fenge}
78650506879	A Graph Distance based structural clustering approach for networks	In the era of information explosion, structured data emerge on a large scale. As a description of structured data, network has drawn attention of researchers in many subjects. Network clustering, as an essential part of this study area, focuses on detecting hidden sub-group using structural features of networks. Much previous research covers measuring network structure and discovering clusters. In this paper, a novel structural metric "Graph Distance" and an effective clustering algorithm GRACE are proposed. The graph distance integrates local density of clusters with global structural properties to reflect the actual network structure. The algorithm GRACE generalizes hierarchical and locality clustering methods and outperforms some existing methods. An empirical evaluation demonstrates the performance of our approach on both synthetic data and real world networks. © Springer-Verlag Berlin Heidelberg 2009.
{fenge}
78651318340	Identifying new categories in Community Question Answering archives: A topic modeling approach	Community Question Answering (CQA) services have evolved into a popular way of information seeking and providing. User-posted questions in CQA are generally organized into hierarchical categories. In this paper, we define and study a novel problem which is referred to as New Category Identification (NCI) in CQA question archives. New Category Identification is primarily concerned with detecting and characterizing new or emerging categories which are not included in the existing category hierarchy. We define this problem formally, and propose both unsupervised and semi-supervised topic modeling methods to solve it. Experiments with a ground-truth set built from Yahoo! Answers show that our methods identify and interpret new categories effectively. © 2010 ACM.
{fenge}
78751538302	A domain-related authority model for web pages based on source and related information	The Internet has become a great source for searching and acquiring information, while the authority of the resources is difficult to evaluate. In this paper we propose a domain-related authority model which aims to calculate the authority of web pages in a specific domain using the source and related information. These two factors, together with link structure, are what we mainly consider in our model. We also add the domain knowledge to adapt to the characteristics of the domain. Experiments on the finance domain show that our model is able to provide good authority scores and ranks for web pages and is helpful for people to better understand the pages.
{fenge}
78751539169	Improving question answering based on query expansion with wikipedia	As an emerging area in information retrieval, question answering aims at retrieving answers to user-posted questions from a given sentence collection or text corpus. In question answering, the queries are usually submitted in the form of short sentences which are unable to represent user intentions sufficiently. In this study, we present a novel framework which improves question answering through query expansion. We enrich representation of queries with Wikipedia concepts generated by the proposed QRWiki retrieval model. Then the enriched queries are exploited to benefit the process of question answering. The experiments with benchmark datasets show that the proposed framework performs significantly better than the baseline system, and is effective in boosting the performance of question answering. © 2010 IEEE.
{fenge}
79951749953	Augmenting Chinese online video recommendations by using virtual ratings predicted by review sentiment classification	In this paper we aim to resolve the recommendation problem by using the virtual ratings in online environments when user rating information is not available. As a matter of fact, in most of current websites especially the Chinese video-sharing ones, the traditional pure rating based collaborative filtering recommender methods are not fully qualified due to the sparsity of rating data. Motivated by our prior work on the investigation of user reviews that broadly appear in such sites, we hence propose a new recommender algorithm by fusing a self-supervised emoticon-integrated sentiment classification approach, by which the missing User-Item Rating Matrix can be substituted by the virtual ratings which are predicted by decomposing user reviews as given to the items. To test the algorithm's practical value, we have first identified the self-supervised sentiment classification's higher performance by comparing it with a supervised approach. Moreover, we conducted a statistic evaluation method to show the effectiveness of our recommender system on improving Chinese online video recommendations' accuracy. © 2010 IEEE.
{fenge}
79952812184	Mining Wikipedia and Yahoo! Answers for question expansion in Opinion QA	Opinion Question Answering (Opinion QA) is still a relatively new area in QA research. The achieved methods focus on combining sentiment analysis with the traditional Question Answering methods. Few attempts have been made to expand opinion questions with external background information. In this paper, we introduce the broad-mining and deep-mining strategies. Based on these two strategies, we propose four methods to exploit Wikipedia and Yahoo! Answers for enriching representation of questions in Opinion QA. The experimental results show that the proposed expansion methods perform effectively for improving existing Opinion QA models. © 2010 Springer-Verlag Berlin Heidelberg.
{fenge}
79960566450	An iterative voting method based on word density for text classification	In this paper we present an iterative voting (IV) method using the density based weighting for text classification. An in-class word density is used to weight for each word in a topic, so that the word in documents has an array of weights to vote for given topics, and the highest scored topic will be labeled. During the voting process, the iteration strategy is applied for improving the classification effectiveness. This method shows the competitive performance against SVM, NB, KNN, and it has better time efficiency. © 2011 ACM.
{fenge}
79960583085	A novel semantic-based text representation method for improving text clustering	In text clustering tasks, text representation is a pivotal phase. In recent researches, many methods attempt to use the semantic rela- tionships between words instead of traditional \bag-of-words" model, to improve the clustering results. In this paper, we propose a novel unsu- pervised word sense disambiguation (WSD) method, named Term Co-Occurrence Graph (TCOG), to generalize concepts to represent text ef- fectively and efficiently. A new strategy of assigning weights to concepts is given. Our experiment shows the superiority of representation method integrated TCOG in text clustering tasks. Copyright © 2007 IICAI.
{fenge}
84856002063	Workflow simulation for operational decision support using event graph through process mining	It is increasingly common to see computer-based simulation being used as a vehicle to model and analyze business processes in relation to process management and improvement. While there are a number of business process management (BPM) and business process simulation (BPS) methodologies, approaches and tools available, it is more desirable to have a systemic BPS approach for operational decision support, from constructing process models based on historical data to simulating processes for typical and common problems. In this paper, we have proposed a generic approach of BPS for operational decision support which includes business processes modeling and workflow simulation with the models generated. Processes are modeled with event graphs through process mining from workflow logs that have integrated comprehensive information about the control-flow, data and resource aspects of a business process. A case study of a credit card application is presented to illustrate the steps involved in constructing an event graph. The evaluation detail is also given in terms of precision, generalization and robustness. Based on the event graph model constructed, we simulate the process under different scenarios and analyze the simulation logs for three generic problems in the case study: 1) suitable resource allocation plan for different case arrival rates; 2) teamwork performance under different case arrival rates; and 3) evaluation and prediction for personal performances. Our experimental results show that the proposed approach is able to model business processes using event graphs and simulate the processes for common operational decision support which collectively play an important role in process management and improvement. © 2011 Elsevier B.V. All rights reserved.
{fenge}
84863130224	Zero-sum reward and punishment collaborative filtering recommendation algorithm	In this paper, we propose a novel memory-based collaborative filtering recommendation algorithm. Our algorithm use a new metric named influence weight, which is adjusted with zero-sum reward and punishment mechanism whenever the active user provides a new rating, to select neighbors and weight their opinions. Since the weight of personalized ratings, which contain more value for searching similar neighbors, is magnified appropriately in the formation of influence weight, our algorithm can find similar neighbors more effectively and filter the fake users introduced by shilling attacks automatically. When predicting for the active user, our algorithm select neighbors with the Top-N largest positive influence weights and predict their missing ratings. This rating smoothing method can alleviate data sparsity more efficiently. Then it computes the weighted average of all the selected neighbors' opinions and generates recommendations. Empirical results confirm that our algorithm achieves significant progress in all aspects of accuracy, scalability, robustness against data sparsity and shilling attacks simultaneously. © 2009 IEEE.
{fenge}
84864199796	Lexicon construction: A topic model approach	Sentiment Analysis has been an interesting task of web content mining these years due to rapid growth of user generating content. As the annotated data are expensive to get, the unsupervised approaches are preferred. Usually, a lexicon is required when apply the unsupervised approaches. In the paper, based on Latent Dirichlet Allocation (LDA), we propose a model to construct a lexicon for sentiment analysis task, which is domain independent. Through experiments, we compare our generated lexicon with some widely used lexicons and with trivial lexicon construction algorithm. The experiments show our approach is competitive and flexible. © 2012 IEEE.
{fenge}
84865246077	Using models to assess impact of defective software	We explain a new strategy to model a set of java classes and to abstract a model from them that can be use to study the impact that defects affecting specific classes can have on the whole system. We use the models of the software implementation as an abstraction of the software that can be used for experimentation We used simulation and verification in SPIN but the idea can be applied to implementations in other languages than java and the analysis of defects impact can be done with other verification tools as well. Copyright © 2011 SciTePress.
{fenge}
84866027839	A unified graph model for Chinese product review summarization using richer information	With e-commerce growing rapidly, online product reviews open amounts of studies of extracting useful information from numerous reviews. How to generate informative and concise summaries from reviews automatically has become a critical issue. In this paper, we present a novel unified graph model, composited information graph (CIG), to represent reviews with lexical, topic and together with sentiment information. Based on the model, we propose an automatic approach to address this issue. We use probabilistic methods to model the lexical, topic and sentiment information separately, associate with the discovered information in the CIG model, and generate summaries with a HITS-like algorithm called Mix-HITS considering both the Representativeness and Proportion Approximation. The experiments demonstrate that our method has improved performance over LexRank and ClusterHITS with Chinese and English datasets. Experimental results show that the proposed approach helps to build an effective way towards both the overall and contrastive summarization. © 2012 ACM.
{fenge}
84873616070	Generating virtual ratings from chinese reviews to augment online recommendations	Collaborative filtering (CF) recommenders based on User-Item rating matrix as explicitly obtained from end users have recently appeared promising in recommender systems. However, User-Item rating matrix is not always available or very sparse in some web applications, which has critical impact to the application of CF recommenders. In this article we aim to enhance the online recommender system by fusing virtual ratings as derived from user reviews. Specifically, taking into account of Chinese reviews' characteristics, we propose to fuse the self-supervised emotion-integrated sentiment classification results into CF recommenders, by which the User-Item Rating Matrix can be inferred by decomposing item reviews that users gave to the items. The main advantage of this approach is that it can extend CF recommenders to some web applications without user rating information. In the experiments, we have first identified the self-supervised sentiment classification's higher precision and recall by comparing it with traditional classification methods .Furthermore, the classification results, as behaving as virtual ratings, were incorporated into both user-based and item-based CF algorithms. We have also conducted an experiment to evaluate the proximity between the virtual and real ratings and clarified the effectiveness of the virtual ratings. The experimental results demonstrated the significant impact of virtual ratings on increasing system's recommendation accuracy in different data conditions (i.e., conditions with real ratings and without). © 2013 ACM.
{fenge}
84873279779	TRACK: A novel XML join algorithm for efficient processing twig queries	In order to find all occurrences of a tree/twig pattern in an XML database, a number of holistic twig join algorithms have been proposed. However, most of these algorithms focus on identifying a larger query class or using a novel label scheme to reduce I/O operations, and ignore the deficiency of the root-to-leaf strategy. In this paper, we propose a novel twig join algorithm called Track, which adopts the opposite leaf-to-root strategy to process queries. It brings us two benefits: (i)avoiding too much time checking the element index to make sure all branches are satisfied before a new element comes. (ii)using the tree structure to encode final tree matches so as to avoid the merging process. Further experiments on diverse data sets show that our algorithm is indeed superior to current algorithms in terms of query processing performance. © 2008, Australian Computer Society, Inc.
{fenge}
84878427416	Predicting best responder in community question answering using topic model method	Community question answering (CQA) services provide an open platform for people to share their knowledge and have attracted great attention for its rapidly increasing popularity. As the more knowledge people provided are shared in CQA, how to use the historical knowledge for solving new questions has become a crucial problem. In this paper, we investigate the problem as predicting best responders for new questions and tackle the problem from two perspectives, one is from the asker of the new question, and the other is from the question itself. We propose two supervised topic models, Asker-Responder Topic Model (ARTM) and Question-Responder Topic Model (QRTM) for both two perspectives by tracking people's answering history as background knowledge. Our experiments show that the two supervised topic models can effectively predict best responders for new questions in CQA without any additional works and have significant improvement over the baseline method. © 2012 IEEE.
{fenge}
84878440490	Research on mining common concern via infinite topic modelling	This paper focuses on mining common concern among different textual data sources and analyzing their own eigen topics via infinite topic modelling. By incorporating non-parametric Bayesian approaches, our work achieves a good performance and better accords with the reality by avoiding restrictive assumptions. We proposed extended processes of Dirichlet process(DP) - bidirectional stick-breaking process and multi-branches process - based on strick-breaking construction to model multiple sequences of probability measures in one process rather than simply combine several DPs. On the basis of this new perspective of DP, we discover the common topics and eigen topics via infinite topic modelling in a simple way without setting topic number. The experiments are carried out on three corpora of BBC news, about the UK, the US and China forum respectively. The results present the common concern of these three districts and their eigen interests in other aspects. © 2012 IEEE.
{fenge}
84879085033	A customized dependency tree kernel for effective sentiment classification	This paper introduces a kernel over dependency trees for sentiment classification. In order to classify a text as positive or negative, syntactic and word dependency information should be exploited besides words. Dependency parse trees, generated by automatic sentence parser, contain much syntactic information which would be helpful for sentiment classification. On the other hand, dependency trees contain word dependency information of sentences, and give a deeper understanding of natural language than BOW (bag-of-word) and n-gram schemas. In this paper, we present an approach which exploits such syntactic and word dependency information for sentiment classification. Our approach achieves good performance. We also compared the dependency tree kernel we proposed with some other tree kernels. © 2012 The authors and IOS Press. All rights reserved.
{fenge}
84881495143	Infinite topic modelling for trend tracking hierarchical dirichlet process approaches with wikipedia semantic based method	The current affairs people concern closely vary in different periods and the evolution of trends corresponds to the reports of medias. This paper considers tracking trends by incorporating non-parametric Bayesian approaches with temporal information and presents two topic modelling methods. One utilizes an infinite temporal topic model which obtains the topic distribution over time by placing a time prior when discovering topics dynamically. In order to better organize the event trend, we present another progressive superposed topic model which simulates the whole evolutionary processes of topics, including new topics' generation, stable topics' evolution and old topics' vanishment, via a series of superposed topics distribution generated by hierarchical Dirichlet process. Both of the two approaches aim at solving the real-world task while avoiding Markov assumption and breaking the number limitation of topics. Meanwhile, we employ Wikipedia based semantic background knowledge to improve the discovered topics and their readability. The experiments are carried out on the corpus of BBC news about American Forum. The results demonstrate better organized topics, evolutionary processes of topics over time and model effectiveness. Copyright © 2012 SciTePress - Science and Technology Publications.
{fenge}
84882849855	A random-walk based recommendation algorithm considering item categories	Recommender systems aim at recommending information items or social elements that are likely to be of interest to users. In this paper, we propose a recommendation algorithm which takes into account user's preference on item categories, and computes rank scores in different categories for each item, in order to make suggestions based on both user's previous interactions and item contents. By considering item categories and user preference, we are able to avoid the dominance of some popular items. Empirical experiments on MovieLens dataset demonstrate that the algorithm outperforms other state-of-the-art recommendation algorithms. © 2013 Elsevier B.V.
{fenge}
84889607520	Social recommendation incorporating topic mining and social trust analysis	We study the problem of social recommendation incorporating topic mining and social trust analysis. Different from other works related to social recommendation, we merge topic mining and social trust analysis techniques into recommender systems for finding topics from the tags of the items and estimating the topic-specific social trust. We propose a probabilistic matrix factorization (TTM-F) algorithm and try to enhance the recommendation accuracy by utilizing the estimated topic-specific social trust relations. Moreover, TTMF is also convenient to solve the item cold start problem by inferring the feature (topic) of new items from their tags. Experiments are conducted on three different data sets. The results validate the effectiveness of our method for improving recommendation performance and its applicability to solve the cold start problem. Copyright 2013 ACM.
{fenge}
84902013404	Object typicality for effective Web of Things recommendations	With the rapid growth of "Web of Things" (WoT), there is a pressing need to develop effective mechanisms for the intelligent discovery and selection of these things (items). Recommender systems are viable solutions to address the issue of WoT discovery and selection. However, classical recommender systems are weak in handling sparse recommendation spaces which characterize most WoT recommendations. Moreover, classical recommender systems may not be able to scale up to efficiently process a large number of things on the Web, and yet these systems may produce big-error recommendations that diminish users' trusts on utilizing WoT. The main contribution of our research is the design and development of a novel recommendation method which is underpinned by the principle of object typicality verified in the field of cognitive psychology to address the aforementioned issues related to WoT recommendations. Based on the MovieLens benchmark data set, our experimental results show that the proposed recommendation method is effective and produces the least big-errors. Since the proposed method exploits data generalization by operating at item group and user group level during recommendation time, it is more effective and efficient than other baseline methods given sparse training data. Based on the Netflix benchmark data set that simulates a large WoT recommendation space, the proposed method also significantly outperforms state-of-the-art recommendation methods in terms of Mean Absolute Error (MAE). The business implication of our research is that the proposed recommendation method can enhance the situation awareness of WoT applications which facilitate the reuse of enterprise resources and the interoperability among enterprises. © 2013 Elsevier B.V.
{fenge}
84904159560	Technology of non-burned brick using heavy metal polluted soil and solidification of heavy metal	Ten sets of experiments were designed to process non-burnt bricks by adding different proportion of cement as binder and 10% of carbide slag as activator into heavy metal polluted soil. The results showed that: compressive strength at 3d, 7d and 28d of non-burnt bricks compound by T2 were the highest with 10.552MPa, 19.291 MPa and 20.135 MPa respectively, achieving the high quality standard brick. Besides, leaching concentration of heavy metals were lower than that of GB3838-2002 environmental quality standard for surface water in V water requirements; heavy metals Pb, Zn, Cu, Cd mostly exist in the organic and residual fraction with 97.88%, 90.31%, 97.44% and 98.92% of the total fraction, respectively. © (2014) Trans Tech Publications, Switzerland.
{fenge}
84904991679	Thermal desorption experiment of Polycyclic Aromatic Hydrocarbons (PAHs) contaminated soil used as cement raw meal	Sample polluted soil surrounding Shougang as object, TG, thermal analysis of raw soil and cement raw meal experiments were made, the results show that: the polluted soil contains a variety of PAHs of organic pollutants, the total concentration of PAHs is about 156.39ppm. PAHs contaminated soil can be divided into three stages of weight loss at 850°C: water losing stages, organic matter decomposition stages and inorganic carbonate decomposition stages. With the increase in heating temperature, removal rate of total PAHs in raw soil is high. Using polluted soil as cement siliceous raw material, except naphthalene, acenaphthene, two hydrogen acenaphthene and anthracene, other organic compounds of PAHs have residues at 300°C and small amounts of phenanthrene have residue at 600°C means cement raw material has certain adsorption of PAHs pollutants. Therefore, when co processing PAHs polluted soil into the cement kiln, considering should be focused the content of pollutants in flue gas volatilization and C2 raw mill especially. © (2014) Trans Tech Publications, Switzerland.
{fenge}
84905251560	Wikipedia-based efficient sampling approach for topic model	In this paper, we propose a novel approach called Wikipedia-based Collapsed Gibbs sampling (Wikipedia-based CGS) to improve the efficiency of the collapsed Gibbs sampling(CGS), which has been widely used in latent Dirichlet Allocation (LDA) model. Conventional CGS method views each word in the documents as an equal status for the topic modeling. Moreover, sampling all the words in the documents always leads to high computational complexity. Considering this crucial drawback of LDA we propose the Wikipedia-based CGS approach that commits to extracting more meaningful topics and improving the efficiency of the sampling process in LDA by distinguishing different statuses of words in the documents for sampling topics with Wikipedia as the background knowledge. The experiments on real world datasets show that our Wikipedia-based approach for collapsed Gibbs sampling can significantly improve the efficiency and have a better perplexity compared to existing approaches.
{fenge}
84907259243	Context-aware reasoning middle ware applied in the mobile environment	With the development of the mobile technology, smart phone plays a increasingly important role in people's life which makes it attractive to integrate the context-aware computing with the phone. Middleware is the most common method to support context-aware applications which use the context information to adapt interfaces to respond to user. But the relative weak computing power of the phone and the complex uncertain environment become the A chilles' heel for middleware systems on the mobile devices. This paper presents a Context-Aware Reasoning Middleware (CARM) which provides a solution by adopting the Bayesian network for uncertain inference and designing a mechanism to give the middleware an access to powerful computation ability. We implement the middleware system and shown that the CARM lets applications on the phone to gain the ability of becoming more context-aware.
{fenge}
84921872840	Mining multiple discriminative patterns in software behavior analysis	Sequence Classification has been a challenge task in recent years since sequence doesn’t have explicit features and the high-order temporal characteristics make the number of patterns extremely massive. Pattern-based classification has demonstrated its power in recent studies by mining discriminative features efficiently. Both binary and numerical discriminative features have been utilized for effective sequence classification, but the effect of each type of features hasn’t been analyzed separately. Our method selects the frequent closed unique iterative patterns as our candidate features, mined out the discriminative binary and numerical patterns for sequence classification, and given an insight into the discriminative power improvement by feature combinations. The experimental results on synthetic and real-life datasets reveal the validity of our approach.
{fenge}
84923471496	Adaptive big data analytics for deceptive review detection in online social media	The explosive growth of user-contributed reviews in e-Commerce and online social network sites prompts for the design of novel big data analytics frameworks to cope with such a challenge. The main contributions of our research are twofold. First, we design a novel big data analytics framework that leverages distributed computing and streaming to efficiently process big social media data streams. Second, we apply the proposed framework that is underpinned by a novel parallel co-evolution genetic algorithm to adaptively detect deceptive reviews with respect to different social media contexts. Our experiments show that the proposed big data analytics framework can effectively and efficiently detect deceptive reviews from a big social media data stream, and it outperforms other non-distributed big data analytics solutions. To the best of our knowledge, this is the first successful design of an adaptive big data analytics framework for deceptive review detection under a big data environment.
