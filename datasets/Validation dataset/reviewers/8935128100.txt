{fenge}
27144474795	A formal general framework and service access model for service grid	Constituent resources in a grid system need to be used in a coordinated fashion to deliver nontrivial qualities of service. Various e-science and e-business use cases are investigated to guide how to create grid systems, and determine which functions grid systems should have. Web services emerge as a standard interoperable technology for grid systems. Although the motivations and goals for service grids are obvious, there is no clear definition for service grids to define and describe the general framework and service access model. In this paper, the general framework for service grids is defined in a formal approach, and the virtual organization based service access mechanism is modeled based on Abstract State Machines (ASM). In the service access model we proposed, the Quality of Service (QoS) issue is considered for the user request. This resulting serves as a theoretical base for our service grid system, HowU. © 2005 IEEE.
{fenge}
26444566741	Use case study of grid computing with CGSP	ChinaGrid Support Platform (CGSP) is a grid middleware developed for the deployment of ChinaGrid. CGSP aims to integrate all sorts of heterogeneous resources distributed over CERNET, and provide transparent, high performance, reliable, secure and convenient grid services for scientific researchers and engineers. In addition to supply the portal to ChinaGrid, CGSP offers a whole set of tools for developing and deploying various grid applications. Analyzing large and distributed image dataset is a crucial step in understanding and constructing bioinformatics, military and medical systems. Due to the large scale dataset, such analyzing work is challenging. In this paper, a use case scenario of image processing with CGSP is presented. Such use cases illustrate how to migrate the traditional image process applications to grid systems for different roles of image processing. The purpose of this paper is to introduce the CGSP and let the engineers and scientists from different research areas know how to build a grid testbed with CGSP and how to deploy applications on it smoothly. © Springer-Verlag Berlin Heidelberg 2005.
{fenge}
33644641273	Study of grid authorization based on the decentralized trust management mechanism	The existed grid security mechanism is able not to meet the dynamic, autonomous and scalable requirements of virtual organization. Thus, a model for grid decentralized authorization based on the decentralized trust management mechanism was proposed. The naming relationship and delegation relationship between grid entities were defined in this model. The definition of the naming relationship can express the local naming relationship on the basis of meeting the requirements of the global naming relationship definition. The delegation relationship can implement the autonomous and dynamic authorization delegation, and being characterized by good scalability. On the basis of the model, HowU grid authorization system was realized. The storage of the authorization relationship and its discovery mechanism in grid authorization system were explained.
{fenge}
33644656695	Strategy of data transferring of grid workflow based on weighted directed graph	Aiming at the neglect of network in data transferring, a strategy of data transferring of grid workflow based on weighted directed graph was proposed. The strategy works for grid workflow on the basis of different data process rate. In accordance with the bandwidth between every two grid nodes, the suitable data transfer mode was chosen. The weight between the two nodes was calculated to build a weighted directed graph. The best transfer route from the graph was chosen to process the data transmission, improving the performance of the work flow. The experimental result showed that the data transmission performance of the strategy is better than the traditional one which directly transmits the data by GridFTP on condition that the network structure and transmission speed are to a certain extent.
{fenge}
33645221504	DRIC: Dependable grid computing framework	Grid computing presents a new trend to distributed and Internet computing to coordinate large scale resources sharing and problem solving in dynamic, multi-institutional virtual organizations. Due to the diverse failures and error conditions in the grid environments, developing, deploying, and executing applications over the grid is a challenge, thus dependability is a key factor for grid computing. This paper presents a dependable grid computing framework, called DRIC, to provide an adaptive failure detection service and a policy-based failure handling mechanism. The failure detection service in DRIC is adaptive to users' QoS requirements and system conditions, and the failure-handling mechanism can be set optimized based on decision-making method by a policy engine. The performance evaluation results show that this framework is scalable, high efficiency and low overhead. Copyright © 2006 The Institute of Electronics, Information and Communication Engineers.
{fenge}
33646504618	A novel authorization mechanism for service-oriented virtual organization	There are more challenges for authorization in service-oriented virtual organization. In this paper we propose a novel authorization mechanism for virtual organization, which uses the threshold signature scheme for authorization management and voting mechanism for decision-making. We design three protocols in the authorization mechanism: authorization acquisition protocol, authorization revocation protocol, and secure interaction protocol. Our solution can satisfy the dynamic coalition requirement of virtual organization, and also guarantee the autonomous characteristic of participant organizations and service entities. Privacy preservation is also provided for service entities to interact with authorized entities. © Springer-Verlag Berlin Heidelberg 2005.
{fenge}
33746873365	Joint management of authorization for dynamic virtual organization	In this paper we define a decentralized management mechanism for the dynamic coalition characteristic of virtual organization. We propose an identity-based threshold signature scheme for joint management. We also propose the policy mode for joint management, which uses role-based access control mechanism for authorization policies definition, and voting mechanism for authorization decision-making. Our solution can satisfy the dynamic coalition requirement of virtual organization, and also guarantee the autonomous characteristic of participant organizations and grid entities. Privacy preservation is also provided for grid entities to interact with authorized entities. Authorization revocation mechanism is taken into consideration in this paper. The experimental performance also shows the scalability of the solution. © 2005 IEEE.
{fenge}
33748864443	A virtual-service-domain based bidding algorithm for resource discovery in computational grid	Resource discovery is a basic service in grid computing: gives a description of resources desired and finds the available one to match the description. In computational grid, how to discover resources efficiently has become a crucial factor to evaluate the performance in the whole system. In this paper, we present a bid-based resource discovery algorithm, which converts a resource request into a bidding letter and sends it to a group of physical services owned by the same virtual service to call for bidding. All resources receiving bidding letter make offers to bid according to our algorithm. Job manager selects the best one to response client request. To evaluate the performance of our method, we compare our system with the centralized and peer-to-peer resource discovery approaches. The analysis results show that our system reduces average response time of jobs, leverages the cost of the resource discovery, and improves the system scalability. © 2005 IEEE.
{fenge}
33749016762	A general fault-tolerance framework for grid computing	A general fault-tolerance framework for grid computing is proposed which are dealt with hierarchical structure fault detection services and policy-based fault-handling method, based on the requirements of reliable grid computing. The bottom of the fault detection service is local fault detector, which monitors the objects in local area and sends heartbeat messages to the middle data collector; the middle data collector sends the status list of the monitored objects to the top data collectors within specific interval; the top data collector is managed by an index server. When any fault detected, the system chooses an appropriate fault-handling method, such as checkpointing, retrying, replication. The results of the performance evaluation show that this framework is scalable, high-efficiency and low-overhead.
{fenge}
33751120412	New grid application-key discipline grid	There are various types of wide-area distributed resources involved in the disciplinary research and teaching activities. On traditional mode of constructing key discipline, both the scope of resource sharing and the extent of resource utilization are at the lower level. A new application of grid technology, key discipline grid was proposed to organize and manage those resources in a better way. Key discipline grid integrates the resources by invoking the relative application interface of the grid middleware, thus achieves more deeply sharing and synergy of information, data, software and devices within the discipline, provides a more effective virtual researching environment to the development of key discipline.
{fenge}
33750600721	An adaptive meta-scheduler for data-intensive applications	In data-intensive applications, such as high-energy physics, bio-informatics, we encounter applications involving numerous jobs that access and generate large datasets. Effective scheduling of such applications is a challenge, due to the need to consider for both computational resources and data storage resources. In this paper, we describe an adaptive scheduling model that considers availability of computational, storage and network resources. Based on this model we implement a scheduler used in our campus grid. The results achieved by our scheduler have been analysed by comparing with greedy algorithm that is widely used in computational grids and some data grids. Copyright © 2005, Inderscience Publishers.
{fenge}
33751082426	Peer-tree: A hybrid peer-to-peer overlay for service discovery	Efficient service discovery in dynamic, crossorganizational is one of the challenge aspects in ChinaGrid. Network overlay and search algorithms are two important considerations to the problem. Tree topology of organizations is easily managed but the root is a single point of failure; P2P structure tends to be conversed. To merge the advantages of both, we present a hybrid system with two layers: Tree Layer and Peer Layer. This structure is practical because organizations targeting at sub objects of a subject are inclined to be organized hierarchically as a Superpeer; and all these Superpeers construct an unstructured P2P network that adapts to peer 's interest by Learn Neighbor Algorithm. Experimental evaluation shows that our mechanism exhibits better search performance than fully hierarchical or fully distributed system. © 2006 IEEE.
{fenge}
33751096992	Research on mechanism of data interoperability in grid	To solve the problems of data interoperation among different grids, the architecture of storage resource broker (SRB) and data management module of ChinaGrid is analyzed and the difficulties of the interoperation between SRB and ChinaGrid are discussed. Then, an interface-based mechanism of data interoperation is proposed and the relevant model is set according to this mechanism. This model adopts the strategies of interface-mapping and replica management. It shields the difference of data operation interface and provides users a uniform data view and operation functions with interface-mapping mechanism. Also, it makes sure the data maintain available and consistent by replica management. This model has the advantages of high-flexibility, well-compatibility and easy-extensibility. The interoperation between ChinaGrid and SRB can be implemented by using this mechanism.
{fenge}
34547558544	RB-GACA: An RBAC based grid access control architecture	Grid computing is emerging as a new format of wide area distributed computing. Because the distribution of services and resources in wide-area networks are heterogeneous, dynamic, and multi-domain, security is a critical concern in grid computing. Authorisation and access control, which are important aspects of security, have obtained more and more attention. This paper proposes a universal, scalable authorisation and access control architecture, RB-GACA, for grid computing. It is based on classical access control mechanism in distributed applications, Role Based Access Control (RBAC). The paper provides a flexible policy management approach for various grid environments. We also use a standard policy language for the presentation of access control policies to provide a general and standard support for different services and resources. Copyright © 2005, Inderscience Publishers.
{fenge}
35048888929	HH-MDS: A QoS-aware domain divided information service	Grid computing emerges as effective technologies to couple geographically distributed resources and solve large-scale problems in wide area networks. Resource Monitoring and Information Service (RMIS) is a significant and complex issue in grid platforms. A QoS-aware domain divided information service, HH-MDS, is introduced in this paper. It is an important component of our service grid platform. HH-MDS solves system scalability issue effectively. In additional, several effective QoS strategies are provided to improve the efficiency of resource monitoring and information searching. Based on these strategies, service-oriented definitions and SLA specification are proposed to describe serving capability and relating QoS issues. © Springer-Verlag 2004.
{fenge}
35048894316	An adaptive meta-scheduler for data-intensive applications	In data-intensive applications, such as high-energy physics, bioinformatics, we encounter applications involving numerous jobs that access and generate large datasets. Effective scheduling such applications is challenging, due to a need to consider for both computational resources and data storage resources. In this paper, we describe an adaptive scheduling model that consider availability of computational, storage and network resources. Based on this model we implement a scheduler used in our campus grid. The results achieved by our scheduler have been analyzed by comparing Greedy algorithm that is widely used in computational grids and some data grids. © Springer-Verlag 2004.
{fenge}
37249087371	DGSS: A dependability guided job scheduling system for grid environment	Due to the diverse failures and error conditions in grid environments, node unavailability is increasingly becoming severe and poses great challenges to reliable job scheduling in grid environment. Current job management systems mainly exploit fault recovery mechanism to guarantee the completion of jobs, but sacrificing system efficiency. To address the challenges, in this paper, a node TTF (Time To Failure) prediction model and job completion prediction model are designed. Based on these models, the paper proposes a dependability guided job scheduling system, called DGSS, which provides failure avoidance job scheduling. The experimental results validate the improvement in the dependability of job execution and system resources utilization. © Springer-Verlag Berlin Heidelberg 2007.
{fenge}
84887988514	Adapting grid computing environments dependable with virtual machines: Design, implementation, and evaluations	Due to its potential, using virtual machines in grid computing is attracting increasing attention. Most of the researches focus on how to create or destroy a virtual execution environments for different kinds of applications, while the policy of managing the virtual environments is not widely discussed. This paper proposes the design, implementation, and evaluation of an adaptive and dependable virtual execution environment for grid computing, ADVE, which focuses on the policy of managing virtual machines in grid environments. To build a dependable virtual execution environments for grid applications, ADVE provides an set of adaptive policies managing virtual machine, such as when to create and destroy a new virtual execution environment, when to migrate applications from one virtual execution environment to a new virtual execution environment. We conduct experiments over a cluster to evaluate the performance of ADVE, and the experimental results show that ADVE can improve the throughput and the reliability of grid resources with the adaptive management of virtual machines. © 2011 Springer Science+Business Media, LLC.
{fenge}
84888015441	A disk bandwidth allocation mechanism with priority	Virtualization is a popular technology. Services and applications running on each virtual machine have to compete with each other for limited physical computer or network resources. Each virtual machine has different I/O requirement and special priority. Without proper scheduling resource management, a load surge in a virtual machine may inevitably degrade other's performance. In addition, each virtual machine may run different kinds of application, which have different disk bandwidth demands and service priorities. When assigning I/O resources, we should deal with each case on demand. In this paper, we propose a dynamic virtual machine disk bandwidth control mechanism in virtualization environment. A Disk Credit Algorithm is introduced to support a fine-gained disk bandwidth allocation mechanism among virtual machines. We can assign disk bandwidth according to each virtual machine's service priority/weight and its requirement. Related experiments show that the mechanism can improve the VMs' isolation and guarantee the performance of the specific virtual machine well. © 2013 Springer Science+Business Media New York.
{fenge}
84897585362	SafeStack: Automatically patching stack- Based buffer overflow vulnerabilities	Buffer overflow attacks still pose a significant threat to the security and availability of today's computer systems. Although there are a number of solutions proposed to provide adequate protection against buffer overflow attacks, most of existing solutions terminate the vulnerable program when the buffer overflow occurs, effectively rendering the program unavailable. The impact on availability is a serious problem on service-oriented platforms. This paper presents SafeStack, a system that can automatically diagnose and patch stack-based buffer overflow vulnerabilities. The key technique of our solution is to virtualize memory accesses and move the vulnerable buffer into protected memory regions, which provides a fundamental and effective protection against recurrence of the same attack without stopping normal system execution. We developed a prototype on a Linux system, and conducted extensive experiments to evaluate the effectiveness and performance of the system using a range of applications. Our experimental results showed that SafeStack can quickly generate runtime patches to successfully handle the attack's recurrence. Furthermore, SafeStack only incurs acceptable overhead for the patched applications. © 2013 IEEE.
{fenge}
84908582764	An adaptive PSO based on motivation mechanism and acceleration restraint operator	To obtain precise solutions in optimization problems and decrease the risk of being trapped in local optima, researchers have studied on various improved particle swarm optimizations (PSO) and made a series of achievements. However, these methods focus on artificially altering the physical rules of motion, rather than strengthening the individual self-learning and adjustment during the optimization process, which is the original motive of the swarm-based evolutionary algorithms. In this paper, we propose a fresh self-adaptive variant, MMARO-PSO, which employs motivation mechanism to simulate the behavior of intelligent organisms more vividly. We manage to simplify the update formulas and give each term a definite bio-psychic sense. Furthermore, we introduce a vectorized operator to restrain particle's acceleration, instead of the inertia weight parameter in conventional methods. Large number of experiments were conducted and the results illustrate that these innovations make the technique perform more consistently to find a better balance between global exploration and local exploitation, compared with the existing versions, e.g. SPSO, e1-PSO, ARFPSO, and (k, l)PSO.
{fenge}
44649135696	ADVE: Adaptive and Dependable Virtual Environments for grid computing	Due to its potential, the use of virtual machines in grid computing is attracting increasing attention. Most of the researches focus on how to create or destroy a virtual execution environments for different kinds of applications, the policy of managing the virtual environments isn't widely discussed. This paper proposes an adaptive and dependable virtual execution environment for grid computing called ADVE, which focuses on the policy of managing dependable virtual execution environments, such as when to create and destroy a new virtual execution execution environment, when to migrate applications from one virtual workspace to a new virtual workspace. We conduct experiments over a cluster to evaluate the performance of ADVE, and the experimental results show that ADVE can improve the throughput and the reliability of Grid resources with the adaptive management of virtual machines. © 2008 Springer-Verlag Berlin Heidelberg.
{fenge}
47649114929	GNSD: A novel service discovery mechanism for grid environment	Due to the highly distributed and dynamic features, service discovery is a key requirement in grid computing. The paper first introduces the existing service discovery mechanisms in distributed computing, and then points out the problems in MDS which is widely used in grid systems. In order to address these issues, GNSD, a novel service discovery mechanism is proposed, which is based on the OSPF (Open Shortest Path First) flooding mechanism and combines the advantages of tree architecture and flat architecture. The time and space complexity of both GNSD and MDS are also analyzed. Experimental results show that GNSD not only accelerates the service discovery but also relieves the burden of servers at the cost of little extra storage and communication traffic. Furthermore, it is more robust. As a conclusion, GNSD is an efficient service discovery mechanism. © 2006 IEEE.
{fenge}
56749150037	Scalable DHT-based Information Service for large-scale grids	Current grid information service is centralized or hierarchical and proves inefficient as grid scale rapidly increases. The introduction of P2P techniques into grids breaks an encouraging path. However, frequent join and departure of resource nodes require strong self-organization capacity of system to maintain their rigid structure. Moreover, arranging identifier space for P2P nodes is knotty and has great impact on system performance. If the identifier space is too large, some nodes will be overloaded. On the contraiy, small identifier space will bring the same problem as millennium bug. To address the issues, this paper proposes a scalable DHT-based (Distributed Hash Table) Information Service (DIS) for grid system, which organizes grid resources into a DHT ring based on VO (Virtual Organization). To save the identifier space while retaining the scalability and system performance, only stable VOs can join DIS via a new DHT node, whereas volatile VOs join DIS through being the sub-domain of other VO. Experimental results show that DIS provides rapid resource query, strong scalability and high throughput, meanwhile avoiding the key node failure as well as the bottleneck problem. Copyright 2008 ACM.
{fenge}
57849145725	DAGMap: Efficient scheduling for DAG grid workflow job	DAG has been extensively used in grid workflow modeling. Since the computational capacity of available grid resources tends to be heterogeneous, efficient and effective workflow job scheduling becomes essential. It poses great challenges to achieve minimum job accomplishing time while maintaining high grid resources utilization efficiency. Based on list scheduling and group scheduling, in this paper we propose a novel static scheduling heuristic, called DAGMap. DAGMap consists of three phases, namely prioritizing, grouping, and independent task scheduling. Three salient features of DAGMap are 1) Task grouping is based on dependency relationships and task upward priority; 2) Critical tasks are scheduled first; and 3) Min-Min and Max-Min selective scheduling are used for independent tasks. The experimental results show that DAGMap can achieve better performance than other previous algorithms in terms of makespan, speedup, and efficiency. © 2008 IEEE.
{fenge}
62749096690	VNIX: Managing virtual machines on clusters	With the development of virtualization technology, it's desirable to deploy virtual machines to high performance clusters used for data centers. VNIX, developed in Services Computing Technology and System lab, tries to help cluster administrators to manage a large number of Virtual Machines (VMs) distributed on clusters. To reduce the complexity of virtualization management, VNIX provides a whole-set of tools for monitoring, deploying, controlling, and configuring virtual machines on clusters. In addition to those basic management functions, VNIX also offers a number of specialized tools for clustering VMs. Due to the complex dynamic environment in clusters, it's challenging to design such tools. In this paper, we present the design of VNIX, and we describe several use cases of managing VMs in clusters with VNIX. Such use cases illustrate various ways of using VNIX to simplify the management work and to improve resource utilization. © 2008 IEEE.
{fenge}
67049134861	WAGA: A flexible web-based framework for grid applications	The research about the interaction between grid environments and users is becoming popular. Many scientists propose the integration for web 2.0 technologies and grid computing. In this paper, we propose a flexible web-based framework for grid applications - WAGA, which tries to bridge the gap between grid middleware and grid applications. WAGA provides a WYSIWYG (what you see is what you get) way for the programming for grid applications by adopting participation, interaction and sharing features of web 2.0 technology. With WAGA, a grid user is able to use the grid resources and to develop grid applications without understanding the underlying complexity of grids. WAGA is composed with a web GUI (called WAGA-designer) and some web-based APIs. WAGA-designer is used by grid users to develop application-based web portal, and the web APIs are used by the WAGA-designer. The use case study shows that WAGA is flexible for grid users, and the performance evaluation shows that WAGA works with high efficiency. © 2008 IEEE.
{fenge}
70349783221	Adapting grid applications to safety using fault-tolerant methods: Design, implementation and evaluations	Grid applications have been prone to encountering problems such as failures or malicious attacks during execution in recent years, due to their distributed and large-scale features. The application itself, however, has limited power to address these problems. This paper presents the design, implementation, and evaluation of an adaptive framework- Dynasa, which strives to handle security problems using adaptive fault-tolerance (i.e., checkpointing and replication) during the execution of applications according to the status of the Grid environments. We evaluate our adaptive framework experimentally using the Grid5000 testbed and the experimental results have demonstrated that Dynasa enables the application itself to handle the security problems efficiently. The starting of the adaptive component is less than 1 s and the adaptive action is less than 0.1 s with the checkpoint interval of 20 s. Compared with non-adaptive method, experimental results demonstrate that Dynasa achieves better performance in terms of execution time, network bandwidth consumed, and CPU load, resulting in up to a 50% lower overhead. © 2009 Elsevier B.V. All rights reserved.
{fenge}
70350131361	An adaptive and safe ubicomp for HPC applications	This paper presents an adaptive component-based infrastructure, which is composed with two parts, the mobile devices and the grid infrastructure. Because of the distributed, dynamic, and large-scale features, the ubiquitous computing (ubicomp) is vulnerable to malicious attacks for HPC applications. This paper presents an adaptive component at the grid infrastructure side to target the safety problems; the adaptive component makes adaptive replication actions according to different kinds of safety situations. This paper also presents the evaluation for the adaptive actions, which show that the adaptive method can handle the safety problems for HPC applications in ubicomp. Copyright © 2009, Inderscience Publishers.
{fenge}
70350578845	Analysis and evaluation of grid reliability in image processing	A model to analyze grid reliability was proposed after user's practice was studied, the grid reliability in image processing was analyzed. Based on fault injection, a grid component reliability evaluation environment was implemented, which tested the component reliability by comparing the component throughput between with non-fault workload and with fault load. Based on the reliability analysis model, the reliability relationships between the image processing application and every key component of the image grid middleware were analyzed. With the reliability evaluation environment, the reliability of the container of the image grid was evaluated over a cluster. Based on the analysis and evaluation, the suggestion for software development and software deployment was proposed.
{fenge}
71749088619	Evaluating MapReduce on virtual machines: The Hadoop case	MapReduce is emerging as an important programming model for large scale parallel application. Meanwhile, Hadoop is an open source implementation of MapReduce enjoying wide popularity for developing data intensive applications in the cloud. As, in the cloud, the computing unit is virtual machine (VM) based; it is feasible to demonstrate the applicability of MapReduce on virtualized data center. Although the potential for poor performance and heavy load no doubt exists, virtual machines can instead be used to fully utilize the system resources, ease the management of such systems, improve the reliability, and save the power. In this paper, a series of experiments are conducted to measure and analyze the performance of Hadoop on VMs. Our experiments are used as a basis for outlining several issues that will need to be considered when implementing MapReduce to fit completely in the cloud. © 2009 Springer-Verlag.
{fenge}
72049115513	Live virtual machine migration with adaptive memory compression	Live migration of virtual machines has been a powerful tool to facilitate system maintenance, load balancing, fault tolerance, and power-saving, especially in clusters or data centers. Although pre-copy is a predominantly used approach in the state of the art, it is difficult to provide quick migration with low network overhead, due to a great amount of transferred data during migration, leading to large performance degradation of virtual machine services. This paper presents the design and implementation of a novel memory-compressionbased VM migration approach (MECOM) that first uses memory compression to provide fast, stable virtual machine migration, while guaranteeing the virtual machine services to be slightly affected. Based on memory page characteristics, we design an adaptive zero-aware compression algorithm for balancing the performance and the cost of virtual machine migration. Pages are quickly compressed in batches on the source and exactly recovered on the target. Experiment demonstrates that compared with Xen, our system can significantly reduce 27.1% of downtime, 32% of total migration time and 68.8% of total transferred data on average. ©2009 IEEE.
{fenge}
76549103994	DAGMap: Efficient and dependable scheduling of DAG workflow job in grid	DAG has been extensively used in Grid workflow modeling. Since Grid resources tend to be heterogeneous and dynamic, efficient and dependable workflow job scheduling becomes essential. It poses great challenges to achieve minimum job accomplishing time and high resource utilization efficiency, while providing fault tolerance. Based on list scheduling and group scheduling, in this paper, we propose a novel scheduling heuristic called DAGMap. DAGMap consists of two phases, namely Static Mapping and Dependable Execution. Four salient features of DAGMap are: (1) Task grouping is based on dependency relationships and task upward priority; (2) Critical tasks are scheduled first; (3) Min-Min and Max-Min selective scheduling are used for independent tasks; and (4) Checkpoint server with cooperative checkpointing is designed for dependable execution. The experimental results show that DAGMap can achieve better performance than other previous algorithms in terms of speedup, efficiency, and dependability. © 2009 Springer Science+Business Media, LLC.
{fenge}
77649304688	SMU: Towards cloud oriented service mashup	Based on increasing popularity of cloud computing, social computing and web 2.0 technology, Internet resources are extremely increasing. How to provide service invoking interfaces ceaselessly while minimizing the cost of service development, which can meet the growing needs of end users, becomes a challenging issue for service providers. Meanwhile, service mashup technology is getting more attention in both enterprise and academia for building new end users applications fast in the complex and heterogeneous network environment. Therefore, we propose a new method of service mashup with the advantages of the cloud, grid, web services and other technologies. We develop cloud oriented Service MashUp system prototype (SMU). In SMU, we support the service information interaction, classification, and process during the procedure of service mashup to meet various needs of the multi-level and the multi-role of service applications. Our experiments show that SMU can reach the purpose of building personal service applications quickly and easily. © 2009 IEEE.
{fenge}
77949579437	A method of multi-VM automatic network configuration	In multi-VM (virtual machine) environment, the virtual machine network management plays an important role. Traditional multi-VM management systems are accustomed to using the DHCP mechanism. However, with the development of virtual network technology, DHCP is not suitable for constructing the stable and transparent virtual network environment. In this paper, we propose a method of multi-VM automatic network configuration, which focuses on multi-VM to initialize and configure the virtual network and provides a unified network management for physical and virtual machine system. We introduce concise communication model and protocol into the system to form a unified set of management mechanisms devoting to construct and simplify virtual machine environment. Through the performance comparison with XenServer, the multi-VM automatic network configuration system could improve the communication efficiency by 8-17% in average during the period of network initialization, and it stabilizes the whole network during the period of changing network configuration. ©2009 IEEE.
{fenge}
77950020115	Scalable DHT- and ontology-based information service for large-scale grids	Current grid information services are centralized or hierarchical and prove inefficient as the scale of the grid rapidly increases. The introduction of the P2P DHT technique into grids brings an encouraging path. However, current applications of the P2P DHT technique to grids do not consider the Virtual Organization (VO) management mode of grid resources. Frequent joining and leaving of resources requires strong self-organization capacity of the system to maintain the rigid structure. Moreover, arranging a moderate identifier space for a DHT ring is knotty. A large identifier space will make some nodes overloaded, while a small identifier space will bring forth the same problem as the millennium bug. In addition, current grid services are described in XML-based standards, which only support syntactic keyword and taxonomy-based queries without reasoning ability at the semantic level, leading to poor precision and integrality. To address these issues, the paper proposes a scalable DHT- and ontology-based Information Service (DIS) for a grid system, which organizes resources into a DHT ring based on the VO mode. To save the identifier space, only stable VOs can join DIS via a new DHT node, whereas volatile VOs join DIS via being the sub-domain of other VOs. Furthermore, ontology-based information integration is adopted in DIS and a novel ontology for grid resources is designed, which supports semantic-based information queries. By integrating DHT- and semantic-based query techniques, DIS speeds up the information query and improves the query precision and integrality. DIS is evaluated over the ChinaGrid environment and experimental results show that DIS provides rapid resource query, high throughput and strong scalability. © 2009 Elsevier B.V. All rights reserved.
{fenge}
77951492200	Adaptive multi-round scheduling strategy for divisible workloads in grid environments	Scheduling is the key to divisible workload execution. UMR (Uniform Multi-Round) algorithm potentially performs near optimal by improving overlap of communication and computation. However, it is questioned how a static schedule works effectively in dynamic grid environment. The paper roposes an adaptive divisible workload scheduling system, which can adjust the schedule in a proactive way. An adaptive UMR-based multi-round algorithm (called AUMR) is presented and evaluated. In AUMR, if the run-time resource monitor notifies the scheduler ofany resource changes, the scheduler will evaluate its impact and adjust the schedule if necessary. The experiment results show a considerable performance improvement by AUMR in dynamic grid environment.
{fenge}
78650028829	MR-Scope: A real-time tracing tool for MapReduce	MapReduce programming model is emerging as an efficient tool for data-intensive applications. Hadoop, an open-source implementation of MapReduce, has been widely adopted and experienced by both academia and enterprise. Recently, lots of efforts have been done on improving the performance of MapReduce system and on analyzing the MapReduce process based on the log files generated during the Hadoop execution. Visualizing log files seems to be a very useful tool to understand the behavior of the Hadoop process. In this paper, we present MRScope, a real-time MapReduce tracing tool. MR-Scope provides a real-time insight of the MapReduce process, including the ongoing progress of every task hosted in Task Tracker. In addition, it displays the health of the Hadoop cluster data nodes, the distribution of the file system's blocks and their replicas and the content of the different block splits of the file system. We implement MR-Scope in native Hadoop 0.1. Experimental results demonstrat that MR-Scope's overhead is less than 4% when running wordcount benchmark. Copyright 2010 ACM.
{fenge}
78650776850	VMcol: A collector of garbage for virtual machine image files	Virtual disk for a virtual machine (VM) is a virtual image file on a physical node. Inside a VM, the guest VM operates the virtual disk as the general OS, while outside the VM, the virtual image file grows larger and larger with the data operation of the VM, because of the semantic gap between the guest VM and the virtual machine monitor (VMM), the delete operation in guest VM cannot be received to the VMM. This leads to data space vanishing on physical node, even there are a large volume of data space released inside the VM. To target this, we present the design, implementation and evaluation of the VMcol, a system that collects the garbage space lively which has been deleted in the guest VM. When a file is deleted in the guest VM, VMcol will reclaim the deleted data for the corresponding virtual image files without interrupting the service of the VM and requiring additional physical space. The performance evaluation shows that VMcol improves the storage utilization with little performance penalty of VMs in terms of CPU utilization and I/O bandwidth. © 2010 Springer-Verlag.
{fenge}
79951738630	VirtCFT: A transparent VM-level fault-tolerant system for virtual clusters	A virtual cluster consists of a multitude of virtual machines and software components that are doomed to fail eventually. In many environments, such failures can result in unanticipated, potentially devastating failure behavior and in service unavailability. The ability of failover is essential to the virtual cluster's availability, reliability, and manageability. Most of the existing methods have several common disadvantages: requiring modifications to the target processes or their OSes, which is usually error prone and sometimes impractical; only targeting at taking checkpoints of processes, not whole entire OS images, which limits the areas to be applied. In this paper we present VirtCFT, an innovative and practical system of fault tolerance for virtual cluster. VirtCFT is a system-level, coordinated distributed checkpointing fault tolerant system. It coordinates the distributed VMs to periodically reach the globally consistent state and take the checkpoint of the whole virtual cluster including states of CPU, memory, disk of each VM as well as the network communications. When faults occur, VirtCFT will automatically recover the entire virtual cluster to the correct state within a few seconds and keep it running. Superior to all the existing fault tolerance mechanisms, VirtCFT provides a simpler and totally transparent fault tolerant platform that allows existing, unmodified software and operating system (version unawareness) to be protected from the failure of the physical machine on which it runs. We have implemented this system based on the Xen virtualization platform. Our experiments with real-world benchmarks demonstrate the effectiveness and correctness of VirtCFT. © 2010 IEEE.
{fenge}
79951803083	Virtual machine management based on agent service	With the popularity of virtualization, the problem that how to manage hundreds even thousands of virtual machines running on multiple physical computing nodes becomes important. Current virtual machine management systems only can obtain basic information of virtual machines and execute simple operations on them, such as start, reboot and shutdown. In this paper, we design a virtual machine management approach based on agent service. Agent service can provide detail running status information inside virtual machines. It also has been a bridge for host machines and virtual machines to interact with each other. Agent service is designed to automatically start when virtual machine boots up. By agent service we can get real-time information about virtual machines. We evaluate monitoring overhead and the performance of batch operations when using agent. The experimental results show that agent mechanism outperforms methods using Libvirt or VMware tools. © 2010 IEEE.
{fenge}
79956127449	Optimizing the live migration of virtual machine by CPU scheduling	Live migration has been proposed to reduce the downtime for migrated VMs by pre-copying the generated run-time memory state files from the original host to the migration destination host. However, if the rate for such a dirty memory generation is high, it may take a long time to accomplish live migration because a large amount of data needs to be transferred. In extreme cases when dirty memory generation rate is faster than pre-copy speed, live migration will fail. In this work we address the problem by designing an optimization scheme for live migration, under which according to pre-copy speed, the VCPU working frequency may be reduced so that at a certain phase of the pre-copy the remaining dirty memory can reach a desired small amount. The VM downtime during the migration can be limited. The scheme works for the scenario where the migrated application has a high memory writing speed, or the pre-copy speed is slow, e.g., due to low network bandwidth between the migration parties. The method improves migration liveness at the cost of application performance, and works for those applications for which interruption causes much more serious problems than quality deterioration. Compared to the original live migration, our experiments show that the optimized scheme can reduce up to 88% of application downtime with an acceptable overhead. © 2010 Elsevier Ltd. All rights reserved.
{fenge}
79957984912	An optimistic checkpoint mechanism based on job characteristics and resource availability for dynamic grids	In the paper, based on the job characteristics and resources availability, an optimistic checkpoint mechanism for dynamic grids(OCM4G) is proposed. It can determine whether to checkpoint a given job running on a given resource node and establish optimal aperiodic checkpoint intervals by applying the knowledge of job characteristics and resource availability. We evaluate OCM4G over a real grid environment (ChinaGrid) and the results show that OCM4G achieves better performance than the periodic checkpoint and the analytical method of calculating aperiodic checkpoint intervals. © 2011 Wuhan University and Springer-Verlag Berlin Heidelberg.
{fenge}
79960608390	A service mashup system for complex and heterogeneous network environment	Service mashup system (SMU) was present to solve questions such as service information interaction, classification, and processing during the procedure of service mashup. The system implements a mechanism for service searching, discovering, interpreting and integrating in the complex heterogeneous network environment, which enables users to search services by keywords, and mashup services to produce personal service applications by using visual development tools. Experiments show that with the SMU system one can easily and quickly build personal service applications. The server response time in loading services is in ms level, and the cost of the server is very low. The peak throughput of the server appears when the number of the concurrent request number is between 200-300.
{fenge}
80051554855	Virtual machine VCPU scheduling in the multi-core environment: Issues and challenges	The policies and mechanisms of VCPU (virtual CPU) scheduling in a virtual machine system are key factors to determine the system performance. Because the architecture of the software stack in the virtual machine system is different from the traditional computer systems, when scheduling the VCPUs in virtual machines, simply adopting scheduling strategies and algorithms of existing operating systems without any modifications can lead to drastic degradation of the system performance. Moreover, with the multi-core technology being employed for physical processors, the complexity of the VCPU scheduling is increased. Firstly, the architecture of the virtual machine system and its two-stage scheduling framework are depicted and analyzed in detail in this paper. Because the deterministic mapping relationship between application threads and physical cores is difficult to establish in the two-stage framework, and part functions of operating systems move down to virtual machine monitor, VCPU scheduling will confront many problems and challenges that mainly embody four aspects: the semantic gap between guest operating systems and a virtual machine monitor, the synchronization mechanisms in a multiprocessor operating system, the structure of shared cache in multi-core processors and emerging asymmetric multi-core structure. And then advantages and limitations of the existing solutions for these problems are discussed and analyzed deeply, and suggestions for further researches are presented.
{fenge}
80051575571	Automatic power-aware reconfiguration of processor resource in virtualized clusters	Virtualization provides significant benefits of system maintenance, load balancing, fault tolerance, and power-saving in clusters or data centers. It also enables dynamic reconfiguration of computing resource for application environment. However, current dynamic resource control approaches mainly focus on how to satisfy the application-level quality of service (QoS) when application workloads vary with time. They are driven by application performance, which is often specific to certain class of applications and also weakens the response capability of control systems. In this paper, a resource-use-status-driven resource reconfiguration scheme (RUSiC) is presented to automatically adapt to dynamic workload changes to meet the demands of application performance. According to the new characteristics introduced by system virtualization, the scheme is designed to be a two-layer resource reconfiguration model to exactly grasp the demands of applications. Based on real resource use status, the scheme adjusts proper resource configuration for applications in time. Furthermore, the scheme introduces power-saving into resource reconfiguration process and avoids considerable unnecessary power and cooling consumption by reducing the number of active physical nodes in a new resource configuration. Experiments demonstrate that the scheme can quickly detect and respond to shifting resource demands as application workloads change over time.
{fenge}
80053159129	Dynamic processor resource configuration in virtualized environments	Virtualization can provide significant benefits in data centers, such as dynamic resource configuration, live virtual machine migration. Services are deployed in virtual machines (VMs) and resource utilization can be greatly improved. In this paper, we present VScheduler, a system that dynamically adjusts processor resource configuration of virtual machines, including the amount of virtual resource and a new mapping of virtual machines and physical nodes. VScheduler implements a two-level resource configuration scheme - local resource configuration (LRC) for an individual virtual machine and global resource configuration (GRC) for a whole cluster or data center. GRC especially takes variation tendency of workloads into account when remapping virtual machines to physical nodes. We implement our techniques in Xen and conduct a detailed evaluation using RUBiS and dbench. The experimental results show that VScheduler not only satisfies resource demands of services, but also reduces the number of virtual machines migration, which can provide a stable VM distribution on physical nodes in data centers. © 2011 IEEE.
{fenge}
80855140414	A cloud service cache system based on memory template of virtual machine	In data centers and cloud computing environments, the number of virtual machines (VMs) increases when the number of service requests increases. Since services are invoked on demand, the corresponding virtual machines will be created and shut down frequently. This makes the time of starting a virtual machine a crucial performance bottleneck for services in data centers. Besides, if virtual machines read image files from disks to start themselves, additional overhead to access disk will be generated. In this paper, we present a cloud service cache system based on memory template of virtual machines - VCache to improve the response time of cloud computing services, and to reduce the disk access overhead. This system can create and maintain service cache VMs through memory templates, which are snapshots of running virtual machines. By creating virtual machines from cached image files, the ser-vice running in these VMs can be deployed rapidly, which greatly reduces the launching time of the service and disk I/O load. We evaluate our system with experiments, and the experimental results show that the average time for creating a VM is reduced about 80% and the amount of data through disk access decreases more than 50%. © 2011 IEEE.
{fenge}
80855164523	An approach to use cluster-wide free memory in virtual environment	Memory and I/O intensive applications always use a huge amount of memory and the performance decreases quickly when memory pressure arises. With the development of high performance network and widely used in cluster, the latency of remote memory access is much less than that of disk operation. In this paper, we present an approach to let the VM (Virtual Machine) use cluster-wide free memory, which can overcome the limitation of physical memory by exploiting low-latency access to the memory of other nodes in cluster. This approach can reduce the execution time for memory and I/O intensive applications significantly by utilizing cluster-wide memory and increase the whole cluster utilization. © 2011 IEEE.
{fenge}
81455132008	EAPAC: An enhanced application placement framework for data centers	Emerging data centers may host a large number of applications that consume CPU power, memory, and I/O resources. Previous studies focus on the allocation of resources in order to perfectly satisfy the demands seen in the current cycle, and the existing application placement algorithms are all based on applications. The existing application placement algorithms in literature assume that the consumption of system resources is proportional to the level of workloads submitted to the system. In this paper, we revealed that it may not be the case in some circumstances. Based on this observation, we design and implement an application placement framework, called EAPAC, for data centers. The developed framework is able to judiciously allocate to application servers a proper mixture of different types of application requests as well as an appropriate number of requests in each type. Further, we investigate the issue of resource conflicts among different applications when there exist concurrent requests in the system. We have conducted extensive experiments to evaluate the performance of the developed framework. The experiment results show that compared with the existing studies, EAPAC can improve the performance by 30% in terms of the reply rate. Especially, when there are concurrent requests in the system, the performance can be improved by 100%. © 2011 IEEE.
{fenge}
84861991251	Toward scalable Web systems on multicore clusters: Making use of virtual machines	Limited by the existing design pattern, a lot of existing softwares have not yet taken full use of multicore processing power, incurring low utilization of hardware, even a bottleneck of the whole system. To address this problem, in this paper, we propose a VM-based Web system on multicore clusters. The VM-based Web system is scheduled by Linux Virtual Server (LVS) and we implement the web server with Tomcat. In the mean time, we develop VNIX, a set of VM management toolkit, to facilitate managing VMs on clusters, aiming at improving the usage of multicore CPU power. To reduce resources contention among VMs, we propose to deploy LVS schedulers distributively on different physical nodes. To evaluate our approach, we conduct extensive experiments to compare VM-based Web system with classical physical machine-based Web system. Our experimental results demonstrate that the proposed VM-based Web system can result in throughput improvements of up to three times compared with the same multicore clusters, with an error rate at the server side as low as 20% of that of classic systems. © 2011 Springer Science+Business Media, LLC.
{fenge}
84862914864	LCM: A lightweight communication mechanism in HPC cloud	Inspired by the concept of cloud computing, the construction of HPC Cloud with traditional HPC resources not only provides new opportunities to address the challenges to the traditional HPC, but also brings many exciting research problems. One of them is how to reduce the network overhead of virtual cluster in HPC cloud. In order to resolve the problem, this paper presents the design and implementation of lightweight communication mechanism for virtual cluster in HPC Cloud, called LCM, which maintains binary compatibility for applications written in standard socket interface. We implemented our design on Xen 3.2 with Linux kernel 2.6.18, and evaluated the speed of file transfer, the running time of NAS Parallel benchmark and binary compatibility using binary image of real socket applications. In our tests, we have proved that LCM realizes the high performance that is comparable to UNIX domain socket and ensures full binary compatibility. © 2011 IEEE.
{fenge}
84863177621	Fast saving and restoring virtual machines with page compression	More and more enterprises are moving beyond server virtualization to desktop virtualization in recent years. In virtualization environments, centralized shared storage systems are generally used to take advantage of virtualization features such as VM migration. Network file system (NFS) is considered to be the best choice in small or medium sized LANs due to its flexibility and low cost. But it becomes the bottleneck when many clients access the server simultaneously, especially when multiple virtual machines access a large amount of data at the same time, such as operation save and restore. In this paper, we present a new method named ComIO to quickly save and restore virtual machines using page compression. Based on the analysis of virtual machines' memory characteristics, we design a fast enhanced characteristic-based compression (ECBC) algorithm. Combined with multi-threaded techniques, the compression tasks are parallelized for significantly shortened compresssion time. Page boundary alignment is proposed to enable wanted page data to be directly extracted from the compressed block. The experimental results demonstrate that compared with Xen, our method ComIO not only greatly reduces the time spent on saving and restoring virtual machines on average, but also indirectly augments the effective storage space. © 2011 IEEE.
{fenge}
84865549560	Effectively deploying services on virtualization infrastructure	Virtualization technology provides an opportunity to acieve efficient usage of computing resources. However, the management of services on virtualization infrastructure is still in the preliminary stage. Contstructing user service environments quickly and efficiently remains a challenge. This paper presents a service oriented multiple-VM deployment system (SO-MVDS) for creating and configuring virtual appliances running services on-demand. The system provides a template management model where all the virtual machines are created based on the templates with the software environment pre-prepared. To improve the deployment performance, we explore some strategies for incremental mechanisms and deployment. We also design a service deployment mechanism to dynamically and automatically deploy multiple services within virtual appliances. We evaluate both the deployment time and I/O performance using the proposed incremental mechanism. The experimental results show that the incremental mechanism outperforms the clone one. © 2012 Higher Education Press and Springer-Verlag Berlin Heidelberg.
{fenge}
84869065478	Assessing MapReduce for Internet computing: A comparison of Hadoop and BitDew-MapReduce	MapReduce is emerging as an important programming model for data-intensive application. Adapting this model to desktop grid would allow taking advantage of the vast amount of computing power and distributed storage to execute new range of application able to process enormous amount of data. In 2010, we have presented the first implementation of MapReduce dedicated to Internet Desktop Grid based on the BitDew middleware. In this paper, we present new optimizations to BitDew-MapReduce (BitDew-MR): aggressive task backup, intermediate result backup, task re-execution mitigation and network failure hiding. We propose a new experimental framework which emulates key fundamental aspects of Internet Desktop Grid. Using the framework, we compare BitDew-MR and the open-source Hadoop middleware on Grid5000. Our experimental results show that 1) BitDew-MR successfully passes all the stress-tests of the framework while Hadoop is unable to work in typical wide-area network topology which includes PC hidden behind firewall and NAT; 2) BitDew-MR outperforms Hadoop performances on several aspects: scalability, fairness, resilience to node failures, and network disconnections. © 2012 IEEE.
{fenge}
84874602411	Optimizing Xen hypervisor by using lock-aware scheduling	System virtualization enables multiple isolated running environments to be safely consolidated on a physical server, achieving better physical resource utilization and power saving. Virtual machine has been an essential component in most of the cloud/data-center system software stacks. However, virtualization brings negative impacts on synchronization in guest operating system (guest OS) and thus dramatically degrades the performance of the virtual machine. Therefore, how to effectively eliminate or alleviate the disadvantageous impacts has been becoming an open research issue. Xen hyper visor is a wide used virtualized platform in the area of industry and research. In this work, our aim is to optimize Xen hyper visor to minimize the impacts of virtualization on synchronization in guest OS. We propose a lock-aware scheduling mechanism, which focuses on improving the performance of virtual machines where spin-lock primitive is frequently invoked, as well as guaranteeing the scheduling fairness. The mechanism adopts a flexible scheduling algorithm based on the information of spin-lock, which is updated dynamically. We have modified Xen and Linux to implement the scheduling mechanism. Experimental results show that the optimized system can nearly eliminate the impacts of virtualization on synchronization and improve the performance of virtual machines substantially. Although the proposed mechanism is aimed at optimizing Xen hyper visor, it can also be applied to some other Para virtualized platforms. © 2012 IEEE.
{fenge}
84874664055	Dependable Grid Workflow Scheduling Based on Resource Availability	Due to the highly dynamic feature, dependable workflow scheduling is critical in the Grid environment. Various scheduling algorithms have been proposed, but seldom consider the resource reliability. Current Grid systems mainly exploit fault tolerance mechanism to guarantee the dependable workflow execution, which, however, wastes system resources. The paper proposes a dependable Grid workflow scheduling system (called DGWS). It introduces a Markov Chain-based resource availability prediction model. Based on the model, a reliability cost driven workflow scheduling algorithm is presented. The performance evaluation results, including the simulation on both parametric randomly generated DAGs and two real scientific workflow applications, demonstrate that compared to present workflow scheduling algorithms, DGWS improves the success ratio of tasks and diminishes the makespan of workflow, so improves the dependability of workflow execution in the dynamic Grid environments. © 2012 Springer Science+Business Media Dordrecht.
{fenge}
84875110798	Cranduler: A dynamic and reusable scheduler for cloud infrastructure service	As an import trend of cyberspace in the future, cloud computing has attracted much attention from the IT industry. Many research institutions and companies have launched their own cloud platforms, which have virtual machine schedulers to manage the infrastructure resource pool. The virtual machine scheduling modules in these platforms are built in the platform and it is hard for developers to re-program. Since developers cannot design and implement special policies in the platform, the flexibility of the virtual machine scheduler is poor. Furthermore, the schedule architecture which has a firm and unchangeable interface is designed and customized for one kind of cloud platform. It leads to poor portability. To target the problems above, this paper presents a dynamic and reusable scheduling system for cloud infrastructure service, called Cranduler, which introduces the advantages of cluster schedulers to the virtual machine scheduling in cloud infrastructure. The scheduling policies of Cranduler could be dynamically configured by developers. Developers can easily insert the custom policy. In addition, Cranduler provides a set of unified interfaces to the cloud platform, which make the system easily access resources from different cloud platforms and be reused in different cloud platforms. © 2013 Springer-Verlag.
{fenge}
84880072950	Supporting parallel soft real-time applications in virtualized environment	The prevalence of multicore processors and virtualization technology enables parallel soft real-time applications to run in virtualized environment. However, current hypervisors do not provide adequate support for them because of soft real-time constraints and synchronization problems, which result in frequent deadline misses and serious performance degradation. In this paper, we propose a novel parallel soft real-time scheduling algorithm which addresses them well, and implement a parallel soft real-time scheduler, named Poris, based on Xen. Our evaluation shows that Poris shortens the execution time of PARSEC benchmark by up to 44.12% compared to Credit scheduler. © 2013 Authors.
{fenge}
84880571233	Developing an optimized application hosting framework in Clouds	A Cloud system, which is also often called a data center, may host a large number of application servers (termed as applications for short in this paper) that consume various types of resource, such as CPU, memory, and I/O. In such a scenario, the application placement strategy, which specifies how to host applications across the physical servers in the Cloud, is critical to achieve good system- and/or client-oriented performance. The existing application placement algorithms in literature assume that the consumption of system resources is proportional to the level of workloads submitted to the system. In this paper, we reveal that it may not be the case in some circumstances. Based on this observation, we design and implement an application placement framework, called EAPAC, for Clouds. The developed framework is able to achieve the optimized performance by judiciously allocating to the applications a proper mixture of different types of application request as well as an appropriate number of requests in each type. Further, we investigate the issue of resource conflicts among different applications when there exist concurrent requests in the system. We have conducted extensive experiments to evaluate the performance of the developed framework. The experiment results show that compared with the existing method in literature, EAPAC can improve the performance by 35% in terms of the reply rate. © 2013 Elsevier Inc.
{fenge}
84881030710	Performance implications of non-uniform VCPU-PCPU mapping in virtualization environment	Virtualization technology promises to provide better isolation and consolidation in traditional servers. However, with VMM (virtual machine monitor) layer getting involved, virtualization system changes the architecture of traditional software stack, bringing about limitations in resource allocating. The non-uniform VCPU (virtual CPU)-PCPU (physical CPU) mapping, deriving from both the configuration or the deployment of virtual machines and the dynamic runtime feature of applications, causes the different percentage of processor allocation in the same physical machine,and the VCPUs mapped these PCPUs will gain asymmetric performance. The guest OS, however, is agnostic to the non-uniformity. With assumption that all VCPUs have the same performance, it can carry out sub-optimal policies when allocating virtual resource for applications. Likewise, application runtime system can also make the same mistakes. Our focus in this paper is to understand the performance implications of the non-uniform VCPU-PCPU mapping in a virtualization system. Based on real measurements of a virtualization system with state of art multi-core processors running different commercial and emerging applications, we demonstrate that the presence of the non-uniform mapping has negative impacts on application's performance predictability. This study aims to provide timely and practical insights on the problem of non-uniform VCPU mapping, when virtual machines being deployed and configured, in emerging cloud. © 2012 Springer Science+Business Media, LLC.
{fenge}
84883369215	RTRM: A response time-based replica management strategy for cloud storage system	Replica management has become a hot research topic in storage systems. This paper presents a dynamic replica management strategy based on response time, named RTRM. RTRM strategy consists of replica creation, replica selection, and replica placement mechanisms. RTRM sets a threshold for response time, if the response time is longer than the threshold, RTRM will increase the number of replicas and create new replica. When a new request comes, RTRM will predict the bandwidth among the replica servers, and make the replica selection accordingly. The replica placement refers to search new replica placement location, and it is a NP-hard problem. Based on graph theory, this paper proposes a reduction algorithm to solve this problem. The simulation results show that RTRM strategy performs better than the five built-in replica management strategies in terms of network utilization and service response time. © 2013 Springer-Verlag.
{fenge}
84888594108	Guaranteeing QoS of media-based applications in virtualized environment	With the rapid development of web technology and smart phone, multimedia contents spread all over the Internet. The prevalence of virtualization technology enables multimedia service providers to run media servers in virtualized servers or rented virtual machines (VMs) in a cloud environment. Although server consolidation using virtualization can substantially increase the efficient use of server resources, it introduces resources competition among VMs running different applications. Recently, hypervisors do not make any Quality of Service (QoS) guarantee for media-based applications if they are consolidated with other network-intensive applications, which leads to significant performance degradation. For example, Xen only offers a static method to allocate network bandwidth. In this paper, we find that the performance of media-based applications running in VMs degrades seriously when they are consolidated with other VMs running network-intensive applications and argues that dynamic network bandwidth allocation is essential to guarantee the QoS of media-based applications. Then, we present a dynamic network bandwidth allocation system in virtualized environment, which allocates network bandwidth dynamically and effectively, and does not interrupt running services in VMs. The experiments show that our system can not only guarantee the QoS of media-based applications well but also maximize the system's the overall performance while ensuring the QoS of media-based applications. © 2013 Taylor & Francis.
{fenge}
84890554086	VRAS: A lightweight local resource allocation system for virtual machine monitor	Traditional computing resource allocations in virtualization environment devote to provide fairness of resource distribution when the overall workload of host is heavy. That makes those allocations lack of efficiency under light workloads. To target this, we design and implement a lightweight resource allocation system, virtual resource allocation system (VRAS). Considering the fact that workloads can be balanced by migrating virtual machines to other hosts, we propose a request driven mechanism to focus on resource allocation under light workloads. We also present some allocation strategies used in VRAS to explain how it works on processor and memory resources. Our experiment results demonstrate that VRAS can result in throughput improvements of 28 % for RUBiS application, and the network overhead reduction of 81 %, comparing with the traditional allocation methods. © 2013 Springer Science+Business Media New York.
{fenge}
84894534753	Virtual machine scheduling for parallel soft real-time applications	With the prevalence of multicore processors in computer systems, many soft real-time applications, such as media-based ones, use parallel programming models to utilize hardware resources better and possibly shorten response time. Meanwhile, virtualization technology is widely used in cloud data centers. More and more cloud services including such parallel soft real-time applications are running in virtualized environment. However, current hyper visors do not provide adequate support for them because of soft real-time constraints and synchronization problems, which result in frequent deadline misses and serious performance degradation. CPU schedulers in underlying hyper visors are central to these issues. In this paper, we identify and analyze CPU scheduling problems in hyper visors, and propose a novel scheduling algorithm considering both soft real-time constraints and synchronization problems. In our proposed method, real-time priority is introduced to accelerate event processing of parallel soft real-time applications, and dynamic time slice is used to schedule virtual CPUs. Besides, all runnable virtual CPUs of virtual machines running parallel soft real-time applications are scheduled simultaneously to address synchronization problems. We implement a parallel soft real-time scheduler, named Poris, based on Xen. Our evaluation shows Poris can significantly improve the performance of parallel soft real-time applications. For example, compared to the Credit scheduler, Poris improves the performance of media player by up to a factor of 1.35, and shortens the execution time of PARSEC benchmark by up to 44.12%. © 2013 IEEE.
{fenge}
84899761390	Cost-aware client-side file caching for data-intensive applications	Parallel and distributed file systems are widely used to provide high throughput in high-performance computing and Cloud computing systems. To increase the parallelism, I/O requests are partitioned into multiple sub-requests (or 'flows') and distributed across different data nodes. Therefore the completion time of an I/O request depends on the slowest sub-request and the performance of file systems is extremely poor if data nodes have highly unbalanced response time. Client-side caching offers a promising direction for addressing this issue. However, current work has primarily used client-side memory as a read cache and employed a write-through policy which provides the strictest consistency. Write-through requires synchronous update for every write and significantly under-utilizes the client-side cache when the applications are write-intensive. The write-back policy, on the other hand, can better utilize the client-side cache for applications with significantly I/O requirements. However, this policy introduces the notorious cache consistency problem and is ineffective when the cache size is constrained. we propose a cost-aware client-side file caching (CCFC) strategy, that is designed to perform better than conventional write-back and write-through. This strategy enables new trade-off points across I/O performance, data consistency and cache size dimensions. Using benchmark workloads such as MADbench2, IOR and HPIO, we evaluate our new cache policy alongside conventional write-back and write-through. We find that the proposed CCFC strategy can achieve up to 110% throughput improvement compared to the conventional write-back and write-through policies with the same cache size on an 85-node cluster. © 2013 IEEE.
{fenge}
84899901883	Morpho: A decoupled MapReduce framework for elastic cloud computing	MapReduce as a service enjoys wide adoption in commercial clouds today [3,23]. But most cloud providers just deploy native Hadoop [24] systems on their cloud platforms to provide MapReduce services without any adaptation to these virtualized environments [6,25]. In cloud environments, the basic executing units of data processing are virtual machines. Each user's virtual cluster needs to deploy HDFS [26] every time when it is initialized, while the user's input and output data should be transferred between the HDFS and external persistent data storage to ensure that the native Hadoop works properly. These costly data movements can lead to significant performance degradation of MapReduce jobs in the cloud. We present Morpho - a modified version of the Hadoop MapReduce framework, which decouples storage and computation into physical clusters and virtual clusters respectively. In Morpho, the map/reduce tasks are still running in VMs without corresponding ad-hoc HDFS deployments; instead, HDFS is deployed on the underlying physical machines. When MapReduce computation is performing, the map tasks can get data directly from physical machines without any extra data transfers. We design data location perception module to improve the cooperativity of the computation and storage layers, which means that the map tasks can intelligently fetch information about the network topology of physical machines and the VM placements. Additionally, Morpho also achieves high performance by two complementary strategies for data placement and VM placement, which can provide better map and reduce input locality. Furthermore, our data placement strategy can mitigate the resource contentions between jobs. The evaluation of our Morpho system prototype shows it achieves a nearly 62% speedup of job execution time and a significant reduction in network traffic of the entire system compared with the traditional cloud computing scheme of Amazon and other cloud providers. © 2013 Elsevier B.V. All rights reserved.
{fenge}
84901458639	MECOM: Live migration of virtual machines by adaptively compressing memory pages	Live migration of virtual machines has been a powerful tool to facilitate system maintenance, load balancing, fault tolerance, and power-saving, especially in clusters or data centers. Although pre-copy is extensively used to migrate memory data of virtual machines, it cannot provide quick migration with low network overhead but leads to large performance degradation of virtual machine services due to the great amount of transferred data during migration. To solve the problem, this paper presents the design and implementation of a novel memory-compression-based VM migration approach (MECOM for short) that uses memory compression to provide fast, stable virtual machine migration, while guaranteeing the virtual machine services to be slightly affected. Based on memory page characteristics, we design an adaptive zero-aware compression algorithm for balancing the performance and the cost of virtual machine migration. Using the proposed scheme pages are rapidly compressed in batches on the source and exactly recovered on the target. Experimental results demonstrate that compared with Xen, our system can significantly reduce downtime, total migration time, and total transferred data by 27.1%, 32%, and 68.8% respectively. © 2013 Elsevier B.V. All rights reserved.
{fenge}
84904573374	Iteration based collective I/O strategy for Parallel I/O systems	MPI collective I/O is a widely used I/O method that helps data-intensive scientific applications gain better I/O performance. However, it has been observed that existing collective I/O strategies do not perform well due to the access contention problem. Existing collective I/O optimization strategies mainly focus on the I/O phase efficiency and ignore the shuffle cost that may limit the potential of their performance improvement. We observe that as the size of I/O becomes larger, one I/O operation from the upper application would be separated into several iterations to complete. So, I/O requests in each file domain do not necessarily issue to the parallel file system simultaneously unless they are carried out within the same iteration step. Based on that observation, this paper proposes a new collective I/O strategy that reorganizes I/O requests within each file domain instead of coordinating requests across file domains, such that we can eliminate access contentions without introducing extra shuffle cost between aggregators and computing processes. Using benchmark workloads IOR, we evaluate our new strategy and compare with the conventional one. The proposed strategy achieves up to 47%-63% I/O bandwidth improvement compared to the existing ROMIO collective I/O strategy. © 2014 IEEE.
{fenge}
84904425336	Communication-driven scheduling for virtual clusters in cloud	Recent research already confirmed the feasibility of running tightly-coupled parallel applications with virtual clusters. However, such types of applications suffer from significant performance degradation, especially as the overcommitment is common in cloud. That is, the number of executable Virtual CPUs (VCPUs) is often larger than that of available Physical CPUs (PCPUs) in the system. The performance degradation mainly results from that the current Virtual Machine Monitors (VMMs) cannot co-schedule (or coordinate at the same time) the VCPUs that host parallel application threads/processes with synchronization requirements. We introduce a communication-driven scheduling approach for virtual clusters in this paper, which can effectively mitigate the performance degradation of tightly-coupled parallel applications running atop them in overcommitted situation. There are two key contributions. 1) We propose a communication-driven VM scheduling (CVS) algorithm, by which the involved VMM schedulers can autonomously schedule suitable VMs at runtime. 2) We integrate the CVS algorithm into Xen VMM scheduler, and rigorously implement a prototype. We evaluate our design on a real cluster environment, and experiments show that our solution attains better performance for tightly-coupled parallel applications than the state-of-the-art approaches like Credit scheduler of Xen, balance scheduling, and hybrid scheduling. Copyright © 2014 ACM.
{fenge}
84906772115	Page classifier and placer: A scheme of managing hybrid caches	Hybrid cache architecture (HCA), which uses two or more cache hierarchy designs in a processor, may outperform traditional cache architectures because no single memory technology can deliver the optimal power, performance and density at the same time. The general HCA scheme has also been proposed to manage cache regions that have different usage patterns. However previous HCA management schemes control data placement at cache set level and are oblivious to software's different power and performance characteristics in different hardware cache regions. This hardware-only approach may lead to performance loss and may fail to guarantee quality of service. We propose a new HCA approach that enables OS to be aware of underlying hybrid cache architecture and to control data placement, at OS page level, onto difference cache regions. Our approach employs a light-weighted hardware profiler to monitor cache behaviors at OS page level and to capture the hot pages. With this knowledge, OS will be able to dynamically select different cache placement policies to optimize placement of data to achieve higher performance, lower power consumption and better quality of service. Our simulation experiments demonstrate that the proposed hybrid HCA achieves 7.8% performance improvement on a dual-core system compared to a traditional SRAM-only cache architecture and at the same time reduces area cost. © 2014 IFIP International Federation for Information Processing.
{fenge}
84906776842	A real-time scheduling framework based on multi-core dynamic partitioning in virtualized environment	With the prevalence of virtualization and cloud computing, many real-time applications are running in virtualized cloud environments. However, their performance cannot be guaranteed because current hypervisors' CPU schedulers aim to share CPU resources fairly and improve system throughput. They do not consider real-time constraints of these applications, which result in frequent deadline misses. In this paper, we present a real-time scheduling framework in virtualized environment. In the framework, we propose a mechanism called multi-core dynamic partitioning to divide physical CPUs (PCPUs) into two pools dynamically according to the scheduling parameters of real-time virtual machines (RT-VMs). We apply different schedulers to these pools to schedule RT-VMs and non-RT-VMs respectively. Besides, we design a global earliest deadline first (vGEDF) scheduler to schedule RT-VMs. We implement a prototype in the Xen hypervisor and conduct experiments to verify its effectiveness. © 2014 IFIP International Federation for Information Processing.
{fenge}
84919474001	Dynamic and fast processing of queries on large-scale RDF data	As RDF data continue to gain popularity, we witness the fast growing trend of RDF datasets in both the number of RDF repositories and the size of RDF datasets. Many known RDF datasets contain billions of RDF triples (subject, predicate and object). One of the grant challenges for managing these huge RDF data is how to execute RDF queries efficiently. In this paper, we address the query processing problems against the billion triple challenges. We first identify some causes for the problems of existing query optimization schemes, such as large intermediate results, initial query cost estimation errors. Then, we present our block-oriented dynamic query plan generation approach powered with pipelining execution. Our approach consists of two phases. In the first phase, a near-optimal execution plan for queries is chosen by identifying the processing blocks of queries. We group the join patterns sharing a join variable into building blocks of the query plan since executing them first provides opportunities to reduce the size of intermediate results generated. In the second phase, we further optimize the initial pipelining for a given query plan. We employ optimization techniques, such as sideways information passing and semi-join, to further reduce the size of intermediate results, improve the query processing cost estimation and speed up the performance of query execution. Experimental results on several RDF datasets of over a billion triples demonstrate that our approach outperforms existing RDF query engines that rely on dynamic programming based static query processing strategies.
{fenge}
12444304401	Grid-oriented collaborative network computing platform	There exists much load unbalance of Internet resources. It is significant to fully use spare resources on Internet to solve large-scale science computing issues, not disturbing the resource owner's work. Based on grid and P2P technology, a collaborative network computing platform is proposed in this paper. Based on the collaboration and resource sharing among resource managers, the properties of fault tolerance and load balance are realized for the global resource management in this collaborative network computing platform. Two simple collaborative algorithms, one is about idle manager applying for application, and the other is about overloaded manager applying for resources, are proposed in this paper. Finally the performance analysis is given.
